[
  {
    "objectID": "tareas/tarea-4.html",
    "href": "tareas/tarea-4.html",
    "title": "Tarea 4",
    "section": "",
    "text": "Fecha de entrega: jueves 28 de noviembre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los leguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-4.html#preguntas",
    "href": "tareas/tarea-4.html#preguntas",
    "title": "Tarea 4",
    "section": "",
    "text": "Fecha de entrega: jueves 28 de noviembre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los leguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-4.html#datos",
    "href": "tareas/tarea-4.html#datos",
    "title": "Tarea 4",
    "section": "Datos",
    "text": "Datos\nsalud_peru.csv\ndata_germany.csv"
  },
  {
    "objectID": "tareas/tarea-4.html#pregunta-1",
    "href": "tareas/tarea-4.html#pregunta-1",
    "title": "Tarea 4",
    "section": "Pregunta 1",
    "text": "Pregunta 1\nLos datos del archivo salud_peru.csv contienen información de una encuesta en hogares realizada en Perú. Un programa del gobierno otorgó un seguro de salud para cubrir a hogares de trabajadores informales y pobres, típicamente excluidos de los servicios de salud. Para ello, se uso un índice de ingreso (IFH), expresado en soles, para determinar la elegibilidad. Aquellos hogares con un IFH menor o igual a 55 soles son considerados pobres. Se desea estimar el efecto del programa en la probabilidad de recibir algún tipo de anteción médica, curative, y sobre la probabilidad de recibir algún tipo de asistencia médica en un hospital o con un doctor, hospinter. La columna ifh contiene el indicador del ingreso.\n\n[10 puntos] Genere una gráfica donde muestre evidencia de una discontinuidad en la variable curative para aquellos hogares que recibieron los beneficios del programa. Debe usar solo a los trabajadores informales, formal==0. Primero, realice la gráfica con una ventana de 100 soles a la izquierda y 100 soles a la derecha del corte de elegibilidad y en la que cada punto represente la media de la variable curative en bins de 5 soles. Agregue una línea de regresión lineal para cada lado del corte de elegibilidad.\n[5 puntos] Genere el mismo gráfico que en la parte a., pero ahora con una ventana de 2 soles a cada lado de la discontinuidad.\n[5 puntos] Genere el mismo gráfico que en la parte a., pero calcule la media de la variable curative en bins de 10 soles.\n[5 puntos] Ahora use rdplot del paquete rdrobust para construir el mismo gráfico.\n[10 puntos] Estime la versión más básica de un modelo de regresión discontinua para el efecto del programa sobre hospinter. Reporte el coeficiente estimado del efecto del tratamiento y su significancia estadística. Use una ventana de 20 soles en el IFH antes y después del corte de elegibilidad. Interprete sus resultados.\n[5 puntos] Estime la misma especificación que en la parte d., pero ahora con una ventana de 10 soles en el IFH. Interprete sus resultados.\n[5 puntos] Regrese a una ventana de 20 soles como en la parte d., pero ahora permita un coeficiente distinto para el IFH antes y después del corte, y un polinomio de orden 2 para la variable de asignación. Interprete sus resultados.\n[5 puntos] Use rdrobust para estimar el efecto usando un polinomio de orden 2 y una regresión local no paramétrica. Use algún selector de ancho de banda óptimo."
  },
  {
    "objectID": "tareas/tarea-4.html#pregunta-2",
    "href": "tareas/tarea-4.html#pregunta-2",
    "title": "Tarea 4",
    "section": "Pregunta 2",
    "text": "Pregunta 2\nEl archivo data_germany.csv contiene los datos empleados por Abadie, Diamond y Hainmueller (2015) para estimar el efecto de la reunificación de Alemania en el PIB per cápita (gdp) usando el método de control sintético.\n\n[15 puntos] Estime el control sintético del PIB per cápita de Alemania del Oeste usando como grupo donador a los 21 países incluidos en los datos. Esto es, encuentre la matriz \\(W\\) que otorga pesos a las distintas regiones usando una serie de predictores observables. Para este propósito, use como predictores el promedio de las siguientes variables para el periodo 1981-1990:\n\nLa apertura comercial, trade\nLa tasa de inflación, infrate\n\nAdemás, use como predictores especiales los siguientes valores:\n\nEl promedio de la participación de la industria en el PIB, industry, de 1981 a 1990\nEl promedio de la escolaridad, schooling, de 1980 y 1985\nLa tasa de inversión, invest80, de 1980\n\nNote que Alemania Occidental está identificada con el número 7 de la columna index. Realice el procedimiento de optimización para minimizar las discrepancias entre la unidad tratada y su sintético usando el periodo 1960-1989.\n¿Qué regiones y con qué pesos contribuyen a construir la Alemania Occidental sintética? Use el procedimiento que vimos en clase, aunque no podrá replicar exactamente los resultados del artículo, por ahora. Notará esto en los valores que obtenga para \\(W\\).\n[10 puntos] Obtenga un gráfico en donde represente las series de tiempo del PIB per cápita de Alemania Occidental que efectivamente se realizó, la de su correspondiente control sintético y la del promedio simple del resto de países.\n[10 puntos] Genere una gráfica de brecha que muestre el efecto del terrorismo sobre el PIB per cápita. La brecha es la diferencia entre la serie de tiempo realizada y su contraparte sintética.\n[15 puntos] Ahora seguiremos la estrategia de estimación que siguen los autores en el artículo. Mostraremos que, con su método, podemos obtener el gráfico de placebo en el tiempo de la figura 4 del artículo.\nLos autores siguen un procedimiento de validación cruzada o cross-validation, muy usado también en ciencia de datos. Para ello, dividen la muestra pre intervención en un periodo de entrenamiento y otro de validación. La idea es obtener \\(V\\) en el periodo de entrenamiento y usar dicho vector como pesos en la estimación de \\(W\\) en el periodo de validación.\nPrimero, estime el control sintético para el periodo de validación, usando los siguientes predictores y periodos de optimización:\n\nspecial.predictors = list(\n  list(\"industry\",1971, c(\"mean\")),\n  list(\"schooling\",c(1960,1965), c(\"mean\")),\n  list(\"invest60\" ,1980, c(\"mean\")))\n\ntime.predictors.prior = 1960:1964\ntime.optimize.ssr = 1965:1975\ntime.plot = 1960:1990\n\nPosteriormente, use el vector \\(V\\) obtenido con el procedimiento de entrenamiento anterior para estimar el control sintético, pero ahora con los siguientes predictores y periodos de referencia (el periodo de validación). Para indicar una matriz \\(V\\) en específico explore las opciones de la función synth.\n\nspecial.predictors = list(\n      list(\"industry\" ,1971:1975, c(\"mean\")),\n      list(\"schooling\",c(1970,1975), c(\"mean\")),\n      list(\"invest70\" ,1980, c(\"mean\"))\n      )\n\ntime.predictors.prior = 1965:1975\ntime.optimize.ssr = 1960:1975\ntime.plot = 1960:1990\n\nFinalmente, obtenga el gráfico de trayectorias y compruebe que replica la figura 4 del artículo."
  },
  {
    "objectID": "tareas/tarea-3.html",
    "href": "tareas/tarea-3.html",
    "title": "Tarea 3",
    "section": "",
    "text": "Fecha de entrega: jueves 7 de noviembre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los leguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-3.html#preguntas",
    "href": "tareas/tarea-3.html#preguntas",
    "title": "Tarea 3",
    "section": "",
    "text": "Fecha de entrega: jueves 7 de noviembre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los leguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-3.html#datos",
    "href": "tareas/tarea-3.html#datos",
    "title": "Tarea 3",
    "section": "Datos",
    "text": "Datos\ndatos_jcf_analisis.csv"
  },
  {
    "objectID": "tareas/tarea-3.html#pregunta-1",
    "href": "tareas/tarea-3.html#pregunta-1",
    "title": "Tarea 3",
    "section": "Pregunta 1",
    "text": "Pregunta 1\nStevenson, B. & Wolfers, J. (2006)1 estudian los efectos de la introducción de leyes que permiten el divorcio unilateral en los Estados Unidos. La librería bacondecomp incluye los datos usados en dicho artículo (debe instalar y cargar la librería). Usaremos los datos de 1964 a 1996 para mostrar cómo impactan las leyes de divorcio express (unilateral) a la tasa de suicidios en mujeres.\nAl correr el pedazo de código anterior, obtendrá un objeto de datos wd en donde la variable de impacto es la tasa de suicidios en mujeres, suicide_rate, st identifica a los estados, year identifica a los años y divyear es el año en que se introdujo la legislación del divorcio unilateral. La última fila del código crea el indicador de tratamiento unilaterial, que toma el valor de 1 para los estados tratados en los periodos post tratamiento.\n\nwd &lt;- divorce %&gt;% \nfilter(year&gt;=1964 & year&lt;=1996 & sex==2) %&gt;% \nmutate(suicide_rate=suicide*1000000/(stpop*fshare),\n   year=as.numeric(year),\n   divyear = ifelse(divyear&gt;1996, Inf, divyear),\n   unilateral=ifelse(year&gt;divyear, 1, 0))\n\n\n[5 puntos] Presente una tabla donde muestre el número de estados que es tratado en cada periodo del panel. ¿Cuántos estados son nunca tratados? ¿Cuántos estados son siempre tratados?\nSi hacemos un tabulado de divyear para un año fijo, notamos cuántos estados se vuelven tratados en cada año. Solo 5 estados son nunca tratados. Por otro lado, como el panel comienza en 1964 y hay 9 estados tratados en 1950, estos 9 estados son siempre tratados.\n[5 puntos] Como punto de partida, estime el efecto del tratamiento sobre suicide_rate usando efectos fijos por estado y año (TWFE) y empleando una librería específica para efectos fijos, como felm. Tome en cuenta la agrupación de los errores. Interprete sus resultados.\n[5 puntos] Compruebe que puede obtener el mismo resultado con una regresión lineal usando el paquete lm e incluyendo, además de la variable de tratamiento, dummies de estado y de año.\n[10 puntos] Ahora muestre que podemos obtener el coeficiente de TWFE a partir de una regresión bivariada entre la tasa de suicidios y unilateral, una vez purgada por efectos fijos. Para ello, primero estime una regresión de unilateral en función de los efectos fijos. Obtenga la predicción y luego defina una nueva variable igual a la diferencia entre unilateral y la predicción que acaba de obtener. Finalmente, obtenga el coeficiente de TWFE con una regresión de la tasa de suicidios en función de la diferencia antes definida.\n[10 puntos] Realice la descomposición de Goodman-Bacon (2021). Construya un gráfico donde muestre en el eje \\(x\\) el peso otorgado a cada comparación 2x2 que el estimador de TWFE realiza mecánicamente y en el eje \\(y\\) el efecto estimado correspondiente a cada comparación. Interprete el gráfico obtenido.\n[10 puntos] Implemente el estimador de Callaway & Sant’Anna (2021) para estimar los efectos del tratamiento específicos para cada cohorte, usando el paquete did. Utilice como grupo de comparación los estados no tratados aún. La columna stid es un identificador numérico de los estados (lo requerirá cuando use att_gt del paquete did).\n[5 puntos] Reporte los resultados agregados obtenidos a partir del estimador Callaway & Sant’Anna (2021), usando una agregación dinámica que muestre los efectos promedio para cada periodo antes y después del tratamiento. Grafique e interprete los resultados.\n[5 puntos] Reporte los resultados agregados obtenidos a partir del estimador Callaway & Sant’Anna (2021), usando una agregación or grupos que muestre los efectos promedio para cada cohorte del tratamiento. Grafique e interprete los resultados.\n[5 puntos] ¿Cuáles son las ventajas del estimador de Callaway & Sant’Anna (2021) respecto al estimador de TWFE?"
  },
  {
    "objectID": "tareas/tarea-3.html#pregunta-2",
    "href": "tareas/tarea-3.html#pregunta-2",
    "title": "Tarea 3",
    "section": "Pregunta 2",
    "text": "Pregunta 2\nLa ENIGH 2020 incluyó un módulo para la evaluación del Programa Jóvenes Construyendo el futuro. Se buscó que la cobertura de la encuesta pudiera incluir suficientes participantes del programa para poder compararlos con los no participantes. Los datos en datos_jcf_analisis.csv fueron construidos a partir de dicha encuesta. En este ejercicio estimaremos el efecto de participar en el programa sobre el ingreso trimestral, ingtot_tri, usando métodos de matching.\nLas siguientes variables están incluidas en el archivo de datos: mujer (dummy de sexo), indigena (dummy de pertenencia a una etnia), rural (dummy del ámbito rural), escoacum (años de escolaridad), casadounion (dummy para casados o en unión libre), jefehog (dummy para jefes del hogar), haymenores (dummy para la presencia de menores de edad en el hogar), proggob (dummy para beneficiarios de programas de gobierno), y tot_integ (número de miembros del hogar). También se incluye la clave de las entidades, cve_ent.\n\n[10 puntos] Considere la comparación para el ingreso trimestral, ingtot_tri, entre beneficiarios y su grupo de comparación, que serán los jóvenes que no asisten a la escuela y no están empleados. Los beneficiarios tienen jcf2==1 y los jóvenes que no asisten a la escuela y no están empleados tienen jcf2==0. Muestre qué tan similares o qué tan diferentes son los individuos en ambos grupos en términos de las características indicadas anteriormente y del ingreso trimestral.\n[10 puntos] Estime el TOT (TT o ATT) del programa en el ingreso trimestral, ingtot_tri usando el algoritmo de vecino más cercano. Para estimar el impacto en el ingreso trimestral se comparan a los beneficiarios de JCF con los jóvenes que no asisten a la escuela y no están empleados. Los beneficiarios tienen jcf2==1 y los jóvenes que no asisten a la escuela y no están empleados tienen jcf2==0. Escoja la especificación del propensity score que más le parezca adecuada. Realice la inferencia estadística con errores agrupados a nivel grupo de emparejamiento. ¿De qué tamaño es el TOT estimado y es este efecto estadísticamente significativo?\n[10 puntos] En el matching de la parte b., evalúe qué tan bueno es el procedimiento en balancear las características observadas una vez realizado el matching. Cree un love plot para evaluar qué tan bueno es el procedimiento de matching para obtener una muestra balanceada.\n[10 puntos] Estime ahora el TOT en el ingreso trimestral, como en la parte b., pero usando un caliper de 0.05 y 5 vecinos a ser emparejados. ¿Cómo cambian sus resultados respecto a los de la parte b.?"
  },
  {
    "objectID": "tareas/tarea-3.html#footnotes",
    "href": "tareas/tarea-3.html#footnotes",
    "title": "Tarea 3",
    "section": "Notas",
    "text": "Notas\n\n\nStevenson, B. & Wolfers, J. (2006). Bargaining in the Shadow of the Law: Divorce Laws and Family Distress. The Quarterly Journal of Economics, 121(1), 267-288.↩︎"
  },
  {
    "objectID": "tareas/tarea-2.html",
    "href": "tareas/tarea-2.html",
    "title": "Tarea 2",
    "section": "",
    "text": "Fecha de entrega: viernes 3 de octubre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los leguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-2.html#datos",
    "href": "tareas/tarea-2.html#datos",
    "title": "Tarea 2",
    "section": "Datos",
    "text": "Datos\ncrepon_morocco_balance.csv\ncrepon_morocco_analysis.csv\nSTAR_public_use.csv"
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-1",
    "href": "tareas/tarea-2.html#pregunta-1",
    "title": "Tarea 2",
    "section": "Pregunta 1",
    "text": "Pregunta 1\nEn Crepon et al. (2015)1 se estudia una intervención en Marruecos en la que se analiza el efecto de la adopción de microfinanzas, a través de un experimento de campo. En 81 de 162 localidades estudiadas se introdujo aleatoriamente una empresa de microfinanzas. Para seleccionar las localidades de tratamiento, primero se emparejaron localidades de acuerdo a características observables y, para cada pareja se asignó a tratamiento y otra a control. La variable que identifica a las parejas es paire. La base de datos crepon_morocco_balance.csv contiene los datos de este estudio usados para mostrar la integridad del diseño. La variable treatment es la variable de asignación aleatoria, mientras que la variable client es la variable de adopción\n\n[3 puntos] Primero recordaremos cómo mostrar que el tratamiento efectivamente fue asignado de manera aleatoria. El siguiente código lee los datos que debemos usar y se queda con las observaciones de la línea base. Con estos datos, mostraremos que la variable members_resid_bl, que indica el número de personas que viven en cada hogar está balanceado entre los grupos asignados a tratamiento y control. Noten que la media del número de personas que viven en el hogar en el grupo de control es 5.14 (d.e. 2.70) y que hay 2,266 hogares en dicho grupo de control. Esto es exactamente lo que se reporta en la fila correspondiente a Number members en la tabla 1 del artículo.\n\ndata.morocco&lt;-read_csv(\"../files/crepon_morocco_balance.csv\",\n                      locale = locale(encoding = \"latin1\")) %&gt;% \n clean_names() %&gt;% \n filter(merge_indicator!=1)\n\ndata.morocco %&gt;% \n group_by(treatment) %&gt;%\n summarize(mean=mean(members_resid_bl, na.rm=T),\n           std=sd(members_resid_bl, na.rm=T),\n           n=n()) %&gt;%\nungroup()\n\n# A tibble: 2 × 4\n  treatment  mean   std     n\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1         0  5.14  2.69  2266\n2         1  5.19  2.76  2199\n\n\nObtenga ahora el valor de la diferencia entre el grupo de tratamiento y el de control, así como su valor \\(p\\) (últimas dos columnas). Para ello, estime una regresión en la que la variable dependiente sea número de personas que vive en el hogar members_resid_bl, en función de la variable de asignación treatment y variables dummy de pareja de localidad (la variable paire indica cuáles son las parejas). La regresión permite recuperar la diferencia de 0.04 personas que se reporta en la fila correspondiente en la tabla 1. Para recuperar el valor \\(p\\), estime errores agrupados usando la variable demi_paire, que es la clave de las distintas localidades, como variable de agrupación. Una forma de realizar esto es con la función coef_test del paquete clubSandwich.2\n[2 puntos] Ahora mostremos que efectivamente este es un ejemplo de una intervención con cumplimiento imperfecto. Genere un cuadro que indique: 1) cuántas personas que fueron asignadas a recibir el tratamiento efectivamente fueron clientes; 2) cuántas personas que fueron asignadas a recibir el tratamiento no se convirtieron en clientes; 3) cuántas personas que no fueron asignadas a recibir el tratamiento sí se convirtieron en clientes; y 4) cuántas personas que no fueron asignadas a recibir el tratamiento tampoco se convirtieron en clientes.\n[5 puntos] Ahora mostraremos que la adopción, es decir, convertirse en cliente, no es independiente de las características de los hogares. Considere las variables members_resid_bl y act_number_bl, que indican el número de miembros del hogar y el número de actividades económicas del hogar. Para cada una de estas dos variables, utilice la misma especificación que en la parte a., pero ahora usando la variable cliente como regresor. ¿Qué concluye?\n[5 puntos] Con estos elementos estamos convencidos de que es necesario emplear lo que sabemos sobre cumplimiento imperfecto. Usaremos ahora los datos en crepon_morocco_analysis.csv, que contiene los datos empleados para evaluar el impacto de la adopción. Estos datos están listos para analizarse. Estime la forma reducida del efecto de ser asignado al tratamiento sobre gasto total, expense_total. Comente los resultados, en particular, comente sobre la magnitud y la significancia estadística de la variable treatment. Aquí y en adelante, incluya los siguientes controles en la regresión: members_resid_bl, nadults_resid_bl, head_age_bl, act_livestock_bl, act_business_bl, borrowed_total_bl, members_resid_d_bl, nadults_resid_d_bl, head_age_d_bl, act_livestock_d_bl, act_business_d_bl, borrowed_total_d_bl, ccm_resp_activ, other_resp_activ, ccm_resp_activ_d y other_resp_activ_d. Además, incluya efectos fijos por pareja introduciendo la variable paire como factor. Use los mismos errores estándar que en la parte a. Con esto deberá poder recuperar el coeficiente y el error estándar de la columna (3) de la tabla 3.\n[5 puntos] Estime ahora la primera etapa, es decir, estime por MCO el efecto causal de la asignación sobre la adopción. Comente sobre la magnitud, la significancia estadística y la interpretación de la variable treatment en términos del comportamiento de los cumplidores. Debería poder replicar el coeficiente y el error estándar de la columna 1 en la tabla 2 del artículo.\n[5 puntos] Considere la columna 3 del panel A en la Tabla 9 del artículo. Aquí se reporta la estimación por MCO de la relación entre client y gasto total, con los mismos controles y tipo de errores que antes. Replique este resultado. ¿Se puede interpretar de forma causal el coeficiente sobre client?\n[5 puntos] ¿Cuáles son los dos supuestos econométricos que permiten la estimación del Local Average Treatment Effect (LATE) en el contexto de este problema? Comente sobre la evidencia que respalda el supuesto de que los instrumentos no son débiles en este problema.\n[5 puntos] Estime el efecto del cumplimiento sobre el gasto total, usando la asignación aleatoria como instrumento del cumplimiento. Es decir, estime el LATE. Use los mismos controles y tipo de errores que en c. Este resultado se reporta en la columna 3 del panel B en la Tabla 9. ¿Cuál es la interpretación del coeficiente de la variable client? En R, la función ivreg del paquete AER le permite hacer la estimación de MC2E."
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-2",
    "href": "tareas/tarea-2.html#pregunta-2",
    "title": "Tarea 2",
    "section": "Pregunta 2",
    "text": "Pregunta 2\nSea una variable de resultados \\(y_i\\), una variable de asignación aleatoria \\(Z_i\\) y una variable de adopción \\(D_i\\). El estimador de Wald se define como:\n\\[\\hat{\\beta}_{Wald}=\\frac{\\bar{Y}_{Z_i=1}-\\bar{Y}_{Z_i=0}}{\\bar{D}_{Z_i=1}-\\bar{D}_{Z_i=0}}\\]\nEn esta pregunta mostraremos cómo el estimador de Wald es equivalente al estimador de VI cuando no hay controles. Use nuevamente los datos en crepon_morocco_analysis.csv.\n\n[10 puntos] Obtenga el estimador de Wald como el cociente de la diferencia en gasto total promedio entre los hogares asignados a tratamiento y control dividido por la diferencia en la probabilidad de adopción entre los hogares asignados a tratamiento y control. Recuerde que la variable del gasto total es expense_total.\n[5 puntos] Ahora estime por MC2E el efecto de la adopción sobre el gasto total, usando la variable de asignación como instrumento para la adopción. Use ivreg para estimar el efecto directamente. ¿Qué ventaja observa con respecto al estimador de Wald?\n[10 puntos] Ahora estime por MC2E el efecto de la adopción sobre el gasto total, usando la variable de asignación como instrumento para la adopción. A diferencia del punto previo, realice la estimación a mano, es decir, primero estime los valores ajustados de la variable endógena en una primera etapa y luego use estos valores ajustados en la estimación estructural. ¿Qué desventaja observa con respecto a la estimación del punto previo?"
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-3",
    "href": "tareas/tarea-2.html#pregunta-3",
    "title": "Tarea 2",
    "section": "Pregunta 3",
    "text": "Pregunta 3\nEn la Pregunta 2, parte a, obtuvo el estimador de Wald para aproximar el efecto de la adopción en el gasto total como un cosciente de dos diferencias de medias.\n\n[5 puntos] Utilice un procedimiento bootstrap a mano para estimar el error estándar del estimador de Wald usando 50 repeticiones. Es decir, debe realizar un remuestreo de los datos originales y para cada muestra obtener el estimador de Wald. Luego, obtenga la desviación estándar de los 50 estadísticos calculados. Utilice una semilla para poder replicar sus resultados.\n[5 puntos] Reemplace la semilla de la parte a. por una nueva semilla y estime nuevamente el error estándar del estimador de Wald con 50 repeticiones. Comente sobre la diferencia entre este error estándar y el de la parte a.\n[5 puntos] Regrese el valor de la semilla al usado en a. y estime nuevamente el error estándar del estimador de Wald, esta vez usando 1000 repeticiones. Comente sobre la diferencia entre este error estándar y el de la parte a."
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-4",
    "href": "tareas/tarea-2.html#pregunta-4",
    "title": "Tarea 2",
    "section": "Pregunta 4",
    "text": "Pregunta 4\nConsidere nuevamente la base STAR_public_use.csv usada en la Tarea 1 del artículo Angrist, Lang y Oreopoulos (2009)3. En esta pregunta nos concentraremos en los efectos de la intervención en el año 2, mostrados en la columna (4) de la Tabla 6, sobre dos variables, el promedio de calificaciones gpa_year2 y los créditos completados credits_earned2.\nEl propósito de esta pregunta es mostrar la función de los \\(z\\)-scores en el análisis de efectos de tratamiento. De nuevo, puede quedarse solo con las observaciones que tienen noshow igual a 0. Antes de comenzar su análisis, sustituya por NA los valores en credits_earned2 para aquellas observaciones que tienen \\(NA\\) en la variable prob_year1.\n\n[5 puntos] Para tener un punto de comparación, estime la ecuación del efecto de tratamiento para gpa_year2 usando la misma especificación que en la pregunta 5 de la Tarea 1. Use también errores robustos. Deberá poder replicar los coeficientes y errores estándar del panel A, columna (4). ¿Cómo se interpretan el coeficiente sobre la variable ssp?\n[5 puntos] Genere un \\(z\\)-score para la variable gpa_year2 al que llame gpa_year2_sd. Para ello, calcule la media y desviación estándar de gpa_year2 para el grupo de control y luego genere gpa_year2_sd restándole a gpa_year2 la media obtenida y dividiendo esta diferencia por la desviación estándar obtenida. Compruebe que si calcula la media y la desviación estándar de gpa_year2_sd, en el grupo de control estas deberían ser 0 y 1, respectivamente.\n[5 puntos] Realice la misma estimación que en la parte a., pero ahora use como variable dependiente gpa_year2_sd. ¿Cómo se interpreta el coeficiente sobre ssp? ¿Qué es diferente y qué es igual entre los resultados obtenidos en esta parte y los obtenidos en la parte a.?\n[5 puntos] Ahora realizaremos un índice de mejora en educación, al agregar los resultados de estos dos indicadores en una sola variable, como se describe en Banerjee et al. (2015)4. Para ello, primero genere credits_earned2_sd, que será la versión estandarizada de credits_earned2, siguiendo el mismo procedimiento que en la parte b. En seguida, genere una nueva variable llamada indice_escolar, que será el promedio de credits_earned2_sd y gpa_year2_sd. Luego, calcule la media y la desviación estándar de indice_escolar en el grupo de control. Finalmente, genere una nueva variable indice_escolar_sd restándole a indice_escolar la media antes calculada y dividiendo esta diferencia por la desviación estándar antes calculada. Muestre que la variable indice_escolar_sd tiene media 0 y desviación estándar 1 en el grupo de control.\n[5 puntos] Estime ahora el efecto de tratamiento sobre indice_escolar_sd, siguiendo la misma especificación econométrica que en la parte a. y usando errores robustos. ¿Qué concluye?"
  },
  {
    "objectID": "tareas/tarea-2.html#footnotes",
    "href": "tareas/tarea-2.html#footnotes",
    "title": "Tarea 2",
    "section": "Notas",
    "text": "Notas\n\n\nPor ejemplo, suponga que estima un modelo al que llame modelo1. Entonces, si ejecuta\n\ncoef_test(modelo1,\n          vcov=\"CR1S\",\n          cluster=mis_datos$demi_paire)[1:2,]\n\nobtendrá los coeficientes con los errores agrupados requeridos. La opción CR1S toma en cuenta el número de grupos o clusters para realizar inferencia. Puede leer más al respecto en la ayuda al ejecutar ?vcovCR. Este es el tipo de ajuste de muestras finitas que usan los autores. Esta corrección consiste en multiplicar la matriz de sándwich agrupada CR0 por \\(\\frac{G(N-1)}{(G-1)(N-p)}\\), donde \\(G\\) es el número de grupos, \\(N\\) es el número total de observaciones y \\(p\\) es el número de regresores.↩︎\nCrépon, B., Devoto, F., Duflo, E., & Parienté, W. (2015). Estimating the impact of microcredit on those who take it up: Evidence from a randomized experiment in Morocco. American Economic Journal: Applied Economics, 7(1), 123-50.↩︎\nAngrist, J., Lang, D., y Oreopoulos, P. (2009). Incentives and services for college achievement: Evidence from a randomized trial. American Economic Journal: Applied Economics, 1(1), 136-63.↩︎\nBanerjee, A. et al. (2015). A multifaceted program causes lasting progress for the very poor: Evidence from six countries. Science, 348(6236).↩︎"
  },
  {
    "objectID": "tareas/tarea-1.html",
    "href": "tareas/tarea-1.html",
    "title": "Tarea 1",
    "section": "",
    "text": "Fecha de entrega: lunes 15 de septiembre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los leguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-1.html#preguntas",
    "href": "tareas/tarea-1.html#preguntas",
    "title": "Tarea 1",
    "section": "",
    "text": "Fecha de entrega: lunes 15 de septiembre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los leguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-1.html#datos",
    "href": "tareas/tarea-1.html#datos",
    "title": "Tarea 1",
    "section": "Datos",
    "text": "Datos\nmuestra-enoe-123.csv\nSTAR_public_use.csv"
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-1",
    "href": "tareas/tarea-1.html#pregunta-1",
    "title": "Tarea 1",
    "section": "Pregunta 1",
    "text": "Pregunta 1\nSuponga que para un experimento en un laboratorio se asignó a un grupo pacientes a un brazo de tratamiento o a uno de control. Antes de comenzar el experimento se recolectaron una serie de características \\(x_{ji}\\), \\(j=1,\\ldots 10\\), de cada paciente. Se busca medir el efecto del tratamiento sobre una variable de resultados \\(y_i\\). En el experimento, se trabaja con \\(\\alpha=0.10\\).\n\n[5 puntos] El investigador A quedó a cargo de comprobar el balance de la asignación del tratamiento y le reporta lo siguiente:\nPara verificar que la aleatorización fue exitosa, tomé la serie de variables pre-intervención y la dummy de asignación al tratamiento \\(T_i\\) para correr la siguiente regresión: \\[T_i=\\alpha+\\sum_{j=1}^{10}x_{ji}'\\beta +\\varepsilon_i\\]\nDespués realicé una prueba \\(F\\) de significancia conjunta sobre los coeficientes \\(\\beta_j\\) que resultó tener un valor \\(p\\) de 0.043.\nExplique cuál es la hipótesis nula en la prueba realizada y qué se esperaría de haberse logrado una aleatorización exitosa del tratamiento.\n[5 puntos] ¿Qué concluye a partir de lo que le reporta el investigador A?\n[5 puntos] Por otro lado, el investigador B le reporta lo siguiente:\nYo realicé un análisis para determinar el balance en la asignación del tratamiento. Para cada una de las características \\(x_{ji}\\) corrí la siguiente regresión: \\[x_{ji}=\\gamma+\\pi T_i+u_i\\] A continuación, le reporto una tabla con los valores p asociados al coeficiente estimado de \\(\\pi\\) en cada una de las 10 regresiones.\n\n\n\n\n\n\n\n\n\n\nCaracterística\nValor \\(p\\)\n\nCaracterística\nValor \\(p\\)\n\n\n\n\n\\(x_{1i}\\)\n0.025\n\n\\(x_{6i}\\)\n0.015\n\n\n\\(x_{2i}\\)\n0.012\n\n\\(x_{7i}\\)\n0.033\n\n\n\\(x_{3i}\\)\n0.027\n\n\\(x_{8i}\\)\n0.019\n\n\n\\(x_{4i}\\)\n0.076\n\n\\(x_{9i}\\)\n0.028\n\n\n\\(x_{5i}\\)\n0.002\n\n\\(x_{10i}\\)\n0.017\n\n\n\nExplique la hipótesis nula detrás de las pruebas que realizó el investigador B y qué se esperaría de haberse logrado una aleatorización exitosa del tratamiento,\n[5 puntos] ¿Cómo reconcilia la evidencia encontrada por el investigador A y el B y qué concluye sobre el balance en la asignación del tratamiento? ¿Qué características tendría una diferencia de medias de \\(y_i\\) después del tratamiento como estimador del impacto de este?"
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-2",
    "href": "tareas/tarea-1.html#pregunta-2",
    "title": "Tarea 1",
    "section": "Pregunta 2",
    "text": "Pregunta 2\nSe implemetó un programa para la entrega de semilla mejorada para la producción de frijol. La semilla se entregó a productores de hasta 10 hectáreas que ya reciben servicios de asistencia técnica y fertilizantes por parte del gobierno. El gobierno está interesado en estimar el impacto de la semilla mejorada en los rendimientos de la producción de frijol una vez que se realiza la cosecha, \\(y_i\\).\nPara responder esta pregunta, el gobierno invierte una gran cantidad de recursos en una encuesta representativa de los productores de frijol de hasta 10 hectáreas de todo el país y donde se identifica si el productor recibió o no la semilla mejorada (\\(T_i\\)), además de un amplio cuestionario sobre insumos usados en la producción, prácticas agrícolas y características socioeconómicas de los productores y sus familas.\n\n[10 puntos] Se propone que para estimar el efecto del programa se comparen los rendimientos de los productores que recibieron la semilla con los que no la recibieron. Argumente en términos del sesgo de selección sobre la conveniencia de esta estrategia para estimar el efecto causal de la semilla mejorada.\n[5 puntos] Para implementar la propuesta del punto a., se propone estimar la siguiente regresión: \\[ y_i = \\alpha + \\beta T_i + \\varepsilon_i \\]\nMuestre si el estimador de MCO de \\(\\beta\\) es consistente o no para el efecto de tratamiento.\n[5 puntos] Describa cómo realizaría el experimento ideal para la identificación del efecto causal de proveer semilla mejorada sobre el rendimiento. Describa cómo asignaría el tratamiento, qué condiciones deberían verificarse para asegurar la integridad del diseño y qué posibles obstáculos encontraría para la implementación de la estrategia que propone."
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-3",
    "href": "tareas/tarea-1.html#pregunta-3",
    "title": "Tarea 1",
    "section": "Pregunta 3",
    "text": "Pregunta 3\n[10 puntos] Replique el ejercicio en MHE que ejemplifica el teorema de la regresión de la FEC. Para esto use el archivo de datos muestra-enoe-123.csv, que contiene una muestra del primer trimestre de 2023 de la ENOE e incluye personas que trabajan y reciben un ingreso. lingreso es el log del ingreso mensual y escolaridad son los años de educación. Primero, estime una regresión de lingreso en función de escolaridad usando los microdatos. Luego, obtenga la media de lingreso para cada nivel de escolaridad y estime una regresión de las medias en función de escolaridad, pesando por el número de observaciones usadas para construir cada media. Compare los coeficientes estimados."
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-4",
    "href": "tareas/tarea-1.html#pregunta-4",
    "title": "Tarea 1",
    "section": "Pregunta 4",
    "text": "Pregunta 4\nUse los datos del archivo STAR_public_use.csv para este problema. En este problema replicará la fila correspondiente a la variable High school GPA (calificación en la preparatoria) de la Tabla 1 en Angrist et al. (2009).1\n\n[5 puntos] Obtenga la media y la desviación estándar de la edad, gpa0 en los datos, en el grupo de control (columna 1), restringiendo la muestra a aquellos individuos con noshow igual a 0.\n[10 puntos] Usando una regresión lineal, muestre que la calificación en la preparatoria no está correlacionada con la asignación a los tratamientos (ssp, sfp y sfsp). De nuevo, debe restringir la muestra quienes tienen noshow igual a 0. Reporte los coeficientes y los errores estándar (columnas 2 a 4).\n[5 puntos] Realice una prueba de significancia conjunta de los coeficientes obtenidos en el punto b. Reporte el estadístico \\(F\\) y el valor \\(p\\) asociado (columna 5).\n[10 puntos] ¿Cuál es el propósito de la prueba F realizada en el punto c.? ¿Qué hipótesis nula prueban los autores?"
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-5",
    "href": "tareas/tarea-1.html#pregunta-5",
    "title": "Tarea 1",
    "section": "Pregunta 5",
    "text": "Pregunta 5\nNuevamente, use los datos del archivo STAR_public_use.csv. En este problema, replicará dos columnas del efecto de tratamiento de la Tabla 5. Note que de nuevo se deben usar solo las observaciones que tienen noshow igual a 0. Los autores también sustituyen los valores de gpa_year1 por NA cuando la variable grade_20059_fall es NA; y sustituyen grade_20059_fall por NA cuando la variable gpa_year1 es NA. Además, note que se usan las siguientes variables de control: sex, mtongue, hsgroup, numcourses_nov1, lastmin, mom_edn, y dad_edn, todas ellas categóricas.\n\n[10 puntos] Estime el efecto de cada tipo de tratamiento sobre el promedio o GPA, denotado gpa_year1 en los datos, para toda la muestra (Panel B, columna 1). Calcule correctamente los errores estándar. Interprete los resultados.\n[10 puntos] Estime el efecto sobre el GPA de recibir cada tipo de tratamiento, considerando los tratamientos SSP o SFP (de cualquier tipo) en las mujeres de la muestra (Panel B, columna 6). Esto es, considere el tratamiento SSP como un primer tipo de tratamiento y, ya sea SFP o SFSP, como un segundo tipo de tratamiento. Calcule correctamente los errores estándar. Interprete sus resultados."
  },
  {
    "objectID": "tareas/tarea-1.html#footnotes",
    "href": "tareas/tarea-1.html#footnotes",
    "title": "Tarea 1",
    "section": "Notas",
    "text": "Notas\n\n\nAngrist, J., Lang, D., y Oreopoulos, P. (2009). Incentives and services for college achievement: Evidence from a randomized trial. American Economic Journal: Applied Economics, 1(1), 136-63.↩︎"
  },
  {
    "objectID": "tareas/index.html",
    "href": "tareas/index.html",
    "title": "Tareas",
    "section": "",
    "text": "Tarea 1\n\nFecha de entrega: lunes 15 de septiembre a las 20:00 en Teams\nPreguntas\nRespuestas\n\n\n\n\nTarea 2\n\nFecha de entrega: viernes 3 de octubre a las 20:00 en Teams\nPreguntas\nRespuestas\n\n\n\n\nTarea 3\n\nFecha de entrega: lunes 10 de noviembre a las 20:00 en Teams\n\n\n\n\nTarea 4\n\nFecha de entrega: lunes 1 de diciembre a las 20:00 en Teams",
    "crumbs": [
      "Tareas"
    ]
  },
  {
    "objectID": "reglas.html",
    "href": "reglas.html",
    "title": "Reglas",
    "section": "",
    "text": "No se tolerarán actos de discriminación. Se procura un ambiente de respeto entre todos los miembros de la clase.\nToda la comunicación relativa al curso se dará por medio del correo institucional del CIDE.\nLas tareas y exámenes se entregarán a través de Teams.\nLos participantes en la sesión deberán procurar que haya un ambiente silencioso para el desarrollo de la clase.\nSe aplicarán estrictamente los lineamientos generales contenidos en el código de ética del CIDE en términos de plagio y fraude en tareas, exámenes y proyecto final.",
    "crumbs": [
      "Reglas"
    ]
  },
  {
    "objectID": "programa.html",
    "href": "programa.html",
    "title": "Programa",
    "section": "",
    "text": "Conocer las condiciones que permiten la identificación de efectos causales en economía y otras ciencias sociales.\nConocer los fundamentos teóricos sobre los que se sustentan las metodologías para la estimación de relaciones causales.\nImplementar los métodos de inferencia causal empleando software, interpretar los resultados y reportar las conclusiones en forma de artículos científicos y/o reportes de política.\nConocer e implementar buenas prácticas en el uso de software, orientadas a la transparencia y la replicabilidad en la investigación.\nConocer los temas que conforman la literatura actual de inferencia causal.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#objetivos",
    "href": "programa.html#objetivos",
    "title": "Programa",
    "section": "",
    "text": "Conocer las condiciones que permiten la identificación de efectos causales en economía y otras ciencias sociales.\nConocer los fundamentos teóricos sobre los que se sustentan las metodologías para la estimación de relaciones causales.\nImplementar los métodos de inferencia causal empleando software, interpretar los resultados y reportar las conclusiones en forma de artículos científicos y/o reportes de política.\nConocer e implementar buenas prácticas en el uso de software, orientadas a la transparencia y la replicabilidad en la investigación.\nConocer los temas que conforman la literatura actual de inferencia causal.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#referencias",
    "href": "programa.html#referencias",
    "title": "Programa",
    "section": "Referencias",
    "text": "Referencias\nEl curso se basa en los siguientes textos:\n\n(MHE) Angrist, J.D. & Pischke, J.S. (2013). Mostly Harmless Econometrics: An Empiricists Companion. Princeton University Press.\n(MM ) Angrist, J.D. & Pischke, J.S. (2014). Mastering ’Metrics: The Path from Cause to Effect. Princeton University Press.\n(CT) Cameron, A.C. & P.K. Trivedi. (2005). Microeconometrics: Methods and applications. Oxford University Press.\n(MT) Cunningham, S. (2021). Causal inference: The mixtape. Yale University Press. Disponible en línea.\nDiNardo, J. & D.S. Lee. (2011). Program Evaluation and Research Designs. En Handbook of Labor Economics, 4A: 463-536.\nHuntington-Klein, N. (2021). The effect: An introduction to research design and causality. Chapman and Hall/CRC.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#contenido-temático",
    "href": "programa.html#contenido-temático",
    "title": "Programa",
    "section": "Contenido temático",
    "text": "Contenido temático\nUnidad 1. Introducción\n\nInferencia causal\n\nModelo de resultados potenciales\nCausalidad en economía y las ciencias sociales\nRevisión de métodos de regresión\n\nReplicabilidad y transparencia en la evaluación\n\nQuarto para la generación de reportes científicos\n\n\nUnidad 2. Métodos para la inferencia causal\n\nMétodos experimentales\n\nAsignación aleatoria\nErrores estándar\nLATE y variables instrumentales\nCorrección por prueba de múltiples hipótesis\nAplicaciones de métodos experimentales\n\nDiferencia en diferencias\n\nSupuestos fundamentales\nEfectos fijos individuales\nDID desfasado\nANCOVA\nAplicaciones de DID\n\nMétodos de pareamiento\n\nSupuestos fundamentales\nPareamiento exacto\nPareamiento por puntaje de propensión (PSM)\nAplicaciones del PSM\n\nDiseños con discontinuidades\n\nSupuestos fundamentales\nDiscontinuidades nítidas y difusas\nDiscontinuidades geográficas\nPliegues en la regresión\nAplicaciones diseños con discontinuidades\n\nControl sintético\n\nSupuestos fundamentales\nInferencia basada en placebos\nAplicaciones de control sintético\n\n\nUnidad 3. Temas actuales de inferencia causal\n\nExtensiones I\n\nAprendizaje automatizado y big data para la inferencia causal",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#evaluación-del-curso",
    "href": "programa.html#evaluación-del-curso",
    "title": "Programa",
    "section": "Evaluación del curso",
    "text": "Evaluación del curso\n\nExamen parcial: 20%\nExamen final: 30%\nProyecto final: 20%\nTareas (4): 20% (5% cada una)\nExposiciones (2): 10% (7% presentación y 3% resumen en cada una)",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#tareas",
    "href": "programa.html#tareas",
    "title": "Programa",
    "section": "Tareas",
    "text": "Tareas\nCuatro tareas teórico-prácticas. Las tareas deben entregarse de manera individual, pero se recomienda ampliamente colaborar en grupos de estudio. Para evitar confusiones, escriban en su tarea con quiénes colaboraron. Las tareas deberán entregarse en Teams antes de la fecha y hora señalada. No se aceptarán tareas fuera de tiempo. Por favor, no comprima los archivos en carpetas comprimidas. Las tareas deberán contener dos archivos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los leguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#software",
    "href": "programa.html#software",
    "title": "Programa",
    "section": "Software",
    "text": "Software\nR será el paquete standard usado en las sesiones prácticas. Más aún, el uso de cualquier software es aceptado siempre que se cumplan con los requisitos de replicabilidad y reportes de las tareas y exámenes. Habrá una sesión especial para introducir el uso de Quarto para la generación de reportes científicos.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#exámenes",
    "href": "programa.html#exámenes",
    "title": "Programa",
    "section": "Exámenes",
    "text": "Exámenes\n\nExamen parcial: martes 1 de octubre en el horario de clase.\nExamen final: por definir.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#exposiciones",
    "href": "programa.html#exposiciones",
    "title": "Programa",
    "section": "Exposiciones",
    "text": "Exposiciones\nCada alumno realizará una presentación de uno los artículos aplicados marcados con “+” en la lista de lecturas. Cada presentación deberá ser de máximo 15 minutos y debe incluir el contenido que el presentador considere relevante. La presentación deberá abordar, mínimamente: 1) el problema a investigar, 2) la metodología empleada, 3) la pertinencia de la metodología y la teoría vista en el curso, 4) los datos empleados, 5) los principales resultados, y 6) una crítica sobre la validez y las conclusiones del estudio. La presentación deberá acompañarse de un breve resumen de máximo una página de extensión que sintetice los puntos anteriores, para ser distribuido con el resto de la clase.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#proyecto-final",
    "href": "programa.html#proyecto-final",
    "title": "Programa",
    "section": "Proyecto final",
    "text": "Proyecto final\nEl proyecto final consistirá en un protocolo de investigación de una evaluación de impacto. El tema y la metodología es libre, pero se evaluará el potencial para realizarse en el corto plazo. Se aconseja seleccionar un tema para el que se empleen datos de libre acceso. El protocolo deberá incluir, mínimamente: 1) una revisión de literatura, 2) un bosquejo de las motivaciones teóricas del problema, 3) la metodología empírica a emplear, 4) la fuente de datos a usar, y 5) los resultados preliminares. El proyecto debe presentarse en formato escrito con una extensión máxima de 20 cuartillas. Se recomienda ampliamente dar seguimiento al proyecto en horas de oficina para recibir retroalimentación respecto a los avances y resolver posibles dudas y dificultades.\nEntrega: fecha por definir, a través de Teams.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#lista-de-lecturas",
    "href": "programa.html#lista-de-lecturas",
    "title": "Programa",
    "section": "Lista de lecturas",
    "text": "Lista de lecturas\nLas lecturas obligatorias (marcadas con “*”) permiten una discusión informada en la clase. Las lecturas que serán presentadas en exposiciones también son obligatorias y están marcadas con “+”. El resto de las lecturas no serán cubiertas en clase, pero son ampliamente recomendables. En las sesiones de exposiciones se espera que el resto de la clase tenga el conocimiento suficiente sobre el material presentado para participar en la discusión.\nLa lista de lecturas está disponible aquí.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "notas/múltiples-hipótesis.html",
    "href": "notas/múltiples-hipótesis.html",
    "title": "Múltiples hipótesis",
    "section": "",
    "text": "En el contexto de evaluación, cometemos el error tipo I al concluir que hay un efecto de tratamiento cuando la \\(H_0\\) es verdadera, es decir, cuando \\(H_0:\\;\\beta_i=0\\). En una investigación fijamos \\(\\alpha\\), la probabilidad de rechazar \\(H_0\\) cuando \\(H_0\\) es cierta. Por ejemplo, en economía trabajamos con \\(\\alpha=0.05\\) o \\(\\alpha=0.01\\).\nEl problema con probar múltiples hipótesis es que inflamos la tasa de error tipo I. Por ejemplo, si tenemos 100 hipótesis y si usamos un valor estándar de \\(\\alpha=0.05\\), esperaríamos rechazar 5 hipótesis por suerte.\nSi realizamos una prueba, la probabilidad de cometer un error es \\(\\alpha\\) y la de no cometer un error es \\(1-\\alpha\\).\nSi realizamos \\(n\\) pruebas, la probabilidad de no cometer un error es \\((1-\\alpha)^n\\) y la probabilidad de cometer al menos un error es \\(1-(1-\\alpha)^n\\).\nEs decir, la probabilidad de cometer al menos un error se incrementa exponencialmente.\nVeamos esto gráficamente:\n\nalpha=0.05\nn &lt;- 1:1000\np &lt;- 1-(1-alpha)^n\n\nplot(p,n, xlab=\"n\", ylab=\"1-(1-alpha)^n\")\n\n\n\n\n\n\n\n\nPara enfrentar este problema seguimos dos estrategias:\n\nControlar o ajustar \\(\\alpha\\)\nCrear índices que agreguen varias variables\n\n\n\nSiguiendo a Popper (1995), definimos familias de variables y haremos el ajuste hacia adentro de estas familias. Por ejemplo, en el artículo que estudiamos de Banerjee et al. (2015), las familias son:\n\nSeguridad alimentaria\nConsumo\nActivos\nSalud mental\n\nDentro de cada familia tenemos \\(n\\) hipótesis \\(H_i\\), con un valor \\(p\\) asociado \\(p_i\\). Recordemos que \\(p_i\\) es la probabilidad de que el estadístico \\(T_i\\) exceda el valor teórico \\(t_i\\). Ordenemos las hipótesis de menor a mayor,con \\(p_1\\) siendo el valor más pequeño: \\(p_1\\leq p_2\\ldots \\leq p_n\\).\n\n\nEl método propuesto por Bonferroni controla la tasa de error por familia (FEWR por family-wise error rate) definida como la probabilidad de cometer al menos un error tipo I.\nEste método consiste en rechazar \\(H_i\\) si \\(p_i\\leq \\alpha_i\\), donde \\(\\alpha_i\\) se escoge de forma que \\(\\sum_i\\alpha_i=\\alpha\\). Usualmente se hace \\(\\alpha_i=\\frac{\\alpha}{n}\\).\nPor ejemplo, con dos tests y \\(\\alpha=0.05\\), \\(\\alpha_i^B=0.025\\).\nNoten que esta corrección es bastante conservadora.\nAlternativamente, podemos ver esta correción como crear unos valores \\(p^B\\) ajustados: \\(p_i^B=p_i\\times n\\).\n¿Por qué preocuparnos por la FWER?\nLa idea de la FWER tiene sentido si nos preocupa tener incluso un solo falso positivo. En la práctica, podemos vivir con algunos falsos positivos.\n\n\n\nEste método controla la tasa de falso descubrimiento. Si \\(V\\) es el número de falsos rechazos (cuando rechazamos la \\(H_0\\) que es verdadera) y si \\(R\\) es el número total de rechazos, entonces \\(Q=V/R\\) es la proporción de falsos rechazos.\nAl valor esperado de \\(Q\\) se le conoce como tasa de falsos rechazos (FDR por false discovery rate).\nSea \\(k\\) el más grande de los \\(i\\) tal que\n\\[p_i\\leq\\frac{i}{n}\\alpha\\] entonces la corrección consiste en rechazar todos los \\(H_i\\) para \\(i=1,2,\\ldots,k\\). En la práctica usamos R\n\n\n\nUsemos los datos del artículo de Benjamini & Hochberg (1995), que tienen 15 hipótesis y trabajan con \\(\\alpha=0.05\\):\n\ndata.pvalues&lt;-read_csv(\"../files/data_benjamini_hochberg.csv\",\n                       locale = locale(encoding = \"latin1\"))  \nn &lt;- 15\nalpha &lt;- 0.05\n\ndata.pvalues\n\n# A tibble: 15 × 2\n   poriginal hipotesis\n       &lt;dbl&gt;     &lt;dbl&gt;\n 1    0.0001         1\n 2    0.0004         2\n 3    0.0019         3\n 4    0.0095         4\n 5    0.0201         5\n 6    0.0278         6\n 7    0.0298         7\n 8    0.0344         8\n 9    0.0459         9\n10    0.324         10\n11    0.426         11\n12    0.572         12\n13    0.653         13\n14    0.759         14\n15    1             15\n\n\nSi hacemos la correción de Bonferroni:\n\ndata.bonferroni &lt;- data.pvalues %&gt;% \n  mutate(bonferroni_alpha=alpha/n) %&gt;% \n  mutate(bonferrini_rechazar=ifelse(poriginal&lt;=bonferroni_alpha,1,0))\n\ndata.bonferroni\n\n# A tibble: 15 × 4\n   poriginal hipotesis bonferroni_alpha bonferrini_rechazar\n       &lt;dbl&gt;     &lt;dbl&gt;            &lt;dbl&gt;               &lt;dbl&gt;\n 1    0.0001         1          0.00333                   1\n 2    0.0004         2          0.00333                   1\n 3    0.0019         3          0.00333                   1\n 4    0.0095         4          0.00333                   0\n 5    0.0201         5          0.00333                   0\n 6    0.0278         6          0.00333                   0\n 7    0.0298         7          0.00333                   0\n 8    0.0344         8          0.00333                   0\n 9    0.0459         9          0.00333                   0\n10    0.324         10          0.00333                   0\n11    0.426         11          0.00333                   0\n12    0.572         12          0.00333                   0\n13    0.653         13          0.00333                   0\n14    0.759         14          0.00333                   0\n15    1             15          0.00333                   0\n\n\nPero si ahora hacemos la de Benjamini & Hochberg\n\ndata.bh &lt;- data.pvalues %&gt;% \n  mutate(bh_alpha=alpha*hipotesis/n) %&gt;% \n  mutate(bh_rechazar=ifelse(poriginal&lt;=bh_alpha,1,0))\n\ndata.bh\n\n# A tibble: 15 × 4\n   poriginal hipotesis bh_alpha bh_rechazar\n       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;\n 1    0.0001         1  0.00333           1\n 2    0.0004         2  0.00667           1\n 3    0.0019         3  0.01              1\n 4    0.0095         4  0.0133            1\n 5    0.0201         5  0.0167            0\n 6    0.0278         6  0.02              0\n 7    0.0298         7  0.0233            0\n 8    0.0344         8  0.0267            0\n 9    0.0459         9  0.03              0\n10    0.324         10  0.0333            0\n11    0.426         11  0.0367            0\n12    0.572         12  0.04              0\n13    0.653         13  0.0433            0\n14    0.759         14  0.0467            0\n15    1             15  0.05              0\n\n\n\n\n\n\nOtra forma comúnmente usada de evitar el problema de las múltiples hipótesis es crear índices. Kling, Liebmand y Katz (2007) proponen el siguiente promedio de los \\(z\\)-score para generar un solo índice. Para ello, se sigue el siguiente procedimiento:\n\nDefinir las familias y las variables que componen cada familia, donde \\(y_{ij}\\) es la \\(j\\)ésima variable en la familia con \\(J\\) variables.\nDefinir las varibles \\(y_{ij}\\) de tal forma que mayores valores se interpreten como mejora.\nCrear \\(z_{ij}\\) como \\(z_{ij}=\\frac{y_{ij}-\\bar{y_j}^C}{sd(y_j)^C}\\sim(0,1)\\), es decir, estandarizar cada una de las \\(J\\) variables usando al grupo de control como referencia.\nCrear \\(z_i\\), un solo índice para cada individuo que agregue los \\(J\\) índices creados antes\n\nEl procedimiento descrito en Banerjee et al. (2015) es bastante general, pues incluye el caso donde hay varias rondas de seguimiento y varios países.\nPodemos escribir el índice descrito como:\n\\[z_i=\\frac{(\\frac{1}{J}\\sum_j z_{ij})-\\bar{z}_j^C}{sd(z_j^C)}\\]\nEsta transformación tiene la ventaja de que en la siguiente regresión de efecto de tratamiento\n\\[z_i=\\alpha+\\beta T_i + X_i'\\gamma+\\varepsilon_i\\]\nel coeficiente \\(\\beta\\) se interpreta como el efecto del tratamiento medido en desviaciones estándar con respecto a la media del grupo de control.\nNoten que todos las variables dentro de la familia pesan igual. Quizás nos gustaría tomar en cuenta la correlación entre las variables dentro del índice\n\n\nAnderson (2008) propone el siguiente índice, que puede verse como una generalización del de Kling:\n\\[\\bar{s}_i=\\frac{1}{W_{i}}\\sum_{j\\in J} w_j z_{ij}\\]\nEn este índice, \\(w_j\\) es el peso para la variable \\(j\\) y \\(W_i=\\sum_{j\\in J}w_{j}\\). Los pesos son una función de la matriz de covarianzas entre las variables que conforman la familia. Diversos software ya incluyen funciones para obtener los índices de Anderson (2008)."
  },
  {
    "objectID": "notas/múltiples-hipótesis.html#control-del-error-tipo-i",
    "href": "notas/múltiples-hipótesis.html#control-del-error-tipo-i",
    "title": "Múltiples hipótesis",
    "section": "",
    "text": "Siguiendo a Popper (1995), definimos familias de variables y haremos el ajuste hacia adentro de estas familias. Por ejemplo, en el artículo que estudiamos de Banerjee et al. (2015), las familias son:\n\nSeguridad alimentaria\nConsumo\nActivos\nSalud mental\n\nDentro de cada familia tenemos \\(n\\) hipótesis \\(H_i\\), con un valor \\(p\\) asociado \\(p_i\\). Recordemos que \\(p_i\\) es la probabilidad de que el estadístico \\(T_i\\) exceda el valor teórico \\(t_i\\). Ordenemos las hipótesis de menor a mayor,con \\(p_1\\) siendo el valor más pequeño: \\(p_1\\leq p_2\\ldots \\leq p_n\\).\n\n\nEl método propuesto por Bonferroni controla la tasa de error por familia (FEWR por family-wise error rate) definida como la probabilidad de cometer al menos un error tipo I.\nEste método consiste en rechazar \\(H_i\\) si \\(p_i\\leq \\alpha_i\\), donde \\(\\alpha_i\\) se escoge de forma que \\(\\sum_i\\alpha_i=\\alpha\\). Usualmente se hace \\(\\alpha_i=\\frac{\\alpha}{n}\\).\nPor ejemplo, con dos tests y \\(\\alpha=0.05\\), \\(\\alpha_i^B=0.025\\).\nNoten que esta corrección es bastante conservadora.\nAlternativamente, podemos ver esta correción como crear unos valores \\(p^B\\) ajustados: \\(p_i^B=p_i\\times n\\).\n¿Por qué preocuparnos por la FWER?\nLa idea de la FWER tiene sentido si nos preocupa tener incluso un solo falso positivo. En la práctica, podemos vivir con algunos falsos positivos.\n\n\n\nEste método controla la tasa de falso descubrimiento. Si \\(V\\) es el número de falsos rechazos (cuando rechazamos la \\(H_0\\) que es verdadera) y si \\(R\\) es el número total de rechazos, entonces \\(Q=V/R\\) es la proporción de falsos rechazos.\nAl valor esperado de \\(Q\\) se le conoce como tasa de falsos rechazos (FDR por false discovery rate).\nSea \\(k\\) el más grande de los \\(i\\) tal que\n\\[p_i\\leq\\frac{i}{n}\\alpha\\] entonces la corrección consiste en rechazar todos los \\(H_i\\) para \\(i=1,2,\\ldots,k\\). En la práctica usamos R\n\n\n\nUsemos los datos del artículo de Benjamini & Hochberg (1995), que tienen 15 hipótesis y trabajan con \\(\\alpha=0.05\\):\n\ndata.pvalues&lt;-read_csv(\"../files/data_benjamini_hochberg.csv\",\n                       locale = locale(encoding = \"latin1\"))  \nn &lt;- 15\nalpha &lt;- 0.05\n\ndata.pvalues\n\n# A tibble: 15 × 2\n   poriginal hipotesis\n       &lt;dbl&gt;     &lt;dbl&gt;\n 1    0.0001         1\n 2    0.0004         2\n 3    0.0019         3\n 4    0.0095         4\n 5    0.0201         5\n 6    0.0278         6\n 7    0.0298         7\n 8    0.0344         8\n 9    0.0459         9\n10    0.324         10\n11    0.426         11\n12    0.572         12\n13    0.653         13\n14    0.759         14\n15    1             15\n\n\nSi hacemos la correción de Bonferroni:\n\ndata.bonferroni &lt;- data.pvalues %&gt;% \n  mutate(bonferroni_alpha=alpha/n) %&gt;% \n  mutate(bonferrini_rechazar=ifelse(poriginal&lt;=bonferroni_alpha,1,0))\n\ndata.bonferroni\n\n# A tibble: 15 × 4\n   poriginal hipotesis bonferroni_alpha bonferrini_rechazar\n       &lt;dbl&gt;     &lt;dbl&gt;            &lt;dbl&gt;               &lt;dbl&gt;\n 1    0.0001         1          0.00333                   1\n 2    0.0004         2          0.00333                   1\n 3    0.0019         3          0.00333                   1\n 4    0.0095         4          0.00333                   0\n 5    0.0201         5          0.00333                   0\n 6    0.0278         6          0.00333                   0\n 7    0.0298         7          0.00333                   0\n 8    0.0344         8          0.00333                   0\n 9    0.0459         9          0.00333                   0\n10    0.324         10          0.00333                   0\n11    0.426         11          0.00333                   0\n12    0.572         12          0.00333                   0\n13    0.653         13          0.00333                   0\n14    0.759         14          0.00333                   0\n15    1             15          0.00333                   0\n\n\nPero si ahora hacemos la de Benjamini & Hochberg\n\ndata.bh &lt;- data.pvalues %&gt;% \n  mutate(bh_alpha=alpha*hipotesis/n) %&gt;% \n  mutate(bh_rechazar=ifelse(poriginal&lt;=bh_alpha,1,0))\n\ndata.bh\n\n# A tibble: 15 × 4\n   poriginal hipotesis bh_alpha bh_rechazar\n       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;\n 1    0.0001         1  0.00333           1\n 2    0.0004         2  0.00667           1\n 3    0.0019         3  0.01              1\n 4    0.0095         4  0.0133            1\n 5    0.0201         5  0.0167            0\n 6    0.0278         6  0.02              0\n 7    0.0298         7  0.0233            0\n 8    0.0344         8  0.0267            0\n 9    0.0459         9  0.03              0\n10    0.324         10  0.0333            0\n11    0.426         11  0.0367            0\n12    0.572         12  0.04              0\n13    0.653         13  0.0433            0\n14    0.759         14  0.0467            0\n15    1             15  0.05              0"
  },
  {
    "objectID": "notas/múltiples-hipótesis.html#creación-de-índices",
    "href": "notas/múltiples-hipótesis.html#creación-de-índices",
    "title": "Múltiples hipótesis",
    "section": "",
    "text": "Otra forma comúnmente usada de evitar el problema de las múltiples hipótesis es crear índices. Kling, Liebmand y Katz (2007) proponen el siguiente promedio de los \\(z\\)-score para generar un solo índice. Para ello, se sigue el siguiente procedimiento:\n\nDefinir las familias y las variables que componen cada familia, donde \\(y_{ij}\\) es la \\(j\\)ésima variable en la familia con \\(J\\) variables.\nDefinir las varibles \\(y_{ij}\\) de tal forma que mayores valores se interpreten como mejora.\nCrear \\(z_{ij}\\) como \\(z_{ij}=\\frac{y_{ij}-\\bar{y_j}^C}{sd(y_j)^C}\\sim(0,1)\\), es decir, estandarizar cada una de las \\(J\\) variables usando al grupo de control como referencia.\nCrear \\(z_i\\), un solo índice para cada individuo que agregue los \\(J\\) índices creados antes\n\nEl procedimiento descrito en Banerjee et al. (2015) es bastante general, pues incluye el caso donde hay varias rondas de seguimiento y varios países.\nPodemos escribir el índice descrito como:\n\\[z_i=\\frac{(\\frac{1}{J}\\sum_j z_{ij})-\\bar{z}_j^C}{sd(z_j^C)}\\]\nEsta transformación tiene la ventaja de que en la siguiente regresión de efecto de tratamiento\n\\[z_i=\\alpha+\\beta T_i + X_i'\\gamma+\\varepsilon_i\\]\nel coeficiente \\(\\beta\\) se interpreta como el efecto del tratamiento medido en desviaciones estándar con respecto a la media del grupo de control.\nNoten que todos las variables dentro de la familia pesan igual. Quizás nos gustaría tomar en cuenta la correlación entre las variables dentro del índice\n\n\nAnderson (2008) propone el siguiente índice, que puede verse como una generalización del de Kling:\n\\[\\bar{s}_i=\\frac{1}{W_{i}}\\sum_{j\\in J} w_j z_{ij}\\]\nEn este índice, \\(w_j\\) es el peso para la variable \\(j\\) y \\(W_i=\\sum_{j\\in J}w_{j}\\). Los pesos son una función de la matriz de covarianzas entre las variables que conforman la familia. Diversos software ya incluyen funciones para obtener los índices de Anderson (2008)."
  },
  {
    "objectID": "notas/index.html",
    "href": "notas/index.html",
    "title": "Notas",
    "section": "",
    "text": "LATE\nMúltiples hipótesis",
    "crumbs": [
      "Notas"
    ]
  },
  {
    "objectID": "lecturas.html",
    "href": "lecturas.html",
    "title": "Lecturas",
    "section": "",
    "text": "Las lecturas obligatorias (marcadas con “*”) permiten una discusión informada en la clase. Las lecturas que serán presentadas en exposiciones también son obligatorias y están marcadas con “+”. El resto de las lecturas no serán cubiertas en clase, pero son ampliamente recomendables. En las sesiones de exposiciones se espera que el resto de la clase tenga el conocimiento suficiente sobre el material presentado para participar en la discusión.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-1",
    "href": "lecturas.html#semana-1",
    "title": "Lecturas",
    "section": "Semana 1",
    "text": "Semana 1\n\nDiseño y econometría\n\n* Freedman, D. A. (1991). Statistical models and shoe leather. Sociological methodology, 291-313.\n* Athey, S., & Imbens, G. W. (2017). The state of applied econometrics: Causality and policy evaluation. Journal of Economic Perspectives, 31(2), 3-32.\nHeckman, J. J. (2001). Micro data, heterogeneity, and the evaluation of public policy: Nobel lecture. Journal of political Economy, 109(4), 673-748.\n\nHeckman, J. J., & Vytlacil, E. J. (2007). Econometric evaluation of social programs, part I: Causal models, structural models and econometric policy evaluation. Handbook of econometrics, 6, 4779-4874.\n\nInferencia causal\n\nGMPRV, Capítulo 3\n\n* MHE, Capítulo 2 (The Experimental Ideal)\nMT, Capítulo 4 (Potential Outcomes Model)",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-2",
    "href": "lecturas.html#semana-2",
    "title": "Lecturas",
    "section": "Semana 2",
    "text": "Semana 2\n\nEvaluación por métodos experimentales\n\n* CT, Capítulo 25, Secciones 1, 2\n\nGMPRV, Capítulo 4\n\nCT, Capítulo 25, Sección 3\n\nRevisión de métodos de regresión\n\n* MHE, Capítulo 3 (Making Regression Make Sense)\nMM, Capítulo 2 (Regression)\n\nTransparencia y replicabilidad\n\n* Christensen, G., & Miguel, E. (2018). Transparency, reproducibility, and the credibility of economics research. Journal of Economic Literature, 56(3), 920-80.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-3",
    "href": "lecturas.html#semana-3",
    "title": "Lecturas",
    "section": "Semana 3",
    "text": "Semana 3\n\nInferencia estadística\n\n* MM, Capítulo 1 (Randomized Trials), Apéndice (Mastering Inference)\nMT, Capítulo 2 (Probability and Regression Review)\n\nErrores estándar no estándar\n\nAbadie, A., Athey, S., Imbens, G. W., & Wooldridge, J. M. (2023). When should you adjust standard errors for clustering?. The Quarterly Journal of Economics, 138(1), 1-35.\n* MHE, Capítulo 8 (Nonstandard Standard Errors Issues)\nCameron, A. C., & Miller, D. L. (2015). A practitioner’s guide to cluster-robust inference. Journal of Human Resources, 50(2), 317-372.\nStock, J. H. (2010). The other transformation in econometric practice: Robust tools for inference. Journal of Economic Perspectives, 24(2), 83-94.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-4",
    "href": "lecturas.html#semana-4",
    "title": "Lecturas",
    "section": "Semana 4",
    "text": "Semana 4\n\nAplicaciones de evaluaciones experimentales\n\n+ Arceo-Gomez, E. O., & Campos-Vazquez, R. M. (2014). Race and marriage in the labor market: A discrimination correspondence study in a developing country. American Economic Review, 104(5), 376-80.\n+ Ascencio, S. J., & Chang, H. I. (2024). Do primaries improve evaluations of public officials? Experimental evidence from Mexico. Political Behavior, 1-22.\nBaird, S., McIntosh, C., & Özler, B. (2011). Cash or condition? Evidence from a cash transfer experiment. The Quarterly journal of economics, 126(4), 1709-1753.\n\n* Banerjee, A., Duflo, E., Goldberg, N., Karlan, D., Osei, R., Parienté, W., Shapiro, J., Thuysbaert, B. & Udry, C. (2015). A multifaceted program causes lasting progress for the very poor: Evidence from six countries. Science, 348(6236), 1260799.\nBlattman, C., Emeriau, M., & Fiala, N. (2018). Do anti-poverty programs sway voters? Experimental evidence from Uganda. Review of Economics and Statistics, 100(5), 891-905.\n+ Bruhn, M., Karlan, D., & Schoar, A. (2018). The impact of consulting services on small and medium enterprises: Evidence from a randomized trial in Mexico. Journal of Political Economy, 126(2), 635-687.\n+ Davies, E., Deffebach, P., Iacovone, L., & Mckenzie, D. (2024). Training microentrepreneurs over Zoom: Experimental evidence from Mexico. Journal of Development Economics, 167, 103244.\n+ De La O, A. L., Fernández-Vázquez, P. & García, F. M. (2023). Federal and state audits do not increase compliance with a grant program to improve municipal infrastructure: A pre-registered field experiment. Journal of Development Economics, 162, 103043.\nDuflo, E., Dupas, P., & Kremer, M. (2015). Education, HIV, and early fertility: Experimental evidence from Kenya. American Economic Review, 105(9), 2757-97.\n\nDupas, P. (2011). Do teenagers respond to HIV risk information? Evidence from a field experiment in Kenya. American Economic Journal: Applied Economics, 3(1), 1-34.\n\n+ Gertler, P. (2004). Do conditional cash transfers improve child health? Evidence from PROGRESA’s control randomized experiment. American economic review, 94(2), 336-341.\n+ Hoyos, R. D., Attanasio, O., & Meghir, C. (2024). Targeting high school scholarships to the poor: the impact of a program in Mexico. Economic Development and Cultural Change, 72(4), 1747-1768.\nLondoño-Vélez, J., & Querubin, P. (2022). The Impact of Emergency Cash Assistance in a Pandemic: Experimental Evidence from Colombia. The Review of Economics and Statistics, 1-27\nMartínez A, C., Puentes, E., & Ruiz-Tagle, J. (2018). The effects of micro-entrepreneurship programs on labor market performance: experimental evidence from Chile. American Economic Journal: Applied Economics, 10(2), 101-24.\nMousa, S. (2020). Building social cohesion between Christians and Muslims through soccer in post-ISIS Iraq. Science, 369(6505), 866-870.\n\nPoertner, M. (2023). Does Political Representation Increase Participation? Evidence from Party Candidate Lotteries in Mexico. American Political Science Review, 117(2), 537-556.\n+ Sadka, J., Seira, E., & Woodruff, C. (2024). Information and Bargaining through Agents: Experimental Evidence from Mexico’s Labour Courts. Review of Economic Studies, rdae003.\n+ Seira, E., Elizondo, A., & Laguna-Müggenburg, E. (2017). Are information disclosures effective? evidence from the credit card market. American Economic Journal: Economic Policy, 9(1), 277-307.\n\n+ Tagliati, F. (2022). Welfare effects of an in-kind transfer program: Evidence from Mexico. Journal of Development Economics, 154, 102753.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-5",
    "href": "lecturas.html#semana-5",
    "title": "Lecturas",
    "section": "Semana 5",
    "text": "Semana 5\n\nLATE y variables instrumentales\n\nCT, Capítulo 25, Sección 7\n\nGMPRV, Capítulo 5\n\nMHE, Capítulo 4 (Instrumental Variables in Action)\n\n* MM, Capítulo 3 (Instrumental Variables)\nMT, Capítulo 7 (Instrumental Variables)\n\nCorrección por prueba de múltiples hipótesis\n\n* Angelucci, M., Karlan, D., & Zinman, J. (2015). Microcredit impacts: Evidence from a randomized microcredit program placement experiment by Compartamos Banco. American Economic Journal: Applied Economics, 7(1), 151-82.\n* Benjamini, Y., & Hochberg, Y. (1995). Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the royal statistical society. Series B (Methodological), 289-300.\n\nBrodeur, A., Lé, M., Sangnier, M., & Zylberberg, Y. (2016). Star Wars: The empirics strike back. American Economic Journal: Applied Economics, 8(1), 1-32.\n\nSavin, N. E. (1984). Multiple hypothesis testing. Handbook of econometrics, 2, 827-879.\n\n* Shaffer, J. P. (1995). Multiple hypothesis testing. Annual review of psychology, 46(1), 561-584.\n\nANCOVA\n\n* McKenzie, D. (2012). Beyond baseline and follow-up: The case for more T in experiments. Journal of development Economics, 99(2), 210-221.\nRojas Valdes, R.I., Wydick, B., & Lybbert, T.J. (2021). Can Hope Elevate Microfinance? Evidence from Oaxaca, Mexico. Oxford Economic Papers.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-6",
    "href": "lecturas.html#semana-6",
    "title": "Lecturas",
    "section": "Semana 6",
    "text": "Semana 6\n\nAplicaciones LATE\n\nAngrist, J. D. (1990). Lifetime earnings and the Vietnam era draft lottery: evidence from social security administrative records. The American Economic Review, 313-336.\n\n* Angrist, J. D. (2006). Instrumental variables methods in experimental criminological research: what, why and how. Journal of Experimental Criminology, 2(1), 23-44.\n\nAngrist, J. D., Imbens, G., & Rubin, D. B. (1996). Identification of causal effects using instrumental variables. Journal of the American statistical Association, 91(434), 444-455.\n\n* Crépon, B., Devoto, F., Duflo, E., & Parienté, W. (2015). Estimating the impact of microcredit on those who take it up: Evidence from a randomized experiment in Morocco. American Economic Journal: Applied Economics, 7(1), 123-50.\n\nDevoto, F., Duflo, E., Dupas, P., Parienté, W., & Pons, V. (2012). Happiness on tap: Piped water adoption in urban Morocco. American Economic Journal: Economic Policy, 4(4), 68-99.\n+ De La O, A. L. (2013). Do conditional cash transfers affect electoral behavior? Evidence from a randomized experiment in Mexico. American Journal of Political Science, 57(1), 1-14.\n\n+ Gonzalez-Navarro, M., & Quintana-Domeque, C. (2016). Paving streets for the poor: Experimental analysis of infrastructure effects. Review of Economics and Statistics, 98(2), 254-267.\nHeckman, J. J., & Vytlacil, E. J. (2007). Econometric evaluation of social programs, part II: Using the marginal treatment effect to organize alternative econometric estimators to evaluate social programs, and to forecast their effects in new environments. Handbook of econometrics, 6, 4875-5143.\n\nImbens, G. W., & Angrist, J. D. (1994). Identification and estimation of local average treatment effects. Econometrica (1986-1998), 62(2), 467.\nKling, J. R., Liebman, J. B., & Katz, L. F. (2007). Experimental analysis of neighborhood effects. Econometrica, 75(1), 83-119.\n\nDiferencia en diferencias\n\nCT, Capítulo 25, Sección 25.5\nGMPRV, Capítulo 7\n\n* MM, Capítulo 5 (Differences-in-differences)\nMT, Capítulo 9 (Difference in differences), secciones 1 a 5",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-7",
    "href": "lecturas.html#semana-7",
    "title": "Lecturas",
    "section": "Semana 7",
    "text": "Semana 7\n\nDID desfasado\n\n* MT, Capítulo 9 (Difference in differences), sección 9.6\nBaker, A. C., Larcker, D. F., & Wang, C. C. (2022). How much should we trust staggered difference-in-differences estimates?. Journal of Financial Economics, 144(2), 370-395.\nCallaway, B., & Sant’Anna, P. H. (2021). Difference-in-differences with multiple time periods. Journal of Econometrics, 225(2), 200-230.\nGoodman-Bacon, A. (2021). Difference-in-differences with variation in treatment timing. Journal of Econometrics, 225(2), 254-277.\nMarcus, M., & Sant’Anna, P. H. (2021). The role of parallel trends in event study settings: An application to environmental economics. Journal of the Association of Environmental and Resource Economists, 8(2), 235-275.\n* Roth, J., Sant’Anna, P. H., Bilinski, A., & Poe, J. (2023). What’s Trending in Difference-in-Differences? A Synthesis of the Recent Econometrics Literature. Journal of Econometrics, 235(2), 2218-2244.\n\nMétodos de pareamiento\n\nGMPRV, Capítulo 8\n* MH, Capítulo 3, Sección 3.3\n* MT, Capítulo 5\n\nAplicaciones del PSM\n\nAbadie, A., & Imbens, G. W. (2016). Matching on the estimated propensity score. Econometrica, 84(2), 781-807.\n\nAngrist, J., Estimating the Labor Market Impact of Voluntary Military Service Using Social Security Data on Military Applicants, Econometrica 66(2), 1998, 249-288.\n+ Becerril, J., & Abdulai, A. (2010). The impact of improved maize varieties on poverty in Mexico: a propensity score-matching approach. World development, 38(7), 1024-1035.\n* Caliendo, M., & Kopeinig, S. (2008). Some practical guidance for the implementation of propensity score matching. Journal of economic surveys, 22(1), 31-72.\n\n+ Chang, A., Miranda-Moreno, L., Cao, J., & Welle, B. (2017). The effect of BRT implementation and streetscape redesign on physical activity: A case study of Mexico City. Transportation Research Part A: Policy and Practice, 100, 337-347.\n\n* Dehejia, R. H., & Wahba, S. (1999). Causal effects in nonexperimental studies: Reevaluating the evaluation of training programs. Journal of the American statistical Association, 94(448), 1053-1062.\n+ Diaz, J. J., & Handa, S. (2006). An assessment of propensity score matching as a nonexperimental impact estimator evidence from Mexico’s PROGRESA program. Journal of human resources, 41(2), 319-345.\n+ Espinosa, V., & Rubin, D. B. (2015). Did the military interventions in the Mexican drug war increase violence?. The American Statistician, 69(1), 17-27.\n+ García-Díaz, R., Sosa-Rubí, S. G., Serván-Mori, E., & Nigenda, G. (2018). Welfare effects of health insurance in Mexico: The case of Seguro Popular de Salud. PloS one, 13(7), e0199876.\n\n* LaLonde, R. J. (1986). Evaluating the econometric evaluations of training programs with experimental data. The American economic review, 604-620.\nWellalage, N. H., & Locke, S. (2020). Remittance and financial inclusion in refugee migrants: inverse probability of treatment weighting using the propensity score. Applied Economics, 52(9), 929-950.\n+ Stabridis, O., & Salgado-Viveros, C. (2023). Efectos de género y etnicidad en la brecha salarial entre jornaleros agrícolas del noroeste mexicano. Frontera Norte, 35.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-9",
    "href": "lecturas.html#semana-9",
    "title": "Lecturas",
    "section": "Semana 9",
    "text": "Semana 9\n\nAplicaciones de DID\n\n* Bertrand, M., Duflo, E., & Mullainathan, S. (2004). How much should we trust differences-in-differences estimates? The Quarterly journal of economics, 119(1), 249-275.\n+ Boruchowicz, C., Parker, S. W., & Robbins, L. (2022). Time use of youth during a pandemic: Evidence from Mexico. World Development, 149, 105687.\n+ Cabrera-Hernández, F., Padilla-Romo, M., & Peluffo, C. (2023). Full-time schools and educational trajectories: Evidence from high-stakes exams. Economics of Education Review, 96, 102443.\nCampos, R. M., Esquivel, G., & Santillán, A. S. (2017). El impacto del salario mínimo en los ingresos y el empleo en México. Revista CEPAL.\n* Card, D. (1990). The impact of the Mariel boatlift on the Miami labor market. ILR Review, 43(2), 245-257.\n+ Chort, I., & Öktem, B. (2024). Agricultural shocks, coping policies and deforestation: Evidence from the coffee leaf rust epidemic in Mexico. American Journal of Agricultural Economics, 106(3), 1020-1057.\n+ Djourelova, M. (2023). Persuasion through Slanted Language: Evidence from the Media Coverage of Immigration. American Economic Review, 113(3), 800-835.\n+ Conti, G., & Ginja, R. (2023). Who Benefits from Free Health Insurance?: Evidence from Mexico. Journal of Human Resources, 58(1), 146-182.\n* Card, D., & Krueger, A. B. (2000). Minimum wages and employment: a case study of the fast-food industry in New Jersey and Pennsylvania: reply. American Economic Review, 0(5), 1397-1420.\nChen, H., Qian, W., & Wen, Q. (2021). The impact of the COVID-19 pandemic on consumption: Learning from high-frequency transaction data. AEA Papers and Proceedings, 111, 307-11.\n+ Clarke, D., & Mühlrad, H. (2021). Abortion laws and women’s health. Journal of Health Economics, 76, 102413.\n+ Gutiérrez Vázquez, E. Y., & Parrado, E. A. (2016). Abortion legalization and childbearing in Mexico. Studies in family planning, 47(2), 113-128.\n\nQian, N. (2008). Missing women and the price of tea in China: The effect of sex-specific earnings on sex imbalance. The Quarterly Journal of Economics, 123(3), 1251-1285.\nWolfers, J. (2006). Did unilateral divorce laws raise divorce rates? A reconciliation and new results. American Economic Review, 96(5), 1802-1820.\nZhang, R., Li, Y., Zhang, A. L., Wang, Y., & Molina, M. J. (2020). Identifying airborne transmission as the dominant route for the spread of COVID-19. Proceedings of the National Academy of Sciences.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-10",
    "href": "lecturas.html#semana-10",
    "title": "Lecturas",
    "section": "Semana 10",
    "text": "Semana 10\n\nDiseños con discontinuidades\n\nGMPRV, Capítulo 6\n\nDiscontinuidades nítidas y difusas\n\nMHE, Capítulo 6\n\n* MM, Capítulo 4\n* MT, Capítulo 6",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-11",
    "href": "lecturas.html#semana-11",
    "title": "Lecturas",
    "section": "Semana 11",
    "text": "Semana 11\n\nAplicaciones de diseños con discontinuidades\n\nAbdulkadiroğlu, A., Angrist, J., & Pathak, P. (2014). The elite illusion: Achievement effects at Boston and New York exam schools. Econometrica, 82(1), 137-196.\n+ Aguilar, A., Gutierrez, E., & Seira, E. (2021). The effectiveness of sin food taxes: Evidence from Mexico. Journal of Health Economics, 77, 102455.\n+ Alix-Garcia, J., McIntosh, C., Sims, K. R., & Welch, J. R. (2013). The ecological footprint of poverty alleviation: evidence from Mexico’s Oportunidades program. Review of Economics and Statistics, 95(2), 417-435.\nAnagol, S., & Fujiwara, T. (2016). The runner-up effect. Journal of Political Economy, 124(4), 927-991.\nAngrist, J. D., & Lavy, V. (1999). Using Maimonides’ rule to estimate the effect of class size on scholastic achievement. The Quarterly Journal of Economics, 114(2), 533-575.\nBagues, M., & Campa, P. (2021). Can gender quotas in candidate lists empower women? Evidence from a regression discontinuity design. Journal of Public Economics, 194, 104315.\nBosch, M., & Schady, N. (2019). The effect of welfare payments on work: Regression discontinuity evidence from Ecuador. Journal of Development Economics, 139, 17-27.\n\nCalonico, S., Cattaneo, M. D., Farrell, M. H., & Titiunik, R. (2019). Regression discontinuity designs using covariates. Review of Economics and Statistics, 101(3), 442-451.\n\n+ Cañedo, A. P., Fabregas, R., & Gupta, P. (2023). Emergency cash transfers for informal workers: Impact evidence from Mexico. Journal of Public Economics, 219, 104820.\nCard, D., Dobkin, C., & Maestas, N. (2009). Does Medicare save lives? The quarterly journal of economics, 124(2), 597-636.\n\nCarpenter, C., & Dobkin, C. (2009). The effect of alcohol consumption on mortality: regression discontinuity evidence from the minimum drinking age. American Economic Journal: Applied Economics, 1(1), 164-82.\n\nCook, T. D., & Wong, V. C. (2008). Empirical tests of the validity of the regression discontinuity design. Annales d’Economie et de Statistique, 127-150.\n\n+ Davis, L. W. (2008). The effect of driving restrictions on air quality in Mexico City. Journal of Political Economy, 116(1), 38-81.\n\n+ Davis, L. W. (2017). Saturday driving restrictions fail to improve air quality in Mexico City. Scientific Reports, 7, 41652.\n+ Del Valle, A., de Janvry, A., & Sadoulet, E. (2020). Rules for recovery: Impact of indexed disaster funds on shock coping in Mexico. American Economic Journal: Applied Economics, 12(4), 164-95.\n+ Del Valle, A. (2024). Saving Lives with Indexed Disaster Funds: Evidence from Mexico. American Economic Journal: Economic Policy, 16(2), 442-479.\n+ Dell, M. (2015). Trafficking networks and the Mexican drug war. American Economic Review, 105(6), 1738-79.\n+ Goodwin, M. B., Gonzalez, F., & Fontenla, M. (2024). The impact of daylight saving time in Mexico. Applied Economics, 56(1), 22-32.\n* Lee, D. S., & Lemieux, T. (2010). Regression discontinuity designs in economics. Journal of economic literature, 48(2), 281-355.\nMacPherson, C., & Sterck, O. (2021). Empowering refugees through cash and agriculture: A regression discontinuity design. Journal of Development Economics, 149, 102614.\nMakarin, A., Pique, R., & Aragón, F. (2020). National or sub-national parties: Does party geographic scope matter? Journal of Development Economics, 102516.\n\n* Manacorda, M., Miguel, E., & Vigorito, A. (2011). Government transfers and political support. American Economic Journal: Applied Economics, 3(3), 1-28.\n\nMoussa, W., Salti, N., Irani, A., Al Mokdad, R., Jamaluddine, Z., Chaaban, J., & Ghattas, H. (2022). The impact of cash transfers on Syrian refugee children in Lebanon. World Development, 150, 105711.\n+ Sierra, G. D. R., Martínez, A. A. G., Cruz, M. Á. M., & Barrientos, L. G. Z. (2024). The impact of subsidies on house prices in Mexico’s mortgage market for low-income households 2008–2019. Journal of Housing Economics, 63, 101970.\nSohn, H., & Lee, S. W. (2019). Causal Impact of Having a College Degree on Women’s Fertility: Evidence From Regression Kink Designs. Demography, 56(3), 969-990.\nTakaku, R., & Yokoyama, I. (2021). What the COVID-19 school closure left in its wake: evidence from a regression discontinuity analysis in Japan. Journal of Public Economics, 195, 104364.\nTuttle, C. (2019). Snapping Back: Food Stamp Bans and Criminal Recidivism. American Economic Journal: Economic Policy, 11(2), 301-27.\n\nAplicaciones de discontinuidades geográficas\n\nGonzalez, R. M. (2021). Cell Phone Access and Election Fraud: Evidence from a Spatial Regression Discontinuity Design in Afghanistan. American Economic Journal: Applied Economics, 13(2), 1-51.\n* Keele, L. J., & Titiunik, R. (2015). Geographic boundaries as regression discontinuities. Political Analysis, 23(1), 127-155.\nKeele, L., & Titiunik, R. (2016). Natural experiments based on geography. Political Science Research and Methods, 4(1), 65-95.\n\nPliegues en la regresión\n\nGamba, S., Jakobsson, N., & Svensson, M. (2022). The impact of cost-sharing on prescription drug demand: evidence from a double-difference regression kink design. The European Journal of Health Economics, 1-9.\nCard, D., Lee, D. S., Pei, Z., & Weber, A. (2017). Regression kink design: Theory and practice. NBER Working Paper 22781.\n\nLurie, I. Z., Sacks, D. W., & Heim, B. (2021). Does the individual mandate affect insurance coverage? Evidence from tax returns. American Economic Journal: Economic Policy, 13(2), 378-407.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-12",
    "href": "lecturas.html#semana-12",
    "title": "Lecturas",
    "section": "Semana 12",
    "text": "Semana 12\n\nControl sintético\n\n* MT, Capítulo 10\n* Abadie, A. (2019). Using synthetic controls: Feasibility, data requirements, and methodological aspects. Journal of Economic Literature.\n* Abadie, A., Diamond, A., & Hainmueller, J. (2010). Synthetic control methods for comparative case studies: Estimating the effect of California’s tobacco control program. Journal of the American statistical Association, 105(490), 493-505.\n+ Abadie, A., Diamond, A., & Hainmueller, J. (2015). Comparative politics and the synthetic control method. American Journal of Political Science, 59(2), 495-510.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-13",
    "href": "lecturas.html#semana-13",
    "title": "Lecturas",
    "section": "Semana 13",
    "text": "Semana 13\n\nAplicaciones de control sintético\n\nAbsher, S., Grier, K., & Grier, R. (2020). The economic consequences of durable left-populist regimes in Latin America. Journal of Economic Behavior & Organization, 177, 787-817.\n\n* Acemoglu, D., Johnson, S., Kermani, A., Kwak, J., & Mitton, T. (2016). The value of connections in turbulent times: Evidence from the United States. Journal of Financial Economics, 121(2), 368-391.\nAlfano, V., Ercolano, S., & Cicatiello, L. (2021). School openings and the COVID-19 outbreak in Italy. A provincial-level analysis using the synthetic control method. Health Policy.\nArkhangelsky, D., Athey, S., Hirshberg, D. A., Imbens, G. W., & Wager, S. (2021). Synthetic difference-in-differences. American Economic Review, 111(12), 4088-4118.\n+ Boly, M., & Sanou, A. (2022). Biofuels and food security: Evidence from Indonesia and Mexico. Energy Policy, 163, 112834.\nBotosaru, I., & Ferman, B. (2019). On the role of covariates in the synthetic control method. The Econometrics Journal, 22(2), 117-130.\n\nCalderón, G., Robles, G., Díaz-Cayeros, A., & Magaloni, B. (2015). The beheading of criminal organizations and the dynamics of violence in Mexico. Journal of Conflict Resolution, 59(8), 1455-1485.\n\n+ Campos-Vazquez, R. M., & Esquivel, G. (2020). The effect of doubling the minimum wage and decreasing taxes on inflation in Mexico. Economics Letters, 109051.\n\n+ Campos-Vazquez, R. M., & Esquivel, G. (2023). The Effect of the Minimum Wage on Poverty: Evidence from a Quasi-Experiment in Mexico. The Journal of Development Studies, 59(3), 360-380.\n+ Cepeda-Francese, C. A., & Ramírez-Álvarez, A. A. (2023). Reforming justice under a security crisis: The case of the criminal justice reform in Mexico. World Development, 163, 106148.\nGeloso, V., & Pavlik, J. B. (2021). The Cuban revolution and infant mortality: A synthetic control approach. Explorations in Economic History, 80, 101376.\nGrier, K., & Maynard, N. (2016). The economic consequences of Hugo Chavez: A synthetic control analysis. Journal of Economic Behavior & Organization, 125, 1-21.\n+ González-Rozada, M., & Ruffo, H. (2024). Do trade agreements contribute to the decline in labor share? Evidence from Latin American countries. World Development, 177, 106561.\nMitze, T., Kosfeld, R., Rode, J., & Wälde, K. (2020). Face masks considerably reduce COVID-19 cases in Germany. Proceedings of the National Academy of Sciences, 117(51), 32293-32301.\nPeri, G., & Yasenov, V. (2019). The Labor Market Effects of a Refugee Wave Synthetic Control Method Meets the Mariel Boatlift. Journal of Human Resources, 54(2), 267-309.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-14",
    "href": "lecturas.html#semana-14",
    "title": "Lecturas",
    "section": "Semana 14",
    "text": "Semana 14\n\nAprendizaje automático y big data\n\nAthey, S. (2017). Beyond prediction: Using big data for policy problems. Science, 355(6324), 483-485.\n\n* Athey, S., & Imbens, G. W. (2019). Machine learning methods that economists should know about. Annual Review of Economics, 11.\n+ Baiardi, A., & Naghi, A. A. (2021). The value added of machine learning to causal inference: Evidence from revisited studies. arXiv preprint arXiv:2101.00878.\nChetty, R. (2021). Improving equality of opportunity: New insights from big data. Contemporary Economic Policy, 39(1), 7-41.\nChernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W., & Robins, J. (2018). Double/debiased machine learning for treatment and structural parameters. Econometrics Journal, 21(1), pp. C1–C68.\n+ Chernozhukov, V., Demirer, M., Duflo, E., & Fernandez-Val, I. (2018). Generic machine learning inference on heterogeneous treatment effects in randomized experiments, with an application to immunization in India. Woring Paper No. w24678. National Bureau of Economic Research.\nCole, M. A., Elliott, R. J., & Liu, B. (2020). The impact of the Wuhan Covid-19 lockdown on air pollution and health: a machine learning and augmented synthetic control approach. Environmental and Resource Economics, 76(4), 553-580.\nDell, M. (2024). Deep Learning for Economists. arXiv preprint arXiv:2407.15339.\nNaimi, A. I., Mishler, A. E., & Kennedy, E. H. (2017). Challenges in obtaining valid causal effect estimates with machine learning algorithms. ArXiv preprint 1711.07137.\nStorm, H., Baylis, K., & Heckelei, T. (2020). Machine learning in agricultural and applied economics. European Review of Agricultural Economics, 47(3), 849-892.\nTorrats-Espinosa, G. (2021). Using machine learning to estimate the effect of racial segregation on COVID-19 mortality in the United States. Proceedings of the National Academy of Sciences, 118(7).\n+ Wager, S., & Athey, S. (2018). Estimation and inference of heterogeneous treatment effects using random forests. Journal of the American Statistical Association, 113(523), 1228-1242.\n* Varian, H. R. (2014). Big data: New tricks for econometrics. Journal of Economic Perspectives, 28(2), 3-28",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#otras-lecturas-sobre-temas-no-cubiertos-en-el-curso",
    "href": "lecturas.html#otras-lecturas-sobre-temas-no-cubiertos-en-el-curso",
    "title": "Lecturas",
    "section": "Otras lecturas sobre temas no cubiertos en el curso",
    "text": "Otras lecturas sobre temas no cubiertos en el curso\n\nMás allá de los experimentos\n\nBarrett, C. B., & Carter, M. R. (2010). The power and pitfalls of experiments in development economics: Some non-random reflections. Applied economic perspectives and policy, 32(4), 515-548.\n\nBarrett, C. B., & Carter, M. R. (2020). Finding our balance? Revisiting the randomization revolution in development economics ten years further on. World Development, 127, 104789.\n\nHjort, J., Moreira, D., Rao, G., & Santini, J. F. (2021). How research affects policy: Experimental evidence from 2,150 Brazilian municipalities. American Economic Review, 111(5), 1442-80.\nDeaton, A., Case. (2019). Randomization in the tropics revisited: a theme and eleven variations. In Randomized controlled trials in the field of development: A critical perspective. Oxford University Press. Forthcoming.\n\nRavallion, Martin. (2020). Should the randomistas (continue to) rule? National Bureau of Economic Research, Working Paper 27554.\n\nModelos estructurales en evaluación\n\nAbbring, J. H., & Heckman, J. J. (2007). Econometric evaluation of social programs, part III: Distributional treatment effects, dynamic treatment effects, dynamic discrete choice, and general equilibrium policy evaluation. Handbook of econometrics, 6, 5145-5303.\n\nAttanasio, O. P., Meghir, C., & Santiago, A. (2011). Education choices in Mexico: using a structural model and a randomized experiment to evaluate Progresa. The Review of Economic Studies, 79(1), 37-66.\n\nDuflo, E., Hanna, R., & Ryan, S. P. (2012). Incentives work: Getting teachers to come to school. American Economic Review, 102(4), 1241-78.}\nHamilton, B. H., Hincapié, A., Miller, R. A., & Papageorge, N. W. (2018). Innovation and Diffusion of Medical Treatment. National Bureau of Economic Working Paper 24577.\n\nKeane, M. P. (2010). A structural perspective on the experimentalist school. Journal of Economic Perspectives, 24(2), 47-58.\nKeane, M. P., Todd, P. E., & Wolpin, K. I. (2011). The structural estimation of behavioral models: Discrete choice dynamic programming methods and applications. In Handbook of labor economics (Vol. 4, pp. 331-461). Elsevier.\n\nLow, H., & Meghir, C. (2017). The use of structural models in econometrics. Journal of Economic Perspectives, 31(2), 33-58.\nMa, X., Lawell, C. Y. L., & Rozelle, S. (2020). Peer effects and the use of subsidized goods: A structural econometric model of a health promotion program in rural China. Working paper, Cornell University.\n\nNevo, A., & Whinston, M. D. (2010). Taking the dogma out of econometrics: Structural modeling and credible inference. Journal of Economic Perspectives, 24(2), 69-82.\n\nTodd, P. E., & Wolpin, K. I. (2010). Structural estimation and policy evaluation in developing countries. Annu. Rev. Econ., 2(1), 21-50.\nWolpin, K. I. (2013). The limits of inference without theory. MIT Press.\n\nEvaluaciones de impacto a nivel de economía local (LEWIE)\n\nTaylor, J. E., Dyer, G. A., Stewart, M., Yunez-Naude, A., & Ardila, S. (2003). The economics of ecotourism: A Galápagos Islands economy-wide perspective. Economic Development and Cultural Change, 51(4), 977-997.\nTaylor, J. E., & Filipski, M. J. (2014). Beyond experiments in development economics: Local economy-wide impact evaluation. Oxford University Press.\nTaylor, J. E., Filipski, M. J., Alloush, M., Gupta, A., Rojas Valdes, R.I., & Gonzalez-Estrada, E. (2016). Economic impact of refugees. Proceedings of the National Academy of Sciences, 201604566.\n\nCombinación de metodologías no experimentales\n\nCattaneo, M. D., Frandsen, B. R., & Titiunik, R. (2015). Randomization inference in the regression discontinuity design: An application to party advantages in the US Senate. Journal of Causal Inference, 3(1), 1-24.\n\nDonohue III, J. J., & Ho, D. E. (2007). The Impact of Damage Caps on Malpractice Claims: Randomization Inference with Difference‐in‐Differences. Journal of Empirical Legal Studies, 4(1), 69-102.\n\nKeele, L., Titiunik, R., & Zubizarreta, J. R. (2015). Enhancing a geographic regression discontinuity design through matching to estimate the effect of ballot initiatives on voter turnout. Journal of the Royal Statistical Society. Series A (Statistics in Society), 223-239.\n\nLevasseur, P. (2019). Can social programs break the vicious cycle between poverty and obesity? Evidence from urban Mexico. World Development, 113, 143-156.\n\nMacKinnon, J. G., & Webb, M. D. (2020). Randomization inference for difference-in-differences with few treated clusters. Journal of Econometrics.\n\nParker, S. W., Saenz, J., & Wong, R. (2018). Health insurance and the aging: Evidence from the Seguro Popular program in Mexico. Demography, 55(1), 361-386.\nSant’Anna, P. H., & Zhao, J. (2020). Doubly robust difference-in-differences estimators. Journal of Econometrics, 219(1), 101-122.\n\nImpactos de largo plazo\n\nAthey, S., Chetty, R., Imbens, G. W., & Kang, H. (2019). The surrogate index: Combining short-term proxies to estimate long-term treatment effects more rapidly and precisely, National Bureau of Economic Research, Working Paper 26463.\nHamory, J., Miguel, E., Walker, M., Kremer, M., & Baird, S. (2021). Twenty-year economic impacts of deworming. Proceedings of the National Academy of Sciences, 118(14).\nDupas, P., Duflo, E. & Kremer, M. (2021). The Impact of Free Secondary Education: Experimental Evidence from Ghana. Stanford University Working Paper.\n\nParker, S. W., & Vogl, T. (2018). Do conditional cash transfers improve economic outcomes in the next generation? Evidence from Mexico (No. w24303). National Bureau of Economic Research.\n\nEtica\n\nHumphreys, M. (2015). Reflections on the ethics of social experimentation. Journal of Globalization and Development, 6(1), 87-112.\nLewis, J. (2020). Experimental Design: Ethics, Integrity, and the Scientific Method. Handbook of Research Ethics and Scientific Integrity, 459-474.\nRayzberg, M. S. (2019). Fairness in the field: The ethics of resource allocation in randomized controlled field experiments. Science, Technology, & Human Values, 44(3), 371-398.\n\nCredibilidad e inferencia estadística\n\nAmrhein, V., Greenland, S., & McShane, B. (2019). Scientists rise up against statistical significance. Nature. 567, 305-307.\n\nAngrist, J. D., & Pischke, J. S. (2010). The credibility revolution in empirical economics: How better research design is taking the con out of econometrics. Journal of economic perspectives, 24(2), 3-30.\n\nGreenland, S., Senn, S. J., Rothman, K. J., Carlin, J. B., Poole, C., Goodman, S. N., & Altman, D. G. (2016). Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations. European journal of epidemiology, 31(4), 337-350.\nLeamer, E. E. (1983). Let’s take the con out of econometrics. The American Economic Review, 73(1), 31-43.\nLeamer, E. E. (2010). Tantalus on the Road to Asymptopia. Journal of Economic Perspectives, 24(2), 31-46.\nNuzzo, R. (2014). Scientific method: statistical errors. Nature News, 506(7487), 150.\nSims, C. A. (2010). But economics is not an experimental science. Journal of Economic Perspectives, 24(2), 59-68.\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129-133.\n\nInferencia por aleatorización\n\nAbadie, A., Athey, S., Imbens, G. W., & Wooldridge, J. M. (2020). Sampling‐Based versus Design‐Based Uncertainty in Regression Analysis. Econometrica, 88(1), 265-296.\n\nAthey, S., & Imbens, G. W. (2017). The econometrics of randomized experiments. In Handbook of economic field experiments (Vol. 1, pp. 73-140). North-Holland.\n\nHo, D. E., & Imai, K. (2006). Randomization inference with natural experiments: An analysis of ballot effects in the 2003 California recall election. Journal of the American Statistical Association, 101(475), 888-900.\n\nKerwin, J. T., & Thornton, R. L. (2020). Making the grade: The sensitivity of education program effectiveness to input choices and outcome measures. Review of Economics and Statistics, 1-45.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "diapositivas/index.html",
    "href": "diapositivas/index.html",
    "title": "Diapositivas",
    "section": "",
    "text": "Introducción del curso\nInferencia causal\nDiseños experimentales\nRegresión\nInferencia estadística\nErrores estándar e inferencia\nBootstrap\nLATE y variables instrumentales\nMúltiples hipótesis\nDiferencia en diferencias\nEmparejamiento\nDiscontinuidades",
    "crumbs": [
      "Diapositivas"
    ]
  },
  {
    "objectID": "cronograma.html",
    "href": "cronograma.html",
    "title": "Cronograma",
    "section": "",
    "text": "El siguiente cronograma es informativo sobre la organización del curso:",
    "crumbs": [
      "Cronograma"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Inferencia Causal",
    "section": "",
    "text": "Profesor: Irvin Rojas (irvin.rojas@cide.edu).\nHorario de clases: martes (8:00 a 11:10).\nPlataforma del curso: Microsoft Teams.\nHorario de oficina: martes y jueves (18:00 a 19:00).\n\n¡Bienvenidas, bienvenidos!\nEste es un sitio para las y los estudiantes del curso de Inferencia Causal de la Maestría en Economía del CIDE. Sin embargo, otras personas pueden encontrar útiles los recursos de este sitio, como el programa del curso, las tareas y la lista de lecturas.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "materiales.html",
    "href": "materiales.html",
    "title": "Materiales",
    "section": "",
    "text": "Datasets\nSlides"
  },
  {
    "objectID": "notas/late.html",
    "href": "notas/late.html",
    "title": "LATE",
    "section": "",
    "text": "En esta nota se presenta la derivación del Local Average Treatment Effect (LATE) de acuerdo con Angrist, Imbens & Rubin (1996)\nFrecuentemente nos encontraremos con intervenciones donde la aleatorización ocurre de manera íntegra, pero no todos aquellos asignados a cierto tratamiento efectivamente lo reciben.\nConsideraremos la diferencia entre ser asignado al tratamiento y recibir el tratamiento pues, por ejemplo, al evaluar un programa que asigna aleatoriamente a niños a escuelas de prestigio, nos interesa el efecto de efectivamente asistir a dichas escuelas y, quizás no tanto, el efecto de haber sido sorteado para asistir a dichas escuelas por medio de un experimento.\nUsaremos un estimador de variables instrumentales (VI) para relacionar los efectos de la asignación con los efectos de la adopción. El resultado principal al que llegaremos es el siguiente:\n\\[\\text{Efecto de la asignación en } Y=(\\text{Efecto de la asignación en la adopción})\\times (\\text{Efecto de la adopción en }Y)\\]\nPor tanto:\n\\[\\text{Efecto de la adopción en }Y=\\frac{\\text{Efecto de la asignación en }Y}{\\text{Efecto de las asignación en la adopción}}\\]\nAhora derivaremos formalmente este resultado, pero la intuición es importante: el efecto causal de la adopción es el efecto de la asignación, escalado por el efecto de la asignación en la adopción\n\n\nConsideremos, para la asignación y el cumplimiento, las dos posibles situaciones:\nAsignación: \\(Z_i=\\begin{cases} 1 \\\\0 \\\\ \\end{cases}\\)\nCumplimiento: \\(D_i=\\begin{cases} 1 \\\\0 \\\\ \\end{cases}\\)\nSi \\(Y_i\\) variable de resultados, nos importa el efecto de \\(D_i\\) sobre \\(Y_i\\).\n\\(D_i(Z)\\) es el indicador de cumplir, dada la asignación \\(Z\\), por lo que con cumplimiento perfecto tendríamos \\(D_i(Z)=Z_i\\). En general, hay asignados que no cumplen y no asignados que cumplen.\nCon esta notación podemos escribir la variable de pacto de \\(i\\) como \\(Y_i(Z,D)\\).\nNoten que \\(Y_i(Z,D)\\) y \\(D_i(Z)\\) son resultados potenciales.\n\n\n\nSupuesto 1: Stable Unit Treatment Value Assumption (SUTVA)\nEste supuesto indica que los resultados potenciales de \\(i\\) no están correlacionados con los de los otros individuos. Por tanto podemos escribir:\n\\[Y_i(Z,D)=Y_i(Z_i,D_i)\\] Y además:\n\\[D_i(Z)=D_i(Z_i)\\]\nSupuesto 2: asignación aleatoria\nLa asignación de \\(Z_i\\) es aleatoria, es decir:\n\\[P(Z=C)=P(Z=C')\\quad \\forall\\quad C,C'\\]\nLos supuestos 1 y 2 nos permiten identificar los efectos causales de \\(Z\\) en \\(Y\\) y de \\(Z\\) en \\(D\\) calculando diferencias de medias por grupos de \\(Z\\):\n\n\\(ITT_Y\\) comparar las medias de \\(y\\) entre quienes \\(Z=1\\) y quienes \\(Z=0\\)\n\\(ITT_D\\) comparar las medias de \\(D\\) entre quienes \\(Z=1\\) y quienes \\(Z=0\\)\n\nLos dos efectos causales antes descritos reciben el nombre de intención a tratar o intention to treat, o como se encuentra frecuentemente, \\(ITT\\). Este parámetro nos dice el efecto que resulta de ser asignado, es decir, refleja la intención que se tenía para tratar a un grupo y a otro no.\nHasta ahora el supuesto crítico es la asignación aleatoria de \\(Z\\). Sin embargo, \\(D_i\\) puede no serlo y, en general, no lo es. Por tanto, una comparación de \\(y\\) entre grupos de \\(D\\) es inapropiada. Necesitamos algunos supuestos para decir algo del efecto causal de \\(D\\) sobre \\(Y\\)\nSupuesto 3: restricción de exclusión\nEste supuestos indica que la asignación al tratamiento es independiente de los resultados potenciales:\n\\[Y(Z,D)=Y(Z',D)\\quad \\forall \\quad Z,Z',D\\]\nEste supuesto implica que podemos escribir:\n\\[Y_i(1,d)=Y_i(0,d) \\quad d=\\{0,1\\}\\]\nEs decir, la exclusión resuleve el problema contrafactual.\nAdemás, con el supuesto 3 podemos escribir:\n\\[Y(D)=Y(Z,D)=Y(Z',D)\\quad \\forall \\quad Z,Z',D\\]\npor el supuesto 1:\n\\[Y_i(D_i)=Y_i(Z,D)\\]\nSupuesto 4: el efecto causal promedio de \\(Z\\) sobre \\(D\\) es distinto de cero\nEste supuesto implica que, si se asignan individuos a ser tratados, esperamos que algunos efectivamente cumplan:\n\\[E(D_i(1)-D_i(0))\\neq0\\]\nEn otras palabras, la asignación tiene efecto sobre el cumplimiento.\nSupuesto 5: monotonicidad\nEste supuesto dice que no hay un individuo que:\n\nCuando se le asigna, no cumple\nCuando no se le asigna, cumple\n\n\\[D_i(1)\\geq D_i(0) \\quad \\forall\\quad i=1,\\ldots N\\]\nNoten que este supuesto se debe pensar en términos contrafactuales. A un individuo que no cumple cuando se le asigna y cumple cuando no se le asigna se le conoce como retador o defier."
  },
  {
    "objectID": "notas/late.html#notación",
    "href": "notas/late.html#notación",
    "title": "LATE",
    "section": "",
    "text": "Consideremos, para la asignación y el cumplimiento, las dos posibles situaciones:\nAsignación: \\(Z_i=\\begin{cases} 1 \\\\0 \\\\ \\end{cases}\\)\nCumplimiento: \\(D_i=\\begin{cases} 1 \\\\0 \\\\ \\end{cases}\\)\nSi \\(Y_i\\) variable de resultados, nos importa el efecto de \\(D_i\\) sobre \\(Y_i\\).\n\\(D_i(Z)\\) es el indicador de cumplir, dada la asignación \\(Z\\), por lo que con cumplimiento perfecto tendríamos \\(D_i(Z)=Z_i\\). En general, hay asignados que no cumplen y no asignados que cumplen.\nCon esta notación podemos escribir la variable de pacto de \\(i\\) como \\(Y_i(Z,D)\\).\nNoten que \\(Y_i(Z,D)\\) y \\(D_i(Z)\\) son resultados potenciales."
  },
  {
    "objectID": "notas/late.html#supuestos",
    "href": "notas/late.html#supuestos",
    "title": "LATE",
    "section": "",
    "text": "Supuesto 1: Stable Unit Treatment Value Assumption (SUTVA)\nEste supuesto indica que los resultados potenciales de \\(i\\) no están correlacionados con los de los otros individuos. Por tanto podemos escribir:\n\\[Y_i(Z,D)=Y_i(Z_i,D_i)\\] Y además:\n\\[D_i(Z)=D_i(Z_i)\\]\nSupuesto 2: asignación aleatoria\nLa asignación de \\(Z_i\\) es aleatoria, es decir:\n\\[P(Z=C)=P(Z=C')\\quad \\forall\\quad C,C'\\]\nLos supuestos 1 y 2 nos permiten identificar los efectos causales de \\(Z\\) en \\(Y\\) y de \\(Z\\) en \\(D\\) calculando diferencias de medias por grupos de \\(Z\\):\n\n\\(ITT_Y\\) comparar las medias de \\(y\\) entre quienes \\(Z=1\\) y quienes \\(Z=0\\)\n\\(ITT_D\\) comparar las medias de \\(D\\) entre quienes \\(Z=1\\) y quienes \\(Z=0\\)\n\nLos dos efectos causales antes descritos reciben el nombre de intención a tratar o intention to treat, o como se encuentra frecuentemente, \\(ITT\\). Este parámetro nos dice el efecto que resulta de ser asignado, es decir, refleja la intención que se tenía para tratar a un grupo y a otro no.\nHasta ahora el supuesto crítico es la asignación aleatoria de \\(Z\\). Sin embargo, \\(D_i\\) puede no serlo y, en general, no lo es. Por tanto, una comparación de \\(y\\) entre grupos de \\(D\\) es inapropiada. Necesitamos algunos supuestos para decir algo del efecto causal de \\(D\\) sobre \\(Y\\)\nSupuesto 3: restricción de exclusión\nEste supuestos indica que la asignación al tratamiento es independiente de los resultados potenciales:\n\\[Y(Z,D)=Y(Z',D)\\quad \\forall \\quad Z,Z',D\\]\nEste supuesto implica que podemos escribir:\n\\[Y_i(1,d)=Y_i(0,d) \\quad d=\\{0,1\\}\\]\nEs decir, la exclusión resuleve el problema contrafactual.\nAdemás, con el supuesto 3 podemos escribir:\n\\[Y(D)=Y(Z,D)=Y(Z',D)\\quad \\forall \\quad Z,Z',D\\]\npor el supuesto 1:\n\\[Y_i(D_i)=Y_i(Z,D)\\]\nSupuesto 4: el efecto causal promedio de \\(Z\\) sobre \\(D\\) es distinto de cero\nEste supuesto implica que, si se asignan individuos a ser tratados, esperamos que algunos efectivamente cumplan:\n\\[E(D_i(1)-D_i(0))\\neq0\\]\nEn otras palabras, la asignación tiene efecto sobre el cumplimiento.\nSupuesto 5: monotonicidad\nEste supuesto dice que no hay un individuo que:\n\nCuando se le asigna, no cumple\nCuando no se le asigna, cumple\n\n\\[D_i(1)\\geq D_i(0) \\quad \\forall\\quad i=1,\\ldots N\\]\nNoten que este supuesto se debe pensar en términos contrafactuales. A un individuo que no cumple cuando se le asigna y cumple cuando no se le asigna se le conoce como retador o defier."
  },
  {
    "objectID": "presentaciones.html",
    "href": "presentaciones.html",
    "title": "Presentaciones",
    "section": "",
    "text": "Por favor, seleccione una de las lecturas marcadas con una “+” de la lista de lecturas y envíe un correo al profesor para que se le asigne una fecha de presentación.\n\n\n\n\n\n\n\n\n\nAutores\nTema\nPresentador o presentadora\nFecha de exposición\n\n\n\n\nAscencio & Chang (2024)\nExperimental\nJosé Luis Valle\nLunes 8 de septiembre\n\n\nHoyos, Attanasio & Meghir (2024)\nExperimental\nDulce López\nLunes 8 de septiembre\n\n\nGonzalez-Navarro & Quintana-Domeque (2016)\nLATE\nEmiliano Villacaña\nLunes 22 de septiembre\n\n\nBoruchowicz, Parker & Robbins (2022)\nDID\nJosé Luis Cadena\nLunes 13 de octubre\n\n\n\nDID\n\nLunes 13 de octubre\n\n\n\nDiscontinuidades\n\nLunes 27 de octubre\n\n\n\nDiscontinuidades\n\nLunes 27 de octubre\n\n\nGonzález-Rozada & Ruffo (2024)\nControl Sintético\nJosé Luis Cadena\nLunes 10 de noviembre\n\n\n\nControl Sintético\n\nLunes 10 de noviembre\n\n\n\nMachine learning\n\nLunes 24 de noviembre",
    "crumbs": [
      "Presentaciones"
    ]
  },
  {
    "objectID": "prueba.html#slide-con-estilo",
    "href": "prueba.html#slide-con-estilo",
    "title": "Prueba Reveal",
    "section": "Slide con estilo",
    "text": "Slide con estilo\nEste slide debería tener fondo oscuro y texto centrado."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Example schedule:\n\n\n\n\n\n\n\n\n\nMorning\nAfternoon\n\n\n\n\nL\nIntro + Data manipulation\ngit / GitHub\n\n\nM\nGeneralised Linear Models\nData visualisation\n\n\nX\nMixed models / GAM / Bayes\nFunctional programming + Students work\n\n\nJ\nMultivariate analyses\nReproducible workflows\n\n\nV\nUsing R as GIS + Students work\nProject presentations"
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html",
    "href": "tareas/tarea-1-respuestas.html",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Suponga que para un experimento en un laboratorio se asignó a un grupo pacientes a un brazo de tratamiento o a uno de control. Antes de comenzar el experimento se recolectaron una serie de características \\(x_{ji}\\), \\(j=1,\\ldots 10\\), de cada paciente. Se busca medir el efecto del tratamiento sobre una variable de resultados \\(y_i\\). En el experimento, se trabaja con \\(\\alpha=0.10\\).\n\n[5 puntos] El investigador A quedó a cargo de comprobar el balance de la asignación del tratamiento y le reporta lo siguiente:\nPara verificar que la aleatorización fue exitosa, tomé la serie de variables pre-intervención y la dummy de asignación al tratamiento \\(T_i\\) para correr la siguiente regresión: \\[T_i=\\alpha+\\sum_{j=1}^{10}x_{ji}'\\beta +\\varepsilon_i\\]\nDespués realicé una prueba \\(F\\) de significancia conjunta sobre los coeficientes \\(\\beta_j\\) que resultó tener un valor \\(p\\) de 0.043.\nExplique cuál es la hipótesis nula en la prueba realizada y qué se esperaría de haberse logrado una aleatorización exitosa del tratamiento.\nSi la integridad del diseño se mantuvo durante el experimento, se esperaría que las características observables no predijeran el estado de tratamiento. En otras palabras, esperaríamos que los coeficientes en su conjunto no fueran significativos. Es decir, \\(H_0: \\beta_1=\\beta_2=\\ldots=\\beta_k=0\\).\n[5 puntos] ¿Qué concluye a partir de lo que le reporta el investigador A?\nEn este caso, el valor \\(p\\) indica una baja probabilidad de observar el estadístico \\(F\\), es decir, un valor de \\(F\\) que no es consistente con la hipótesis nula. Por tanto, se concluye que los coeficientes no son iguales que cero al mismo tiempo o que hay características que permiten predecir el estatus de tratamiento.\n[5 puntos] Por otro lado, el investigador B le reporta lo siguiente:\nYo realicé un análisis para determinar el balance en la asignación del tratamiento. Para cada una de las características \\(x_{ji}\\) corrí la siguiente regresión: \\[x_{ji}=\\gamma+\\pi T_i+u_i\\] A continuación, le reporto una tabla con los valores p asociados al coeficiente estimado de \\(\\pi\\) en cada una de las 10 regresiones.\n\n\n\n\n\n\n\n\n\n\nCaracterística\nValor \\(p\\)\n\nCaracterística\nValor \\(p\\)\n\n\n\n\n\\(x_{1i}\\)\n0.025\n\n\\(x_{6i}\\)\n0.015\n\n\n\\(x_{2i}\\)\n0.012\n\n\\(x_{7i}\\)\n0.033\n\n\n\\(x_{3i}\\)\n0.027\n\n\\(x_{8i}\\)\n0.019\n\n\n\\(x_{4i}\\)\n0.076\n\n\\(x_{9i}\\)\n0.028\n\n\n\\(x_{5i}\\)\n0.002\n\n\\(x_{10i}\\)\n0.017\n\n\n\nExplique la hipótesis nula detrás de las pruebas que realizó el investigador B y qué se esperaría de haberse logrado una aleatorización exitosa del tratamiento,\nOtra forma de proveer evidencia de la integridad del tratamiento es analizando el balance de las características observadas entre grupos de tratamiento. En este caso, si las medias de cada \\(x_{ij}\\) entre los grupos de tratados y de control son iguales, esperaríamos que el coeficiente \\(\\pi\\) fuera no significativo, es decir \\(H_0: \\pi=0\\). Con el nivel de significancia de \\(\\alpha=0.10\\), rechazamos la \\(H_0\\) en todos los casos, por lo que se concluye que las característias no están balanceadas entre los grupos de tratamiento.\n[5 puntos] ¿Cómo reconcilia la evidencia encontrada por el investigador A y el B y qué concluye sobre el balance en la asignación del tratamiento? ¿Qué características tendría una diferencia de medias de \\(y_i\\) después del tratamiento como estimador del impacto de este?\nAmbos investigadores aportan evidencia que indica que la asignación aleatoria estuvo comprometida y que no se crearon grupos similares entre los grupos de tratamiento y control. Por lo tanto, una comparación de medias de la variable de resultados entre los grupos de tratamiento y control sería un estimador sesgado e inconsistente para el valor poblacional de dicha diferencia.\n\n\n\n\nSe implemetó un programa para la entrega de semilla mejorada para la producción de frijol. La semilla se entregó a productores de hasta 10 hectáreas que ya reciben servicios de asistencia técnica y fertilizantes por parte del gobierno. El gobierno está interesado en estimar el impacto de la semilla mejorada en los rendimientos de la producción de frijol una vez que se realiza la cosecha, \\(y_i\\).\nPara responder esta pregunta, el gobierno invierte una gran cantidad de recursos en una encuesta representativa de los productores de frijol de hasta 10 hectáreas de todo el país y donde se identifica si el productor recibió o no la semilla mejorada (\\(T_i\\)), además de un amplio cuestionario sobre insumos usados en la producción, prácticas agrícolas y características socioeconómicas de los productores y sus familas.\n\n[10 puntos] Se propone que para estimar el efecto del programa se comparen los rendimientos de los productores que recibieron la semilla con los que no la recibieron. Argumente en términos del sesgo de selección sobre la conveniencia de esta estrategia para estimar el efecto causal de la semilla mejorada.\nEs muy probable que los productores que ya se encontraban atendidos por el gobierno a través de asistencia técnica y fertilizantes sean muy distintos de quienes no estaban atendidos. Los productores ya atendidos seguramente tienen mejores prácticas productivas, que les permiten tener mayores rendimientos. Por tanto, al comparar el rendimiento de estos productores con los rendimientos de quienes no recibieron semilla sería imposible aislar el impacto solo de la semilla. En otras palabras, los productores ya atendidos tendrían un rendimiento superior en ausencia de tratamiento que los productores no tratados, es decir, esperaríamos un sesgo de selección positivo. Por tanto, a pesar de que se invirtieron una cantidad importante de recursos en levantar una encuesta representativa, la forma en que se asignó el programa impide que una comparación observacional permita estimar el efecto causal de la semilla.\n[5 puntos] Para implementar la propuesta del punto a., se propone estimar la siguiente regresión: \\[ y_i = \\alpha + \\beta T_i + \\varepsilon_i\\]\nMuestre si el estimador de MCO de \\(\\beta\\) es consistente o no para el efecto de tratamiento.\nEstimar una regresión por MCO produciría un estimador \\(\\hat{\\beta}\\) inconsistente para el verdadero efecto de tratamiento \\(\\beta_0\\). Para ver esto, recordemos que el estimador de MCO puede reescribirse como sigue:\n\\[\\hat{\\beta}=\\beta_0 + \\left(N^{1-}\\sum x_i x_i'\\right)\\left(N^{-1}\\sum x_i u_i\\right)\\]\nSi podemos aplicar una LGN a \\(\\left(N^{1-}\\sum x_i x_i'\\right)\\), sabemos que el límite es una matriz finita y no nula. Entonces, para que \\(\\hat{\\beta} \\overset{p}{\\to} \\beta_0\\) se requiere que, al aplicar una LGN a \\(\\left(N^{-1}\\sum x_i u_i\\right)\\), la probabilidad límite sea 0. Esto ocurre si E(x_iu_i)=0, es decir, si no hay correlación entre los no observables y los regresores. Por los argumentos hechos arriba, esto es muy probable que se viole pues uno de los regresores es \\(T_i\\), que está correlacionado con observables y no observables que hacen más o menos probable que un productor reciba la semilla mejorada.\n[5 puntos] Describa cómo realizaría el experimento ideal para la identificación del efecto causal de proveer semilla mejorada sobre el rendimiento. Describa cómo asignaría el tratamiento, qué condiciones deberían verificarse para asegurar la integridad del diseño y qué posibles obstáculos encontraría para la implementación de la estrategia que propone.\nNo hay respuestas correctas o incorrectas. Consideraré sus argumentos.\n\n\n\n\n\n[10 puntos] Replique el ejercicio en MHE que ejemplifica el teorema de la regresión de la FEC. Para esto use el archivo de datos muestra-enoe-123.csv, que contiene una muestra del primer trimestre de 2023 de la ENOE e incluye personas que trabajan y reciben un ingreso. lingreso es el log del ingreso mensual y escolaridad son los años de educación. Primero, estime una regresión de lingreso en función de escolaridad usando los microdatos. Luego, obtenga la media de lingreso para cada nivel de escolaridad y estime una regresión de las medias en función de escolaridad, pesando por el número de observaciones usadas para construir cada media. Compare los coeficientes estimados.\nCorramos la regresión con los microdatos:\n\ndf &lt;- read_csv(\"../files/muestra-enoe-123.csv\") \n\nsummary(lm(lingreso ~ escolaridad,\ndata = df))\n\n\nCall:\nlm(formula = lingreso ~ escolaridad, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.6859 -0.3123  0.0462  0.4179  3.0679 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 8.216881   0.024243  338.94   &lt;2e-16 ***\nescolaridad 0.060347   0.002105   28.67   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6973 on 6554 degrees of freedom\nMultiple R-squared:  0.1115, Adjusted R-squared:  0.1113 \nF-statistic: 822.1 on 1 and 6554 DF,  p-value: &lt; 2.2e-16\n\n\nCada año de escolaridad se asocia con un incremento de 6% en el ingreso.\nAhora calculemos la media del ingreso por cada año de educación, asegurándonos de conservar también el número de observaciones empleada para hacer dicho cálculo:\n\ndf.agregada &lt;- df %&gt;% \n  group_by(escolaridad) %&gt;% \n  summarise(lingreso = mean(lingreso, na.rm=T),\n            n = n())\n\nCorremos la regresión con los datos agregados, pesando por el número de observaciones en cada grupo:\n\nsummary(lm(lingreso ~ escolaridad,\n              data = df.agregada,\n              weights = n))\n\n\nCall:\nlm(formula = lingreso ~ escolaridad, data = df.agregada, weights = n)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-2.7905 -0.1961  0.3220  1.1960  3.8566 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 8.216881   0.056804  144.65  &lt; 2e-16 ***\nescolaridad 0.060347   0.004932   12.24 1.86e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.634 on 19 degrees of freedom\nMultiple R-squared:  0.8874, Adjusted R-squared:  0.8815 \nF-statistic: 149.7 on 1 and 19 DF,  p-value: 1.861e-10\n\n\nEl coeficiente estimado de los años de escolaridad es exactamente el mismo.\n\n\n\n\nUse los datos del archivo STAR_public_use.csv para este problema. En este problema replicará la fila correspondiente a la variable High school GPA (calificación en la preparatoria) de la Tabla 1 en Angrist et al. (2009).1\n\n[5 puntos] Obtenga la media y la desviación estándar de la edad, gpa0 en los datos, en el grupo de control (columna 1), restringiendo la muestra a aquellos individuos con noshow igual a 0.\nDespués de eliminar a lo sindividuos que tienen noshow igual a 1, obtenemos la media y desviación estándar reportadas en la tabla. Noten que deben restringir al grupo de control para obtener dichas cifras. La columna del tamaño de la muestra se obtiene sin restringir al grupo de control, aunque esto no se pedía en la pregunta.\n\ndata.angrist &lt;- read_csv(\"../files/STAR_public_use.csv\",\n                       locale = locale(encoding = \"latin1\"))   %&gt;% \n  clean_names() %&gt;% \n  filter(noshow==0)\n\n#Media y desviación estándar\ndata.angrist %&gt;% \n  filter(control==1) %&gt;% \n  summarize(media=mean(gpa0, na.rm=T),\n            desvest=sd(gpa0, na.rm=T))\n\n# A tibble: 1 × 2\n  media desvest\n  &lt;dbl&gt;   &lt;dbl&gt;\n1  78.7    4.22\n\n#N\ndata.angrist %&gt;% \n  summarize(n())\n\n# A tibble: 1 × 1\n  `n()`\n  &lt;int&gt;\n1  1571\n\n\n[10 puntos] Usando una regresión lineal, muestre que la calificación en la preparatoria no está correlacionada con la asignación a los tratamientos (ssp, sfp y sfsp). De nuevo, debe restringir la muestra quienes tienen noshow igual a 0. Reporte los coeficientes y los errores estándar (columnas 2 a 4).\nLa regresión es:\n\nsummary(balance &lt;- lm(gpa0 ~ ssp + sfp+ sfsp,\n            data = data.angrist))\n\n\nCall:\nlm(formula = gpa0 ~ ssp + sfp + sfsp, data = data.angrist)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.6567  -3.4567  -0.1567   3.3433   8.6612 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 78.65672    0.13718 573.377   &lt;2e-16 ***\nssp          0.16997    0.30779   0.552    0.581    \nsfp          0.23795    0.30372   0.783    0.433    \nsfsp        -0.01787    0.38433  -0.047    0.963    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.233 on 1567 degrees of freedom\nMultiple R-squared:  0.0005287,  Adjusted R-squared:  -0.001385 \nF-statistic: 0.2763 on 3 and 1567 DF,  p-value: 0.8425\n\n\n[5 puntos] Realice una prueba de significancia conjunta de los coeficientes obtenidos en el punto b. Reporte el estadístico \\(F\\) y el valor \\(p\\) asociado (columna 5).\nEl estadístico \\(F\\) ya es calculado con la regresión. Basta con pedirlo:\n\nsummary(balance)$fstatistic\n\n       value        numdf        dendf \n   0.2762878    3.0000000 1567.0000000 \n\n\n¿Pero cómo puedo calcular el valor \\(p\\)? Basta usar la definición, es la probabilidad de observar un valor más extremo que el estadístico, bajo la distribución teórica. En este caso, la distribución teórica es una \\(F\\) y debemos especificar los grados de libertad en el numerador y en el denominador:\n\npf(q = summary(balance)$fstatistic[1],\n   df1 = summary(balance)$fstatistic[2],\n   df2 = summary(balance)$fstatistic[3],\n   lower.tail=FALSE)\n\n    value \n0.8425407 \n\n\n[10 puntos] ¿Cuál es el propósito de la prueba F realizada en el punto c.? ¿Qué hipótesis nula prueban los autores?\nAquí se busca probar que la asignación a los tres tipos de tratamiento no está correlacionada con la calificación en la preparatoria La \\(H_0\\) es que \\(\\beta_{SSP}=\\beta_{SFP}=\\beta_{SFSP}=0\\). Si rechazamos la hipótesis nula concluiríamos que hay diferencias entre grupos en la calificación en la preparatoria En este caso, el estadístico \\(F\\) es pequeño y su valor \\(p\\) indica que es muy probable de observarlo bajo la hipótesis nula por lo que no hay bases para rechazarla.\n\n\n\n\nNuevamente, use los datos del archivo STAR_public_use.csv. En este problema, replicará dos columnas del efecto de tratamiento de la Tabla 5. Note que de nuevo se deben usar solo las observaciones que tienen noshow igual a 0. Los autores también sustituyen los valores de gpa_year1 por NA cuando la variable grade_20059_fall es NA; y sustituyen grade_20059_fall por NA cuando la variable gpa_year1 es NA. Además, note que se usan las siguientes variables de control: sex, mtongue, hsgroup, numcourses_nov1, lastmin, mom_edn, y dad_edn, todas ellas categóricas.\n\n[10 puntos] Estime el efecto de cada tipo de tratamiento sobre el promedio o GPA, denotado gpa_year1 en los datos, para toda la muestra (Panel B, columna 1). Calcule correctamente los errores estándar. Interprete los resultados.\nHaciendo la sustitución sugerida por los autores, estimamos:\n\ndata.angrist &lt;- data.angrist %&gt;% \n      mutate(gpa_year1=ifelse(is.na(grade_20059_fall),NA,gpa_year1),\n             grade_20059_fall=ifelse(is.na(gpa_year1),NA,grade_20059_fall))\n\nreg1&lt;-lm(gpa_year1 ~ ssp + sfp+ sfsp+\n           factor(sex)+\n           factor(mtongue)+\n           factor(hsgroup)+\n           factor(numcourses_nov1)+\n           factor(lastmin)+\n           factor(mom_edn)+\n           factor(dad_edn),\n         data=data.angrist)\n\nNoten que los coeficientes estimados son correctos, pero no los errores estándar:\n\nsummary(reg1)$coef[1:4,]\n\n              Estimate Std. Error  t value     Pr(&gt;|t|)\n(Intercept) 1.60138378 0.46453145 3.447310 0.0005854449\nssp         0.07259427 0.06603498 1.099331 0.2718404422\nsfp         0.01025889 0.06515735 0.157448 0.8749178181\nsfsp        0.20971238 0.08554012 2.451626 0.0143604306\n\n\nLos errores estándar correctos son los robustos:\n\ncoeftest(reg1, vcov = vcovHC(reg1, \"HC1\"))[1:4,]\n\n              Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 1.60138378 0.46059228 3.4767925 0.0005252628\nssp         0.07259427 0.06601070 1.0997349 0.2716642613\nsfp         0.01025889 0.06357889 0.1613569 0.8718389856\nsfsp        0.20971238 0.09221545 2.2741566 0.0231293441\n\n\nFinalmente, lo que se reporta en la tabla como la media del grupo de control no es la constante en la regresión, sino la media y desviación estándar. Noten que se usa la muestra que efectivamente se usa en la regresión, es decir, sin valores faltantes.\n\ndata.angrist %&gt;%\n    filter(!is.na(gpa_year1) & !is.na(grade_20059_fall)\n     & !is.na(ssp)\n     & !is.na(sfp)\n     & !is.na(sfsp)\n     & !is.na(sex)\n     & !is.na(mtongue)\n     & !is.na(hsgroup)\n     & !is.na(numcourses_nov1)\n     & !is.na(lastmin)\n     & !is.na(mom_edn)\n     & !is.na(dad_edn)\n     & control==1) %&gt;%\n  summarize(media=mean(gpa_year1,\n                       na.rm=TRUE),\n            desvest=sd(gpa_year1,\n                       na.rm=TRUE))\n\n# A tibble: 1 × 2\n  media desvest\n  &lt;dbl&gt;   &lt;dbl&gt;\n1  1.80   0.902\n\ndata.angrist %&gt;%\n  filter(!is.na(gpa_year1) & !is.na(grade_20059_fall)\n     & !is.na(ssp)\n     & !is.na(sfp)\n     & !is.na(sfsp)\n     & !is.na(sex)\n     & !is.na(mtongue)\n     & !is.na(hsgroup)\n     & !is.na(numcourses_nov1)\n     & !is.na(lastmin)\n     & !is.na(mom_edn)\n     & !is.na(dad_edn)) %&gt;%\n  summarize(numero=n())\n\n# A tibble: 1 × 1\n  numero\n   &lt;int&gt;\n1   1255\n\n\n[10 puntos] Estime el efecto sobre el GPA de recibir cada tipo de tratamiento, considerando los tratamientos SSP o SFP (de cualquier tipo) en las mujeres de la muestra (Panel B, columna 6). Esto es, considere el tratamiento SSP como un primer tipo de tratamiento y, ya sea SFP o SFSP, como un segundo tipo de tratamiento. Calcule correctamente los errores estándar. Interprete sus resultados.\nDefinimos la variable de recibir el tratamiento SFP o SFSP. Luego estimamos:\n\ndata.angrist &lt;- data.angrist %&gt;%\n      mutate(sspany = ifelse(sfp == 1 | sfsp == 1, 1, \n    0))\n\nreg2&lt;-lm(gpa_year1 ~ ssp + sspany+\n           factor(mtongue)+\n           factor(hsgroup)+\n           factor(numcourses_nov1)+\n           factor(lastmin)+\n           factor(mom_edn)+\n           factor(dad_edn),\n         data=filter(data.angrist,\n                     female==1))\n\nLos coeficientes con los errores correctos son:\n\ncoeftest(reg2, vcov = vcovHC(reg2, \"HC1\"))[1:3,]\n\n             Estimate Std. Error  t value     Pr(&gt;|t|)\n(Intercept) 2.5333972 0.28335814 8.940619 3.428412e-18\nssp         0.1162368 0.08199976 1.417526 1.567753e-01\nsspany      0.1468443 0.07291557 2.013895 4.440376e-02\n\n\nLa media en el control:\n\ndata.angrist %&gt;%\n  filter(!is.na(gpa_year1) & !is.na(grade_20059_fall)\n     & !is.na(ssp)\n     & !is.na(sfp)\n     & !is.na(sfsp)\n     & !is.na(sex)\n     & !is.na(mtongue)\n     & !is.na(hsgroup)\n     & !is.na(numcourses_nov1)\n     & !is.na(lastmin)\n     & !is.na(mom_edn)\n     & !is.na(dad_edn)\n     & control==1\n     & female==1) %&gt;%\n  summarize(media=mean(gpa_year1,\n                       na.rm=TRUE),\n            desvest=sd(gpa_year1,\n                       na.rm=TRUE))\n\n# A tibble: 1 × 2\n  media desvest\n  &lt;dbl&gt;   &lt;dbl&gt;\n1  1.73   0.891\n\ndata.angrist %&gt;%\n  filter(!is.na(gpa_year1) & !is.na(grade_20059_fall)\n     & !is.na(ssp)\n     & !is.na(sfp)\n     & !is.na(sfsp)\n     & !is.na(sex)\n     & !is.na(mtongue)\n     & !is.na(hsgroup)\n     & !is.na(numcourses_nov1)\n     & !is.na(lastmin)\n     & !is.na(mom_edn)\n     & !is.na(dad_edn)\n     & female==1) %&gt;%\n  summarize(numero=n())\n\n# A tibble: 1 × 1\n  numero\n   &lt;int&gt;\n1    729"
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-1",
    "href": "tareas/tarea-1-respuestas.html#pregunta-1",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Suponga que para un experimento en un laboratorio se asignó a un grupo pacientes a un brazo de tratamiento o a uno de control. Antes de comenzar el experimento se recolectaron una serie de características \\(x_{ji}\\), \\(j=1,\\ldots 10\\), de cada paciente. Se busca medir el efecto del tratamiento sobre una variable de resultados \\(y_i\\). En el experimento, se trabaja con \\(\\alpha=0.10\\).\n\n[5 puntos] El investigador A quedó a cargo de comprobar el balance de la asignación del tratamiento y le reporta lo siguiente:\nPara verificar que la aleatorización fue exitosa, tomé la serie de variables pre-intervención y la dummy de asignación al tratamiento \\(T_i\\) para correr la siguiente regresión: \\[T_i=\\alpha+\\sum_{j=1}^{10}x_{ji}'\\beta +\\varepsilon_i\\]\nDespués realicé una prueba \\(F\\) de significancia conjunta sobre los coeficientes \\(\\beta_j\\) que resultó tener un valor \\(p\\) de 0.043.\nExplique cuál es la hipótesis nula en la prueba realizada y qué se esperaría de haberse logrado una aleatorización exitosa del tratamiento.\nSi la integridad del diseño se mantuvo durante el experimento, se esperaría que las características observables no predijeran el estado de tratamiento. En otras palabras, esperaríamos que los coeficientes en su conjunto no fueran significativos. Es decir, \\(H_0: \\beta_1=\\beta_2=\\ldots=\\beta_k=0\\).\n[5 puntos] ¿Qué concluye a partir de lo que le reporta el investigador A?\nEn este caso, el valor \\(p\\) indica una baja probabilidad de observar el estadístico \\(F\\), es decir, un valor de \\(F\\) que no es consistente con la hipótesis nula. Por tanto, se concluye que los coeficientes no son iguales que cero al mismo tiempo o que hay características que permiten predecir el estatus de tratamiento.\n[5 puntos] Por otro lado, el investigador B le reporta lo siguiente:\nYo realicé un análisis para determinar el balance en la asignación del tratamiento. Para cada una de las características \\(x_{ji}\\) corrí la siguiente regresión: \\[x_{ji}=\\gamma+\\pi T_i+u_i\\] A continuación, le reporto una tabla con los valores p asociados al coeficiente estimado de \\(\\pi\\) en cada una de las 10 regresiones.\n\n\n\n\n\n\n\n\n\n\nCaracterística\nValor \\(p\\)\n\nCaracterística\nValor \\(p\\)\n\n\n\n\n\\(x_{1i}\\)\n0.025\n\n\\(x_{6i}\\)\n0.015\n\n\n\\(x_{2i}\\)\n0.012\n\n\\(x_{7i}\\)\n0.033\n\n\n\\(x_{3i}\\)\n0.027\n\n\\(x_{8i}\\)\n0.019\n\n\n\\(x_{4i}\\)\n0.076\n\n\\(x_{9i}\\)\n0.028\n\n\n\\(x_{5i}\\)\n0.002\n\n\\(x_{10i}\\)\n0.017\n\n\n\nExplique la hipótesis nula detrás de las pruebas que realizó el investigador B y qué se esperaría de haberse logrado una aleatorización exitosa del tratamiento,\nOtra forma de proveer evidencia de la integridad del tratamiento es analizando el balance de las características observadas entre grupos de tratamiento. En este caso, si las medias de cada \\(x_{ij}\\) entre los grupos de tratados y de control son iguales, esperaríamos que el coeficiente \\(\\pi\\) fuera no significativo, es decir \\(H_0: \\pi=0\\). Con el nivel de significancia de \\(\\alpha=0.10\\), rechazamos la \\(H_0\\) en todos los casos, por lo que se concluye que las característias no están balanceadas entre los grupos de tratamiento.\n[5 puntos] ¿Cómo reconcilia la evidencia encontrada por el investigador A y el B y qué concluye sobre el balance en la asignación del tratamiento? ¿Qué características tendría una diferencia de medias de \\(y_i\\) después del tratamiento como estimador del impacto de este?\nAmbos investigadores aportan evidencia que indica que la asignación aleatoria estuvo comprometida y que no se crearon grupos similares entre los grupos de tratamiento y control. Por lo tanto, una comparación de medias de la variable de resultados entre los grupos de tratamiento y control sería un estimador sesgado e inconsistente para el valor poblacional de dicha diferencia."
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-2",
    "href": "tareas/tarea-1-respuestas.html#pregunta-2",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Se implemetó un programa para la entrega de semilla mejorada para la producción de frijol. La semilla se entregó a productores de hasta 10 hectáreas que ya reciben servicios de asistencia técnica y fertilizantes por parte del gobierno. El gobierno está interesado en estimar el impacto de la semilla mejorada en los rendimientos de la producción de frijol una vez que se realiza la cosecha, \\(y_i\\).\nPara responder esta pregunta, el gobierno invierte una gran cantidad de recursos en una encuesta representativa de los productores de frijol de hasta 10 hectáreas de todo el país y donde se identifica si el productor recibió o no la semilla mejorada (\\(T_i\\)), además de un amplio cuestionario sobre insumos usados en la producción, prácticas agrícolas y características socioeconómicas de los productores y sus familas.\n\n[10 puntos] Se propone que para estimar el efecto del programa se comparen los rendimientos de los productores que recibieron la semilla con los que no la recibieron. Argumente en términos del sesgo de selección sobre la conveniencia de esta estrategia para estimar el efecto causal de la semilla mejorada.\nEs muy probable que los productores que ya se encontraban atendidos por el gobierno a través de asistencia técnica y fertilizantes sean muy distintos de quienes no estaban atendidos. Los productores ya atendidos seguramente tienen mejores prácticas productivas, que les permiten tener mayores rendimientos. Por tanto, al comparar el rendimiento de estos productores con los rendimientos de quienes no recibieron semilla sería imposible aislar el impacto solo de la semilla. En otras palabras, los productores ya atendidos tendrían un rendimiento superior en ausencia de tratamiento que los productores no tratados, es decir, esperaríamos un sesgo de selección positivo. Por tanto, a pesar de que se invirtieron una cantidad importante de recursos en levantar una encuesta representativa, la forma en que se asignó el programa impide que una comparación observacional permita estimar el efecto causal de la semilla.\n[5 puntos] Para implementar la propuesta del punto a., se propone estimar la siguiente regresión: \\[ y_i = \\alpha + \\beta T_i + \\varepsilon_i\\]\nMuestre si el estimador de MCO de \\(\\beta\\) es consistente o no para el efecto de tratamiento.\nEstimar una regresión por MCO produciría un estimador \\(\\hat{\\beta}\\) inconsistente para el verdadero efecto de tratamiento \\(\\beta_0\\). Para ver esto, recordemos que el estimador de MCO puede reescribirse como sigue:\n\\[\\hat{\\beta}=\\beta_0 + \\left(N^{1-}\\sum x_i x_i'\\right)\\left(N^{-1}\\sum x_i u_i\\right)\\]\nSi podemos aplicar una LGN a \\(\\left(N^{1-}\\sum x_i x_i'\\right)\\), sabemos que el límite es una matriz finita y no nula. Entonces, para que \\(\\hat{\\beta} \\overset{p}{\\to} \\beta_0\\) se requiere que, al aplicar una LGN a \\(\\left(N^{-1}\\sum x_i u_i\\right)\\), la probabilidad límite sea 0. Esto ocurre si E(x_iu_i)=0, es decir, si no hay correlación entre los no observables y los regresores. Por los argumentos hechos arriba, esto es muy probable que se viole pues uno de los regresores es \\(T_i\\), que está correlacionado con observables y no observables que hacen más o menos probable que un productor reciba la semilla mejorada.\n[5 puntos] Describa cómo realizaría el experimento ideal para la identificación del efecto causal de proveer semilla mejorada sobre el rendimiento. Describa cómo asignaría el tratamiento, qué condiciones deberían verificarse para asegurar la integridad del diseño y qué posibles obstáculos encontraría para la implementación de la estrategia que propone.\nNo hay respuestas correctas o incorrectas. Consideraré sus argumentos."
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-3",
    "href": "tareas/tarea-1-respuestas.html#pregunta-3",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "[10 puntos] Replique el ejercicio en MHE que ejemplifica el teorema de la regresión de la FEC. Para esto use el archivo de datos muestra-enoe-123.csv, que contiene una muestra del primer trimestre de 2023 de la ENOE e incluye personas que trabajan y reciben un ingreso. lingreso es el log del ingreso mensual y escolaridad son los años de educación. Primero, estime una regresión de lingreso en función de escolaridad usando los microdatos. Luego, obtenga la media de lingreso para cada nivel de escolaridad y estime una regresión de las medias en función de escolaridad, pesando por el número de observaciones usadas para construir cada media. Compare los coeficientes estimados.\nCorramos la regresión con los microdatos:\n\ndf &lt;- read_csv(\"../files/muestra-enoe-123.csv\") \n\nsummary(lm(lingreso ~ escolaridad,\ndata = df))\n\n\nCall:\nlm(formula = lingreso ~ escolaridad, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.6859 -0.3123  0.0462  0.4179  3.0679 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 8.216881   0.024243  338.94   &lt;2e-16 ***\nescolaridad 0.060347   0.002105   28.67   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6973 on 6554 degrees of freedom\nMultiple R-squared:  0.1115, Adjusted R-squared:  0.1113 \nF-statistic: 822.1 on 1 and 6554 DF,  p-value: &lt; 2.2e-16\n\n\nCada año de escolaridad se asocia con un incremento de 6% en el ingreso.\nAhora calculemos la media del ingreso por cada año de educación, asegurándonos de conservar también el número de observaciones empleada para hacer dicho cálculo:\n\ndf.agregada &lt;- df %&gt;% \n  group_by(escolaridad) %&gt;% \n  summarise(lingreso = mean(lingreso, na.rm=T),\n            n = n())\n\nCorremos la regresión con los datos agregados, pesando por el número de observaciones en cada grupo:\n\nsummary(lm(lingreso ~ escolaridad,\n              data = df.agregada,\n              weights = n))\n\n\nCall:\nlm(formula = lingreso ~ escolaridad, data = df.agregada, weights = n)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-2.7905 -0.1961  0.3220  1.1960  3.8566 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 8.216881   0.056804  144.65  &lt; 2e-16 ***\nescolaridad 0.060347   0.004932   12.24 1.86e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.634 on 19 degrees of freedom\nMultiple R-squared:  0.8874, Adjusted R-squared:  0.8815 \nF-statistic: 149.7 on 1 and 19 DF,  p-value: 1.861e-10\n\n\nEl coeficiente estimado de los años de escolaridad es exactamente el mismo."
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-4",
    "href": "tareas/tarea-1-respuestas.html#pregunta-4",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Use los datos del archivo STAR_public_use.csv para este problema. En este problema replicará la fila correspondiente a la variable High school GPA (calificación en la preparatoria) de la Tabla 1 en Angrist et al. (2009).1\n\n[5 puntos] Obtenga la media y la desviación estándar de la edad, gpa0 en los datos, en el grupo de control (columna 1), restringiendo la muestra a aquellos individuos con noshow igual a 0.\nDespués de eliminar a lo sindividuos que tienen noshow igual a 1, obtenemos la media y desviación estándar reportadas en la tabla. Noten que deben restringir al grupo de control para obtener dichas cifras. La columna del tamaño de la muestra se obtiene sin restringir al grupo de control, aunque esto no se pedía en la pregunta.\n\ndata.angrist &lt;- read_csv(\"../files/STAR_public_use.csv\",\n                       locale = locale(encoding = \"latin1\"))   %&gt;% \n  clean_names() %&gt;% \n  filter(noshow==0)\n\n#Media y desviación estándar\ndata.angrist %&gt;% \n  filter(control==1) %&gt;% \n  summarize(media=mean(gpa0, na.rm=T),\n            desvest=sd(gpa0, na.rm=T))\n\n# A tibble: 1 × 2\n  media desvest\n  &lt;dbl&gt;   &lt;dbl&gt;\n1  78.7    4.22\n\n#N\ndata.angrist %&gt;% \n  summarize(n())\n\n# A tibble: 1 × 1\n  `n()`\n  &lt;int&gt;\n1  1571\n\n\n[10 puntos] Usando una regresión lineal, muestre que la calificación en la preparatoria no está correlacionada con la asignación a los tratamientos (ssp, sfp y sfsp). De nuevo, debe restringir la muestra quienes tienen noshow igual a 0. Reporte los coeficientes y los errores estándar (columnas 2 a 4).\nLa regresión es:\n\nsummary(balance &lt;- lm(gpa0 ~ ssp + sfp+ sfsp,\n            data = data.angrist))\n\n\nCall:\nlm(formula = gpa0 ~ ssp + sfp + sfsp, data = data.angrist)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.6567  -3.4567  -0.1567   3.3433   8.6612 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 78.65672    0.13718 573.377   &lt;2e-16 ***\nssp          0.16997    0.30779   0.552    0.581    \nsfp          0.23795    0.30372   0.783    0.433    \nsfsp        -0.01787    0.38433  -0.047    0.963    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.233 on 1567 degrees of freedom\nMultiple R-squared:  0.0005287,  Adjusted R-squared:  -0.001385 \nF-statistic: 0.2763 on 3 and 1567 DF,  p-value: 0.8425\n\n\n[5 puntos] Realice una prueba de significancia conjunta de los coeficientes obtenidos en el punto b. Reporte el estadístico \\(F\\) y el valor \\(p\\) asociado (columna 5).\nEl estadístico \\(F\\) ya es calculado con la regresión. Basta con pedirlo:\n\nsummary(balance)$fstatistic\n\n       value        numdf        dendf \n   0.2762878    3.0000000 1567.0000000 \n\n\n¿Pero cómo puedo calcular el valor \\(p\\)? Basta usar la definición, es la probabilidad de observar un valor más extremo que el estadístico, bajo la distribución teórica. En este caso, la distribución teórica es una \\(F\\) y debemos especificar los grados de libertad en el numerador y en el denominador:\n\npf(q = summary(balance)$fstatistic[1],\n   df1 = summary(balance)$fstatistic[2],\n   df2 = summary(balance)$fstatistic[3],\n   lower.tail=FALSE)\n\n    value \n0.8425407 \n\n\n[10 puntos] ¿Cuál es el propósito de la prueba F realizada en el punto c.? ¿Qué hipótesis nula prueban los autores?\nAquí se busca probar que la asignación a los tres tipos de tratamiento no está correlacionada con la calificación en la preparatoria La \\(H_0\\) es que \\(\\beta_{SSP}=\\beta_{SFP}=\\beta_{SFSP}=0\\). Si rechazamos la hipótesis nula concluiríamos que hay diferencias entre grupos en la calificación en la preparatoria En este caso, el estadístico \\(F\\) es pequeño y su valor \\(p\\) indica que es muy probable de observarlo bajo la hipótesis nula por lo que no hay bases para rechazarla."
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-5",
    "href": "tareas/tarea-1-respuestas.html#pregunta-5",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Nuevamente, use los datos del archivo STAR_public_use.csv. En este problema, replicará dos columnas del efecto de tratamiento de la Tabla 5. Note que de nuevo se deben usar solo las observaciones que tienen noshow igual a 0. Los autores también sustituyen los valores de gpa_year1 por NA cuando la variable grade_20059_fall es NA; y sustituyen grade_20059_fall por NA cuando la variable gpa_year1 es NA. Además, note que se usan las siguientes variables de control: sex, mtongue, hsgroup, numcourses_nov1, lastmin, mom_edn, y dad_edn, todas ellas categóricas.\n\n[10 puntos] Estime el efecto de cada tipo de tratamiento sobre el promedio o GPA, denotado gpa_year1 en los datos, para toda la muestra (Panel B, columna 1). Calcule correctamente los errores estándar. Interprete los resultados.\nHaciendo la sustitución sugerida por los autores, estimamos:\n\ndata.angrist &lt;- data.angrist %&gt;% \n      mutate(gpa_year1=ifelse(is.na(grade_20059_fall),NA,gpa_year1),\n             grade_20059_fall=ifelse(is.na(gpa_year1),NA,grade_20059_fall))\n\nreg1&lt;-lm(gpa_year1 ~ ssp + sfp+ sfsp+\n           factor(sex)+\n           factor(mtongue)+\n           factor(hsgroup)+\n           factor(numcourses_nov1)+\n           factor(lastmin)+\n           factor(mom_edn)+\n           factor(dad_edn),\n         data=data.angrist)\n\nNoten que los coeficientes estimados son correctos, pero no los errores estándar:\n\nsummary(reg1)$coef[1:4,]\n\n              Estimate Std. Error  t value     Pr(&gt;|t|)\n(Intercept) 1.60138378 0.46453145 3.447310 0.0005854449\nssp         0.07259427 0.06603498 1.099331 0.2718404422\nsfp         0.01025889 0.06515735 0.157448 0.8749178181\nsfsp        0.20971238 0.08554012 2.451626 0.0143604306\n\n\nLos errores estándar correctos son los robustos:\n\ncoeftest(reg1, vcov = vcovHC(reg1, \"HC1\"))[1:4,]\n\n              Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 1.60138378 0.46059228 3.4767925 0.0005252628\nssp         0.07259427 0.06601070 1.0997349 0.2716642613\nsfp         0.01025889 0.06357889 0.1613569 0.8718389856\nsfsp        0.20971238 0.09221545 2.2741566 0.0231293441\n\n\nFinalmente, lo que se reporta en la tabla como la media del grupo de control no es la constante en la regresión, sino la media y desviación estándar. Noten que se usa la muestra que efectivamente se usa en la regresión, es decir, sin valores faltantes.\n\ndata.angrist %&gt;%\n    filter(!is.na(gpa_year1) & !is.na(grade_20059_fall)\n     & !is.na(ssp)\n     & !is.na(sfp)\n     & !is.na(sfsp)\n     & !is.na(sex)\n     & !is.na(mtongue)\n     & !is.na(hsgroup)\n     & !is.na(numcourses_nov1)\n     & !is.na(lastmin)\n     & !is.na(mom_edn)\n     & !is.na(dad_edn)\n     & control==1) %&gt;%\n  summarize(media=mean(gpa_year1,\n                       na.rm=TRUE),\n            desvest=sd(gpa_year1,\n                       na.rm=TRUE))\n\n# A tibble: 1 × 2\n  media desvest\n  &lt;dbl&gt;   &lt;dbl&gt;\n1  1.80   0.902\n\ndata.angrist %&gt;%\n  filter(!is.na(gpa_year1) & !is.na(grade_20059_fall)\n     & !is.na(ssp)\n     & !is.na(sfp)\n     & !is.na(sfsp)\n     & !is.na(sex)\n     & !is.na(mtongue)\n     & !is.na(hsgroup)\n     & !is.na(numcourses_nov1)\n     & !is.na(lastmin)\n     & !is.na(mom_edn)\n     & !is.na(dad_edn)) %&gt;%\n  summarize(numero=n())\n\n# A tibble: 1 × 1\n  numero\n   &lt;int&gt;\n1   1255\n\n\n[10 puntos] Estime el efecto sobre el GPA de recibir cada tipo de tratamiento, considerando los tratamientos SSP o SFP (de cualquier tipo) en las mujeres de la muestra (Panel B, columna 6). Esto es, considere el tratamiento SSP como un primer tipo de tratamiento y, ya sea SFP o SFSP, como un segundo tipo de tratamiento. Calcule correctamente los errores estándar. Interprete sus resultados.\nDefinimos la variable de recibir el tratamiento SFP o SFSP. Luego estimamos:\n\ndata.angrist &lt;- data.angrist %&gt;%\n      mutate(sspany = ifelse(sfp == 1 | sfsp == 1, 1, \n    0))\n\nreg2&lt;-lm(gpa_year1 ~ ssp + sspany+\n           factor(mtongue)+\n           factor(hsgroup)+\n           factor(numcourses_nov1)+\n           factor(lastmin)+\n           factor(mom_edn)+\n           factor(dad_edn),\n         data=filter(data.angrist,\n                     female==1))\n\nLos coeficientes con los errores correctos son:\n\ncoeftest(reg2, vcov = vcovHC(reg2, \"HC1\"))[1:3,]\n\n             Estimate Std. Error  t value     Pr(&gt;|t|)\n(Intercept) 2.5333972 0.28335814 8.940619 3.428412e-18\nssp         0.1162368 0.08199976 1.417526 1.567753e-01\nsspany      0.1468443 0.07291557 2.013895 4.440376e-02\n\n\nLa media en el control:\n\ndata.angrist %&gt;%\n  filter(!is.na(gpa_year1) & !is.na(grade_20059_fall)\n     & !is.na(ssp)\n     & !is.na(sfp)\n     & !is.na(sfsp)\n     & !is.na(sex)\n     & !is.na(mtongue)\n     & !is.na(hsgroup)\n     & !is.na(numcourses_nov1)\n     & !is.na(lastmin)\n     & !is.na(mom_edn)\n     & !is.na(dad_edn)\n     & control==1\n     & female==1) %&gt;%\n  summarize(media=mean(gpa_year1,\n                       na.rm=TRUE),\n            desvest=sd(gpa_year1,\n                       na.rm=TRUE))\n\n# A tibble: 1 × 2\n  media desvest\n  &lt;dbl&gt;   &lt;dbl&gt;\n1  1.73   0.891\n\ndata.angrist %&gt;%\n  filter(!is.na(gpa_year1) & !is.na(grade_20059_fall)\n     & !is.na(ssp)\n     & !is.na(sfp)\n     & !is.na(sfsp)\n     & !is.na(sex)\n     & !is.na(mtongue)\n     & !is.na(hsgroup)\n     & !is.na(numcourses_nov1)\n     & !is.na(lastmin)\n     & !is.na(mom_edn)\n     & !is.na(dad_edn)\n     & female==1) %&gt;%\n  summarize(numero=n())\n\n# A tibble: 1 × 1\n  numero\n   &lt;int&gt;\n1    729"
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#footnotes",
    "href": "tareas/tarea-1-respuestas.html#footnotes",
    "title": "Respuestas a la tarea 1",
    "section": "Notas",
    "text": "Notas\n\n\nAngrist, J., Lang, D., y Oreopoulos, P. (2009). Incentives and services for college achievement: Evidence from a randomized trial. American Economic Journal: Applied Economics, 1(1), 136-63.↩︎"
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html",
    "href": "tareas/tarea-2-respuestas.html",
    "title": "Respuestas a la tarea 2",
    "section": "",
    "text": "En Crepon et al. (2015)1 se estudia una intervención en Marruecos en la que se analiza el efecto de la adopción de microfinanzas, a través de un experimento de campo. En 81 de 162 localidades estudiadas se introdujo aleatoriamente una empresa de microfinanzas. Para seleccionar las localidades de tratamiento, primero se emparejaron localidades de acuerdo a características observables y, para cada pareja se asignó a tratamiento y otra a control. La variable que identifica a las parejas es paire. La base de datos crepon_morocco_balance.csv contiene los datos de este estudio usados para mostrar la integridad del diseño. La variable treatment es la variable de asignación aleatoria, mientras que la variable client es la variable de adopción\n\n[3 puntos] Primero recordaremos cómo mostrar que el tratamiento efectivamente fue asignado de manera aleatoria. El siguiente código lee los datos que debemos usar y se queda con las observaciones de la línea base. Con estos datos, mostraremos que la variable members_resid_bl, que indica el número de personas que viven en cada hogar está balanceado entre los grupos asignados a tratamiento y control. Noten que la media del número de personas que viven en el hogar en el grupo de control es 5.14 (d.e. 2.70) y que hay 2,266 hogares en dicho grupo de control. Esto es exactamente lo que se reporta en la fila correspondiente a Number members en la tabla 1 del artículo.\n\n  data.morocco&lt;-read_csv(\"../files/crepon_morocco_balance.csv\",\n                         locale = locale(encoding = \"latin1\")) %&gt;% \n    clean_names() %&gt;% \n    filter(merge_indicator!=1)\n\n  data.morocco %&gt;% \n    group_by(treatment) %&gt;%\n    summarize(mean=mean(members_resid_bl, na.rm=T),\n              std=sd(members_resid_bl, na.rm=T),\n              n=n()) %&gt;% \n    ungroup()\n\n# A tibble: 2 × 4\n  treatment  mean   std     n\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1         0  5.14  2.69  2266\n2         1  5.19  2.76  2199\n\n\nObtenga ahora el valor de la diferencia entre el grupo de tratamiento y el de control, así como su valor \\(p\\) (últimas dos columnas). Para ello, estime una regresión en la que la variable dependiente sea número de personas que vive en el hogar members_resid_bl, en función de la variable de asignación treatment y variables dummy de pareja de localidad (la variable paire indica cuáles son las parejas). La regresión permite recuperar la diferencia de 0.04 personas que se reporta en la fila correspondiente en la tabla 1. Para recuperar el valor \\(p\\), estime errores agrupados usando la variable demi_paire, que es la clave de las distintas localidades, como variable de agrupación. Una forma de realizar esto es con la función coef_test del paquete clubSandwich.2\nEstimamos la regresión con el número de personas como variable dependiente en función de la asignación al tratamiento y de las parejas:\n\ndif_members &lt;- lm(members_resid_bl ~ treatment + factor(paire),\n   data=data.morocco)\n\nsummary(dif_members)$coef[1:7,]\n\n                  Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)     4.06166091  0.3047365 13.3284357 9.311212e-40\ntreatment       0.04334484  0.0707258  0.6128576 5.400023e-01\nfactor(paire)2  1.78431373  0.4152704  4.2967514 1.770771e-05\nfactor(paire)3  1.06107184  0.4356350  2.4356902 1.490300e-02\nfactor(paire)4 -3.08333333  0.4594672 -6.7106719 2.184193e-11\nfactor(paire)5  1.85814080  0.4442115  4.1830089 2.933028e-05\nfactor(paire)6  2.88352450  0.4262934  6.7641779 1.517259e-11\n\nnobs(dif_members)\n\n[1] 4465\n\ncoef_test(dif_members,\n          vcov = \"CR1S\", \n          cluster = data.morocco$demi_paire)[1:2,]\n\n       Coef. Estimate     SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)   4.0617 0.0647  62.80        1.03      0.00911   **\n   treatment   0.0433 0.0787   0.55       76.54      0.58361     \n\n\nObtenemos un coeficiente de 0.04334484, que se redondea a 0.04 en la tabla. El valor \\(p\\) de 0.583 es exactamente el reportado en la última columna. Aquí lo clave es calcular los errores agrupados.\n[2 puntos] Ahora mostremos que efectivamente este es un ejemplo de una intervención con cumplimiento imperfecto. Genere un cuadro que indique: 1) cuántas personas que fueron asignadas a recibir el tratamiento efectivamente fueron clientes; 2) cuántas personas que fueron asignadas a recibir el tratamiento no se convirtieron en clientes; 3) cuántas personas que no fueron asignadas a recibir el tratamiento sí se convirtieron en clientes; y 4) cuántas personas que no fueron asignadas a recibir el tratamiento tampoco se convirtieron en clientes.\n\ndata.morocco %&gt;%\n  mutate(treatment=factor(treatment, levels=c(0,1),labels=c(\"Control\", \"Tratamiento\"))) %&gt;%\n      mutate(client=factor(client, levels=c(0,1),labels=c(\"No cliente\", \"Cliente\"))) %&gt;% \n  tabyl(treatment, client,\n        show_na = F)\n\n   treatment No cliente Cliente\n     Control       2101       0\n Tratamiento       1753     251\n\n\nEste es un ejemplo de una intervención con incumplimiento de un solo lado. De aquellos asignados al tratamiento, 251 se convirtieron en clientes y 1,753 no. De aquellos asignados al control, ninguno tuvo acceso a microfinanzas. En otras palabras, podemos descartar la presencia de siempre cumplidores (always-takers). Por tanto, en este tipo de aplicaciones, el efecto del tratamiento en los tratados (támbien llamado TOT, ATET o TT) es igual al LATE.\n[5 puntos] Ahora mostraremos que la adopción, es decir, convertirse en cliente, no es independiente de las características de los hogares. Considere las variables members_resid_bl y act_number_bl, que indican el número de miembros del hogar y el número de actividades económicas del hogar. Para cada una de estas dos variables, utilice la misma especificación que en la parte a., pero ahora usando la variable cliente como regresor. ¿Qué concluye?\nPara el número de miembros del hogar:\n\nr1 &lt;- lm(members_resid_bl ~ client + factor(paire),\n                         data=data.morocco)\ncoef_test(r1,\n          vcov = \"CR1S\", \n          cluster = data.morocco$demi_paire)[1:2,]\n\n       Coef. Estimate    SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)     4.18 0.128  32.70         1.0       0.0195    *\n      client     0.43 0.180   2.38        45.4       0.0214    *\n\n\nPara el número de actividades económicas del hogar:\n\nr2 &lt;- lm(act_number_bl ~ client + factor(paire),\n                            data=data.morocco)\ncoef_test(r2,\n          vcov = \"CR1S\", \n          cluster = data.morocco$demi_paire)[1:2,]\n\n       Coef. Estimate     SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)    1.109 0.2330   4.76         1.0      0.13185     \n      client    0.191 0.0687   2.78        45.4      0.00787   **\n\n\nLa adopción no es independiente de las características de los hogares. Parece ser que los hogares que se convierten en clientes son más grandes y tienen más actividades económicas. Por tanto, comparar las variables de impacto entre quienes adoptarony no adoptaron implicaría un sesgo de selección.\n[5 puntos] Con estos elementos estamos convencidos de que es necesario emplear lo que sabemos sobre cumplimiento imperfecto. Usaremos ahora los datos en crepon_morocco_analysis.csv, que contiene los datos empleados para evaluar el impacto de la adopción. Estos datos están listos para analizarse. Estime la forma reducida del efecto de ser asignado al tratamiento sobre gasto total, expense_total. Comente los resultados, en particular, comente sobre la magnitud y la significancia estadística de la variable treatment. Aquí y en adelante, incluya los siguientes controles en la regresión: members_resid_bl, nadults_resid_bl, head_age_bl, act_livestock_bl, act_business_bl, borrowed_total_bl, members_resid_d_bl, nadults_resid_d_bl, head_age_d_bl, act_livestock_d_bl, act_business_d_bl, borrowed_total_d_bl, ccm_resp_activ, other_resp_activ, ccm_resp_activ_d y other_resp_activ_d. Además, incluya efectos fijos por pareja introduciendo la variable paire como factor. Use los mismos errores estándar que en la parte a. Con esto deberá poder recuperar el coeficiente y el error estándar de la columna (3) de la tabla 3.\nLa forma reducida estima la relación causal entre la variable de gasto y la asignación aleatoria. Se estima un efecto de 4057 unidades monetarias en el gasto, estadísticamente significativo al 5%. Este es el efecto de ser asignado al tratamiento o ITT.\n\ndata.morocco&lt;-read_csv(\"../files/crepon_morocco_analysis.csv\")   %&gt;% \n  clean_names() \n\nres_fr&lt;- lm(expense_total ~ treatment +\n              members_resid_bl + nadults_resid_bl +\n              head_age_bl + act_livestock_bl + act_business_bl +\n              borrowed_total_bl + members_resid_d_bl +\n              nadults_resid_d_bl + head_age_d_bl + act_livestock_d_bl +\n              act_business_d_bl + borrowed_total_d_bl +\n              ccm_resp_activ + other_resp_activ + ccm_resp_activ_d + \n              other_resp_activ_d + factor(paire),\n            data=data.morocco)\n\ncoef_test(res_fr,\n          vcov = \"CR1S\",\n          cluster = data.morocco$demi_paire)[1:2,]\n\n       Coef. Estimate   SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)   -18493 6735  -2.75         2.1        0.105     \n   treatment     4057 1721   2.36        74.4        0.021    *\n\n\nEste efecto estimado tiene una interpretación causal. Sin embargo, lo que nos está diciendo es la diferencia en el gasto en hogares donde el programa fue ofrecido y donde no. Pero no la diferencia en el efectivamente usar microfinanzas, que puede ser el parámetro de mayor interés. En otras palabras, el ITT es como un efecto del tratamiento, diluido por el no cumplimiento.\n[5 puntos] Estime ahora la primera etapa, es decir, estime por MCO el efecto causal de la asignación sobre la adopción. Comente sobre la magnitud, la significancia estadística y la interpretación de la variable treatment en términos del comportamiento de los cumplidores. Debería poder replicar el coeficiente y el error estándar de la columna 1 en la tabla 2 del artículo.\nLa primera etapa muestra un aumento de 16.7% en la probabilidad de ser cliente debido al tratamiento. Este efecto es estadísticamente significativo al 10%. En otras palabras, 16.7% de los individuos en la muestra son cumplidores, es decir, se vuelven clientes solo porque se les ofreció el tratamiento.\n\nres_fs&lt;- lm(client ~ treatment +\n              members_resid_bl + nadults_resid_bl +\n                head_age_bl + act_livestock_bl + act_business_bl +\n                borrowed_total_bl + members_resid_d_bl +\n                nadults_resid_d_bl + head_age_d_bl + act_livestock_d_bl +\n                act_business_d_bl + borrowed_total_d_bl +\n                ccm_resp_activ + other_resp_activ + ccm_resp_activ_d + \n                other_resp_activ_d + factor(paire),\n            data=data.morocco)\n\ncoef_test(res_fs,\n          vcov = \"CR1S\", \n          cluster = data.morocco$demi_paire)[1:2,]\n\n       Coef. Estimate     SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)  -0.0988 0.0549   -1.8         2.1        0.208     \n   treatment   0.1672 0.0118   14.2        74.4       &lt;0.001  ***\n\n\n[5 puntos] Considere la columna 3 del panel A en la Tabla 9 del artículo. Aquí se reporta la estimación por MCO de la relación entre client y gasto total, con los mismos controles y tipo de errores que antes. Replique este resultado. ¿Se puede interpretar de forma causal el coeficiente sobre client?\nNoten que para replicar la entrada la clave está en condicionar a aquellos asignados al tratamiento (como se indica en la tabla del artículo). No se puede interpretar de manera causal la relación de 11934 unidades monetarias más en el gasto en los clientes con respecto a los no clientes pues es muy posible que haya sesgo de selección. Por ejemplo, si los hogares más educados deciden adoptar en mayor medida los productos de microfinanzas, es posible pensar que esos mismos hogares hubieran tenido mayor gasto incluso sin microfinanzas. Estaríamos entonces sobreestimando el efecto del tratamiento.\n\nres_mco &lt;- lm(expense_total ~ client +\n                members_resid_bl + nadults_resid_bl +\n                head_age_bl + act_livestock_bl + act_business_bl +\n                borrowed_total_bl + members_resid_d_bl +\n                nadults_resid_d_bl + head_age_d_bl + act_livestock_d_bl +\n                act_business_d_bl + borrowed_total_d_bl +\n                ccm_resp_activ + other_resp_activ + ccm_resp_activ_d + \n                other_resp_activ_d + factor(paire),\n              data=filter(data.morocco,treatment==1))\n\ncoef_test(res_mco,\n          vcov = \"CR1S\", \n          cluster =filter(data.morocco,treatment==1)$demi_paire)[1:2,]\n\n       Coef. Estimate   SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)   -12718 9447  -1.35        65.8       0.1828     \n      client    11934 5580   2.14        41.1       0.0384    *\n\n\n[5 puntos] ¿Cuáles son los dos supuestos econométricos que permiten la estimación del Local Average Treatment Effect (LATE) en el contexto de este problema? Comente sobre la evidencia que respalda el supuesto de que los instrumentos no son débiles en este problema.\nLos supuestos necesarios son:\nRelevancia del instrumento. Se requiere que la asignación aleatoria del tratamiento efectivamente afecte la probabilidad de ser cliente. La evidencia que respalda este requerimiento es el resultado de la primera etapa. El estadístico \\(F\\) de la primera etapa es 10.86, apenas arriba de la regla de dedo de 10 que comúnmente se usa para decir que no hay presencia de instrumentos débiles.\nExclusión. Se requiere que el instrumento no pertenezca a la ecuación estructural. Esto se garantiza por la asignación aleatoria del tratamiento.\n[5 puntos] Estime el efecto del cumplimiento sobre el gasto total, usando la asignación aleatoria como instrumento del cumplimiento. Es decir, estime el LATE. Use los mismos controles y tipo de errores que en c. Este resultado se reporta en la columna 3 del panel B en la Tabla 9. ¿Cuál es la interpretación del coeficiente de la variable client? En R, la función ivreg del paquete AER le permite hacer la estimación de MC2E.\nEl LATE estimado es de 24263 monetarias adicionales de gasto debido a ser cliente. Esta cifra es considerablemente mayor que las 4057 unidades monetarias estimada en la forma reducida. Este es un efecto local pues solo considera el cambio en el gasto debido a ser cliente de la microfinanciera, en aquellos individuos que cambiaron su comportamiento debido a la asignación aleatoria del tratamiento. Noten también que en todas las regresiones se incluye errores agrupados a nivel pareja o paire.\n\nres_iv &lt;- ivreg(expense_total ~ client + members_resid_bl + nadults_resid_bl\n     + head_age_bl + act_livestock_bl + act_business_bl \n     + borrowed_total_bl + members_resid_d_bl + nadults_resid_d_bl\n     + head_age_d_bl + act_livestock_d_bl + act_business_d_bl \n     + borrowed_total_d_bl + ccm_resp_activ + other_resp_activ \n     + ccm_resp_activ_d  + other_resp_activ_d + factor(paire) |\n       treatment +  members_resid_bl + nadults_resid_bl\n     + head_age_bl + act_livestock_bl + act_business_bl \n     + borrowed_total_bl + members_resid_d_bl + nadults_resid_d_bl\n     + head_age_d_bl + act_livestock_d_bl + act_business_d_bl \n     + borrowed_total_d_bl + ccm_resp_activ + other_resp_activ \n     + ccm_resp_activ_d  + other_resp_activ_d + factor(paire),\n     data=data.morocco)\n\nsummary(res_iv)$coefficients[1:2,]\n\n             Estimate Std. Error   t value   Pr(&gt;|t|)\n(Intercept) -16095.68   11033.49 -1.458802 0.14468442\nclient       24263.46   12419.55  1.953651 0.05080007\n\ncoef_test(res_iv,\n          vcov = \"CR1S\", \n          cluster = data.morocco$demi_paire)[1:2,]\n\n       Coef. Estimate   SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)   -16096 7144  -2.25        2.11       0.1464     \n      client    24263 9944   2.44       74.45       0.0171    *\n\n\n\n\n\n\nSea una variable de resultados \\(y_i\\), una variable de asignación aleatoria \\(Z_i\\) y una variable de adopción \\(D_i\\). El estimador de Wald se define como:\n\\[\\hat{\\beta}_{Wald}=\\frac{\\bar{Y}_{Z_i=1}-\\bar{Y}_{Z_i=0}}{\\bar{D}_{Z_i=1}-\\bar{D}_{Z_i=0}}\\]\nEn esta pregunta mostraremos cómo el estimador de Wald es equivalente al estimador de VI cuando no hay controles. Use nuevamente los datos en crepon_morocco_analysis.csv.\n\n[10 puntos] Obtenga el estimador de Wald como el cociente de la diferencia en gasto total promedio entre los hogares asignados a tratamiento y control dividido por la diferencia en la probabilidad de adopción entre los hogares asignados a tratamiento y control. Recuerde que la variable del gasto total es expense_total.\nObtenemos el estadístico de Wald, usando la definición:\n\ndata.morocco&lt;-read_csv(\"../files/crepon_morocco_analysis.csv\")   %&gt;% \n  clean_names() \n\nmean_cliente&lt;-data.morocco %&gt;%\n  group_by(treatment) %&gt;% \n  summarize(p_cliente=mean(client, na.rm=F)) %&gt;% \n  ungroup()\n\nmean_gasto&lt;-data.morocco %&gt;%\n  group_by(treatment) %&gt;% \n  summarize(m_gasto=mean(expense_total, na.rm=F)) %&gt;% \n  ungroup()\n\n#Neceistamos la diferencia de gastos y de probabilidad de ser cliente\ndif_gasto &lt;- mean_gasto[2,2]-mean_gasto[1,2]\ndif_cliente &lt;- mean_cliente[2,2]-mean_cliente[1,2]\n\nWald &lt;- as.numeric(dif_gasto / dif_cliente)\nWald\n\n[1] 22869.23\n\n\n[5 puntos] Ahora estime por MC2E el efecto de la adopción sobre el gasto total, usando la variable de asignación como instrumento para la adopción. Use ivreg para estimar el efecto directamente. ¿Qué ventaja observa con respecto al estimador de Wald?\nNotemos que obtenemos lo mismo al hacer una estimación de variables instrumentales. El coeficiente sobre la variable client es igual al estadístico de Wald. El estadístico de Wald es idéntico al estimador de variables instrumentales cuando el instrumento es binario. La mayor ventaja de realizar la estimación de esta manera es que podemos obtener errores estándar, lo cual nos permite hacer inferencia estadística sobre el tamaño del efecto de ser cliente en el gasto.\n\nWald_vi &lt;- ivreg(expense_total ~ client  | treatment,\n                data=data.morocco)\n\n#Notemos que obtenemos directamente el error estándar\nsummary(Wald_vi)\n\n\nCall:\nivreg(formula = expense_total ~ client | treatment, data = data.morocco)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n -44264  -21394  -17064   -4804 1305816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    21395       1496  14.298   &lt;2e-16 ***\nclient         22869      12684   1.803   0.0714 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 74610 on 4932 degrees of freedom\nMultiple R-Squared: 0.00651, Adjusted R-squared: 0.006309 \nWald test: 3.251 on 1 and 4932 DF,  p-value: 0.07144 \n\n\n[10 puntos] Ahora estime por MC2E el efecto de la adopción sobre el gasto total, usando la variable de asignación como instrumento para la adopción. A diferencia del punto previo, realice la estimación a mano, es decir, primero estime los valores ajustados de la variable endógena en una primera etapa y luego use estos valores ajustados en la estimación estructural. ¿Qué desventaja observa con respecto a la estimación del punto previo?\nPodemos obtener el mismo coeficiente haciendo MC2E a mano, lo cual nunca es recomendable debido a que la inferencia sobre el coeficiente de la segunda etapa es incorrecta. Sin embargo, nos deja ver cómo podemos entender el proceso de estimación conceptualmente.\nEstimamos la primera etapa y obtenemos los valores ajustados:\n\np.e &lt;- lm(client ~ treatment,\n                data=data.morocco)\n\ndata.morocco &lt;- data.morocco %&gt;% \n  mutate(client_hat = predict(p.e))\n\nAhora usamos los valores ajustados en la regresión de la segunda etapa:\n\ns.e &lt;- lm(expense_total ~ client_hat,\n                data=data.morocco)\n\nsummary(s.e)\n\n\nCall:\nlm(formula = expense_total ~ client_hat, data = data.morocco)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n -25225  -21394  -17879   -5647 1305816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    21395       1501  14.256   &lt;2e-16 ***\nclient_hat     22869      12721   1.798   0.0723 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 74830 on 4932 degrees of freedom\nMultiple R-squared:  0.0006549,  Adjusted R-squared:  0.0004522 \nF-statistic: 3.232 on 1 and 4932 DF,  p-value: 0.07228\n\n\nY obtenemos de nuevo 22,869 unidades monetarias como impacto estimado.\nLa desventaja de este procedimiento es que los errores estándar son incorrectos pues la estimación de la ecuación estructural no considera el error muestral de la primera etapa y, por tanto, considera a los valores de client_hat como si fueran directamente observados.\n\n\n\n\nEn la Pregunta 2, parte a, obtuvo el estimador de Wald para aproximar el efecto de la adopción en el gasto total como un cosciente de dos diferencias de medias.\n\n[5 puntos] Utilice un procedimiento bootstrap a mano para estimar el error estándar del estimador de Wald usando 50 repeticiones. Es decir, debe realizar un remuestreo de los datos originales y para cada muestra obtener el estimador de Wald. Luego, obtenga la desviación estándar de los 50 estadísticos calculados. Utilice una semilla para poder replicar sus resultados.\nYa sabemos calcular un estadístico de Wald, como en la Pregunta 2, parte a. La idea ahora es repetir dicho proceso B veces, pero en cada repetición con una muestra bootstrap a la mano:\n\ndata.morocco&lt;- read.csv(\"../files/crepon_morocco_analysis.csv\") %&gt;%\n  select(treatment,client,expense_total)\n\nobs &lt;- nrow(data.morocco)\n\n#Solo para ejemplificar, la siguiente línea pide el remuestreo, es decir, obtener una muestra de tamaño N de la muestra original, con reemplazo\ndata.b &lt;-data.morocco[sample(nrow(data.morocco),obs, replace = TRUE),]\n\n#Simplemente repetimos el proceso anterior B veces\nset.seed(821)\nB=50\n#Inicializamos el vector donde guardaremos los W estimados\nWrep50_1 &lt;- data.frame(W=matrix(ncol = 1, nrow = B))\n\nfor (i in 1:B)\n{\n  data.b &lt;-data.morocco[sample(nrow(data.morocco),obs, replace = TRUE),]\n\n  #Literalmente pegamos el cálculo de un W, hecho en la Pregunta 2a\n\n  mean_cliente&lt;-data.b %&gt;%\ngroup_by(treatment) %&gt;% \nsummarize(p_cliente=mean(client, na.rm=F)) %&gt;% \nungroup()\n\n  mean_gasto&lt;-data.b %&gt;%\ngroup_by(treatment) %&gt;% \nsummarize(m_gasto=mean(expense_total, na.rm=F)) %&gt;% \nungroup()\n\n  dif_gasto &lt;- mean_gasto[2,2]-mean_gasto[1,2]\n  dif_cliente &lt;- mean_cliente[2,2]-mean_cliente[1,2]\n\n  #Y lo guardamos en la posición adecuada\n\n  Wrep50_1[i,1] &lt;- as.numeric(dif_gasto / dif_cliente)\n}\n\n#El error estimado es simplemente la desviación estándar de los B estadísticos estimados\nsd(Wrep50_1$W)\n\n[1] 14735.91\n\n\n[5 puntos] Reemplace la semilla de la parte a. por una nueva semilla y estime nuevamente el error estándar del estimador de Wald con 50 repeticiones. Comente sobre la diferencia entre este error estándar y el de la parte a.\nEl cambio que observamos en el error estándar estimado por bootstrap entre esta parte y la parte a. es que al cambiar la semilla, los números aleatorios generados son distitnos y, por tanto, cada muestra bootstrap tiene distintos individuos.\n\n#Simplemente cambiamos la semilla\nset.seed(8212)\nB=50\n#Inicializamos el vector donde guardaremos los W estimados\nWrep50_2 &lt;- data.frame(W=matrix(ncol = 1, nrow = B))\n\nfor (i in 1:B)\n{\n  data.b &lt;-data.morocco[sample(nrow(data.morocco),obs, replace = TRUE),]\n\n  mean_cliente&lt;-data.b %&gt;%\ngroup_by(treatment) %&gt;% \nsummarize(p_cliente=mean(client, na.rm=F)) %&gt;% \nungroup()\n\n  mean_gasto&lt;-data.b %&gt;%\ngroup_by(treatment) %&gt;% \nsummarize(m_gasto=mean(expense_total, na.rm=F)) %&gt;% \nungroup()\n\n  dif_gasto &lt;- mean_gasto[2,2]-mean_gasto[1,2]\n  dif_cliente &lt;- mean_cliente[2,2]-mean_cliente[1,2]\n\n  Wrep50_2[i,1] &lt;- as.numeric(dif_gasto / dif_cliente)\n}\n\nsd(Wrep50_2$W)\n\n[1] 14869.02\n\n\n[5 puntos] Regrese el valor de la semilla al usado en a. y estime nuevamente el error estándar del estimador de Wald, esta vez usando 1000 repeticiones. Comente sobre la diferencia entre este error estándar y el de la parte a.\nAhora las diferencias en el error estimado surgen porque tenemos muchas más repeticiones bootstrap. Lo más importante de estos procedimientos es que pueda implementarlos a otros contextos. Por ejemplo, podemos hacer obtener errores bootstrap para el vector de coeficientes de una estimación de MC2E, para el producto de dos coeficientes, etc.\n\n#Regresamos a la primera semilla pero ahora B=1000\nset.seed(820)\nB=1000\n\nWrep1000 &lt;- data.frame(W=matrix(ncol = 1, nrow = B))\n\nfor (i in 1:B)\n{\n  data.b &lt;-data.morocco[sample(nrow(data.morocco),obs, replace = TRUE),]\n\n  mean_cliente&lt;-data.b %&gt;%\ngroup_by(treatment) %&gt;% \nsummarize(p_cliente=mean(client, na.rm=F)) %&gt;% \nungroup()\n\n  mean_gasto&lt;-data.b %&gt;%\ngroup_by(treatment) %&gt;% \nsummarize(m_gasto=mean(expense_total, na.rm=F)) %&gt;% \nungroup()\n\n  dif_gasto &lt;- mean_gasto[2,2]-mean_gasto[1,2]\n  dif_cliente &lt;- mean_cliente[2,2]-mean_cliente[1,2]\n\n  Wrep1000[i,1] &lt;- as.numeric(dif_gasto / dif_cliente)\n}\n\n#El error estimado es simplemente la desviación estándar de los B estadísticos estimados\nsd(Wrep1000$W)\n\n[1] 12998.05\n\n\n\n\n\n\nConsidere nuevamente la base STAR_public_use.csv usada en la Tarea 1 del artículo Angrist, Lang y Oreopoulos (2009)3. En esta pregunta nos concentraremos en los efectos de la intervención en el año 2, mostrados en la columna (4) de la Tabla 6, sobre dos variables, el promedio de calificaciones gpa_year2 y los créditos completados credits_earned2.\nEl propósito de esta pregunta es mostrar la función de los \\(z\\)-scores en el análisis de efectos de tratamiento. De nuevo, puede quedarse solo con las observaciones que tienen noshow igual a 0. Antes de comenzar su análisis, sustituya por NA los valores en credits_earned2 para aquellas observaciones que tienen \\(NA\\) en la variable prob_year1.\n\n[5 puntos] Para tener un punto de comparación, estime la ecuación del efecto de tratamiento para gpa_year2 usando la misma especificación que en la pregunta 5 de la Tarea 1. Use también errores robustos. Deberá poder replicar los coeficientes y errores estándar del panel A, columna (4). ¿Cómo se interpretan el coeficiente sobre la variable ssp?\nUsando la misma especificación que usamos en la Tarea 1, obtenemos los coeficientes en el artículo.\n\ndata.angrist&lt;-read_csv(\"../files/STAR_public_use.csv\",\n                 locale = locale(encoding = \"latin1\"))   %&gt;% \n  clean_names()\n\ndata.angrist&lt;-data.angrist %&gt;% \n  filter(noshow==0) %&gt;% \n  mutate(credits_earned2=ifelse(is.na(prob_year1),NA,credits_earned2)) \n\n\nr1 &lt;-lm(gpa_year2 ~ ssp + sfp+ sfsp+\n             factor(sex)+\n             factor(mtongue)+\n             factor(hsgroup)+\n             factor(numcourses_nov1)+\n             factor(lastmin)+\n             factor(mom_edn)+\n             factor(dad_edn),\n           data.angrist)\ncoeftest(r1, vcov = vcovHC(r1, \"HC1\"))[1:4,]\n\n               Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)  2.87240513 0.45314003  6.3388908 3.261488e-10\nssp          0.05018813 0.07423854  0.6760388 4.991454e-01\nsfp         -0.01807372 0.06618352 -0.2730848 7.848347e-01\nsfsp         0.07158763 0.09081195  0.7883063 4.306722e-01\n\n\n[5 puntos] Genere un \\(z\\)-score para la variable gpa_year2 al que llame gpa_year2_sd. Para ello, calcule la media y desviación estándar de gpa_year2 para el grupo de control y luego genere gpa_year2_sd restándole a gpa_year2 la media obtenida y dividiendo esta diferencia por la desviación estándar obtenida. Compruebe que si calcula la media y la desviación estándar de gpa_year2_sd, en el grupo de control estas deberían ser 0 y 1, respectivamente.\nCreamos un z-score:\n\ngpa_year2_stats &lt;- data.angrist %&gt;% \n    filter(control==1) %&gt;% \n    summarize(media=mean(gpa_year2,na.rm=T),\n              desvest=sd(gpa_year2,na.rm=T))\n\ndata.angrist &lt;- data.angrist %&gt;% \n    mutate(gpa_year2_sd=(gpa_year2-gpa_year2_stats$media)/gpa_year2_stats$desvest)\n\nTiene media igual a 0:\n\ndata.angrist %&gt;%\n  filter(control==1) %&gt;% \n  summarize(media=mean(gpa_year2_sd,na.rm=T))\n\n# A tibble: 1 × 1\n     media\n     &lt;dbl&gt;\n1 1.60e-16\n\n\nY desviación estándar igual a 1:\n\ndata.angrist %&gt;%\n  filter(control==1) %&gt;% \n  summarize(desvest=sd(gpa_year2_sd,na.rm=T)) \n\n# A tibble: 1 × 1\n  desvest\n    &lt;dbl&gt;\n1       1\n\n\n[5 puntos] Realice la misma estimación que en la parte a., pero ahora use como variable dependiente gpa_year2_sd. ¿Cómo se interpreta el coeficiente sobre ssp? ¿Qué es diferente y qué es igual entre los resultados obtenidos en esta parte y los obtenidos en la parte a.?\nRealizamos la estimación, pero con la variable dependiente estandarizada:\n\nr2 &lt;-lm(gpa_year2_sd ~ ssp + sfp+ sfsp+\n             factor(sex)+\n             factor(mtongue)+\n             factor(hsgroup)+\n             factor(numcourses_nov1)+\n             factor(lastmin)+\n             factor(mom_edn)+\n             factor(dad_edn),\n           data.angrist)\n\ncoeftest(r2, vcov = vcovHC(r2, \"HC1\"))[1:4,]\n\n               Estimate Std. Error    t value   Pr(&gt;|t|)\n(Intercept)  0.94640721 0.50806908  1.8627530 0.06273961\nssp          0.05627187 0.08323764  0.6760388 0.49914542\nsfp         -0.02026459 0.07420621 -0.2730848 0.78483470\nsfsp         0.08026539 0.10182006  0.7883063 0.43067220\n\n\nLos coeficientes estimados son diferentes. Ahora el coeficiente sobre ssp es el efecto que tiene el programa en el z-score del promedio de calificaciones, es decir, el SSP tiene un efecto de 0.056 desviaciones estándar en el z-score del promedio de calificaciones, aunque este efecto no es estadísticamente significativo. La magnitud del error estándar también es diferente, pues ahora las variables están en distintas unidades. Noten, en cambio, que el estadístico t asociado a SSP es exactamente igual al de la parte a., por lo que en ambos casos no se rechaza la \\(H_0\\).\n\ncoeftest(r1, vcov = vcovHC(r1, \"HC1\"))[1:4,]\n\n               Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)  2.87240513 0.45314003  6.3388908 3.261488e-10\nssp          0.05018813 0.07423854  0.6760388 4.991454e-01\nsfp         -0.01807372 0.06618352 -0.2730848 7.848347e-01\nsfsp         0.07158763 0.09081195  0.7883063 4.306722e-01\n\n\n[5 puntos] Ahora realizaremos un índice de mejora en educación, al agregar los resultados de estos dos indicadores en una sola variable, como se describe en Banerjee et al. (2015)4. Para ello, primero genere credits_earned2_sd, que será la versión estandarizada de credits_earned2, siguiendo el mismo procedimiento que en la parte b. En seguida, genere una nueva variable llamada indice_escolar, que será el promedio de credits_earned2_sd y gpa_year2_sd. Luego, calcule la media y la desviación estándar de indice_escolar en el grupo de control. Finalmente, genere una nueva variable indice_escolar_sd restándole a indice_escolar la media antes calculada y dividiendo esta diferencia por la desviación estándar antes calculada. Muestre que la variable indice_escolar_sd tiene media 0 y desviación estándar 1 en el grupo de control.\nPrimero creamos la versión estandarizada de la variable de créditos:\n\ncredits_earned2_stats &lt;- data.angrist %&gt;% \n  filter(control==1) %&gt;% \n  summarize(media=mean(credits_earned2,na.rm=T),\n            desvest=sd(credits_earned2,na.rm=T))\n\ndata.angrist &lt;- data.angrist %&gt;% \n  mutate(credits_earned2_sd=(credits_earned2-credits_earned2_stats$media)/credits_earned2_stats$desvest)\n\nLuego calculamos la media de las dos variables estandarizadas:\n\ndata.angrist &lt;- data.angrist %&gt;% \n  mutate(indice_escolar=rowMeans(select(.,credits_earned2_sd,gpa_year2_sd)))\n\nAhora obtenemos la media y la desviación estándar en el grupo de control del promedio antes calculado:\n\nindice_escolar_stats &lt;- data.angrist %&gt;% \n  filter(control==1) %&gt;% \n  summarize(media=mean(indice_escolar,na.rm=T),\n            desvest=sd(indice_escolar,na.rm=T))\n\ndata.angrist &lt;- data.angrist %&gt;% \n  mutate(indice_escolar_sd=(indice_escolar-indice_escolar_stats$media)/indice_escolar_stats$desvest)\n\nEfectivamente tiene media igual a 0:\n\ndata.angrist %&gt;%\n  filter(control==1) %&gt;% \n  summarize(media=mean(indice_escolar_sd,na.rm=T))\n\n# A tibble: 1 × 1\n      media\n      &lt;dbl&gt;\n1 -1.33e-17\n\n\nY desviación estándar igual a 1:\n\ndata.angrist %&gt;%\n  filter(control==1) %&gt;% \n  summarize(desvest=sd(indice_escolar_sd,na.rm=T)) \n\n# A tibble: 1 × 1\n  desvest\n    &lt;dbl&gt;\n1       1\n\n\n[5 puntos] Estime ahora el efecto de tratamiento sobre indice_escolar_sd, siguiendo la misma especificación econométrica que en la parte a. y usando errores robustos. ¿Qué concluye?\nEstimamos usando la misma especificación, pero ahora con el índice compuesto como variable de impacto:\n\nr3 &lt;-lm(indice_escolar_sd ~ ssp + sfp+ sfsp+\n                             factor(sex)+\n                             factor(mtongue)+\n                             factor(hsgroup)+\n                             factor(numcourses_nov1)+\n                             factor(lastmin)+\n                             factor(mom_edn)+\n                             factor(dad_edn),\n                           data.angrist)\n\ncoeftest(r3, vcov = vcovHC(r3, \"HC1\"))[1:4,]\n\n               Estimate Std. Error    t value  Pr(&gt;|t|)\n(Intercept)  0.49452306 0.46650249  1.0600652 0.2893277\nssp          0.02805373 0.08261358  0.3395778 0.7342338\nsfp         -0.02543190 0.07385703 -0.3443396 0.7306511\nsfsp         0.03404990 0.09616572  0.3540753 0.7233445\n\n\nLa ventaja de este procedimiento es que solo probamos una hipótesis en lugar de dos. Si tuviéramos muchas variables de impacto, tendríamos que probar múltiples hipótesis, incrementando la probabilidad de falsos rechazos. La construcción de índices es una alternativa para enfrentar este problema."
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#pregunta-1",
    "href": "tareas/tarea-2-respuestas.html#pregunta-1",
    "title": "Respuestas a la tarea 2",
    "section": "",
    "text": "En Crepon et al. (2015)1 se estudia una intervención en Marruecos en la que se analiza el efecto de la adopción de microfinanzas, a través de un experimento de campo. En 81 de 162 localidades estudiadas se introdujo aleatoriamente una empresa de microfinanzas. Para seleccionar las localidades de tratamiento, primero se emparejaron localidades de acuerdo a características observables y, para cada pareja se asignó a tratamiento y otra a control. La variable que identifica a las parejas es paire. La base de datos crepon_morocco_balance.csv contiene los datos de este estudio usados para mostrar la integridad del diseño. La variable treatment es la variable de asignación aleatoria, mientras que la variable client es la variable de adopción\n\n[3 puntos] Primero recordaremos cómo mostrar que el tratamiento efectivamente fue asignado de manera aleatoria. El siguiente código lee los datos que debemos usar y se queda con las observaciones de la línea base. Con estos datos, mostraremos que la variable members_resid_bl, que indica el número de personas que viven en cada hogar está balanceado entre los grupos asignados a tratamiento y control. Noten que la media del número de personas que viven en el hogar en el grupo de control es 5.14 (d.e. 2.70) y que hay 2,266 hogares en dicho grupo de control. Esto es exactamente lo que se reporta en la fila correspondiente a Number members en la tabla 1 del artículo.\n\n  data.morocco&lt;-read_csv(\"../files/crepon_morocco_balance.csv\",\n                         locale = locale(encoding = \"latin1\")) %&gt;% \n    clean_names() %&gt;% \n    filter(merge_indicator!=1)\n\n  data.morocco %&gt;% \n    group_by(treatment) %&gt;%\n    summarize(mean=mean(members_resid_bl, na.rm=T),\n              std=sd(members_resid_bl, na.rm=T),\n              n=n()) %&gt;% \n    ungroup()\n\n# A tibble: 2 × 4\n  treatment  mean   std     n\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1         0  5.14  2.69  2266\n2         1  5.19  2.76  2199\n\n\nObtenga ahora el valor de la diferencia entre el grupo de tratamiento y el de control, así como su valor \\(p\\) (últimas dos columnas). Para ello, estime una regresión en la que la variable dependiente sea número de personas que vive en el hogar members_resid_bl, en función de la variable de asignación treatment y variables dummy de pareja de localidad (la variable paire indica cuáles son las parejas). La regresión permite recuperar la diferencia de 0.04 personas que se reporta en la fila correspondiente en la tabla 1. Para recuperar el valor \\(p\\), estime errores agrupados usando la variable demi_paire, que es la clave de las distintas localidades, como variable de agrupación. Una forma de realizar esto es con la función coef_test del paquete clubSandwich.2\nEstimamos la regresión con el número de personas como variable dependiente en función de la asignación al tratamiento y de las parejas:\n\ndif_members &lt;- lm(members_resid_bl ~ treatment + factor(paire),\n   data=data.morocco)\n\nsummary(dif_members)$coef[1:7,]\n\n                  Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)     4.06166091  0.3047365 13.3284357 9.311212e-40\ntreatment       0.04334484  0.0707258  0.6128576 5.400023e-01\nfactor(paire)2  1.78431373  0.4152704  4.2967514 1.770771e-05\nfactor(paire)3  1.06107184  0.4356350  2.4356902 1.490300e-02\nfactor(paire)4 -3.08333333  0.4594672 -6.7106719 2.184193e-11\nfactor(paire)5  1.85814080  0.4442115  4.1830089 2.933028e-05\nfactor(paire)6  2.88352450  0.4262934  6.7641779 1.517259e-11\n\nnobs(dif_members)\n\n[1] 4465\n\ncoef_test(dif_members,\n          vcov = \"CR1S\", \n          cluster = data.morocco$demi_paire)[1:2,]\n\n       Coef. Estimate     SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)   4.0617 0.0647  62.80        1.03      0.00911   **\n   treatment   0.0433 0.0787   0.55       76.54      0.58361     \n\n\nObtenemos un coeficiente de 0.04334484, que se redondea a 0.04 en la tabla. El valor \\(p\\) de 0.583 es exactamente el reportado en la última columna. Aquí lo clave es calcular los errores agrupados.\n[2 puntos] Ahora mostremos que efectivamente este es un ejemplo de una intervención con cumplimiento imperfecto. Genere un cuadro que indique: 1) cuántas personas que fueron asignadas a recibir el tratamiento efectivamente fueron clientes; 2) cuántas personas que fueron asignadas a recibir el tratamiento no se convirtieron en clientes; 3) cuántas personas que no fueron asignadas a recibir el tratamiento sí se convirtieron en clientes; y 4) cuántas personas que no fueron asignadas a recibir el tratamiento tampoco se convirtieron en clientes.\n\ndata.morocco %&gt;%\n  mutate(treatment=factor(treatment, levels=c(0,1),labels=c(\"Control\", \"Tratamiento\"))) %&gt;%\n      mutate(client=factor(client, levels=c(0,1),labels=c(\"No cliente\", \"Cliente\"))) %&gt;% \n  tabyl(treatment, client,\n        show_na = F)\n\n   treatment No cliente Cliente\n     Control       2101       0\n Tratamiento       1753     251\n\n\nEste es un ejemplo de una intervención con incumplimiento de un solo lado. De aquellos asignados al tratamiento, 251 se convirtieron en clientes y 1,753 no. De aquellos asignados al control, ninguno tuvo acceso a microfinanzas. En otras palabras, podemos descartar la presencia de siempre cumplidores (always-takers). Por tanto, en este tipo de aplicaciones, el efecto del tratamiento en los tratados (támbien llamado TOT, ATET o TT) es igual al LATE.\n[5 puntos] Ahora mostraremos que la adopción, es decir, convertirse en cliente, no es independiente de las características de los hogares. Considere las variables members_resid_bl y act_number_bl, que indican el número de miembros del hogar y el número de actividades económicas del hogar. Para cada una de estas dos variables, utilice la misma especificación que en la parte a., pero ahora usando la variable cliente como regresor. ¿Qué concluye?\nPara el número de miembros del hogar:\n\nr1 &lt;- lm(members_resid_bl ~ client + factor(paire),\n                         data=data.morocco)\ncoef_test(r1,\n          vcov = \"CR1S\", \n          cluster = data.morocco$demi_paire)[1:2,]\n\n       Coef. Estimate    SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)     4.18 0.128  32.70         1.0       0.0195    *\n      client     0.43 0.180   2.38        45.4       0.0214    *\n\n\nPara el número de actividades económicas del hogar:\n\nr2 &lt;- lm(act_number_bl ~ client + factor(paire),\n                            data=data.morocco)\ncoef_test(r2,\n          vcov = \"CR1S\", \n          cluster = data.morocco$demi_paire)[1:2,]\n\n       Coef. Estimate     SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)    1.109 0.2330   4.76         1.0      0.13185     \n      client    0.191 0.0687   2.78        45.4      0.00787   **\n\n\nLa adopción no es independiente de las características de los hogares. Parece ser que los hogares que se convierten en clientes son más grandes y tienen más actividades económicas. Por tanto, comparar las variables de impacto entre quienes adoptarony no adoptaron implicaría un sesgo de selección.\n[5 puntos] Con estos elementos estamos convencidos de que es necesario emplear lo que sabemos sobre cumplimiento imperfecto. Usaremos ahora los datos en crepon_morocco_analysis.csv, que contiene los datos empleados para evaluar el impacto de la adopción. Estos datos están listos para analizarse. Estime la forma reducida del efecto de ser asignado al tratamiento sobre gasto total, expense_total. Comente los resultados, en particular, comente sobre la magnitud y la significancia estadística de la variable treatment. Aquí y en adelante, incluya los siguientes controles en la regresión: members_resid_bl, nadults_resid_bl, head_age_bl, act_livestock_bl, act_business_bl, borrowed_total_bl, members_resid_d_bl, nadults_resid_d_bl, head_age_d_bl, act_livestock_d_bl, act_business_d_bl, borrowed_total_d_bl, ccm_resp_activ, other_resp_activ, ccm_resp_activ_d y other_resp_activ_d. Además, incluya efectos fijos por pareja introduciendo la variable paire como factor. Use los mismos errores estándar que en la parte a. Con esto deberá poder recuperar el coeficiente y el error estándar de la columna (3) de la tabla 3.\nLa forma reducida estima la relación causal entre la variable de gasto y la asignación aleatoria. Se estima un efecto de 4057 unidades monetarias en el gasto, estadísticamente significativo al 5%. Este es el efecto de ser asignado al tratamiento o ITT.\n\ndata.morocco&lt;-read_csv(\"../files/crepon_morocco_analysis.csv\")   %&gt;% \n  clean_names() \n\nres_fr&lt;- lm(expense_total ~ treatment +\n              members_resid_bl + nadults_resid_bl +\n              head_age_bl + act_livestock_bl + act_business_bl +\n              borrowed_total_bl + members_resid_d_bl +\n              nadults_resid_d_bl + head_age_d_bl + act_livestock_d_bl +\n              act_business_d_bl + borrowed_total_d_bl +\n              ccm_resp_activ + other_resp_activ + ccm_resp_activ_d + \n              other_resp_activ_d + factor(paire),\n            data=data.morocco)\n\ncoef_test(res_fr,\n          vcov = \"CR1S\",\n          cluster = data.morocco$demi_paire)[1:2,]\n\n       Coef. Estimate   SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)   -18493 6735  -2.75         2.1        0.105     \n   treatment     4057 1721   2.36        74.4        0.021    *\n\n\nEste efecto estimado tiene una interpretación causal. Sin embargo, lo que nos está diciendo es la diferencia en el gasto en hogares donde el programa fue ofrecido y donde no. Pero no la diferencia en el efectivamente usar microfinanzas, que puede ser el parámetro de mayor interés. En otras palabras, el ITT es como un efecto del tratamiento, diluido por el no cumplimiento.\n[5 puntos] Estime ahora la primera etapa, es decir, estime por MCO el efecto causal de la asignación sobre la adopción. Comente sobre la magnitud, la significancia estadística y la interpretación de la variable treatment en términos del comportamiento de los cumplidores. Debería poder replicar el coeficiente y el error estándar de la columna 1 en la tabla 2 del artículo.\nLa primera etapa muestra un aumento de 16.7% en la probabilidad de ser cliente debido al tratamiento. Este efecto es estadísticamente significativo al 10%. En otras palabras, 16.7% de los individuos en la muestra son cumplidores, es decir, se vuelven clientes solo porque se les ofreció el tratamiento.\n\nres_fs&lt;- lm(client ~ treatment +\n              members_resid_bl + nadults_resid_bl +\n                head_age_bl + act_livestock_bl + act_business_bl +\n                borrowed_total_bl + members_resid_d_bl +\n                nadults_resid_d_bl + head_age_d_bl + act_livestock_d_bl +\n                act_business_d_bl + borrowed_total_d_bl +\n                ccm_resp_activ + other_resp_activ + ccm_resp_activ_d + \n                other_resp_activ_d + factor(paire),\n            data=data.morocco)\n\ncoef_test(res_fs,\n          vcov = \"CR1S\", \n          cluster = data.morocco$demi_paire)[1:2,]\n\n       Coef. Estimate     SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)  -0.0988 0.0549   -1.8         2.1        0.208     \n   treatment   0.1672 0.0118   14.2        74.4       &lt;0.001  ***\n\n\n[5 puntos] Considere la columna 3 del panel A en la Tabla 9 del artículo. Aquí se reporta la estimación por MCO de la relación entre client y gasto total, con los mismos controles y tipo de errores que antes. Replique este resultado. ¿Se puede interpretar de forma causal el coeficiente sobre client?\nNoten que para replicar la entrada la clave está en condicionar a aquellos asignados al tratamiento (como se indica en la tabla del artículo). No se puede interpretar de manera causal la relación de 11934 unidades monetarias más en el gasto en los clientes con respecto a los no clientes pues es muy posible que haya sesgo de selección. Por ejemplo, si los hogares más educados deciden adoptar en mayor medida los productos de microfinanzas, es posible pensar que esos mismos hogares hubieran tenido mayor gasto incluso sin microfinanzas. Estaríamos entonces sobreestimando el efecto del tratamiento.\n\nres_mco &lt;- lm(expense_total ~ client +\n                members_resid_bl + nadults_resid_bl +\n                head_age_bl + act_livestock_bl + act_business_bl +\n                borrowed_total_bl + members_resid_d_bl +\n                nadults_resid_d_bl + head_age_d_bl + act_livestock_d_bl +\n                act_business_d_bl + borrowed_total_d_bl +\n                ccm_resp_activ + other_resp_activ + ccm_resp_activ_d + \n                other_resp_activ_d + factor(paire),\n              data=filter(data.morocco,treatment==1))\n\ncoef_test(res_mco,\n          vcov = \"CR1S\", \n          cluster =filter(data.morocco,treatment==1)$demi_paire)[1:2,]\n\n       Coef. Estimate   SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)   -12718 9447  -1.35        65.8       0.1828     \n      client    11934 5580   2.14        41.1       0.0384    *\n\n\n[5 puntos] ¿Cuáles son los dos supuestos econométricos que permiten la estimación del Local Average Treatment Effect (LATE) en el contexto de este problema? Comente sobre la evidencia que respalda el supuesto de que los instrumentos no son débiles en este problema.\nLos supuestos necesarios son:\nRelevancia del instrumento. Se requiere que la asignación aleatoria del tratamiento efectivamente afecte la probabilidad de ser cliente. La evidencia que respalda este requerimiento es el resultado de la primera etapa. El estadístico \\(F\\) de la primera etapa es 10.86, apenas arriba de la regla de dedo de 10 que comúnmente se usa para decir que no hay presencia de instrumentos débiles.\nExclusión. Se requiere que el instrumento no pertenezca a la ecuación estructural. Esto se garantiza por la asignación aleatoria del tratamiento.\n[5 puntos] Estime el efecto del cumplimiento sobre el gasto total, usando la asignación aleatoria como instrumento del cumplimiento. Es decir, estime el LATE. Use los mismos controles y tipo de errores que en c. Este resultado se reporta en la columna 3 del panel B en la Tabla 9. ¿Cuál es la interpretación del coeficiente de la variable client? En R, la función ivreg del paquete AER le permite hacer la estimación de MC2E.\nEl LATE estimado es de 24263 monetarias adicionales de gasto debido a ser cliente. Esta cifra es considerablemente mayor que las 4057 unidades monetarias estimada en la forma reducida. Este es un efecto local pues solo considera el cambio en el gasto debido a ser cliente de la microfinanciera, en aquellos individuos que cambiaron su comportamiento debido a la asignación aleatoria del tratamiento. Noten también que en todas las regresiones se incluye errores agrupados a nivel pareja o paire.\n\nres_iv &lt;- ivreg(expense_total ~ client + members_resid_bl + nadults_resid_bl\n     + head_age_bl + act_livestock_bl + act_business_bl \n     + borrowed_total_bl + members_resid_d_bl + nadults_resid_d_bl\n     + head_age_d_bl + act_livestock_d_bl + act_business_d_bl \n     + borrowed_total_d_bl + ccm_resp_activ + other_resp_activ \n     + ccm_resp_activ_d  + other_resp_activ_d + factor(paire) |\n       treatment +  members_resid_bl + nadults_resid_bl\n     + head_age_bl + act_livestock_bl + act_business_bl \n     + borrowed_total_bl + members_resid_d_bl + nadults_resid_d_bl\n     + head_age_d_bl + act_livestock_d_bl + act_business_d_bl \n     + borrowed_total_d_bl + ccm_resp_activ + other_resp_activ \n     + ccm_resp_activ_d  + other_resp_activ_d + factor(paire),\n     data=data.morocco)\n\nsummary(res_iv)$coefficients[1:2,]\n\n             Estimate Std. Error   t value   Pr(&gt;|t|)\n(Intercept) -16095.68   11033.49 -1.458802 0.14468442\nclient       24263.46   12419.55  1.953651 0.05080007\n\ncoef_test(res_iv,\n          vcov = \"CR1S\", \n          cluster = data.morocco$demi_paire)[1:2,]\n\n       Coef. Estimate   SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)   -16096 7144  -2.25        2.11       0.1464     \n      client    24263 9944   2.44       74.45       0.0171    *"
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#pregunta-2",
    "href": "tareas/tarea-2-respuestas.html#pregunta-2",
    "title": "Respuestas a la tarea 2",
    "section": "",
    "text": "Sea una variable de resultados \\(y_i\\), una variable de asignación aleatoria \\(Z_i\\) y una variable de adopción \\(D_i\\). El estimador de Wald se define como:\n\\[\\hat{\\beta}_{Wald}=\\frac{\\bar{Y}_{Z_i=1}-\\bar{Y}_{Z_i=0}}{\\bar{D}_{Z_i=1}-\\bar{D}_{Z_i=0}}\\]\nEn esta pregunta mostraremos cómo el estimador de Wald es equivalente al estimador de VI cuando no hay controles. Use nuevamente los datos en crepon_morocco_analysis.csv.\n\n[10 puntos] Obtenga el estimador de Wald como el cociente de la diferencia en gasto total promedio entre los hogares asignados a tratamiento y control dividido por la diferencia en la probabilidad de adopción entre los hogares asignados a tratamiento y control. Recuerde que la variable del gasto total es expense_total.\nObtenemos el estadístico de Wald, usando la definición:\n\ndata.morocco&lt;-read_csv(\"../files/crepon_morocco_analysis.csv\")   %&gt;% \n  clean_names() \n\nmean_cliente&lt;-data.morocco %&gt;%\n  group_by(treatment) %&gt;% \n  summarize(p_cliente=mean(client, na.rm=F)) %&gt;% \n  ungroup()\n\nmean_gasto&lt;-data.morocco %&gt;%\n  group_by(treatment) %&gt;% \n  summarize(m_gasto=mean(expense_total, na.rm=F)) %&gt;% \n  ungroup()\n\n#Neceistamos la diferencia de gastos y de probabilidad de ser cliente\ndif_gasto &lt;- mean_gasto[2,2]-mean_gasto[1,2]\ndif_cliente &lt;- mean_cliente[2,2]-mean_cliente[1,2]\n\nWald &lt;- as.numeric(dif_gasto / dif_cliente)\nWald\n\n[1] 22869.23\n\n\n[5 puntos] Ahora estime por MC2E el efecto de la adopción sobre el gasto total, usando la variable de asignación como instrumento para la adopción. Use ivreg para estimar el efecto directamente. ¿Qué ventaja observa con respecto al estimador de Wald?\nNotemos que obtenemos lo mismo al hacer una estimación de variables instrumentales. El coeficiente sobre la variable client es igual al estadístico de Wald. El estadístico de Wald es idéntico al estimador de variables instrumentales cuando el instrumento es binario. La mayor ventaja de realizar la estimación de esta manera es que podemos obtener errores estándar, lo cual nos permite hacer inferencia estadística sobre el tamaño del efecto de ser cliente en el gasto.\n\nWald_vi &lt;- ivreg(expense_total ~ client  | treatment,\n                data=data.morocco)\n\n#Notemos que obtenemos directamente el error estándar\nsummary(Wald_vi)\n\n\nCall:\nivreg(formula = expense_total ~ client | treatment, data = data.morocco)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n -44264  -21394  -17064   -4804 1305816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    21395       1496  14.298   &lt;2e-16 ***\nclient         22869      12684   1.803   0.0714 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 74610 on 4932 degrees of freedom\nMultiple R-Squared: 0.00651, Adjusted R-squared: 0.006309 \nWald test: 3.251 on 1 and 4932 DF,  p-value: 0.07144 \n\n\n[10 puntos] Ahora estime por MC2E el efecto de la adopción sobre el gasto total, usando la variable de asignación como instrumento para la adopción. A diferencia del punto previo, realice la estimación a mano, es decir, primero estime los valores ajustados de la variable endógena en una primera etapa y luego use estos valores ajustados en la estimación estructural. ¿Qué desventaja observa con respecto a la estimación del punto previo?\nPodemos obtener el mismo coeficiente haciendo MC2E a mano, lo cual nunca es recomendable debido a que la inferencia sobre el coeficiente de la segunda etapa es incorrecta. Sin embargo, nos deja ver cómo podemos entender el proceso de estimación conceptualmente.\nEstimamos la primera etapa y obtenemos los valores ajustados:\n\np.e &lt;- lm(client ~ treatment,\n                data=data.morocco)\n\ndata.morocco &lt;- data.morocco %&gt;% \n  mutate(client_hat = predict(p.e))\n\nAhora usamos los valores ajustados en la regresión de la segunda etapa:\n\ns.e &lt;- lm(expense_total ~ client_hat,\n                data=data.morocco)\n\nsummary(s.e)\n\n\nCall:\nlm(formula = expense_total ~ client_hat, data = data.morocco)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n -25225  -21394  -17879   -5647 1305816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    21395       1501  14.256   &lt;2e-16 ***\nclient_hat     22869      12721   1.798   0.0723 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 74830 on 4932 degrees of freedom\nMultiple R-squared:  0.0006549,  Adjusted R-squared:  0.0004522 \nF-statistic: 3.232 on 1 and 4932 DF,  p-value: 0.07228\n\n\nY obtenemos de nuevo 22,869 unidades monetarias como impacto estimado.\nLa desventaja de este procedimiento es que los errores estándar son incorrectos pues la estimación de la ecuación estructural no considera el error muestral de la primera etapa y, por tanto, considera a los valores de client_hat como si fueran directamente observados."
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#pregunta-3",
    "href": "tareas/tarea-2-respuestas.html#pregunta-3",
    "title": "Respuestas a la tarea 2",
    "section": "",
    "text": "En la Pregunta 2, parte a, obtuvo el estimador de Wald para aproximar el efecto de la adopción en el gasto total como un cosciente de dos diferencias de medias.\n\n[5 puntos] Utilice un procedimiento bootstrap a mano para estimar el error estándar del estimador de Wald usando 50 repeticiones. Es decir, debe realizar un remuestreo de los datos originales y para cada muestra obtener el estimador de Wald. Luego, obtenga la desviación estándar de los 50 estadísticos calculados. Utilice una semilla para poder replicar sus resultados.\nYa sabemos calcular un estadístico de Wald, como en la Pregunta 2, parte a. La idea ahora es repetir dicho proceso B veces, pero en cada repetición con una muestra bootstrap a la mano:\n\ndata.morocco&lt;- read.csv(\"../files/crepon_morocco_analysis.csv\") %&gt;%\n  select(treatment,client,expense_total)\n\nobs &lt;- nrow(data.morocco)\n\n#Solo para ejemplificar, la siguiente línea pide el remuestreo, es decir, obtener una muestra de tamaño N de la muestra original, con reemplazo\ndata.b &lt;-data.morocco[sample(nrow(data.morocco),obs, replace = TRUE),]\n\n#Simplemente repetimos el proceso anterior B veces\nset.seed(821)\nB=50\n#Inicializamos el vector donde guardaremos los W estimados\nWrep50_1 &lt;- data.frame(W=matrix(ncol = 1, nrow = B))\n\nfor (i in 1:B)\n{\n  data.b &lt;-data.morocco[sample(nrow(data.morocco),obs, replace = TRUE),]\n\n  #Literalmente pegamos el cálculo de un W, hecho en la Pregunta 2a\n\n  mean_cliente&lt;-data.b %&gt;%\ngroup_by(treatment) %&gt;% \nsummarize(p_cliente=mean(client, na.rm=F)) %&gt;% \nungroup()\n\n  mean_gasto&lt;-data.b %&gt;%\ngroup_by(treatment) %&gt;% \nsummarize(m_gasto=mean(expense_total, na.rm=F)) %&gt;% \nungroup()\n\n  dif_gasto &lt;- mean_gasto[2,2]-mean_gasto[1,2]\n  dif_cliente &lt;- mean_cliente[2,2]-mean_cliente[1,2]\n\n  #Y lo guardamos en la posición adecuada\n\n  Wrep50_1[i,1] &lt;- as.numeric(dif_gasto / dif_cliente)\n}\n\n#El error estimado es simplemente la desviación estándar de los B estadísticos estimados\nsd(Wrep50_1$W)\n\n[1] 14735.91\n\n\n[5 puntos] Reemplace la semilla de la parte a. por una nueva semilla y estime nuevamente el error estándar del estimador de Wald con 50 repeticiones. Comente sobre la diferencia entre este error estándar y el de la parte a.\nEl cambio que observamos en el error estándar estimado por bootstrap entre esta parte y la parte a. es que al cambiar la semilla, los números aleatorios generados son distitnos y, por tanto, cada muestra bootstrap tiene distintos individuos.\n\n#Simplemente cambiamos la semilla\nset.seed(8212)\nB=50\n#Inicializamos el vector donde guardaremos los W estimados\nWrep50_2 &lt;- data.frame(W=matrix(ncol = 1, nrow = B))\n\nfor (i in 1:B)\n{\n  data.b &lt;-data.morocco[sample(nrow(data.morocco),obs, replace = TRUE),]\n\n  mean_cliente&lt;-data.b %&gt;%\ngroup_by(treatment) %&gt;% \nsummarize(p_cliente=mean(client, na.rm=F)) %&gt;% \nungroup()\n\n  mean_gasto&lt;-data.b %&gt;%\ngroup_by(treatment) %&gt;% \nsummarize(m_gasto=mean(expense_total, na.rm=F)) %&gt;% \nungroup()\n\n  dif_gasto &lt;- mean_gasto[2,2]-mean_gasto[1,2]\n  dif_cliente &lt;- mean_cliente[2,2]-mean_cliente[1,2]\n\n  Wrep50_2[i,1] &lt;- as.numeric(dif_gasto / dif_cliente)\n}\n\nsd(Wrep50_2$W)\n\n[1] 14869.02\n\n\n[5 puntos] Regrese el valor de la semilla al usado en a. y estime nuevamente el error estándar del estimador de Wald, esta vez usando 1000 repeticiones. Comente sobre la diferencia entre este error estándar y el de la parte a.\nAhora las diferencias en el error estimado surgen porque tenemos muchas más repeticiones bootstrap. Lo más importante de estos procedimientos es que pueda implementarlos a otros contextos. Por ejemplo, podemos hacer obtener errores bootstrap para el vector de coeficientes de una estimación de MC2E, para el producto de dos coeficientes, etc.\n\n#Regresamos a la primera semilla pero ahora B=1000\nset.seed(820)\nB=1000\n\nWrep1000 &lt;- data.frame(W=matrix(ncol = 1, nrow = B))\n\nfor (i in 1:B)\n{\n  data.b &lt;-data.morocco[sample(nrow(data.morocco),obs, replace = TRUE),]\n\n  mean_cliente&lt;-data.b %&gt;%\ngroup_by(treatment) %&gt;% \nsummarize(p_cliente=mean(client, na.rm=F)) %&gt;% \nungroup()\n\n  mean_gasto&lt;-data.b %&gt;%\ngroup_by(treatment) %&gt;% \nsummarize(m_gasto=mean(expense_total, na.rm=F)) %&gt;% \nungroup()\n\n  dif_gasto &lt;- mean_gasto[2,2]-mean_gasto[1,2]\n  dif_cliente &lt;- mean_cliente[2,2]-mean_cliente[1,2]\n\n  Wrep1000[i,1] &lt;- as.numeric(dif_gasto / dif_cliente)\n}\n\n#El error estimado es simplemente la desviación estándar de los B estadísticos estimados\nsd(Wrep1000$W)\n\n[1] 12998.05"
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#pregunta-4",
    "href": "tareas/tarea-2-respuestas.html#pregunta-4",
    "title": "Respuestas a la tarea 2",
    "section": "",
    "text": "Considere nuevamente la base STAR_public_use.csv usada en la Tarea 1 del artículo Angrist, Lang y Oreopoulos (2009)3. En esta pregunta nos concentraremos en los efectos de la intervención en el año 2, mostrados en la columna (4) de la Tabla 6, sobre dos variables, el promedio de calificaciones gpa_year2 y los créditos completados credits_earned2.\nEl propósito de esta pregunta es mostrar la función de los \\(z\\)-scores en el análisis de efectos de tratamiento. De nuevo, puede quedarse solo con las observaciones que tienen noshow igual a 0. Antes de comenzar su análisis, sustituya por NA los valores en credits_earned2 para aquellas observaciones que tienen \\(NA\\) en la variable prob_year1.\n\n[5 puntos] Para tener un punto de comparación, estime la ecuación del efecto de tratamiento para gpa_year2 usando la misma especificación que en la pregunta 5 de la Tarea 1. Use también errores robustos. Deberá poder replicar los coeficientes y errores estándar del panel A, columna (4). ¿Cómo se interpretan el coeficiente sobre la variable ssp?\nUsando la misma especificación que usamos en la Tarea 1, obtenemos los coeficientes en el artículo.\n\ndata.angrist&lt;-read_csv(\"../files/STAR_public_use.csv\",\n                 locale = locale(encoding = \"latin1\"))   %&gt;% \n  clean_names()\n\ndata.angrist&lt;-data.angrist %&gt;% \n  filter(noshow==0) %&gt;% \n  mutate(credits_earned2=ifelse(is.na(prob_year1),NA,credits_earned2)) \n\n\nr1 &lt;-lm(gpa_year2 ~ ssp + sfp+ sfsp+\n             factor(sex)+\n             factor(mtongue)+\n             factor(hsgroup)+\n             factor(numcourses_nov1)+\n             factor(lastmin)+\n             factor(mom_edn)+\n             factor(dad_edn),\n           data.angrist)\ncoeftest(r1, vcov = vcovHC(r1, \"HC1\"))[1:4,]\n\n               Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)  2.87240513 0.45314003  6.3388908 3.261488e-10\nssp          0.05018813 0.07423854  0.6760388 4.991454e-01\nsfp         -0.01807372 0.06618352 -0.2730848 7.848347e-01\nsfsp         0.07158763 0.09081195  0.7883063 4.306722e-01\n\n\n[5 puntos] Genere un \\(z\\)-score para la variable gpa_year2 al que llame gpa_year2_sd. Para ello, calcule la media y desviación estándar de gpa_year2 para el grupo de control y luego genere gpa_year2_sd restándole a gpa_year2 la media obtenida y dividiendo esta diferencia por la desviación estándar obtenida. Compruebe que si calcula la media y la desviación estándar de gpa_year2_sd, en el grupo de control estas deberían ser 0 y 1, respectivamente.\nCreamos un z-score:\n\ngpa_year2_stats &lt;- data.angrist %&gt;% \n    filter(control==1) %&gt;% \n    summarize(media=mean(gpa_year2,na.rm=T),\n              desvest=sd(gpa_year2,na.rm=T))\n\ndata.angrist &lt;- data.angrist %&gt;% \n    mutate(gpa_year2_sd=(gpa_year2-gpa_year2_stats$media)/gpa_year2_stats$desvest)\n\nTiene media igual a 0:\n\ndata.angrist %&gt;%\n  filter(control==1) %&gt;% \n  summarize(media=mean(gpa_year2_sd,na.rm=T))\n\n# A tibble: 1 × 1\n     media\n     &lt;dbl&gt;\n1 1.60e-16\n\n\nY desviación estándar igual a 1:\n\ndata.angrist %&gt;%\n  filter(control==1) %&gt;% \n  summarize(desvest=sd(gpa_year2_sd,na.rm=T)) \n\n# A tibble: 1 × 1\n  desvest\n    &lt;dbl&gt;\n1       1\n\n\n[5 puntos] Realice la misma estimación que en la parte a., pero ahora use como variable dependiente gpa_year2_sd. ¿Cómo se interpreta el coeficiente sobre ssp? ¿Qué es diferente y qué es igual entre los resultados obtenidos en esta parte y los obtenidos en la parte a.?\nRealizamos la estimación, pero con la variable dependiente estandarizada:\n\nr2 &lt;-lm(gpa_year2_sd ~ ssp + sfp+ sfsp+\n             factor(sex)+\n             factor(mtongue)+\n             factor(hsgroup)+\n             factor(numcourses_nov1)+\n             factor(lastmin)+\n             factor(mom_edn)+\n             factor(dad_edn),\n           data.angrist)\n\ncoeftest(r2, vcov = vcovHC(r2, \"HC1\"))[1:4,]\n\n               Estimate Std. Error    t value   Pr(&gt;|t|)\n(Intercept)  0.94640721 0.50806908  1.8627530 0.06273961\nssp          0.05627187 0.08323764  0.6760388 0.49914542\nsfp         -0.02026459 0.07420621 -0.2730848 0.78483470\nsfsp         0.08026539 0.10182006  0.7883063 0.43067220\n\n\nLos coeficientes estimados son diferentes. Ahora el coeficiente sobre ssp es el efecto que tiene el programa en el z-score del promedio de calificaciones, es decir, el SSP tiene un efecto de 0.056 desviaciones estándar en el z-score del promedio de calificaciones, aunque este efecto no es estadísticamente significativo. La magnitud del error estándar también es diferente, pues ahora las variables están en distintas unidades. Noten, en cambio, que el estadístico t asociado a SSP es exactamente igual al de la parte a., por lo que en ambos casos no se rechaza la \\(H_0\\).\n\ncoeftest(r1, vcov = vcovHC(r1, \"HC1\"))[1:4,]\n\n               Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)  2.87240513 0.45314003  6.3388908 3.261488e-10\nssp          0.05018813 0.07423854  0.6760388 4.991454e-01\nsfp         -0.01807372 0.06618352 -0.2730848 7.848347e-01\nsfsp         0.07158763 0.09081195  0.7883063 4.306722e-01\n\n\n[5 puntos] Ahora realizaremos un índice de mejora en educación, al agregar los resultados de estos dos indicadores en una sola variable, como se describe en Banerjee et al. (2015)4. Para ello, primero genere credits_earned2_sd, que será la versión estandarizada de credits_earned2, siguiendo el mismo procedimiento que en la parte b. En seguida, genere una nueva variable llamada indice_escolar, que será el promedio de credits_earned2_sd y gpa_year2_sd. Luego, calcule la media y la desviación estándar de indice_escolar en el grupo de control. Finalmente, genere una nueva variable indice_escolar_sd restándole a indice_escolar la media antes calculada y dividiendo esta diferencia por la desviación estándar antes calculada. Muestre que la variable indice_escolar_sd tiene media 0 y desviación estándar 1 en el grupo de control.\nPrimero creamos la versión estandarizada de la variable de créditos:\n\ncredits_earned2_stats &lt;- data.angrist %&gt;% \n  filter(control==1) %&gt;% \n  summarize(media=mean(credits_earned2,na.rm=T),\n            desvest=sd(credits_earned2,na.rm=T))\n\ndata.angrist &lt;- data.angrist %&gt;% \n  mutate(credits_earned2_sd=(credits_earned2-credits_earned2_stats$media)/credits_earned2_stats$desvest)\n\nLuego calculamos la media de las dos variables estandarizadas:\n\ndata.angrist &lt;- data.angrist %&gt;% \n  mutate(indice_escolar=rowMeans(select(.,credits_earned2_sd,gpa_year2_sd)))\n\nAhora obtenemos la media y la desviación estándar en el grupo de control del promedio antes calculado:\n\nindice_escolar_stats &lt;- data.angrist %&gt;% \n  filter(control==1) %&gt;% \n  summarize(media=mean(indice_escolar,na.rm=T),\n            desvest=sd(indice_escolar,na.rm=T))\n\ndata.angrist &lt;- data.angrist %&gt;% \n  mutate(indice_escolar_sd=(indice_escolar-indice_escolar_stats$media)/indice_escolar_stats$desvest)\n\nEfectivamente tiene media igual a 0:\n\ndata.angrist %&gt;%\n  filter(control==1) %&gt;% \n  summarize(media=mean(indice_escolar_sd,na.rm=T))\n\n# A tibble: 1 × 1\n      media\n      &lt;dbl&gt;\n1 -1.33e-17\n\n\nY desviación estándar igual a 1:\n\ndata.angrist %&gt;%\n  filter(control==1) %&gt;% \n  summarize(desvest=sd(indice_escolar_sd,na.rm=T)) \n\n# A tibble: 1 × 1\n  desvest\n    &lt;dbl&gt;\n1       1\n\n\n[5 puntos] Estime ahora el efecto de tratamiento sobre indice_escolar_sd, siguiendo la misma especificación econométrica que en la parte a. y usando errores robustos. ¿Qué concluye?\nEstimamos usando la misma especificación, pero ahora con el índice compuesto como variable de impacto:\n\nr3 &lt;-lm(indice_escolar_sd ~ ssp + sfp+ sfsp+\n                             factor(sex)+\n                             factor(mtongue)+\n                             factor(hsgroup)+\n                             factor(numcourses_nov1)+\n                             factor(lastmin)+\n                             factor(mom_edn)+\n                             factor(dad_edn),\n                           data.angrist)\n\ncoeftest(r3, vcov = vcovHC(r3, \"HC1\"))[1:4,]\n\n               Estimate Std. Error    t value  Pr(&gt;|t|)\n(Intercept)  0.49452306 0.46650249  1.0600652 0.2893277\nssp          0.02805373 0.08261358  0.3395778 0.7342338\nsfp         -0.02543190 0.07385703 -0.3443396 0.7306511\nsfsp         0.03404990 0.09616572  0.3540753 0.7233445\n\n\nLa ventaja de este procedimiento es que solo probamos una hipótesis en lugar de dos. Si tuviéramos muchas variables de impacto, tendríamos que probar múltiples hipótesis, incrementando la probabilidad de falsos rechazos. La construcción de índices es una alternativa para enfrentar este problema."
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#footnotes",
    "href": "tareas/tarea-2-respuestas.html#footnotes",
    "title": "Respuestas a la tarea 2",
    "section": "Notas",
    "text": "Notas\n\n\nPor ejemplo, suponga que estima un modelo al que llame modelo1. Entonces, si ejecuta\n\ncoef_test(modelo1,\n          vcov=\"CR1S\",\n          cluster=mis_datos$demi_paire)[1:2,]\n\nobtendrá los coeficientes con los errores agrupados requeridos. La opción CR1S toma en cuenta el número de grupos o clusters para realizar inferencia. Puede leer más al respecto en la ayuda al ejecutar ?vcovCR. Este es el tipo de ajuste de muestras finitas que usan los autores. Esta corrección consiste en multiplicar la matriz de sándwich agrupada CR0 por \\(\\frac{G(N-1)}{(G-1)(N-p)}\\), donde \\(G\\) es el número de grupos, \\(N\\) es el número total de observaciones y \\(p\\) es el número de regresores.↩︎\nCrépon, B., Devoto, F., Duflo, E., & Parienté, W. (2015). Estimating the impact of microcredit on those who take it up: Evidence from a randomized experiment in Morocco. American Economic Journal: Applied Economics, 7(1), 123-50.↩︎\nAngrist, J., Lang, D., y Oreopoulos, P. (2009). Incentives and services for college achievement: Evidence from a randomized trial. American Economic Journal: Applied Economics, 1(1), 136-63.↩︎\nBanerjee, A. et al. (2015). A multifaceted program causes lasting progress for the very poor: Evidence from six countries. Science, 348(6236).↩︎"
  },
  {
    "objectID": "tareas/tarea-3-respuestas.html",
    "href": "tareas/tarea-3-respuestas.html",
    "title": "Respuestas a la tarea 3",
    "section": "",
    "text": "Stevenson, B. & Wolfers, J. (2006)1 estudian los efectos de la introducción de leyes que permiten el divorcio unilateral en los Estados Unidos. La librería bacondecomp incluye los datos usados en dicho artículo (debe instalar y cargar la librería). Usaremos los datos de 1964 a 1996 para mostrar cómo impactan las leyes de divorcio express (unilateral) a la tasa de suicidios en mujeres.\nAl correr el pedazo de código anterior, obtendrá un objeto de datos wd en donde la variable de impacto es la tasa de suicidios en mujeres, suicide_rate, st identifica a los estados, year identifica a los años y divyear es el año en que se introdujo la legislación del divorcio unilateral. La última fila del código crea el indicador de tratamiento unilaterial, que toma el valor de 1 para los estados tratados en los periodos post tratamiento.\n\nwd &lt;- divorce %&gt;% \nfilter(year&gt;=1964 & year&lt;=1996 & sex==2) %&gt;% \nmutate(suicide_rate=suicide*1000000/(stpop*fshare),\n   year=as.numeric(year),\n   divyear = ifelse(divyear&gt;1996, Inf, divyear),\n   unilateral=ifelse(year&gt;divyear, 1, 0))\n\n\n[5 puntos] Presente una tabla donde muestre el número de estados que es tratado en cada periodo del panel. ¿Cuántos estados son nunca tratados? ¿Cuántos estados son siempre tratados?\nSi hacemos un tabulado de divyear para un año fijo, notamos cuántos estados se vuelven tratados en cada año. Solo 5 estados son nunca tratados. Por otro lado, como el panel comienza en 1964 y hay 9 estados tratados en 1950, estos 9 estados son siempre tratados.\n\ntable(filter(wd, year==1996)$divyear)\n\n\n1950 1969 1970 1971 1972 1973 1974 1975 1976 1977 1980 1984 1985  Inf \n   9    2    2    7    3   11    3    2    1    3    1    1    1    5 \n\n\n[5 puntos] Como punto de partida, estime el efecto del tratamiento sobre suicide_rate usando efectos fijos por estado y año (TWFE) y empleando una librería específica para efectos fijos, como felm. Tome en cuenta la agrupación de los errores. Interprete sus resultados.\nUsando felm podemos incorporar ya el nivel de agrupación de los errores:\n\nsummary(felm(suicide_rate ~ unilateral | st + year | 0 | st,\n              data = wd))\n\n\nCall:\n   felm(formula = suicide_rate ~ unilateral | st + year | 0 | st,      data = wd) \n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-37.517  -6.157  -0.141   5.577  57.004 \n\nCoefficients:\n           Estimate Cluster s.e. t value Pr(&gt;|t|)  \nunilateral   -3.777        2.201  -1.716   0.0923 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.85 on 1599 degrees of freedom\nMultiple R-squared(full model): 0.6844   Adjusted R-squared: 0.668 \nMultiple R-squared(proj model): 0.007963   Adjusted R-squared: -0.04353 \nF-statistic(full model, *iid*):41.77 on 83 and 1599 DF, p-value: &lt; 2.2e-16 \nF-statistic(proj model): 2.945 on 1 and 50 DF, p-value: 0.09231 \n\n\n[5 puntos] Compruebe que puede obtener el mismo resultado con una regresión lineal usando el paquete lm e incluyendo, además de la variable de tratamiento, dummies de estado y de año.\nEstimamos con dummies:\n\nsummary(m1 &lt;- lm(suicide_rate ~ unilateral + factor(st) + factor(year),\n              data = wd))$coef[1:2,1:3]\n\n             Estimate Std. Error   t value\n(Intercept) 56.732642   2.468251 22.984953\nunilateral  -3.776552   1.054148 -3.582562\n\n\nLuego estimamos errores agrupados:\n\nmodelsummary(list(m1),\n             output = 'gt',\n             vcov=clubSandwich::vcovCR(m1, type='CR1', cluster=wd$st),\n             coef_map = \"unilateral\",\n             gof_map = \"nobs\")\n\n\n\n\n\n\n\n\n(1)\n\n\n\n\nunilateral\n-3.777\n\n\n\n(2.200)\n\n\nNum.Obs.\n1683\n\n\n\n\n\n\n\nObtenemos los mismos coeficientes. Aquí también podrán volver a comprobar la importancia de usar errores agrupados. El error agrupado es más de dos veces más grande que el error clásico.\n[10 puntos] Ahora muestre que podemos obtener el coeficiente de TWFE a partir de una regresión bivariada entre la tasa de suicidios y unilateral, una vez purgada por efectos fijos. Para ello, primero estime una regresión de unilateral en función de los efectos fijos. Obtenga la predicción y luego defina una nueva variable igual a la diferencia entre unilateral y la predicción que acaba de obtener. Finalmente, obtenga el coeficiente de TWFE con una regresión de la tasa de suicidios en función de la diferencia antes definida.\nCorremos la primera regresión para purgar los efectos fijos:\n\nd1 &lt;- lm(unilateral ~ factor(st) + factor(year),\n              data = wd)\n\nDefinimos la nueva variable:\n\nwd &lt;- wd %&gt;% \n  mutate(unilateral_hat = unilateral-predict(d1))\n\nY finalmente estimamos:\n\nsummary(m2 &lt;- lm(suicide_rate ~ unilateral_hat,\n              data = wd))$coef[1:2,1:3]\n\n                Estimate Std. Error    t value\n(Intercept)    54.422503  0.4585884 118.673960\nunilateral_hat -3.776552  1.8276582  -2.066334\n\n\nObtenemos el mismo coeficiente. Frisch–Waugh–Lovell tenían razón.\n[10 puntos] Realice la descomposición de Goodman-Bacon (2021). Construya un gráfico donde muestre en el eje \\(x\\) el peso otorgado a cada comparación 2x2 que el estimador de TWFE realiza mecánicamente y en el eje \\(y\\) el efecto estimado correspondiente a cada comparación. Interprete el gráfico obtenido.\nComo vimos en laboratorio, la descomposición de Bacon se puede obtener con la función bacon:\n\n#Goodman-Bacon decomposition\ndf_bacon &lt;- bacon(suicide_rate ~ unilateral,\n                  data = wd,\n                  id_var = \"st\",\n                  time_var = \"year\")\n\n                      type  weight  avg_est\n1 Earlier vs Later Treated 0.11558  0.13489\n2  Later vs Always Treated 0.41990 -6.95245\n3 Later vs Earlier Treated 0.23125  2.33743\n4     Treated vs Untreated 0.23328 -6.05881\n\ncoef_bacon &lt;- sum(df_bacon$estimate * df_bacon$weight)\n\nprint(paste(\"Suma ponderada de la descomposición =\", round(coef_bacon, 4)))\n\n[1] \"Suma ponderada de la descomposición = -3.7766\"\n\ntwfe &lt;- felm(suicide_rate ~ unilateral | st + year | 0 | st,\n              data = wd)\n\n#Gráfico----\ndf_bacon %&gt;% \n  ggplot(aes(x=weight,\n             y=estimate,\n             shape=type)) +\n  geom_point() +\n  geom_hline(yintercept = round(twfe$coefficients, 4))\n\n\n\n\n\n\n\n\nLas comparaciones que más pesan en el estimador de efectos fijos son las de estados tratados con los que siempre estuvieron tratados en el panel, recibiendo dos de esas comparaciones alrededor de 13 y el 7% del peso (los dos triángulos más hacia la derecha). otra comparación que recibe alrededor de 7% del peso es la de los tratados con los nunca tratados (cruz más hacia la derecha). En total, las comparaciones con los estados que iniciaron siendo tratados se llevan el 42% del peso. Las comparaciones entre los tratados tarde y los tratados temprano también reciben un peso alto de 23%.\n[10 puntos] Implemente el estimador de Callaway & Sant’Anna (2021) para estimar los efectos del tratamiento específicos para cada cohorte, usando el paquete did. Utilice como grupo de comparación los estados no tratados aún. La columna stid es un identificador numérico de los estados (lo requerirá cuando use att_gt del paquete did).\n\natts_nyt &lt;- att_gt(yname = \"suicide_rate\",\n                      tname = \"year\",\n                      idname = \"stid\",\n                      gname = \"divyear\",\n                      data = wd,\n                      control_group = \"notyettreated\",\n                      est_method = 'reg',\n                      bstrap = TRUE,\n                      biters = 1000,\n                      print_details = FALSE,\n                      panel = TRUE)\n\n\nsummary(atts_nyt)\n\n\nCall:\natt_gt(yname = \"suicide_rate\", tname = \"year\", idname = \"stid\", \n    gname = \"divyear\", data = wd, panel = TRUE, control_group = \"notyettreated\", \n    bstrap = TRUE, biters = 1000, est_method = \"reg\", print_details = FALSE)\n\nReference: Callaway, Brantly and Pedro H.C. Sant'Anna.  \"Difference-in-Differences with Multiple Time Periods.\" Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. &lt;https://doi.org/10.1016/j.jeconom.2020.12.001&gt;, &lt;https://arxiv.org/abs/1803.09015&gt; \n\nGroup-Time Average Treatment Effects:\n Group Time ATT(g,t) Std. Error [95% Simult.  Conf. Band]  \n  1969 1965  -1.9053     7.0460      -28.4052     24.5947  \n  1969 1966   4.5124     9.7506      -32.1593     41.1841  \n  1969 1967   0.5622     4.9628      -18.1028     19.2273  \n  1969 1968   5.1789     2.9495       -5.9141     16.2720  \n  1969 1969  -0.7447     5.4222      -21.1373     19.6480  \n  1969 1970 -10.2717     8.6981      -42.9850     22.4415  \n  1969 1971 -12.3880     7.0258      -38.8116     14.0357  \n  1969 1972  -4.1259     3.5784      -17.5843      9.3324  \n  1969 1973   1.4524     6.7785      -24.0415     26.9462  \n  1969 1974  -1.4022     4.6571      -18.9175     16.1131  \n  1969 1975  -0.9265     4.4042      -17.4904     15.6373  \n  1969 1976 -12.7344     6.3437      -36.5930     11.1242  \n  1969 1977  -2.3415     8.9937      -36.1665     31.4834  \n  1969 1978 -11.4247    11.6077      -55.0810     32.2316  \n  1969 1979  -6.0427     8.6485      -38.5694     26.4841  \n  1969 1980  -7.9345     5.4062      -28.2670     12.3979  \n  1969 1981  -1.7430     9.6420      -38.0062     34.5202  \n  1969 1982  -6.7020     8.6390      -39.1929     25.7888  \n  1969 1983   4.7154     9.9666      -32.7688     42.1996  \n  1969 1984  -9.5175    12.0946      -55.0050     35.9699  \n  1969 1985   5.9598    16.8090      -57.2584     69.1779  \n  1969 1986  -8.5962    10.9669      -49.8425     32.6501  \n  1969 1987  -8.6897     7.1293      -35.5027     18.1234  \n  1969 1988 -11.9815     8.1718      -42.7152     18.7522  \n  1969 1989  -5.9781    14.7507      -61.4550     49.4989  \n  1969 1990  -7.7327    10.9077      -48.7562     33.2908  \n  1969 1991 -14.7659    11.0449      -56.3055     26.7737  \n  1969 1992  -6.6956     6.0147      -29.3165     15.9253  \n  1969 1993   0.5290    11.3341      -42.0982     43.1561  \n  1969 1994  -6.1575    15.5254      -64.5480     52.2330  \n  1969 1995  -6.7870    16.7453      -69.7657     56.1918  \n  1969 1996   3.0338    14.3952      -51.1060     57.1736  \n  1970 1965   2.4919     3.2071       -9.5700     14.5539  \n  1970 1966   1.8500     3.3954      -10.9200     14.6201  \n  1970 1967  -2.0438     3.9888      -17.0454     12.9579  \n  1970 1968  -3.7538     6.6390      -28.7228     21.2152  \n  1970 1969   9.0725     3.5768       -4.3799     22.5249  \n  1970 1970   0.3548     4.8941      -18.0519     18.7616  \n  1970 1971  -1.9698     3.3001      -14.3814     10.4418  \n  1970 1972  -1.4067     6.1942      -24.7030     21.8896  \n  1970 1973 -11.2801     3.7512      -25.3881      2.8279  \n  1970 1974 -11.1775     3.3984      -23.9588      1.6038  \n  1970 1975 -12.0330     6.4440      -36.2686     12.2027  \n  1970 1976 -17.7592     8.1638      -48.4631     12.9447  \n  1970 1977 -16.3994     5.2563      -36.1682      3.3695  \n  1970 1978 -29.1877     7.5225      -57.4796     -0.8957 *\n  1970 1979 -26.8802    12.2742      -73.0429     19.2826  \n  1970 1980 -39.5660    11.2142      -81.7422      2.6102  \n  1970 1981 -30.0122    11.7141      -74.0686     14.0442  \n  1970 1982 -36.1714    10.0510      -73.9730      1.6301  \n  1970 1983 -31.0969    12.6179      -78.5522     16.3585  \n  1970 1984 -31.4749    11.8501      -76.0428     13.0929  \n  1970 1985 -30.6346    19.0705     -102.3582     41.0889  \n  1970 1986 -37.0754    18.8397     -107.9311     33.7802  \n  1970 1987 -37.6630    12.4804      -84.6016      9.2755  \n  1970 1988 -43.0563    12.9278      -91.6774      5.5648  \n  1970 1989 -45.1314    15.4236     -103.1389     12.8761  \n  1970 1990 -43.1765     8.6367      -75.6588    -10.6942 *\n  1970 1991 -49.9116    10.1746      -88.1781    -11.6451 *\n  1970 1992 -50.9515    15.7077     -110.0277      8.1247  \n  1970 1993 -44.5526    12.4263      -91.2875      2.1823  \n  1970 1994 -51.5405    17.7308     -118.2253     15.1443  \n  1970 1995 -48.4108    18.4709     -117.8791     21.0576  \n  1970 1996 -48.0618    18.0039     -115.7740     19.6505  \n  1971 1965  -2.2110     3.4990      -15.3706     10.9487  \n  1971 1966  -5.9450     3.5888      -19.4424      7.5524  \n  1971 1967   6.1535     3.8122       -8.1840     20.4910  \n  1971 1968   5.3039     3.7056       -8.6327     19.2406  \n  1971 1969  -4.8826     3.8762      -19.4609      9.6957  \n  1971 1970   0.5878     5.2423      -19.1284     20.3040  \n  1971 1971  -7.5805     5.7237      -29.1072     13.9461  \n  1971 1972 -11.4260     7.4633      -39.4951     16.6431  \n  1971 1973  -5.8221     8.4200      -37.4894     25.8452  \n  1971 1974   5.7926     5.4383      -14.6607     26.2459  \n  1971 1975   0.0590     5.6082      -21.0334     21.1515  \n  1971 1976  -0.7920     8.5841      -33.0767     31.4927  \n  1971 1977   0.5899     8.6109      -31.7955     32.9753  \n  1971 1978  -9.5946     9.7160      -46.1361     26.9469  \n  1971 1979  -8.8180     5.8234      -30.7197     13.0838  \n  1971 1980 -15.0039     7.0155      -41.3890     11.3812  \n  1971 1981  -6.0810     8.4938      -38.0259     25.8640  \n  1971 1982 -15.5575     8.7418      -48.4352     17.3201  \n  1971 1983  -6.7973     5.8661      -28.8595     15.2648  \n  1971 1984  -8.1090     7.3240      -35.6544     19.4363  \n  1971 1985  -9.3683     8.2252      -40.3031     21.5666  \n  1971 1986 -16.9260     6.8736      -42.7773      8.9254  \n  1971 1987 -12.9962    10.8203      -53.6909     27.6985  \n  1971 1988 -14.6487     8.2209      -45.5673     16.2698  \n  1971 1989 -18.7126     8.7625      -51.6682     14.2430  \n  1971 1990 -17.6198     6.4603      -41.9167      6.6771  \n  1971 1991 -17.2789     8.7642      -50.2406     15.6829  \n  1971 1992 -22.1825     9.7043      -58.6799     14.3149  \n  1971 1993  -9.1278     8.6932      -41.8225     23.5669  \n  1971 1994 -13.7091     7.8957      -43.4047     15.9865  \n  1971 1995 -15.3270     6.9365      -41.4150     10.7609  \n  1971 1996 -11.2124     8.8556      -44.5179     22.0931  \n  1972 1965   1.9641     1.8921       -5.1522      9.0804  \n  1972 1966   2.3826     6.3500      -21.4997     26.2648  \n  1972 1967  -3.8865     5.9352      -26.2085     18.4354  \n  1972 1968   7.6954     2.7313       -2.5770     17.9678  \n  1972 1969  -8.7084     2.9283      -19.7216      2.3048  \n  1972 1970   0.1004     2.4628       -9.1621      9.3629  \n  1972 1971   1.1463     3.5806      -12.3201     14.6127  \n  1972 1972  -4.8115     4.9725      -23.5129     13.8899  \n  1972 1973  -2.3073     6.7151      -27.5625     22.9480  \n  1972 1974   0.7950     5.6743      -20.5457     22.1357  \n  1972 1975  -2.8930     4.4361      -19.5769     13.7910  \n  1972 1976  -2.9838    10.4048      -42.1158     36.1483  \n  1972 1977   2.8759     5.6964      -18.5482     24.3000  \n  1972 1978 -13.9499     6.9152      -39.9577     12.0578  \n  1972 1979  -4.7118     9.9019      -41.9524     32.5287  \n  1972 1980  -9.9424     6.4162      -34.0735     14.1886  \n  1972 1981   0.7622     6.5261      -23.7821     25.3066  \n  1972 1982  -5.7949     7.1316      -32.6168     21.0270  \n  1972 1983  -2.5286     7.5776      -31.0275     25.9704  \n  1972 1984  -5.7192     7.8629      -35.2913     23.8529  \n  1972 1985  -8.5492     8.9056      -42.0428     24.9444  \n  1972 1986  -3.2909     6.8649      -29.1097     22.5279  \n  1972 1987 -14.5853     7.4403      -42.5680     13.3975  \n  1972 1988 -12.6795     6.5770      -37.4154     12.0564  \n  1972 1989 -10.9845     7.5084      -39.2234     17.2545  \n  1972 1990  -7.7794     7.7009      -36.7424     21.1835  \n  1972 1991 -13.7033     5.4556      -34.2217      6.8152  \n  1972 1992 -11.0100     9.2787      -45.9068     23.8869  \n  1972 1993 -17.3770     7.7403      -46.4878     11.7338  \n  1972 1994 -16.6543     8.3614      -48.1014     14.7927  \n  1972 1995 -16.0626     6.8331      -41.7617      9.6365  \n  1972 1996 -13.6292     5.4833      -34.2515      6.9932  \n  1973 1965  -1.6544     3.4974      -14.8082     11.4994  \n  1973 1966  -3.5308     4.1384      -19.0953     12.0337  \n  1973 1967   5.5388     6.1119      -17.4477     28.5254  \n  1973 1968  -4.1286     5.8070      -25.9685     17.7113  \n  1973 1969   1.9470     4.0342      -13.2255     17.1195  \n  1973 1970   0.3836     5.3027      -19.5596     20.3269  \n  1973 1971  -0.4064     6.0259      -23.0695     22.2567  \n  1973 1972  -0.7103     5.9888      -23.2339     21.8133  \n  1973 1973   9.0122     6.2229      -14.3918     32.4162  \n  1973 1974   7.0826     6.0502      -15.6722     29.8374  \n  1973 1975   8.7932     9.1829      -25.7433     43.3297  \n  1973 1976   5.5815     7.1821      -21.4301     32.5931  \n  1973 1977   9.2638     7.2386      -17.9602     36.4878  \n  1973 1978  -2.8479     7.3583      -30.5221     24.8263  \n  1973 1979   3.5441     7.6322      -25.1603     32.2486  \n  1973 1980  -3.7998     8.8198      -36.9706     29.3710  \n  1973 1981   3.7874     8.4673      -28.0578     35.6325  \n  1973 1982  -2.3342     8.7502      -35.2434     30.5750  \n  1973 1983   0.3746     7.3718      -27.3506     28.0999  \n  1973 1984  -4.0602     9.0571      -38.1238     30.0034  \n  1973 1985  -3.3503     6.9802      -29.6025     22.9018  \n  1973 1986  -9.9416     4.7668      -27.8693      7.9861  \n  1973 1987 -10.5611     8.7076      -43.3099     22.1877  \n  1973 1988 -13.3770     9.3321      -48.4748     21.7208  \n  1973 1989  -9.7072     7.6883      -38.6226     19.2081  \n  1973 1990 -12.5464     6.1908      -35.8299     10.7370  \n  1973 1991 -15.9396     7.6580      -44.7411     12.8619  \n  1973 1992 -17.9985     7.6618      -46.8143     10.8174  \n  1973 1993 -13.8426     7.9057      -43.5758     15.8907  \n  1973 1994  -9.0985     6.1611      -32.2702     14.0733  \n  1973 1995 -12.4104     3.9817      -27.3856      2.5647  \n  1973 1996 -14.4985     5.5684      -35.4413      6.4443  \n  1974 1965  -3.4980     4.7162      -21.2356     14.2396  \n  1974 1966   4.0405     5.6581      -17.2396     25.3206  \n  1974 1967  -2.4469     2.6938      -12.5781      7.6844  \n  1974 1968  -4.1701     5.3543      -24.3075     15.9672  \n  1974 1969   3.0794     2.0318       -4.5622     10.7210  \n  1974 1970   3.9844     2.6191       -5.8659     13.8348  \n  1974 1971  -7.0304     3.1705      -18.9547      4.8938  \n  1974 1972   6.3385     3.4903       -6.7884     19.4655  \n  1974 1973   0.5656     5.1425      -18.7751     19.9064  \n  1974 1974  -2.4409     4.0471      -17.6621     12.7803  \n  1974 1975   1.3647     5.2484      -18.3746     21.1039  \n  1974 1976  -3.5756     6.2644      -27.1358     19.9845  \n  1974 1977  -4.0728     5.6967      -25.4979     17.3524  \n  1974 1978  -8.9231     5.3983      -29.2258     11.3795  \n  1974 1979  -1.7408     6.2680      -25.3146     21.8330  \n  1974 1980  -9.7770     5.2257      -29.4308      9.8769  \n  1974 1981  -2.8322     5.9365      -25.1594     19.4949  \n  1974 1982  -7.4517     5.0610      -26.4859     11.5825  \n  1974 1983  -4.3400     6.9901      -30.6298     21.9497  \n  1974 1984  -7.8279     6.2809      -31.4501     15.7942  \n  1974 1985   0.9048    11.1563      -41.0536     42.8633  \n  1974 1986  -3.4953     9.5009      -39.2279     32.2373  \n  1974 1987  -9.3045     8.5199      -41.3477     22.7386  \n  1974 1988  -9.0434     8.3263      -40.3583     22.2714  \n  1974 1989  -6.4758    10.3191      -45.2856     32.3340  \n  1974 1990  -7.6369     8.2398      -38.6264     23.3526  \n  1974 1991 -14.7133     7.7174      -43.7382     14.3116  \n  1974 1992 -14.7711     7.9024      -44.4916     14.9495  \n  1974 1993 -11.2274     8.7908      -44.2892     21.8343  \n  1974 1994 -14.4350    10.7126      -54.7247     25.8547  \n  1974 1995 -13.4194     9.8742      -50.5558     23.7171  \n  1974 1996 -14.8017    10.5500      -54.4798     24.8765  \n  1975 1965  18.6039    14.9953      -37.7928     75.0005  \n  1975 1966  -3.3872     3.6269      -17.0279     10.2534  \n  1975 1967  -2.4321     2.2945      -11.0618      6.1977  \n  1975 1968   7.3667     5.5063      -13.3422     28.0756  \n  1975 1969  -4.2480     7.5243      -32.5468     24.0509  \n  1975 1970 -11.4912     8.2671      -42.5836     19.6013  \n  1975 1971   5.6632     9.0191      -28.2574     39.5838  \n  1975 1972 -15.6310     7.8300      -45.0795     13.8175  \n  1975 1973  16.2449     6.2543       -7.2772     39.7670  \n  1975 1974  -0.4082     6.5198      -24.9288     24.1123  \n  1975 1975  -2.3510     2.7082      -12.5365      7.8346  \n  1975 1976  -2.3824     5.5674      -23.3214     18.5565  \n  1975 1977  -4.1345    10.2209      -42.5750     34.3061  \n  1975 1978  -7.0822     6.8336      -32.7830     18.6186  \n  1975 1979 -12.0112    16.0436      -72.3506     48.3282  \n  1975 1980 -10.7602     5.3389      -30.8396      9.3191  \n  1975 1981  -7.1236     5.3099      -27.0940     12.8468  \n  1975 1982 -10.5685     7.5006      -38.7780     17.6410  \n  1975 1983  -9.0308     6.1676      -32.2269     14.1654  \n  1975 1984   9.8022     5.9609      -12.6166     32.2209  \n  1975 1985  -5.6163     8.3174      -36.8977     25.6651  \n  1975 1986  -5.2183     5.2469      -24.9516     14.5150  \n  1975 1987  -0.8638     5.3408      -20.9504     19.2229  \n  1975 1988 -15.3668    11.0217      -56.8188     26.0853  \n  1975 1989  -5.4933     5.4602      -26.0288     15.0421  \n  1975 1990   8.5067     5.8762      -13.5935     30.6068  \n  1975 1991   0.7631     6.3414      -23.0866     24.6128  \n  1975 1992  -4.2255     6.9071      -30.2029     21.7519  \n  1975 1993   1.1200     2.6826       -8.9693     11.2093  \n  1975 1994  -8.3655     7.4179      -36.2640     19.5330  \n  1975 1995   1.8041     4.2049      -14.0103     17.6185  \n  1975 1996  -6.9207     5.8278      -28.8390     14.9976  \n  1976 1965 -11.0522     1.7635      -17.6845     -4.4198 *\n  1976 1966   0.1018     2.2472       -8.3498      8.5534  \n  1976 1967  -5.9143     2.2177      -14.2550      2.4264  \n  1976 1968  -1.6479     2.0075       -9.1981      5.9023  \n  1976 1969  -6.6407     1.8044      -13.4272      0.1457  \n  1976 1970   8.5784     1.9560        1.2219     15.9349 *\n  1976 1971   4.0973     2.6267       -5.7817     13.9763  \n  1976 1972  -0.9903     2.7810      -11.4497      9.4691  \n  1976 1973 -20.1263     3.7082      -34.0728     -6.1797 *\n  1976 1974  39.6133     2.4566       30.3742     48.8524 *\n  1976 1975  -3.5747     2.7191      -13.8010      6.6516  \n  1976 1976   3.7698     5.2187      -15.8576     23.3971  \n  1976 1977  33.5942     4.7165       15.8555     51.3329 *\n  1976 1978  -3.1195     2.2793      -11.6918      5.4528  \n  1976 1979   1.3342     7.1463      -25.5428     28.2112  \n  1976 1980 -10.4124     3.6444      -24.1187      3.2939  \n  1976 1981 -10.4368     5.7416      -32.0309     11.1573  \n  1976 1982 -12.4922     3.5001      -25.6562      0.6717  \n  1976 1983 -15.8081     6.2755      -39.4100      7.7938  \n  1976 1984 -20.6870     3.9057      -35.3762     -5.9978 *\n  1976 1985  -0.2053    11.6139      -43.8848     43.4742  \n  1976 1986 -27.7992     8.3181      -59.0832      3.4848  \n  1976 1987  -9.9985     3.6973      -23.9038      3.9069  \n  1976 1988 -22.8540     5.8685      -44.9254     -0.7826 *\n  1976 1989 -14.3020     6.6385      -39.2692     10.6652  \n  1976 1990 -16.7275     4.7892      -34.7396      1.2846  \n  1976 1991 -29.9838     5.5425      -50.8290     -9.1387 *\n  1976 1992 -35.9431     6.1194      -58.9581    -12.9281 *\n  1976 1993 -33.5630     6.2298      -56.9932    -10.1328 *\n  1976 1994 -19.1785    10.5829      -58.9804     20.6233  \n  1976 1995 -18.8943     9.0197      -52.8170     15.0284  \n  1976 1996 -20.0712     8.0000      -50.1588     10.0164  \n  1977 1965   6.8982    16.7867      -56.2360     70.0325  \n  1977 1966 -11.1214     8.8921      -44.5644     22.3217  \n  1977 1967  10.8566     5.6394      -10.3530     32.0663  \n  1977 1968 -11.0425    11.5273      -54.3962     32.3112  \n  1977 1969  10.1932    17.5653      -55.8693     76.2556  \n  1977 1970   2.9004     6.3522      -20.9899     26.7906  \n  1977 1971   3.0530     8.8535      -30.2448     36.3509  \n  1977 1972  -0.6535     9.6867      -37.0850     35.7780  \n  1977 1973   3.1405     8.8108      -29.9967     36.2777  \n  1977 1974 -14.4506     6.1419      -37.5503      8.6490  \n  1977 1975  -0.1240     5.1265      -19.4045     19.1565  \n  1977 1976   5.5263    19.1535      -66.5093     77.5618  \n  1977 1977  -0.1462    22.8970      -86.2612     85.9688  \n  1977 1978 -17.4422    23.9907     -107.6706     72.7862  \n  1977 1979  -7.6652    33.4449     -133.4505    118.1201  \n  1977 1980 -12.0752    33.7345     -138.9496    114.7993  \n  1977 1981 -11.8110    26.5246     -111.5692     87.9472  \n  1977 1982 -18.5556    17.8424      -85.6604     48.5493  \n  1977 1983   4.2551    34.9957     -127.3627    135.8728  \n  1977 1984  -3.0226    27.5429     -106.6107    100.5655  \n  1977 1985 -14.8995    22.4549      -99.3516     69.5526  \n  1977 1986 -12.3230    15.1342      -69.2421     44.5962  \n  1977 1987 -23.6769    32.2009     -144.7834     97.4296  \n  1977 1988 -25.5547    23.1800     -112.7340     61.6246  \n  1977 1989  -9.2602    40.2793     -160.7493    142.2289  \n  1977 1990 -13.7369    45.3789     -184.4054    156.9316  \n  1977 1991 -25.9731    32.4826     -148.1392     96.1930  \n  1977 1992 -29.9220    23.2090     -117.2102     57.3662  \n  1977 1993 -14.9531    36.2530     -151.2994    121.3933  \n  1977 1994 -11.6033    48.6565     -194.5989    171.3922  \n  1977 1995 -29.0098    23.4604     -117.2435     59.2239  \n  1977 1996 -16.0590    27.5715     -119.7543     87.6363  \n  1980 1965  -4.7817     1.7979      -11.5435      1.9800  \n  1980 1966  -2.0295     2.2447      -10.4716      6.4126  \n  1980 1967   0.2462     2.2137       -8.0794      8.5719  \n  1980 1968   4.9725     2.0119       -2.5943     12.5392  \n  1980 1969  -5.6981     1.8069      -12.4937      1.0976  \n  1980 1970   7.6920     1.9938        0.1932     15.1908 *\n  1980 1971  -9.5134     2.5370      -19.0550      0.0282  \n  1980 1972   5.9170     2.7412       -4.3925     16.2265  \n  1980 1973  -3.6509     3.9272      -18.4212     11.1193  \n  1980 1974   1.1846     4.1580      -14.4537     16.8229  \n  1980 1975  -1.4249     2.7830      -11.8917      9.0419  \n  1980 1976   1.5220     5.7937      -20.2681     23.3121  \n  1980 1977  -1.8998     2.8071      -12.4572      8.6577  \n  1980 1978  -6.1099     5.5846      -27.1135     14.8937  \n  1980 1979   6.0177     8.3504      -25.3879     37.4234  \n  1980 1980 -11.0694     5.3019      -31.0095      8.8707  \n  1980 1981  -7.3267     2.7095      -17.5170      2.8636  \n  1980 1982  -9.2663     9.6255      -45.4675     26.9350  \n  1980 1983   1.6316     3.2901      -10.7423     14.0055  \n  1980 1984  -2.4538     5.2385      -22.1557     17.2480  \n  1980 1985   4.4467     4.7848      -13.5490     22.4423  \n  1980 1986  -9.5981     7.0565      -36.1373     16.9410  \n  1980 1987 -10.0537    11.3335      -52.6787     32.5713  \n  1980 1988 -10.9789     9.1300      -45.3164     23.3587  \n  1980 1989  -6.9527     6.3603      -30.8735     16.9681  \n  1980 1990  -5.3312     6.2450      -28.8183     18.1560  \n  1980 1991  -8.8820     8.2207      -39.7997     22.0356  \n  1980 1992 -12.0023    11.0607      -53.6011     29.5965  \n  1980 1993  -8.3192     7.7315      -37.3969     20.7586  \n  1980 1994 -12.5474     7.1011      -39.2546     14.1597  \n  1980 1995  -6.7308     8.7926      -39.7995     26.3379  \n  1980 1996  -9.1678     7.7440      -38.2927     19.9570  \n  1984 1965   2.2727     1.7801       -4.4222      8.9675  \n  1984 1966  -1.6070     2.2270       -9.9827      6.7688  \n  1984 1967  -1.8538     2.2062      -10.1513      6.4436  \n  1984 1968  -1.3557     1.9974       -8.8679      6.1565  \n  1984 1969   2.1619     1.7839       -4.5474      8.8712  \n  1984 1970  -0.3449     1.9959       -7.8513      7.1614  \n  1984 1971 -10.9305     2.5388      -20.4787     -1.3823 *\n  1984 1972   5.8536     2.7724       -4.5735     16.2806  \n  1984 1973  -1.9239     3.9386      -16.7367     12.8889  \n  1984 1974  -7.1605     4.1538      -22.7827      8.4617  \n  1984 1975  -1.6437     2.7840      -12.1143      8.8270  \n  1984 1976   5.6685     5.5426      -15.1769     26.5139  \n  1984 1977   3.2342     2.7903       -7.2599     13.7282  \n  1984 1978  -7.3151     5.5215      -28.0815     13.4512  \n  1984 1979   1.9466     8.3880      -29.6004     33.4936  \n  1984 1980  -8.6205     5.8434      -30.5974     13.3564  \n  1984 1981  10.4692     4.8613       -7.8141     28.7525  \n  1984 1982  -5.4364     8.0334      -35.6499     24.7771  \n  1984 1983  12.0264     8.4379      -19.7083     43.7612  \n  1984 1984  -0.7730     2.4534      -10.0000      8.4541  \n  1984 1985   4.0744     3.8064      -10.2414     18.3901  \n  1984 1986  -8.0341     2.8724      -18.8371      2.7689  \n  1984 1987 -10.4189     8.9490      -44.0757     23.2379  \n  1984 1988  -7.8277     6.1942      -31.1238     15.4685  \n  1984 1989  -9.2894     3.8762      -23.8677      5.2889  \n  1984 1990  -6.2529     3.0974      -17.9022      5.3963  \n  1984 1991 -10.1584     4.9176      -28.6534      8.3366  \n  1984 1992 -11.4694     8.6653      -44.0592     21.1204  \n  1984 1993  -9.2844     4.4284      -25.9395      7.3707  \n  1984 1994 -14.6630     5.2893      -34.5558      5.2299  \n  1984 1995 -12.5044     3.7261      -26.5181      1.5093  \n  1984 1996 -10.2449     3.2720      -22.5508      2.0611  \n  1985 1965  -4.3499     1.8037      -11.1336      2.4337  \n  1985 1966  37.6989     1.9026       30.5433     44.8545 *\n  1985 1967 -19.2838     2.1912      -27.5247    -11.0429 *\n  1985 1968  -4.2545     2.0230      -11.8629      3.3539  \n  1985 1969  10.5295     1.7198        4.0613     16.9977 *\n  1985 1970   7.2143     1.9831       -0.2439     14.6726  \n  1985 1971   6.9735     2.5669       -2.6806     16.6276  \n  1985 1972   5.8781     2.7153       -4.3340     16.0902  \n  1985 1973 -38.9329     2.9638      -50.0798    -27.7859 *\n  1985 1974   8.7158     4.1963       -7.0665     24.4981  \n  1985 1975  -7.1533     2.6691      -17.1917      2.8851  \n  1985 1976  -0.8308     5.7205      -22.3452     20.6836  \n  1985 1977  -2.2605     2.8358      -12.9256      8.4047  \n  1985 1978   7.7405     5.8788      -14.3694     29.8504  \n  1985 1979  -4.9814     8.5470      -37.1265     27.1637  \n  1985 1980   2.9209     6.2508      -20.5883     26.4300  \n  1985 1981  -4.4773     4.4977      -21.3930     12.4384  \n  1985 1982  13.7629     8.6731      -18.8564     46.3822  \n  1985 1983  -7.4210     8.8419      -40.6751     25.8330  \n  1985 1984  -5.5493     3.0237      -16.9212      5.8225  \n  1985 1985  11.4728     6.8301      -14.2148     37.1605  \n  1985 1986  10.1715     3.1749       -1.7692     22.1123  \n  1985 1987  17.5291     5.1061       -1.6748     36.7330  \n  1985 1988  -9.6423     4.1182      -25.1308      5.8463  \n  1985 1989  19.8229     5.7077       -1.6436     41.2893  \n  1985 1990  26.2350     1.7402       19.6900     32.7799 *\n  1985 1991   6.2209     3.7879       -8.0253     20.4671  \n  1985 1992  18.3602     6.2606       -5.1856     41.9059  \n  1985 1993  23.0343     2.8585       12.2838     33.7849 *\n  1985 1994  15.2612     6.2622       -8.2907     38.8131  \n  1985 1995  15.4633     4.6990       -2.2094     33.1361  \n  1985 1996  26.5282     3.9405       11.7082     41.3483 *\n---\nSignif. codes: `*' confidence band does not cover 0\n\nControl Group:  Not Yet Treated,  Anticipation Periods:  0\nEstimation Method:  Outcome Regression\n\nggdid(atts_nyt)\n\n\n\n\n\n\n\n\n[5 puntos] Reporte los resultados agregados obtenidos a partir del estimador Callaway & Sant’Anna (2021), usando una agregación dinámica que muestre los efectos promedio para cada periodo antes y después del tratamiento. Grafique e interprete los resultados.\nGraficamos:\n\nagg.es &lt;- aggte(atts_nyt,\n                type = \"dynamic\")\nsummary(agg.es)\n\n\nCall:\naggte(MP = atts_nyt, type = \"dynamic\")\n\nReference: Callaway, Brantly and Pedro H.C. Sant'Anna.  \"Difference-in-Differences with Multiple Time Periods.\" Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. &lt;https://doi.org/10.1016/j.jeconom.2020.12.001&gt;, &lt;https://arxiv.org/abs/1803.09015&gt; \n\n\nOverall summary of ATT's based on event-study/dynamic aggregation:  \n    ATT    Std. Error     [ 95%  Conf. Int.]  \n -9.628        3.6814   -16.8433     -2.4127 *\n\n\nDynamic Effects:\n Event time Estimate Std. Error [95% Simult.  Conf. Band]  \n        -20  -4.3499     1.7273       -9.1437      0.4438  \n        -19  19.9858    12.8179      -15.5877     55.5593  \n        -18 -10.4454     7.1783      -30.3673      9.4766  \n        -17  -3.0542     1.1065       -6.1250      0.0167  \n        -16   4.5869     4.4301       -7.7081     16.8819  \n        -15   1.5315     3.4571       -8.0629     11.1259  \n        -14   1.5330     2.3973       -5.1202      8.1862  \n        -13  -1.6021     3.9882      -12.6706      9.4665  \n        -12  -1.2353     9.7939      -28.4163     25.9456  \n        -11  -6.1889     4.7560      -19.3882      7.0103  \n        -10   7.0286     4.9459       -6.6978     20.7550  \n         -9  -5.6915     3.3221      -14.9113      3.5282  \n         -8   1.1876     2.4776       -5.6884      8.0637  \n         -7  -0.6219     1.9773       -6.1096      4.8658  \n         -6   1.1581     2.6672       -6.2441      8.5603  \n         -5  -2.9106     2.1890       -8.9859      3.1647  \n         -4   2.9082     1.6636       -1.7088      7.5251  \n         -3  -1.9822     2.5777       -9.1360      5.1717  \n         -2   0.7311     2.5728       -6.4091      7.8712  \n         -1   1.4763     2.3845       -5.1414      8.0940  \n          0   0.5890     2.7993       -7.1799      8.3579  \n          1  -1.2422     2.9849       -9.5264      7.0419  \n          2  -0.3815     4.2972      -12.3075     11.5445  \n          3  -0.4662     3.9267      -11.3640     10.4316  \n          4  -0.3563     4.3625      -12.4634     11.7509  \n          5  -3.4207     4.5930      -16.1677      9.3262  \n          6  -2.4065     4.5614      -15.0659     10.2529  \n          7  -6.4250     4.6104      -19.2201      6.3702  \n          8  -5.8964     4.8323      -19.3076      7.5148  \n          9  -6.3944     4.2342      -18.1456      5.3568  \n         10  -7.7061     4.6766      -20.6851      5.2729  \n         11  -8.8186     5.5919      -24.3379      6.7008  \n         12  -7.2921     4.2102      -18.9768      4.3926  \n         13 -11.1384     4.3627      -23.2464      0.9695  \n         14 -11.1558     4.5294      -23.7264      1.4148  \n         15 -14.8167     5.0491      -28.8294     -0.8039 *\n         16 -11.6965     4.8488      -25.1533      1.7604  \n         17 -14.3232     4.5793      -27.0320     -1.6143 *\n         18 -17.1010     5.2118      -31.5652     -2.6368 *\n         19 -17.4748     4.4007      -29.6881     -5.2614 *\n         20 -14.9783     4.4988      -27.4638     -2.4928 *\n         21 -15.8960     4.3880      -28.0741     -3.7179 *\n         22 -15.2219     4.6775      -28.2035     -2.2403 *\n         23 -16.2453     5.0965      -30.3895     -2.1010 *\n         24 -17.8714     6.9526      -37.1669      1.4240  \n         25 -17.0567     9.1623      -42.4848      8.3715  \n         26 -27.4244    18.3755      -78.4221     23.5734  \n         27   3.0338    13.0924      -33.3015     39.3691  \n---\nSignif. codes: `*' confidence band does not cover 0\n\nControl Group:  Not Yet Treated,  Anticipation Periods:  0\nEstimation Method:  Outcome Regression\n\nggdid(agg.es)\n\n\n\n\n\n\n\n\nSe obtiene una reducción en la tasa de suicidios que es estadísticamente significativa a partir de 13 años después de la introducción de la legislación.\n[5 puntos] Reporte los resultados agregados obtenidos a partir del estimador Callaway & Sant’Anna (2021), usando una agregación or grupos que muestre los efectos promedio para cada cohorte del tratamiento. Grafique e interprete los resultados.\nGraficamos:\n\nagg.es &lt;- aggte(atts_nyt,\n                type = \"group\")\nsummary(agg.es)\n\n\nCall:\naggte(MP = atts_nyt, type = \"group\")\n\nReference: Callaway, Brantly and Pedro H.C. Sant'Anna.  \"Difference-in-Differences with Multiple Time Periods.\" Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. &lt;https://doi.org/10.1016/j.jeconom.2020.12.001&gt;, &lt;https://arxiv.org/abs/1803.09015&gt; \n\n\nOverall summary of ATT's based on group/cohort aggregation:  \n     ATT    Std. Error     [ 95%  Conf. Int.]  \n -8.2876        3.1063   -14.3757     -2.1994 *\n\n\nGroup Effects:\n Group Estimate Std. Error [95% Simult.  Conf. Band]  \n  1969  -5.3569     8.3373      -26.3972     15.6834  \n  1970 -30.6010    17.1839      -73.9671     12.7651  \n  1971 -10.3173     5.7339      -24.7876      4.1530  \n  1972  -7.9006     4.3825      -18.9604      3.1593  \n  1973  -4.5364     5.4544      -18.3014      9.2285  \n  1974  -7.3929     6.9383      -24.9026     10.1168  \n  1975  -4.3417     3.1516      -12.2952      3.6117  \n  1976 -13.5133     4.6554      -25.2617     -1.7648 *\n  1977 -14.6717     8.1521      -35.2446      5.9012  \n  1980  -7.3295     5.4337      -21.0423      6.3833  \n  1984  -8.2189     2.0860      -13.4831     -2.9547 *\n  1985  15.0381     3.2446        6.8498     23.2264 *\n---\nSignif. codes: `*' confidence band does not cover 0\n\nControl Group:  Not Yet Treated,  Anticipation Periods:  0\nEstimation Method:  Outcome Regression\n\nggdid(agg.es)\n\n\n\n\n\n\n\n\nNotamos un efecto negativo en la tasa de suicidos que es estadísticamente significativa para los estados que fueron tratados en 1970, 1986 y 1984.\n[5 puntos] ¿Cuáles son las ventajas del estimador de Callaway & Sant’Anna (2021) respecto al estimador de TWFE?\nLas ventajas del estimador de Callaway & Sant’Anna respecto a TWFE son las siguientes: - Evita las comapraciones prohibidas (usar unidades tratadas como controles para unidades que son tratadas en periodos posteriores) - Hace explícito el grupo de comparación que se usa para comparar a las unidades tratadas - Hace explícita la manera en que se agregan los resultados de cada comparación \\(ATT(g,t)\\) - No impone efectos monótonos en el tiempo ni homogéneos entre unidades\n\n\n\n\nLa ENIGH 2020 incluyó un módulo para la evaluación del Programa Jóvenes Construyendo el futuro. Se buscó que la cobertura de la encuesta pudiera incluir suficientes participantes del programa para poder compararlos con los no participantes. Los datos en datos_jcf_analisis.csv fueron construidos a partir de dicha encuesta. En este ejercicio estimaremos el efecto de participar en el programa sobre el ingreso trimestral, ingtot_tri, usando métodos de matching.\nLas siguientes variables están incluidas en el archivo de datos: mujer (dummy de sexo), indigena (dummy de pertenencia a una etnia), rural (dummy del ámbito rural), escoacum (años de escolaridad), casadounion (dummy para casados o en unión libre), jefehog (dummy para jefes del hogar), haymenores (dummy para la presencia de menores de edad en el hogar), proggob (dummy para beneficiarios de programas de gobierno), y tot_integ (número de miembros del hogar). También se incluye la clave de las entidades, cve_ent.\n\n[5 puntos] Considere la comparación para el ingreso trimestral, ingtot_tri, entre beneficiarios y su grupo de comparación, que serán los jóvenes que no asisten a la escuela y no están empleados. Los beneficiarios tienen jcf2==1 y los jóvenes que no asisten a la escuela y no están empleados tienen jcf2==0. Muestre qué tan similares o qué tan diferentes son los individuos en ambos grupos en términos de las características indicadas anteriormente y del ingreso trimestral.\nEstadística descriptiva:\n\ndata.jcf &lt;- read_csv(\"../files/datos_jcf_analisis.csv\")\n\nset.seed(1023)\n\nAquí usé datasummary para calcular la estadística descriptiva por grupos:\n\ndatasummary(ingtot_tri + mujer + indigena + rural + escoacum + casadounion + jefehog + haymenores + proggob + tot_integ ~ factor(jcf2) * (mean + sd) * Arguments(na.rm=TRUE),\n                fmt = \"%.2f\",\n                data = data.jcf)\n\n \n\n  \n    \n    \n    tinytable_uy949959h4oavhy4bb3w\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n \n0\n1\n\n\n              \n                 \n                mean\n                sd\n                mean\n                sd\n              \n        \n\n        \n                \n                  ingtot_tri \n                  1510.36\n                  8478.60\n                  9643.06\n                  6632.56\n                \n                \n                  mujer      \n                  0.76   \n                  0.43   \n                  0.59   \n                  0.49   \n                \n                \n                  indigena   \n                  0.22   \n                  0.41   \n                  0.59   \n                  0.49   \n                \n                \n                  rural      \n                  0.40   \n                  0.49   \n                  0.35   \n                  0.48   \n                \n                \n                  escoacum   \n                  10.39  \n                  3.23   \n                  12.03  \n                  2.70   \n                \n                \n                  casadounion\n                  0.53   \n                  0.50   \n                  0.41   \n                  0.49   \n                \n                \n                  jefehog    \n                  0.06   \n                  0.23   \n                  0.14   \n                  0.35   \n                \n                \n                  haymenores \n                  0.66   \n                  0.47   \n                  0.54   \n                  0.50   \n                \n                \n                  proggob    \n                  0.19   \n                  0.39   \n                  0.21   \n                  0.41   \n                \n                \n                  tot_integ  \n                  4.82   \n                  1.97   \n                  4.25   \n                  2.00   \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nClaramente los individuos que participan en el programa son diferentes a los que no. En el programa hay una proporción menor de mujeres que en el grupo no tratado; en el grupo tratado hay un nivel mayor de escolaridad acumulada; y los individuos del grupo tratado viven en hogares más pequeños que los del grupo no tratado. Entre muchas otras diferencias.\nEl problema entonces es que existen factores que influyen en la probabilidad de recibir el tratamiento y en el ingreso, por lo que una comparación simple de individuos tratados y no tratados confundirá el efecto del tratamiento.\n[5 puntos] Estime el TOT (TT o ATT) del programa en el ingreso trimestral, ingtot_tri usando el algoritmo de vecino más cercano. Para estimar el impacto en el ingreso trimestral se comparan a los beneficiarios de JCF con los jóvenes que no asisten a la escuela y no están empleados. Los beneficiarios tienen jcf2==1 y los jóvenes que no asisten a la escuela y no están empleados tienen jcf2==0. Escoja la especificación del propensity score que más le parezca adecuada. Realice la inferencia estadística con errores agrupados a nivel grupo de emparejamiento. ¿De qué tamaño es el TOT estimado y es este efecto estadísticamente significativo?\nEste es el modelo para el propensity score que yo escogí:\n\nsub.data &lt;- data.jcf %&gt;%\ndplyr::select(ingtot_tri, jcf2, mujer, indigena, cve_ent, rural, escoacum, casadounion,\n    jefehog, haymenores, proggob, tot_integ, factor.x)\n\nsub.data &lt;- sub.data[complete.cases(sub.data), ]\n\n\nm.out.a &lt;- matchit(formula=jcf2 ~ mujer + indigena + factor(cve_ent) + rural  + escoacum + casadounion + jefehog + haymenores + proggob + tot_integ,\n                 method = \"nearest\",\n                 distance= \"glm\",\n                 replace = FALSE,\n                 data = sub.data)\n\nEstimamos el efecto del tratamiento:\n\ntt1 &lt;- lm(ingtot_tri ~ jcf2,\n      data = match.data(m.out.a))\n\n#Errores agrupados a nivel subclass\ncoeftest(tt1,\n         vcov. = vcovCL,\n         cluster = ~subclass)\n\n\nt test of coefficients:\n\n            Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  1669.95     407.99  4.0931 5.735e-05 ***\njcf2         7973.11     708.27 11.2572 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSe estima un efecto de 7973 pesos adicionales de ingreso trimestral para los participantes en el programa.\n[5 puntos] En el matching de la parte b., evalúe qué tan bueno es el procedimiento en balancear las características observadas una vez realizado el matching. Cree un love plot para evaluar qué tan bueno es el procedimiento de matching para obtener una muestra balanceada.\nbal.tab del paquete cobalt nos permite ver un resumen del balance:\n\n#Con esto elimino las dummies de estado de la salida\nbal.tab(m.out.a, m.threshold=0.1, un=T)\n\nBalance Measures\n                       Type Diff.Un Diff.Adj        M.Threshold\ndistance           Distance  1.1091   0.0881     Balanced, &lt;0.1\nmujer                Binary -0.1660   0.0551     Balanced, &lt;0.1\nindigena             Binary  0.3714   0.0551     Balanced, &lt;0.1\nfactor(cve_ent)_01   Binary -0.1720  -0.0157     Balanced, &lt;0.1\nfactor(cve_ent)_02   Binary -0.3428  -0.0079     Balanced, &lt;0.1\nfactor(cve_ent)_03   Binary  0.0168   0.0079     Balanced, &lt;0.1\nfactor(cve_ent)_04   Binary  0.5524   0.0157     Balanced, &lt;0.1\nfactor(cve_ent)_05   Binary -0.0544   0.0000     Balanced, &lt;0.1\nrural                Binary -0.0553   0.0709     Balanced, &lt;0.1\nescoacum            Contin.  0.6086  -0.2096 Not Balanced, &gt;0.1\ncasadounion          Binary -0.1170   0.0709     Balanced, &lt;0.1\njefehog              Binary  0.0831   0.0551     Balanced, &lt;0.1\nhaymenores           Binary -0.1193   0.0787     Balanced, &lt;0.1\nproggob              Binary  0.0220   0.0079     Balanced, &lt;0.1\ntot_integ           Contin. -0.2856   0.0158     Balanced, &lt;0.1\n\nBalance tally for mean differences\n                   count\nBalanced, &lt;0.1        14\nNot Balanced, &gt;0.1     1\n\nVariable with the greatest mean difference\n Variable Diff.Adj        M.Threshold\n escoacum  -0.2096 Not Balanced, &gt;0.1\n\nSample sizes\n          Control Treated\nAll          1894     127\nMatched       127     127\nUnmatched    1767       0\n\n\nY finalmente el loveplot:\n\nm.out.a[[\"X\"]][[\"factor(cve_ent)\"]] &lt;- NULL\n\nlove.plot(bal.tab(m.out.a),\n      threshold = .1)\n\n\n\n\n\n\n\n\nParece haber un buen balance, aunque la educación es la única variable que no queda bien balanceada. Después del emparejamiento, las medias (estandarizadas) entre tratados y no tratados difieren en más de 0.1.\n[5 puntos] Estime ahora el TOT en el ingreso trimestral, como en la parte b., pero usando un caliper de 0.05 y 5 vecinos a ser emparejados. ¿Cómo cambian sus resultados respecto a los de la parte b.?\n\nsub.data &lt;- data.jcf %&gt;% \n  dplyr::select(ingtot_tri, jcf2, mujer, indigena, cve_ent, rural, escoacum, \n           casadounion, jefehog, haymenores, proggob, tot_integ, factor.x)\n\nsub.data &lt;- sub.data[complete.cases(sub.data), ] \n\nm.out.c &lt;- matchit(formula=jcf2 ~ mujer + indigena + factor(cve_ent) + rural  + escoacum + casadounion + jefehog + haymenores + proggob + tot_integ,\n                 method = \"nearest\",\n                 distance= \"glm\",\n                 ratio = 5,\n                 caliper = 0.05,\n                 replace = FALSE,\n                 data = sub.data)\n\nEstimamos el efecto del tratamiento:\n\ntt3 &lt;- lm(ingtot_tri ~ jcf2,\n      data = match.data(m.out.c))\n\n#Errores agrupados a nivel subclass\ncoeftest(tt3,\n         vcov. = vcovCL,\n         cluster = ~subclass)\n\n\nt test of coefficients:\n\n            Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  2135.55     372.22  5.7374 1.717e-08 ***\njcf2         7155.74     699.21 10.2341 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSe estima ahora un efecto de 7155 pesos, menor al efecto de 7973 pesos estimado en la parte b."
  },
  {
    "objectID": "tareas/tarea-3-respuestas.html#pregunta-1",
    "href": "tareas/tarea-3-respuestas.html#pregunta-1",
    "title": "Respuestas a la tarea 3",
    "section": "",
    "text": "Stevenson, B. & Wolfers, J. (2006)1 estudian los efectos de la introducción de leyes que permiten el divorcio unilateral en los Estados Unidos. La librería bacondecomp incluye los datos usados en dicho artículo (debe instalar y cargar la librería). Usaremos los datos de 1964 a 1996 para mostrar cómo impactan las leyes de divorcio express (unilateral) a la tasa de suicidios en mujeres.\nAl correr el pedazo de código anterior, obtendrá un objeto de datos wd en donde la variable de impacto es la tasa de suicidios en mujeres, suicide_rate, st identifica a los estados, year identifica a los años y divyear es el año en que se introdujo la legislación del divorcio unilateral. La última fila del código crea el indicador de tratamiento unilaterial, que toma el valor de 1 para los estados tratados en los periodos post tratamiento.\n\nwd &lt;- divorce %&gt;% \nfilter(year&gt;=1964 & year&lt;=1996 & sex==2) %&gt;% \nmutate(suicide_rate=suicide*1000000/(stpop*fshare),\n   year=as.numeric(year),\n   divyear = ifelse(divyear&gt;1996, Inf, divyear),\n   unilateral=ifelse(year&gt;divyear, 1, 0))\n\n\n[5 puntos] Presente una tabla donde muestre el número de estados que es tratado en cada periodo del panel. ¿Cuántos estados son nunca tratados? ¿Cuántos estados son siempre tratados?\nSi hacemos un tabulado de divyear para un año fijo, notamos cuántos estados se vuelven tratados en cada año. Solo 5 estados son nunca tratados. Por otro lado, como el panel comienza en 1964 y hay 9 estados tratados en 1950, estos 9 estados son siempre tratados.\n\ntable(filter(wd, year==1996)$divyear)\n\n\n1950 1969 1970 1971 1972 1973 1974 1975 1976 1977 1980 1984 1985  Inf \n   9    2    2    7    3   11    3    2    1    3    1    1    1    5 \n\n\n[5 puntos] Como punto de partida, estime el efecto del tratamiento sobre suicide_rate usando efectos fijos por estado y año (TWFE) y empleando una librería específica para efectos fijos, como felm. Tome en cuenta la agrupación de los errores. Interprete sus resultados.\nUsando felm podemos incorporar ya el nivel de agrupación de los errores:\n\nsummary(felm(suicide_rate ~ unilateral | st + year | 0 | st,\n              data = wd))\n\n\nCall:\n   felm(formula = suicide_rate ~ unilateral | st + year | 0 | st,      data = wd) \n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-37.517  -6.157  -0.141   5.577  57.004 \n\nCoefficients:\n           Estimate Cluster s.e. t value Pr(&gt;|t|)  \nunilateral   -3.777        2.201  -1.716   0.0923 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.85 on 1599 degrees of freedom\nMultiple R-squared(full model): 0.6844   Adjusted R-squared: 0.668 \nMultiple R-squared(proj model): 0.007963   Adjusted R-squared: -0.04353 \nF-statistic(full model, *iid*):41.77 on 83 and 1599 DF, p-value: &lt; 2.2e-16 \nF-statistic(proj model): 2.945 on 1 and 50 DF, p-value: 0.09231 \n\n\n[5 puntos] Compruebe que puede obtener el mismo resultado con una regresión lineal usando el paquete lm e incluyendo, además de la variable de tratamiento, dummies de estado y de año.\nEstimamos con dummies:\n\nsummary(m1 &lt;- lm(suicide_rate ~ unilateral + factor(st) + factor(year),\n              data = wd))$coef[1:2,1:3]\n\n             Estimate Std. Error   t value\n(Intercept) 56.732642   2.468251 22.984953\nunilateral  -3.776552   1.054148 -3.582562\n\n\nLuego estimamos errores agrupados:\n\nmodelsummary(list(m1),\n             output = 'gt',\n             vcov=clubSandwich::vcovCR(m1, type='CR1', cluster=wd$st),\n             coef_map = \"unilateral\",\n             gof_map = \"nobs\")\n\n\n\n\n\n\n\n\n(1)\n\n\n\n\nunilateral\n-3.777\n\n\n\n(2.200)\n\n\nNum.Obs.\n1683\n\n\n\n\n\n\n\nObtenemos los mismos coeficientes. Aquí también podrán volver a comprobar la importancia de usar errores agrupados. El error agrupado es más de dos veces más grande que el error clásico.\n[10 puntos] Ahora muestre que podemos obtener el coeficiente de TWFE a partir de una regresión bivariada entre la tasa de suicidios y unilateral, una vez purgada por efectos fijos. Para ello, primero estime una regresión de unilateral en función de los efectos fijos. Obtenga la predicción y luego defina una nueva variable igual a la diferencia entre unilateral y la predicción que acaba de obtener. Finalmente, obtenga el coeficiente de TWFE con una regresión de la tasa de suicidios en función de la diferencia antes definida.\nCorremos la primera regresión para purgar los efectos fijos:\n\nd1 &lt;- lm(unilateral ~ factor(st) + factor(year),\n              data = wd)\n\nDefinimos la nueva variable:\n\nwd &lt;- wd %&gt;% \n  mutate(unilateral_hat = unilateral-predict(d1))\n\nY finalmente estimamos:\n\nsummary(m2 &lt;- lm(suicide_rate ~ unilateral_hat,\n              data = wd))$coef[1:2,1:3]\n\n                Estimate Std. Error    t value\n(Intercept)    54.422503  0.4585884 118.673960\nunilateral_hat -3.776552  1.8276582  -2.066334\n\n\nObtenemos el mismo coeficiente. Frisch–Waugh–Lovell tenían razón.\n[10 puntos] Realice la descomposición de Goodman-Bacon (2021). Construya un gráfico donde muestre en el eje \\(x\\) el peso otorgado a cada comparación 2x2 que el estimador de TWFE realiza mecánicamente y en el eje \\(y\\) el efecto estimado correspondiente a cada comparación. Interprete el gráfico obtenido.\nComo vimos en laboratorio, la descomposición de Bacon se puede obtener con la función bacon:\n\n#Goodman-Bacon decomposition\ndf_bacon &lt;- bacon(suicide_rate ~ unilateral,\n                  data = wd,\n                  id_var = \"st\",\n                  time_var = \"year\")\n\n                      type  weight  avg_est\n1 Earlier vs Later Treated 0.11558  0.13489\n2  Later vs Always Treated 0.41990 -6.95245\n3 Later vs Earlier Treated 0.23125  2.33743\n4     Treated vs Untreated 0.23328 -6.05881\n\ncoef_bacon &lt;- sum(df_bacon$estimate * df_bacon$weight)\n\nprint(paste(\"Suma ponderada de la descomposición =\", round(coef_bacon, 4)))\n\n[1] \"Suma ponderada de la descomposición = -3.7766\"\n\ntwfe &lt;- felm(suicide_rate ~ unilateral | st + year | 0 | st,\n              data = wd)\n\n#Gráfico----\ndf_bacon %&gt;% \n  ggplot(aes(x=weight,\n             y=estimate,\n             shape=type)) +\n  geom_point() +\n  geom_hline(yintercept = round(twfe$coefficients, 4))\n\n\n\n\n\n\n\n\nLas comparaciones que más pesan en el estimador de efectos fijos son las de estados tratados con los que siempre estuvieron tratados en el panel, recibiendo dos de esas comparaciones alrededor de 13 y el 7% del peso (los dos triángulos más hacia la derecha). otra comparación que recibe alrededor de 7% del peso es la de los tratados con los nunca tratados (cruz más hacia la derecha). En total, las comparaciones con los estados que iniciaron siendo tratados se llevan el 42% del peso. Las comparaciones entre los tratados tarde y los tratados temprano también reciben un peso alto de 23%.\n[10 puntos] Implemente el estimador de Callaway & Sant’Anna (2021) para estimar los efectos del tratamiento específicos para cada cohorte, usando el paquete did. Utilice como grupo de comparación los estados no tratados aún. La columna stid es un identificador numérico de los estados (lo requerirá cuando use att_gt del paquete did).\n\natts_nyt &lt;- att_gt(yname = \"suicide_rate\",\n                      tname = \"year\",\n                      idname = \"stid\",\n                      gname = \"divyear\",\n                      data = wd,\n                      control_group = \"notyettreated\",\n                      est_method = 'reg',\n                      bstrap = TRUE,\n                      biters = 1000,\n                      print_details = FALSE,\n                      panel = TRUE)\n\n\nsummary(atts_nyt)\n\n\nCall:\natt_gt(yname = \"suicide_rate\", tname = \"year\", idname = \"stid\", \n    gname = \"divyear\", data = wd, panel = TRUE, control_group = \"notyettreated\", \n    bstrap = TRUE, biters = 1000, est_method = \"reg\", print_details = FALSE)\n\nReference: Callaway, Brantly and Pedro H.C. Sant'Anna.  \"Difference-in-Differences with Multiple Time Periods.\" Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. &lt;https://doi.org/10.1016/j.jeconom.2020.12.001&gt;, &lt;https://arxiv.org/abs/1803.09015&gt; \n\nGroup-Time Average Treatment Effects:\n Group Time ATT(g,t) Std. Error [95% Simult.  Conf. Band]  \n  1969 1965  -1.9053     7.0460      -28.4052     24.5947  \n  1969 1966   4.5124     9.7506      -32.1593     41.1841  \n  1969 1967   0.5622     4.9628      -18.1028     19.2273  \n  1969 1968   5.1789     2.9495       -5.9141     16.2720  \n  1969 1969  -0.7447     5.4222      -21.1373     19.6480  \n  1969 1970 -10.2717     8.6981      -42.9850     22.4415  \n  1969 1971 -12.3880     7.0258      -38.8116     14.0357  \n  1969 1972  -4.1259     3.5784      -17.5843      9.3324  \n  1969 1973   1.4524     6.7785      -24.0415     26.9462  \n  1969 1974  -1.4022     4.6571      -18.9175     16.1131  \n  1969 1975  -0.9265     4.4042      -17.4904     15.6373  \n  1969 1976 -12.7344     6.3437      -36.5930     11.1242  \n  1969 1977  -2.3415     8.9937      -36.1665     31.4834  \n  1969 1978 -11.4247    11.6077      -55.0810     32.2316  \n  1969 1979  -6.0427     8.6485      -38.5694     26.4841  \n  1969 1980  -7.9345     5.4062      -28.2670     12.3979  \n  1969 1981  -1.7430     9.6420      -38.0062     34.5202  \n  1969 1982  -6.7020     8.6390      -39.1929     25.7888  \n  1969 1983   4.7154     9.9666      -32.7688     42.1996  \n  1969 1984  -9.5175    12.0946      -55.0050     35.9699  \n  1969 1985   5.9598    16.8090      -57.2584     69.1779  \n  1969 1986  -8.5962    10.9669      -49.8425     32.6501  \n  1969 1987  -8.6897     7.1293      -35.5027     18.1234  \n  1969 1988 -11.9815     8.1718      -42.7152     18.7522  \n  1969 1989  -5.9781    14.7507      -61.4550     49.4989  \n  1969 1990  -7.7327    10.9077      -48.7562     33.2908  \n  1969 1991 -14.7659    11.0449      -56.3055     26.7737  \n  1969 1992  -6.6956     6.0147      -29.3165     15.9253  \n  1969 1993   0.5290    11.3341      -42.0982     43.1561  \n  1969 1994  -6.1575    15.5254      -64.5480     52.2330  \n  1969 1995  -6.7870    16.7453      -69.7657     56.1918  \n  1969 1996   3.0338    14.3952      -51.1060     57.1736  \n  1970 1965   2.4919     3.2071       -9.5700     14.5539  \n  1970 1966   1.8500     3.3954      -10.9200     14.6201  \n  1970 1967  -2.0438     3.9888      -17.0454     12.9579  \n  1970 1968  -3.7538     6.6390      -28.7228     21.2152  \n  1970 1969   9.0725     3.5768       -4.3799     22.5249  \n  1970 1970   0.3548     4.8941      -18.0519     18.7616  \n  1970 1971  -1.9698     3.3001      -14.3814     10.4418  \n  1970 1972  -1.4067     6.1942      -24.7030     21.8896  \n  1970 1973 -11.2801     3.7512      -25.3881      2.8279  \n  1970 1974 -11.1775     3.3984      -23.9588      1.6038  \n  1970 1975 -12.0330     6.4440      -36.2686     12.2027  \n  1970 1976 -17.7592     8.1638      -48.4631     12.9447  \n  1970 1977 -16.3994     5.2563      -36.1682      3.3695  \n  1970 1978 -29.1877     7.5225      -57.4796     -0.8957 *\n  1970 1979 -26.8802    12.2742      -73.0429     19.2826  \n  1970 1980 -39.5660    11.2142      -81.7422      2.6102  \n  1970 1981 -30.0122    11.7141      -74.0686     14.0442  \n  1970 1982 -36.1714    10.0510      -73.9730      1.6301  \n  1970 1983 -31.0969    12.6179      -78.5522     16.3585  \n  1970 1984 -31.4749    11.8501      -76.0428     13.0929  \n  1970 1985 -30.6346    19.0705     -102.3582     41.0889  \n  1970 1986 -37.0754    18.8397     -107.9311     33.7802  \n  1970 1987 -37.6630    12.4804      -84.6016      9.2755  \n  1970 1988 -43.0563    12.9278      -91.6774      5.5648  \n  1970 1989 -45.1314    15.4236     -103.1389     12.8761  \n  1970 1990 -43.1765     8.6367      -75.6588    -10.6942 *\n  1970 1991 -49.9116    10.1746      -88.1781    -11.6451 *\n  1970 1992 -50.9515    15.7077     -110.0277      8.1247  \n  1970 1993 -44.5526    12.4263      -91.2875      2.1823  \n  1970 1994 -51.5405    17.7308     -118.2253     15.1443  \n  1970 1995 -48.4108    18.4709     -117.8791     21.0576  \n  1970 1996 -48.0618    18.0039     -115.7740     19.6505  \n  1971 1965  -2.2110     3.4990      -15.3706     10.9487  \n  1971 1966  -5.9450     3.5888      -19.4424      7.5524  \n  1971 1967   6.1535     3.8122       -8.1840     20.4910  \n  1971 1968   5.3039     3.7056       -8.6327     19.2406  \n  1971 1969  -4.8826     3.8762      -19.4609      9.6957  \n  1971 1970   0.5878     5.2423      -19.1284     20.3040  \n  1971 1971  -7.5805     5.7237      -29.1072     13.9461  \n  1971 1972 -11.4260     7.4633      -39.4951     16.6431  \n  1971 1973  -5.8221     8.4200      -37.4894     25.8452  \n  1971 1974   5.7926     5.4383      -14.6607     26.2459  \n  1971 1975   0.0590     5.6082      -21.0334     21.1515  \n  1971 1976  -0.7920     8.5841      -33.0767     31.4927  \n  1971 1977   0.5899     8.6109      -31.7955     32.9753  \n  1971 1978  -9.5946     9.7160      -46.1361     26.9469  \n  1971 1979  -8.8180     5.8234      -30.7197     13.0838  \n  1971 1980 -15.0039     7.0155      -41.3890     11.3812  \n  1971 1981  -6.0810     8.4938      -38.0259     25.8640  \n  1971 1982 -15.5575     8.7418      -48.4352     17.3201  \n  1971 1983  -6.7973     5.8661      -28.8595     15.2648  \n  1971 1984  -8.1090     7.3240      -35.6544     19.4363  \n  1971 1985  -9.3683     8.2252      -40.3031     21.5666  \n  1971 1986 -16.9260     6.8736      -42.7773      8.9254  \n  1971 1987 -12.9962    10.8203      -53.6909     27.6985  \n  1971 1988 -14.6487     8.2209      -45.5673     16.2698  \n  1971 1989 -18.7126     8.7625      -51.6682     14.2430  \n  1971 1990 -17.6198     6.4603      -41.9167      6.6771  \n  1971 1991 -17.2789     8.7642      -50.2406     15.6829  \n  1971 1992 -22.1825     9.7043      -58.6799     14.3149  \n  1971 1993  -9.1278     8.6932      -41.8225     23.5669  \n  1971 1994 -13.7091     7.8957      -43.4047     15.9865  \n  1971 1995 -15.3270     6.9365      -41.4150     10.7609  \n  1971 1996 -11.2124     8.8556      -44.5179     22.0931  \n  1972 1965   1.9641     1.8921       -5.1522      9.0804  \n  1972 1966   2.3826     6.3500      -21.4997     26.2648  \n  1972 1967  -3.8865     5.9352      -26.2085     18.4354  \n  1972 1968   7.6954     2.7313       -2.5770     17.9678  \n  1972 1969  -8.7084     2.9283      -19.7216      2.3048  \n  1972 1970   0.1004     2.4628       -9.1621      9.3629  \n  1972 1971   1.1463     3.5806      -12.3201     14.6127  \n  1972 1972  -4.8115     4.9725      -23.5129     13.8899  \n  1972 1973  -2.3073     6.7151      -27.5625     22.9480  \n  1972 1974   0.7950     5.6743      -20.5457     22.1357  \n  1972 1975  -2.8930     4.4361      -19.5769     13.7910  \n  1972 1976  -2.9838    10.4048      -42.1158     36.1483  \n  1972 1977   2.8759     5.6964      -18.5482     24.3000  \n  1972 1978 -13.9499     6.9152      -39.9577     12.0578  \n  1972 1979  -4.7118     9.9019      -41.9524     32.5287  \n  1972 1980  -9.9424     6.4162      -34.0735     14.1886  \n  1972 1981   0.7622     6.5261      -23.7821     25.3066  \n  1972 1982  -5.7949     7.1316      -32.6168     21.0270  \n  1972 1983  -2.5286     7.5776      -31.0275     25.9704  \n  1972 1984  -5.7192     7.8629      -35.2913     23.8529  \n  1972 1985  -8.5492     8.9056      -42.0428     24.9444  \n  1972 1986  -3.2909     6.8649      -29.1097     22.5279  \n  1972 1987 -14.5853     7.4403      -42.5680     13.3975  \n  1972 1988 -12.6795     6.5770      -37.4154     12.0564  \n  1972 1989 -10.9845     7.5084      -39.2234     17.2545  \n  1972 1990  -7.7794     7.7009      -36.7424     21.1835  \n  1972 1991 -13.7033     5.4556      -34.2217      6.8152  \n  1972 1992 -11.0100     9.2787      -45.9068     23.8869  \n  1972 1993 -17.3770     7.7403      -46.4878     11.7338  \n  1972 1994 -16.6543     8.3614      -48.1014     14.7927  \n  1972 1995 -16.0626     6.8331      -41.7617      9.6365  \n  1972 1996 -13.6292     5.4833      -34.2515      6.9932  \n  1973 1965  -1.6544     3.4974      -14.8082     11.4994  \n  1973 1966  -3.5308     4.1384      -19.0953     12.0337  \n  1973 1967   5.5388     6.1119      -17.4477     28.5254  \n  1973 1968  -4.1286     5.8070      -25.9685     17.7113  \n  1973 1969   1.9470     4.0342      -13.2255     17.1195  \n  1973 1970   0.3836     5.3027      -19.5596     20.3269  \n  1973 1971  -0.4064     6.0259      -23.0695     22.2567  \n  1973 1972  -0.7103     5.9888      -23.2339     21.8133  \n  1973 1973   9.0122     6.2229      -14.3918     32.4162  \n  1973 1974   7.0826     6.0502      -15.6722     29.8374  \n  1973 1975   8.7932     9.1829      -25.7433     43.3297  \n  1973 1976   5.5815     7.1821      -21.4301     32.5931  \n  1973 1977   9.2638     7.2386      -17.9602     36.4878  \n  1973 1978  -2.8479     7.3583      -30.5221     24.8263  \n  1973 1979   3.5441     7.6322      -25.1603     32.2486  \n  1973 1980  -3.7998     8.8198      -36.9706     29.3710  \n  1973 1981   3.7874     8.4673      -28.0578     35.6325  \n  1973 1982  -2.3342     8.7502      -35.2434     30.5750  \n  1973 1983   0.3746     7.3718      -27.3506     28.0999  \n  1973 1984  -4.0602     9.0571      -38.1238     30.0034  \n  1973 1985  -3.3503     6.9802      -29.6025     22.9018  \n  1973 1986  -9.9416     4.7668      -27.8693      7.9861  \n  1973 1987 -10.5611     8.7076      -43.3099     22.1877  \n  1973 1988 -13.3770     9.3321      -48.4748     21.7208  \n  1973 1989  -9.7072     7.6883      -38.6226     19.2081  \n  1973 1990 -12.5464     6.1908      -35.8299     10.7370  \n  1973 1991 -15.9396     7.6580      -44.7411     12.8619  \n  1973 1992 -17.9985     7.6618      -46.8143     10.8174  \n  1973 1993 -13.8426     7.9057      -43.5758     15.8907  \n  1973 1994  -9.0985     6.1611      -32.2702     14.0733  \n  1973 1995 -12.4104     3.9817      -27.3856      2.5647  \n  1973 1996 -14.4985     5.5684      -35.4413      6.4443  \n  1974 1965  -3.4980     4.7162      -21.2356     14.2396  \n  1974 1966   4.0405     5.6581      -17.2396     25.3206  \n  1974 1967  -2.4469     2.6938      -12.5781      7.6844  \n  1974 1968  -4.1701     5.3543      -24.3075     15.9672  \n  1974 1969   3.0794     2.0318       -4.5622     10.7210  \n  1974 1970   3.9844     2.6191       -5.8659     13.8348  \n  1974 1971  -7.0304     3.1705      -18.9547      4.8938  \n  1974 1972   6.3385     3.4903       -6.7884     19.4655  \n  1974 1973   0.5656     5.1425      -18.7751     19.9064  \n  1974 1974  -2.4409     4.0471      -17.6621     12.7803  \n  1974 1975   1.3647     5.2484      -18.3746     21.1039  \n  1974 1976  -3.5756     6.2644      -27.1358     19.9845  \n  1974 1977  -4.0728     5.6967      -25.4979     17.3524  \n  1974 1978  -8.9231     5.3983      -29.2258     11.3795  \n  1974 1979  -1.7408     6.2680      -25.3146     21.8330  \n  1974 1980  -9.7770     5.2257      -29.4308      9.8769  \n  1974 1981  -2.8322     5.9365      -25.1594     19.4949  \n  1974 1982  -7.4517     5.0610      -26.4859     11.5825  \n  1974 1983  -4.3400     6.9901      -30.6298     21.9497  \n  1974 1984  -7.8279     6.2809      -31.4501     15.7942  \n  1974 1985   0.9048    11.1563      -41.0536     42.8633  \n  1974 1986  -3.4953     9.5009      -39.2279     32.2373  \n  1974 1987  -9.3045     8.5199      -41.3477     22.7386  \n  1974 1988  -9.0434     8.3263      -40.3583     22.2714  \n  1974 1989  -6.4758    10.3191      -45.2856     32.3340  \n  1974 1990  -7.6369     8.2398      -38.6264     23.3526  \n  1974 1991 -14.7133     7.7174      -43.7382     14.3116  \n  1974 1992 -14.7711     7.9024      -44.4916     14.9495  \n  1974 1993 -11.2274     8.7908      -44.2892     21.8343  \n  1974 1994 -14.4350    10.7126      -54.7247     25.8547  \n  1974 1995 -13.4194     9.8742      -50.5558     23.7171  \n  1974 1996 -14.8017    10.5500      -54.4798     24.8765  \n  1975 1965  18.6039    14.9953      -37.7928     75.0005  \n  1975 1966  -3.3872     3.6269      -17.0279     10.2534  \n  1975 1967  -2.4321     2.2945      -11.0618      6.1977  \n  1975 1968   7.3667     5.5063      -13.3422     28.0756  \n  1975 1969  -4.2480     7.5243      -32.5468     24.0509  \n  1975 1970 -11.4912     8.2671      -42.5836     19.6013  \n  1975 1971   5.6632     9.0191      -28.2574     39.5838  \n  1975 1972 -15.6310     7.8300      -45.0795     13.8175  \n  1975 1973  16.2449     6.2543       -7.2772     39.7670  \n  1975 1974  -0.4082     6.5198      -24.9288     24.1123  \n  1975 1975  -2.3510     2.7082      -12.5365      7.8346  \n  1975 1976  -2.3824     5.5674      -23.3214     18.5565  \n  1975 1977  -4.1345    10.2209      -42.5750     34.3061  \n  1975 1978  -7.0822     6.8336      -32.7830     18.6186  \n  1975 1979 -12.0112    16.0436      -72.3506     48.3282  \n  1975 1980 -10.7602     5.3389      -30.8396      9.3191  \n  1975 1981  -7.1236     5.3099      -27.0940     12.8468  \n  1975 1982 -10.5685     7.5006      -38.7780     17.6410  \n  1975 1983  -9.0308     6.1676      -32.2269     14.1654  \n  1975 1984   9.8022     5.9609      -12.6166     32.2209  \n  1975 1985  -5.6163     8.3174      -36.8977     25.6651  \n  1975 1986  -5.2183     5.2469      -24.9516     14.5150  \n  1975 1987  -0.8638     5.3408      -20.9504     19.2229  \n  1975 1988 -15.3668    11.0217      -56.8188     26.0853  \n  1975 1989  -5.4933     5.4602      -26.0288     15.0421  \n  1975 1990   8.5067     5.8762      -13.5935     30.6068  \n  1975 1991   0.7631     6.3414      -23.0866     24.6128  \n  1975 1992  -4.2255     6.9071      -30.2029     21.7519  \n  1975 1993   1.1200     2.6826       -8.9693     11.2093  \n  1975 1994  -8.3655     7.4179      -36.2640     19.5330  \n  1975 1995   1.8041     4.2049      -14.0103     17.6185  \n  1975 1996  -6.9207     5.8278      -28.8390     14.9976  \n  1976 1965 -11.0522     1.7635      -17.6845     -4.4198 *\n  1976 1966   0.1018     2.2472       -8.3498      8.5534  \n  1976 1967  -5.9143     2.2177      -14.2550      2.4264  \n  1976 1968  -1.6479     2.0075       -9.1981      5.9023  \n  1976 1969  -6.6407     1.8044      -13.4272      0.1457  \n  1976 1970   8.5784     1.9560        1.2219     15.9349 *\n  1976 1971   4.0973     2.6267       -5.7817     13.9763  \n  1976 1972  -0.9903     2.7810      -11.4497      9.4691  \n  1976 1973 -20.1263     3.7082      -34.0728     -6.1797 *\n  1976 1974  39.6133     2.4566       30.3742     48.8524 *\n  1976 1975  -3.5747     2.7191      -13.8010      6.6516  \n  1976 1976   3.7698     5.2187      -15.8576     23.3971  \n  1976 1977  33.5942     4.7165       15.8555     51.3329 *\n  1976 1978  -3.1195     2.2793      -11.6918      5.4528  \n  1976 1979   1.3342     7.1463      -25.5428     28.2112  \n  1976 1980 -10.4124     3.6444      -24.1187      3.2939  \n  1976 1981 -10.4368     5.7416      -32.0309     11.1573  \n  1976 1982 -12.4922     3.5001      -25.6562      0.6717  \n  1976 1983 -15.8081     6.2755      -39.4100      7.7938  \n  1976 1984 -20.6870     3.9057      -35.3762     -5.9978 *\n  1976 1985  -0.2053    11.6139      -43.8848     43.4742  \n  1976 1986 -27.7992     8.3181      -59.0832      3.4848  \n  1976 1987  -9.9985     3.6973      -23.9038      3.9069  \n  1976 1988 -22.8540     5.8685      -44.9254     -0.7826 *\n  1976 1989 -14.3020     6.6385      -39.2692     10.6652  \n  1976 1990 -16.7275     4.7892      -34.7396      1.2846  \n  1976 1991 -29.9838     5.5425      -50.8290     -9.1387 *\n  1976 1992 -35.9431     6.1194      -58.9581    -12.9281 *\n  1976 1993 -33.5630     6.2298      -56.9932    -10.1328 *\n  1976 1994 -19.1785    10.5829      -58.9804     20.6233  \n  1976 1995 -18.8943     9.0197      -52.8170     15.0284  \n  1976 1996 -20.0712     8.0000      -50.1588     10.0164  \n  1977 1965   6.8982    16.7867      -56.2360     70.0325  \n  1977 1966 -11.1214     8.8921      -44.5644     22.3217  \n  1977 1967  10.8566     5.6394      -10.3530     32.0663  \n  1977 1968 -11.0425    11.5273      -54.3962     32.3112  \n  1977 1969  10.1932    17.5653      -55.8693     76.2556  \n  1977 1970   2.9004     6.3522      -20.9899     26.7906  \n  1977 1971   3.0530     8.8535      -30.2448     36.3509  \n  1977 1972  -0.6535     9.6867      -37.0850     35.7780  \n  1977 1973   3.1405     8.8108      -29.9967     36.2777  \n  1977 1974 -14.4506     6.1419      -37.5503      8.6490  \n  1977 1975  -0.1240     5.1265      -19.4045     19.1565  \n  1977 1976   5.5263    19.1535      -66.5093     77.5618  \n  1977 1977  -0.1462    22.8970      -86.2612     85.9688  \n  1977 1978 -17.4422    23.9907     -107.6706     72.7862  \n  1977 1979  -7.6652    33.4449     -133.4505    118.1201  \n  1977 1980 -12.0752    33.7345     -138.9496    114.7993  \n  1977 1981 -11.8110    26.5246     -111.5692     87.9472  \n  1977 1982 -18.5556    17.8424      -85.6604     48.5493  \n  1977 1983   4.2551    34.9957     -127.3627    135.8728  \n  1977 1984  -3.0226    27.5429     -106.6107    100.5655  \n  1977 1985 -14.8995    22.4549      -99.3516     69.5526  \n  1977 1986 -12.3230    15.1342      -69.2421     44.5962  \n  1977 1987 -23.6769    32.2009     -144.7834     97.4296  \n  1977 1988 -25.5547    23.1800     -112.7340     61.6246  \n  1977 1989  -9.2602    40.2793     -160.7493    142.2289  \n  1977 1990 -13.7369    45.3789     -184.4054    156.9316  \n  1977 1991 -25.9731    32.4826     -148.1392     96.1930  \n  1977 1992 -29.9220    23.2090     -117.2102     57.3662  \n  1977 1993 -14.9531    36.2530     -151.2994    121.3933  \n  1977 1994 -11.6033    48.6565     -194.5989    171.3922  \n  1977 1995 -29.0098    23.4604     -117.2435     59.2239  \n  1977 1996 -16.0590    27.5715     -119.7543     87.6363  \n  1980 1965  -4.7817     1.7979      -11.5435      1.9800  \n  1980 1966  -2.0295     2.2447      -10.4716      6.4126  \n  1980 1967   0.2462     2.2137       -8.0794      8.5719  \n  1980 1968   4.9725     2.0119       -2.5943     12.5392  \n  1980 1969  -5.6981     1.8069      -12.4937      1.0976  \n  1980 1970   7.6920     1.9938        0.1932     15.1908 *\n  1980 1971  -9.5134     2.5370      -19.0550      0.0282  \n  1980 1972   5.9170     2.7412       -4.3925     16.2265  \n  1980 1973  -3.6509     3.9272      -18.4212     11.1193  \n  1980 1974   1.1846     4.1580      -14.4537     16.8229  \n  1980 1975  -1.4249     2.7830      -11.8917      9.0419  \n  1980 1976   1.5220     5.7937      -20.2681     23.3121  \n  1980 1977  -1.8998     2.8071      -12.4572      8.6577  \n  1980 1978  -6.1099     5.5846      -27.1135     14.8937  \n  1980 1979   6.0177     8.3504      -25.3879     37.4234  \n  1980 1980 -11.0694     5.3019      -31.0095      8.8707  \n  1980 1981  -7.3267     2.7095      -17.5170      2.8636  \n  1980 1982  -9.2663     9.6255      -45.4675     26.9350  \n  1980 1983   1.6316     3.2901      -10.7423     14.0055  \n  1980 1984  -2.4538     5.2385      -22.1557     17.2480  \n  1980 1985   4.4467     4.7848      -13.5490     22.4423  \n  1980 1986  -9.5981     7.0565      -36.1373     16.9410  \n  1980 1987 -10.0537    11.3335      -52.6787     32.5713  \n  1980 1988 -10.9789     9.1300      -45.3164     23.3587  \n  1980 1989  -6.9527     6.3603      -30.8735     16.9681  \n  1980 1990  -5.3312     6.2450      -28.8183     18.1560  \n  1980 1991  -8.8820     8.2207      -39.7997     22.0356  \n  1980 1992 -12.0023    11.0607      -53.6011     29.5965  \n  1980 1993  -8.3192     7.7315      -37.3969     20.7586  \n  1980 1994 -12.5474     7.1011      -39.2546     14.1597  \n  1980 1995  -6.7308     8.7926      -39.7995     26.3379  \n  1980 1996  -9.1678     7.7440      -38.2927     19.9570  \n  1984 1965   2.2727     1.7801       -4.4222      8.9675  \n  1984 1966  -1.6070     2.2270       -9.9827      6.7688  \n  1984 1967  -1.8538     2.2062      -10.1513      6.4436  \n  1984 1968  -1.3557     1.9974       -8.8679      6.1565  \n  1984 1969   2.1619     1.7839       -4.5474      8.8712  \n  1984 1970  -0.3449     1.9959       -7.8513      7.1614  \n  1984 1971 -10.9305     2.5388      -20.4787     -1.3823 *\n  1984 1972   5.8536     2.7724       -4.5735     16.2806  \n  1984 1973  -1.9239     3.9386      -16.7367     12.8889  \n  1984 1974  -7.1605     4.1538      -22.7827      8.4617  \n  1984 1975  -1.6437     2.7840      -12.1143      8.8270  \n  1984 1976   5.6685     5.5426      -15.1769     26.5139  \n  1984 1977   3.2342     2.7903       -7.2599     13.7282  \n  1984 1978  -7.3151     5.5215      -28.0815     13.4512  \n  1984 1979   1.9466     8.3880      -29.6004     33.4936  \n  1984 1980  -8.6205     5.8434      -30.5974     13.3564  \n  1984 1981  10.4692     4.8613       -7.8141     28.7525  \n  1984 1982  -5.4364     8.0334      -35.6499     24.7771  \n  1984 1983  12.0264     8.4379      -19.7083     43.7612  \n  1984 1984  -0.7730     2.4534      -10.0000      8.4541  \n  1984 1985   4.0744     3.8064      -10.2414     18.3901  \n  1984 1986  -8.0341     2.8724      -18.8371      2.7689  \n  1984 1987 -10.4189     8.9490      -44.0757     23.2379  \n  1984 1988  -7.8277     6.1942      -31.1238     15.4685  \n  1984 1989  -9.2894     3.8762      -23.8677      5.2889  \n  1984 1990  -6.2529     3.0974      -17.9022      5.3963  \n  1984 1991 -10.1584     4.9176      -28.6534      8.3366  \n  1984 1992 -11.4694     8.6653      -44.0592     21.1204  \n  1984 1993  -9.2844     4.4284      -25.9395      7.3707  \n  1984 1994 -14.6630     5.2893      -34.5558      5.2299  \n  1984 1995 -12.5044     3.7261      -26.5181      1.5093  \n  1984 1996 -10.2449     3.2720      -22.5508      2.0611  \n  1985 1965  -4.3499     1.8037      -11.1336      2.4337  \n  1985 1966  37.6989     1.9026       30.5433     44.8545 *\n  1985 1967 -19.2838     2.1912      -27.5247    -11.0429 *\n  1985 1968  -4.2545     2.0230      -11.8629      3.3539  \n  1985 1969  10.5295     1.7198        4.0613     16.9977 *\n  1985 1970   7.2143     1.9831       -0.2439     14.6726  \n  1985 1971   6.9735     2.5669       -2.6806     16.6276  \n  1985 1972   5.8781     2.7153       -4.3340     16.0902  \n  1985 1973 -38.9329     2.9638      -50.0798    -27.7859 *\n  1985 1974   8.7158     4.1963       -7.0665     24.4981  \n  1985 1975  -7.1533     2.6691      -17.1917      2.8851  \n  1985 1976  -0.8308     5.7205      -22.3452     20.6836  \n  1985 1977  -2.2605     2.8358      -12.9256      8.4047  \n  1985 1978   7.7405     5.8788      -14.3694     29.8504  \n  1985 1979  -4.9814     8.5470      -37.1265     27.1637  \n  1985 1980   2.9209     6.2508      -20.5883     26.4300  \n  1985 1981  -4.4773     4.4977      -21.3930     12.4384  \n  1985 1982  13.7629     8.6731      -18.8564     46.3822  \n  1985 1983  -7.4210     8.8419      -40.6751     25.8330  \n  1985 1984  -5.5493     3.0237      -16.9212      5.8225  \n  1985 1985  11.4728     6.8301      -14.2148     37.1605  \n  1985 1986  10.1715     3.1749       -1.7692     22.1123  \n  1985 1987  17.5291     5.1061       -1.6748     36.7330  \n  1985 1988  -9.6423     4.1182      -25.1308      5.8463  \n  1985 1989  19.8229     5.7077       -1.6436     41.2893  \n  1985 1990  26.2350     1.7402       19.6900     32.7799 *\n  1985 1991   6.2209     3.7879       -8.0253     20.4671  \n  1985 1992  18.3602     6.2606       -5.1856     41.9059  \n  1985 1993  23.0343     2.8585       12.2838     33.7849 *\n  1985 1994  15.2612     6.2622       -8.2907     38.8131  \n  1985 1995  15.4633     4.6990       -2.2094     33.1361  \n  1985 1996  26.5282     3.9405       11.7082     41.3483 *\n---\nSignif. codes: `*' confidence band does not cover 0\n\nControl Group:  Not Yet Treated,  Anticipation Periods:  0\nEstimation Method:  Outcome Regression\n\nggdid(atts_nyt)\n\n\n\n\n\n\n\n\n[5 puntos] Reporte los resultados agregados obtenidos a partir del estimador Callaway & Sant’Anna (2021), usando una agregación dinámica que muestre los efectos promedio para cada periodo antes y después del tratamiento. Grafique e interprete los resultados.\nGraficamos:\n\nagg.es &lt;- aggte(atts_nyt,\n                type = \"dynamic\")\nsummary(agg.es)\n\n\nCall:\naggte(MP = atts_nyt, type = \"dynamic\")\n\nReference: Callaway, Brantly and Pedro H.C. Sant'Anna.  \"Difference-in-Differences with Multiple Time Periods.\" Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. &lt;https://doi.org/10.1016/j.jeconom.2020.12.001&gt;, &lt;https://arxiv.org/abs/1803.09015&gt; \n\n\nOverall summary of ATT's based on event-study/dynamic aggregation:  \n    ATT    Std. Error     [ 95%  Conf. Int.]  \n -9.628        3.6814   -16.8433     -2.4127 *\n\n\nDynamic Effects:\n Event time Estimate Std. Error [95% Simult.  Conf. Band]  \n        -20  -4.3499     1.7273       -9.1437      0.4438  \n        -19  19.9858    12.8179      -15.5877     55.5593  \n        -18 -10.4454     7.1783      -30.3673      9.4766  \n        -17  -3.0542     1.1065       -6.1250      0.0167  \n        -16   4.5869     4.4301       -7.7081     16.8819  \n        -15   1.5315     3.4571       -8.0629     11.1259  \n        -14   1.5330     2.3973       -5.1202      8.1862  \n        -13  -1.6021     3.9882      -12.6706      9.4665  \n        -12  -1.2353     9.7939      -28.4163     25.9456  \n        -11  -6.1889     4.7560      -19.3882      7.0103  \n        -10   7.0286     4.9459       -6.6978     20.7550  \n         -9  -5.6915     3.3221      -14.9113      3.5282  \n         -8   1.1876     2.4776       -5.6884      8.0637  \n         -7  -0.6219     1.9773       -6.1096      4.8658  \n         -6   1.1581     2.6672       -6.2441      8.5603  \n         -5  -2.9106     2.1890       -8.9859      3.1647  \n         -4   2.9082     1.6636       -1.7088      7.5251  \n         -3  -1.9822     2.5777       -9.1360      5.1717  \n         -2   0.7311     2.5728       -6.4091      7.8712  \n         -1   1.4763     2.3845       -5.1414      8.0940  \n          0   0.5890     2.7993       -7.1799      8.3579  \n          1  -1.2422     2.9849       -9.5264      7.0419  \n          2  -0.3815     4.2972      -12.3075     11.5445  \n          3  -0.4662     3.9267      -11.3640     10.4316  \n          4  -0.3563     4.3625      -12.4634     11.7509  \n          5  -3.4207     4.5930      -16.1677      9.3262  \n          6  -2.4065     4.5614      -15.0659     10.2529  \n          7  -6.4250     4.6104      -19.2201      6.3702  \n          8  -5.8964     4.8323      -19.3076      7.5148  \n          9  -6.3944     4.2342      -18.1456      5.3568  \n         10  -7.7061     4.6766      -20.6851      5.2729  \n         11  -8.8186     5.5919      -24.3379      6.7008  \n         12  -7.2921     4.2102      -18.9768      4.3926  \n         13 -11.1384     4.3627      -23.2464      0.9695  \n         14 -11.1558     4.5294      -23.7264      1.4148  \n         15 -14.8167     5.0491      -28.8294     -0.8039 *\n         16 -11.6965     4.8488      -25.1533      1.7604  \n         17 -14.3232     4.5793      -27.0320     -1.6143 *\n         18 -17.1010     5.2118      -31.5652     -2.6368 *\n         19 -17.4748     4.4007      -29.6881     -5.2614 *\n         20 -14.9783     4.4988      -27.4638     -2.4928 *\n         21 -15.8960     4.3880      -28.0741     -3.7179 *\n         22 -15.2219     4.6775      -28.2035     -2.2403 *\n         23 -16.2453     5.0965      -30.3895     -2.1010 *\n         24 -17.8714     6.9526      -37.1669      1.4240  \n         25 -17.0567     9.1623      -42.4848      8.3715  \n         26 -27.4244    18.3755      -78.4221     23.5734  \n         27   3.0338    13.0924      -33.3015     39.3691  \n---\nSignif. codes: `*' confidence band does not cover 0\n\nControl Group:  Not Yet Treated,  Anticipation Periods:  0\nEstimation Method:  Outcome Regression\n\nggdid(agg.es)\n\n\n\n\n\n\n\n\nSe obtiene una reducción en la tasa de suicidios que es estadísticamente significativa a partir de 13 años después de la introducción de la legislación.\n[5 puntos] Reporte los resultados agregados obtenidos a partir del estimador Callaway & Sant’Anna (2021), usando una agregación or grupos que muestre los efectos promedio para cada cohorte del tratamiento. Grafique e interprete los resultados.\nGraficamos:\n\nagg.es &lt;- aggte(atts_nyt,\n                type = \"group\")\nsummary(agg.es)\n\n\nCall:\naggte(MP = atts_nyt, type = \"group\")\n\nReference: Callaway, Brantly and Pedro H.C. Sant'Anna.  \"Difference-in-Differences with Multiple Time Periods.\" Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. &lt;https://doi.org/10.1016/j.jeconom.2020.12.001&gt;, &lt;https://arxiv.org/abs/1803.09015&gt; \n\n\nOverall summary of ATT's based on group/cohort aggregation:  \n     ATT    Std. Error     [ 95%  Conf. Int.]  \n -8.2876        3.1063   -14.3757     -2.1994 *\n\n\nGroup Effects:\n Group Estimate Std. Error [95% Simult.  Conf. Band]  \n  1969  -5.3569     8.3373      -26.3972     15.6834  \n  1970 -30.6010    17.1839      -73.9671     12.7651  \n  1971 -10.3173     5.7339      -24.7876      4.1530  \n  1972  -7.9006     4.3825      -18.9604      3.1593  \n  1973  -4.5364     5.4544      -18.3014      9.2285  \n  1974  -7.3929     6.9383      -24.9026     10.1168  \n  1975  -4.3417     3.1516      -12.2952      3.6117  \n  1976 -13.5133     4.6554      -25.2617     -1.7648 *\n  1977 -14.6717     8.1521      -35.2446      5.9012  \n  1980  -7.3295     5.4337      -21.0423      6.3833  \n  1984  -8.2189     2.0860      -13.4831     -2.9547 *\n  1985  15.0381     3.2446        6.8498     23.2264 *\n---\nSignif. codes: `*' confidence band does not cover 0\n\nControl Group:  Not Yet Treated,  Anticipation Periods:  0\nEstimation Method:  Outcome Regression\n\nggdid(agg.es)\n\n\n\n\n\n\n\n\nNotamos un efecto negativo en la tasa de suicidos que es estadísticamente significativa para los estados que fueron tratados en 1970, 1986 y 1984.\n[5 puntos] ¿Cuáles son las ventajas del estimador de Callaway & Sant’Anna (2021) respecto al estimador de TWFE?\nLas ventajas del estimador de Callaway & Sant’Anna respecto a TWFE son las siguientes: - Evita las comapraciones prohibidas (usar unidades tratadas como controles para unidades que son tratadas en periodos posteriores) - Hace explícito el grupo de comparación que se usa para comparar a las unidades tratadas - Hace explícita la manera en que se agregan los resultados de cada comparación \\(ATT(g,t)\\) - No impone efectos monótonos en el tiempo ni homogéneos entre unidades"
  },
  {
    "objectID": "tareas/tarea-3-respuestas.html#pregunta-2",
    "href": "tareas/tarea-3-respuestas.html#pregunta-2",
    "title": "Respuestas a la tarea 3",
    "section": "",
    "text": "La ENIGH 2020 incluyó un módulo para la evaluación del Programa Jóvenes Construyendo el futuro. Se buscó que la cobertura de la encuesta pudiera incluir suficientes participantes del programa para poder compararlos con los no participantes. Los datos en datos_jcf_analisis.csv fueron construidos a partir de dicha encuesta. En este ejercicio estimaremos el efecto de participar en el programa sobre el ingreso trimestral, ingtot_tri, usando métodos de matching.\nLas siguientes variables están incluidas en el archivo de datos: mujer (dummy de sexo), indigena (dummy de pertenencia a una etnia), rural (dummy del ámbito rural), escoacum (años de escolaridad), casadounion (dummy para casados o en unión libre), jefehog (dummy para jefes del hogar), haymenores (dummy para la presencia de menores de edad en el hogar), proggob (dummy para beneficiarios de programas de gobierno), y tot_integ (número de miembros del hogar). También se incluye la clave de las entidades, cve_ent.\n\n[5 puntos] Considere la comparación para el ingreso trimestral, ingtot_tri, entre beneficiarios y su grupo de comparación, que serán los jóvenes que no asisten a la escuela y no están empleados. Los beneficiarios tienen jcf2==1 y los jóvenes que no asisten a la escuela y no están empleados tienen jcf2==0. Muestre qué tan similares o qué tan diferentes son los individuos en ambos grupos en términos de las características indicadas anteriormente y del ingreso trimestral.\nEstadística descriptiva:\n\ndata.jcf &lt;- read_csv(\"../files/datos_jcf_analisis.csv\")\n\nset.seed(1023)\n\nAquí usé datasummary para calcular la estadística descriptiva por grupos:\n\ndatasummary(ingtot_tri + mujer + indigena + rural + escoacum + casadounion + jefehog + haymenores + proggob + tot_integ ~ factor(jcf2) * (mean + sd) * Arguments(na.rm=TRUE),\n                fmt = \"%.2f\",\n                data = data.jcf)\n\n \n\n  \n    \n    \n    tinytable_uy949959h4oavhy4bb3w\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n \n0\n1\n\n\n              \n                 \n                mean\n                sd\n                mean\n                sd\n              \n        \n\n        \n                \n                  ingtot_tri \n                  1510.36\n                  8478.60\n                  9643.06\n                  6632.56\n                \n                \n                  mujer      \n                  0.76   \n                  0.43   \n                  0.59   \n                  0.49   \n                \n                \n                  indigena   \n                  0.22   \n                  0.41   \n                  0.59   \n                  0.49   \n                \n                \n                  rural      \n                  0.40   \n                  0.49   \n                  0.35   \n                  0.48   \n                \n                \n                  escoacum   \n                  10.39  \n                  3.23   \n                  12.03  \n                  2.70   \n                \n                \n                  casadounion\n                  0.53   \n                  0.50   \n                  0.41   \n                  0.49   \n                \n                \n                  jefehog    \n                  0.06   \n                  0.23   \n                  0.14   \n                  0.35   \n                \n                \n                  haymenores \n                  0.66   \n                  0.47   \n                  0.54   \n                  0.50   \n                \n                \n                  proggob    \n                  0.19   \n                  0.39   \n                  0.21   \n                  0.41   \n                \n                \n                  tot_integ  \n                  4.82   \n                  1.97   \n                  4.25   \n                  2.00   \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nClaramente los individuos que participan en el programa son diferentes a los que no. En el programa hay una proporción menor de mujeres que en el grupo no tratado; en el grupo tratado hay un nivel mayor de escolaridad acumulada; y los individuos del grupo tratado viven en hogares más pequeños que los del grupo no tratado. Entre muchas otras diferencias.\nEl problema entonces es que existen factores que influyen en la probabilidad de recibir el tratamiento y en el ingreso, por lo que una comparación simple de individuos tratados y no tratados confundirá el efecto del tratamiento.\n[5 puntos] Estime el TOT (TT o ATT) del programa en el ingreso trimestral, ingtot_tri usando el algoritmo de vecino más cercano. Para estimar el impacto en el ingreso trimestral se comparan a los beneficiarios de JCF con los jóvenes que no asisten a la escuela y no están empleados. Los beneficiarios tienen jcf2==1 y los jóvenes que no asisten a la escuela y no están empleados tienen jcf2==0. Escoja la especificación del propensity score que más le parezca adecuada. Realice la inferencia estadística con errores agrupados a nivel grupo de emparejamiento. ¿De qué tamaño es el TOT estimado y es este efecto estadísticamente significativo?\nEste es el modelo para el propensity score que yo escogí:\n\nsub.data &lt;- data.jcf %&gt;%\ndplyr::select(ingtot_tri, jcf2, mujer, indigena, cve_ent, rural, escoacum, casadounion,\n    jefehog, haymenores, proggob, tot_integ, factor.x)\n\nsub.data &lt;- sub.data[complete.cases(sub.data), ]\n\n\nm.out.a &lt;- matchit(formula=jcf2 ~ mujer + indigena + factor(cve_ent) + rural  + escoacum + casadounion + jefehog + haymenores + proggob + tot_integ,\n                 method = \"nearest\",\n                 distance= \"glm\",\n                 replace = FALSE,\n                 data = sub.data)\n\nEstimamos el efecto del tratamiento:\n\ntt1 &lt;- lm(ingtot_tri ~ jcf2,\n      data = match.data(m.out.a))\n\n#Errores agrupados a nivel subclass\ncoeftest(tt1,\n         vcov. = vcovCL,\n         cluster = ~subclass)\n\n\nt test of coefficients:\n\n            Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  1669.95     407.99  4.0931 5.735e-05 ***\njcf2         7973.11     708.27 11.2572 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSe estima un efecto de 7973 pesos adicionales de ingreso trimestral para los participantes en el programa.\n[5 puntos] En el matching de la parte b., evalúe qué tan bueno es el procedimiento en balancear las características observadas una vez realizado el matching. Cree un love plot para evaluar qué tan bueno es el procedimiento de matching para obtener una muestra balanceada.\nbal.tab del paquete cobalt nos permite ver un resumen del balance:\n\n#Con esto elimino las dummies de estado de la salida\nbal.tab(m.out.a, m.threshold=0.1, un=T)\n\nBalance Measures\n                       Type Diff.Un Diff.Adj        M.Threshold\ndistance           Distance  1.1091   0.0881     Balanced, &lt;0.1\nmujer                Binary -0.1660   0.0551     Balanced, &lt;0.1\nindigena             Binary  0.3714   0.0551     Balanced, &lt;0.1\nfactor(cve_ent)_01   Binary -0.1720  -0.0157     Balanced, &lt;0.1\nfactor(cve_ent)_02   Binary -0.3428  -0.0079     Balanced, &lt;0.1\nfactor(cve_ent)_03   Binary  0.0168   0.0079     Balanced, &lt;0.1\nfactor(cve_ent)_04   Binary  0.5524   0.0157     Balanced, &lt;0.1\nfactor(cve_ent)_05   Binary -0.0544   0.0000     Balanced, &lt;0.1\nrural                Binary -0.0553   0.0709     Balanced, &lt;0.1\nescoacum            Contin.  0.6086  -0.2096 Not Balanced, &gt;0.1\ncasadounion          Binary -0.1170   0.0709     Balanced, &lt;0.1\njefehog              Binary  0.0831   0.0551     Balanced, &lt;0.1\nhaymenores           Binary -0.1193   0.0787     Balanced, &lt;0.1\nproggob              Binary  0.0220   0.0079     Balanced, &lt;0.1\ntot_integ           Contin. -0.2856   0.0158     Balanced, &lt;0.1\n\nBalance tally for mean differences\n                   count\nBalanced, &lt;0.1        14\nNot Balanced, &gt;0.1     1\n\nVariable with the greatest mean difference\n Variable Diff.Adj        M.Threshold\n escoacum  -0.2096 Not Balanced, &gt;0.1\n\nSample sizes\n          Control Treated\nAll          1894     127\nMatched       127     127\nUnmatched    1767       0\n\n\nY finalmente el loveplot:\n\nm.out.a[[\"X\"]][[\"factor(cve_ent)\"]] &lt;- NULL\n\nlove.plot(bal.tab(m.out.a),\n      threshold = .1)\n\n\n\n\n\n\n\n\nParece haber un buen balance, aunque la educación es la única variable que no queda bien balanceada. Después del emparejamiento, las medias (estandarizadas) entre tratados y no tratados difieren en más de 0.1.\n[5 puntos] Estime ahora el TOT en el ingreso trimestral, como en la parte b., pero usando un caliper de 0.05 y 5 vecinos a ser emparejados. ¿Cómo cambian sus resultados respecto a los de la parte b.?\n\nsub.data &lt;- data.jcf %&gt;% \n  dplyr::select(ingtot_tri, jcf2, mujer, indigena, cve_ent, rural, escoacum, \n           casadounion, jefehog, haymenores, proggob, tot_integ, factor.x)\n\nsub.data &lt;- sub.data[complete.cases(sub.data), ] \n\nm.out.c &lt;- matchit(formula=jcf2 ~ mujer + indigena + factor(cve_ent) + rural  + escoacum + casadounion + jefehog + haymenores + proggob + tot_integ,\n                 method = \"nearest\",\n                 distance= \"glm\",\n                 ratio = 5,\n                 caliper = 0.05,\n                 replace = FALSE,\n                 data = sub.data)\n\nEstimamos el efecto del tratamiento:\n\ntt3 &lt;- lm(ingtot_tri ~ jcf2,\n      data = match.data(m.out.c))\n\n#Errores agrupados a nivel subclass\ncoeftest(tt3,\n         vcov. = vcovCL,\n         cluster = ~subclass)\n\n\nt test of coefficients:\n\n            Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  2135.55     372.22  5.7374 1.717e-08 ***\njcf2         7155.74     699.21 10.2341 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSe estima ahora un efecto de 7155 pesos, menor al efecto de 7973 pesos estimado en la parte b."
  },
  {
    "objectID": "tareas/tarea-3-respuestas.html#footnotes",
    "href": "tareas/tarea-3-respuestas.html#footnotes",
    "title": "Respuestas a la tarea 3",
    "section": "Notas",
    "text": "Notas\n\n\nStevenson, B. & Wolfers, J. (2006). Bargaining in the Shadow of the Law: Divorce Laws and Family Distress. The Quarterly Journal of Economics, 121(1), 267-288.↩︎"
  },
  {
    "objectID": "tareas/tarea-4-respuestas.html",
    "href": "tareas/tarea-4-respuestas.html",
    "title": "Respuestas a la tarea 4",
    "section": "",
    "text": "Los datos del archivo salud_peru.csv contienen información de una encuesta en hogares realizada en Perú. Un programa del gobierno otorgó un seguro de salud para cubrir a hogares de trabajadores informales y pobres, típicamente excluidos de los servicios de salud. Para ello, se uso un índice de ingreso (IFH), expresado en soles, para determinar la elegibilidad. Aquellos hogares con un IFH menor o igual a 55 soles son considerados pobres. Se desea estimar el efecto del programa en la probabilidad de recibir algún tipo de anteción médica, curative, y sobre la probabilidad de recibir algún tipo de asistencia médica en un hospital o con un doctor, hospinter. La columna ifh contiene el indicador del ingreso.\n\n[10 puntos] Genere una gráfica donde muestre evidencia de una discontinuidad en la variable curative para aquellos hogares que recibieron los beneficios del programa. Debe usar solo a los trabajadores informales, formal==0. Primero, realice la gráfica con una ventana de 100 soles a la izquierda y 100 soles a la derecha del corte de elegibilidad y en la que cada punto represente la media de la variable curative en bins de 5 soles. Agregue una línea de regresión lineal para cada lado del corte de elegibilidad.\nNota: Esta pregunta estuvo basada en el estudiod de Bernal, Carpio & Klein (2017).1\nConstruimos un indicador de elegibilidad:\n\nsalud &lt;- read_csv(\"../files/salud_peru.csv\") %&gt;% \n  filter(formal==0) %&gt;% \n  mutate(ifh_norm=ifh-corte,\n         abajo_corte=ifelse(ifh&lt;=corte, 1, 0))\n\nPartimos la muestra en grupos de cinco soles:\n\nsalud &lt;- salud %&gt;% \n  mutate(bin5=cut(ifh, breaks = c(seq(from=0, to=100, by=5))))\n\nConstruimos la proporción con curative==1 en cada grupo:\n\nsalud5 &lt;- salud %&gt;% \n  group_by(bin5) %&gt;% \n  summarise(curative=mean(curative, na.rm=T)) %&gt;% \n  ungroup()\n\nsalud5 &lt;- salud5 %&gt;% \n  mutate(bin5_num = seq(1:nrow(salud5)))\n\nY hacemos el gráfico:\n\nsalud5 %&gt;% \n  ggplot(aes(x = bin5_num,\n             y = curative)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              se = F,\n              data = filter(salud5, bin5_num&lt;=11)) +\n  geom_smooth(method = lm,\n              se = F,\n              data = filter(salud5, bin5_num&gt;11))\n\n\n\n\n\n\n\n\n[5 puntos] Genere el mismo gráfico que en la parte a., pero ahora con una ventana de 2 soles a cada lado de la discontinuidad.\nSiguiendo el mismo procedimiento:\n\nsalud &lt;- salud %&gt;% \n  mutate(bin2=cut(ifh, breaks = c(seq(from=0, to=100, by=2))))\n\nsalud2  &lt;- salud %&gt;% \n  group_by(bin2) %&gt;% \n  summarise(curative=mean(curative, na.rm=T)) %&gt;% \n  ungroup()\n\nsalud2 &lt;- salud2 %&gt;% \n  mutate(bin2_num = seq(1:nrow(salud2)))\n\nsalud2 %&gt;% \n  ggplot(aes(x = bin2_num,\n             y = curative)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              se = F,\n              data = filter(salud2, bin2_num&lt;=23)) +\n  geom_smooth(method = lm,\n              se = F,\n              data = filter(salud2, bin2_num&gt;23))\n\n\n\n\n\n\n\n\n[5 puntos] Genere el mismo gráfico que en la parte a., pero calcule la media de la variable curative en bins de 10 soles.\nSiguiendo el mismo procedimiento:\n\nsalud &lt;- salud %&gt;% \n  mutate(bin10=cut(ifh, breaks = c(seq(from=0, to=100, by=10))))\n\nsalud10 &lt;- salud %&gt;% \n  group_by(bin10) %&gt;% \n  summarise(curative=mean(curative, na.rm=T)) %&gt;% \n  ungroup()\n\nsalud10 &lt;- salud10 %&gt;% \n  mutate(bin10_num = seq(1:nrow(salud10)))\n\nsalud10 %&gt;% \n  ggplot(aes(x = bin10_num,\n             y = curative)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              se = F,\n              data = filter(salud10, bin10_num&lt;=5)) +\n  geom_smooth(method = lm,\n              se = F,\n              data = filter(salud10, bin10_num&gt;5))\n\n\n\n\n\n\n\n\n[5 puntos] Ahora use rdplot del paquete rdrobust para construir el mismo gráfico.\nPodemos usar rdplot para construir el gráfico, lo que nos permite seleccionar de manera óptima el número de ventanas en las que se construirá la proporción de personas que recibieron atención médica.\n\n(rdplot(y = salud$curative,\n    x = salud$ifh_norm,\n    c=0,\n    p=1))\n\n[1] \"Mass points detected in the running variable.\"\n\n\n\n\n\n\n\n\n\nCall: rdplot\n\nNumber of Obs.                 4161\nKernel                      Uniform\n\nNumber of Obs.                 1786            2375\nEff. Number of Obs.            1786            2375\nOrder poly. fit (p)               1               1\nBW poly. fit (h)             52.680          45.000\nNumber of bins scale          1.000           1.000\n\n\n[10 puntos] Estime la versión más básica de un modelo de regresión discontinua para el efecto del programa sobre hospinter. Reporte el coeficiente estimado del efecto del tratamiento y su significancia estadística. Use una ventana de 20 soles en el IFH antes y después del corte de elegibilidad. Interprete sus resultados.\n\nr1 &lt;- lm(hospinter ~ ifh_norm + abajo_corte,\n       data=filter(salud, ifh_norm&gt;=-20 & ifh_norm &lt;=20))\n\n\nmodelsummary(models = list('20 soles'=r1),\n          output = 'gt',\n          stars = c('***' = .01, '**' = .05, '*' = 0.1),\n          vcov = c(\"HC1\"),\n          fmt = 3,\n          coef_map = 'abajo_corte',\n          gof_map = \"nobs\")\n\n\n\n\n\n\n\n\n20 soles\n\n\n\n\nabajo_corte\n0.047**\n\n\n\n(0.019)\n\n\nNum.Obs.\n2799\n\n\n\n* p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\nCon un modelo lineal y una dummy de elegibilidad, estimamos un efecto de 4.7 puntos porcentuales en la probabilidad de recibir algún tipo de asistencia médica.\n[5 puntos] Estime la misma especificación que en la parte d., pero ahora con una ventana de 10 soles en el IFH. Interprete sus resultados.\nAl restringir la ventana de análisis obtenemos un efecto estimado de 6.6 puntos porcentuales:\n\nr2 &lt;- lm(hospinter ~ ifh_norm + abajo_corte,\n       data=filter(salud, ifh_norm&gt;=-10 & ifh_norm &lt;=10))\n\nmodelsummary(models = list('20 soles'=r1,\n                           '10 soles'=r2),\n          output = 'gt',\n          stars = c('***' = .01, '**' = .05, '*' = 0.1),\n          vcov = c(\"HC1\", \"HC1\"),\n          fmt = 3,\n          coef_map = 'abajo_corte',\n          gof_map = \"nobs\")\n\n\n\n\n\n\n\n\n20 soles\n10 soles\n\n\n\n\nabajo_corte\n0.047**\n0.066**\n\n\n\n(0.019)\n(0.026)\n\n\nNum.Obs.\n2799\n1654\n\n\n\n* p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\n[5 puntos] Regrese a una ventana de 20 soles como en la parte d., pero ahora permita un coeficiente distinto para el IFH antes y después del corte, y un polinomio de orden 2 para la variable de asignación. Interprete sus resultados.\nPermitiendo pendientes distintas y con un polinomio cuadrático de la variable de asignación obtenemos un efecto estimado de 6.8 puntos porcentuales:\n\nr3 &lt;- lm(hospinter ~ ifh_norm*abajo_corte + I(ifh_norm^2)*abajo_corte,\n       data=filter(salud, ifh_norm&gt;=-20 & ifh_norm &lt;=20))\n\n\n\nmodelsummary(models = list('20 soles'=r1,\n                           '10 soles'=r2,\n                           '20 soles diferentes pendientes'=r3\n                           ),\n          output = 'gt',\n          stars = c('***' = .01, '**' = .05, '*' = 0.1),\n          vcov = c(\"HC1\", \"HC1\", \"HC1\"),\n          fmt = 3,\n          coef_map = 'abajo_corte',\n          gof_map = \"nobs\")\n\n\n\n\n\n\n\n\n20 soles\n10 soles\n20 soles diferentes pendientes\n\n\n\n\nabajo_corte\n0.047**\n0.066**\n0.068**\n\n\n\n(0.019)\n(0.026)\n(0.030)\n\n\nNum.Obs.\n2799\n1654\n2799\n\n\n\n* p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\nComo nota, los autores estiman el siguiente modelo para obtener los resultados reportados en la tabla 1 del artículo de 7.8 puntos porcentuales. Ellos introducen una serie de controles, lo cual no es raro en los análisis de diseños con discontinuidades:\n\nr4 &lt;- lm(hospinter ~ ifh_norm + abajo_corte + ifh_norm*abajo_corte + mujer + edad + educ + mieperho + hhmujer + high*ifh_norm + high*abajo_corte ,\n       data=filter(salud, ifh_norm&gt;=-20 & ifh_norm &lt;=20))\n\n\n\nmodelsummary(models = list('20 soles'=r1,\n                           '10 soles'=r2,\n                           '20 soles diferentes pendientes'=r3,\n                           'Publicación'=r4),\n          output = 'gt',\n          stars = c('***' = .01, '**' = .05, '*' = 0.1),\n          vcov = c(\"HC1\", \"HC1\", \"HC1\", \"HC1\"),\n          fmt = 3,\n          coef_map = 'abajo_corte',\n          gof_map = \"nobs\")\n\n\n\n\n\n\n\n\n20 soles\n10 soles\n20 soles diferentes pendientes\nPublicación\n\n\n\n\nabajo_corte\n0.047**\n0.066**\n0.068**\n0.078***\n\n\n\n(0.019)\n(0.026)\n(0.030)\n(0.028)\n\n\nNum.Obs.\n2799\n1654\n2799\n2799\n\n\n\n* p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\n[5 puntos] Use rdrobust para estimar el efecto usando un polinomio de orden 2 y una regresión local no paramétrica. Use algún selector de ancho de banda óptimo.\nPodemos usar rdrobust para estimar el efecto con la selección óptima del ancho de ventana:\n\nsummary(rdrobust(y=salud$hospinter,\n                 x=salud$ifh,\n                 c=55,\n                 p=2,\n                 bwselect='mserd',\n                 vce = 'hc3'))\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 4161\nBW type                       mserd\nKernel                   Triangular\nVCE method                      HC3\n\nNumber of Obs.                 1786         2375\nEff. Number of Obs.             980         1528\nOrder est. (p)                    2            2\nOrder bias  (q)                   3            3\nBW est. (h)                  16.585       16.585\nBW bias (b)                  24.402       24.402\nrho (h/b)                     0.680        0.680\nUnique Obs.                     252          246\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional    -0.082     0.035    -2.313     0.021    [-0.151 , -0.012]    \n        Robust         -         -    -2.229     0.026    [-0.168 , -0.011]    \n=============================================================================\n\n\nEl efecto estimado es de 8.2 puntos porcentuales. La venta seleccionada de manera óptima es de 16.585 soles usando el criterio del error cuadrático medio."
  },
  {
    "objectID": "tareas/tarea-4-respuestas.html#pregunta-1",
    "href": "tareas/tarea-4-respuestas.html#pregunta-1",
    "title": "Respuestas a la tarea 4",
    "section": "",
    "text": "Los datos del archivo salud_peru.csv contienen información de una encuesta en hogares realizada en Perú. Un programa del gobierno otorgó un seguro de salud para cubrir a hogares de trabajadores informales y pobres, típicamente excluidos de los servicios de salud. Para ello, se uso un índice de ingreso (IFH), expresado en soles, para determinar la elegibilidad. Aquellos hogares con un IFH menor o igual a 55 soles son considerados pobres. Se desea estimar el efecto del programa en la probabilidad de recibir algún tipo de anteción médica, curative, y sobre la probabilidad de recibir algún tipo de asistencia médica en un hospital o con un doctor, hospinter. La columna ifh contiene el indicador del ingreso.\n\n[10 puntos] Genere una gráfica donde muestre evidencia de una discontinuidad en la variable curative para aquellos hogares que recibieron los beneficios del programa. Debe usar solo a los trabajadores informales, formal==0. Primero, realice la gráfica con una ventana de 100 soles a la izquierda y 100 soles a la derecha del corte de elegibilidad y en la que cada punto represente la media de la variable curative en bins de 5 soles. Agregue una línea de regresión lineal para cada lado del corte de elegibilidad.\nNota: Esta pregunta estuvo basada en el estudiod de Bernal, Carpio & Klein (2017).1\nConstruimos un indicador de elegibilidad:\n\nsalud &lt;- read_csv(\"../files/salud_peru.csv\") %&gt;% \n  filter(formal==0) %&gt;% \n  mutate(ifh_norm=ifh-corte,\n         abajo_corte=ifelse(ifh&lt;=corte, 1, 0))\n\nPartimos la muestra en grupos de cinco soles:\n\nsalud &lt;- salud %&gt;% \n  mutate(bin5=cut(ifh, breaks = c(seq(from=0, to=100, by=5))))\n\nConstruimos la proporción con curative==1 en cada grupo:\n\nsalud5 &lt;- salud %&gt;% \n  group_by(bin5) %&gt;% \n  summarise(curative=mean(curative, na.rm=T)) %&gt;% \n  ungroup()\n\nsalud5 &lt;- salud5 %&gt;% \n  mutate(bin5_num = seq(1:nrow(salud5)))\n\nY hacemos el gráfico:\n\nsalud5 %&gt;% \n  ggplot(aes(x = bin5_num,\n             y = curative)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              se = F,\n              data = filter(salud5, bin5_num&lt;=11)) +\n  geom_smooth(method = lm,\n              se = F,\n              data = filter(salud5, bin5_num&gt;11))\n\n\n\n\n\n\n\n\n[5 puntos] Genere el mismo gráfico que en la parte a., pero ahora con una ventana de 2 soles a cada lado de la discontinuidad.\nSiguiendo el mismo procedimiento:\n\nsalud &lt;- salud %&gt;% \n  mutate(bin2=cut(ifh, breaks = c(seq(from=0, to=100, by=2))))\n\nsalud2  &lt;- salud %&gt;% \n  group_by(bin2) %&gt;% \n  summarise(curative=mean(curative, na.rm=T)) %&gt;% \n  ungroup()\n\nsalud2 &lt;- salud2 %&gt;% \n  mutate(bin2_num = seq(1:nrow(salud2)))\n\nsalud2 %&gt;% \n  ggplot(aes(x = bin2_num,\n             y = curative)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              se = F,\n              data = filter(salud2, bin2_num&lt;=23)) +\n  geom_smooth(method = lm,\n              se = F,\n              data = filter(salud2, bin2_num&gt;23))\n\n\n\n\n\n\n\n\n[5 puntos] Genere el mismo gráfico que en la parte a., pero calcule la media de la variable curative en bins de 10 soles.\nSiguiendo el mismo procedimiento:\n\nsalud &lt;- salud %&gt;% \n  mutate(bin10=cut(ifh, breaks = c(seq(from=0, to=100, by=10))))\n\nsalud10 &lt;- salud %&gt;% \n  group_by(bin10) %&gt;% \n  summarise(curative=mean(curative, na.rm=T)) %&gt;% \n  ungroup()\n\nsalud10 &lt;- salud10 %&gt;% \n  mutate(bin10_num = seq(1:nrow(salud10)))\n\nsalud10 %&gt;% \n  ggplot(aes(x = bin10_num,\n             y = curative)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              se = F,\n              data = filter(salud10, bin10_num&lt;=5)) +\n  geom_smooth(method = lm,\n              se = F,\n              data = filter(salud10, bin10_num&gt;5))\n\n\n\n\n\n\n\n\n[5 puntos] Ahora use rdplot del paquete rdrobust para construir el mismo gráfico.\nPodemos usar rdplot para construir el gráfico, lo que nos permite seleccionar de manera óptima el número de ventanas en las que se construirá la proporción de personas que recibieron atención médica.\n\n(rdplot(y = salud$curative,\n    x = salud$ifh_norm,\n    c=0,\n    p=1))\n\n[1] \"Mass points detected in the running variable.\"\n\n\n\n\n\n\n\n\n\nCall: rdplot\n\nNumber of Obs.                 4161\nKernel                      Uniform\n\nNumber of Obs.                 1786            2375\nEff. Number of Obs.            1786            2375\nOrder poly. fit (p)               1               1\nBW poly. fit (h)             52.680          45.000\nNumber of bins scale          1.000           1.000\n\n\n[10 puntos] Estime la versión más básica de un modelo de regresión discontinua para el efecto del programa sobre hospinter. Reporte el coeficiente estimado del efecto del tratamiento y su significancia estadística. Use una ventana de 20 soles en el IFH antes y después del corte de elegibilidad. Interprete sus resultados.\n\nr1 &lt;- lm(hospinter ~ ifh_norm + abajo_corte,\n       data=filter(salud, ifh_norm&gt;=-20 & ifh_norm &lt;=20))\n\n\nmodelsummary(models = list('20 soles'=r1),\n          output = 'gt',\n          stars = c('***' = .01, '**' = .05, '*' = 0.1),\n          vcov = c(\"HC1\"),\n          fmt = 3,\n          coef_map = 'abajo_corte',\n          gof_map = \"nobs\")\n\n\n\n\n\n\n\n\n20 soles\n\n\n\n\nabajo_corte\n0.047**\n\n\n\n(0.019)\n\n\nNum.Obs.\n2799\n\n\n\n* p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\nCon un modelo lineal y una dummy de elegibilidad, estimamos un efecto de 4.7 puntos porcentuales en la probabilidad de recibir algún tipo de asistencia médica.\n[5 puntos] Estime la misma especificación que en la parte d., pero ahora con una ventana de 10 soles en el IFH. Interprete sus resultados.\nAl restringir la ventana de análisis obtenemos un efecto estimado de 6.6 puntos porcentuales:\n\nr2 &lt;- lm(hospinter ~ ifh_norm + abajo_corte,\n       data=filter(salud, ifh_norm&gt;=-10 & ifh_norm &lt;=10))\n\nmodelsummary(models = list('20 soles'=r1,\n                           '10 soles'=r2),\n          output = 'gt',\n          stars = c('***' = .01, '**' = .05, '*' = 0.1),\n          vcov = c(\"HC1\", \"HC1\"),\n          fmt = 3,\n          coef_map = 'abajo_corte',\n          gof_map = \"nobs\")\n\n\n\n\n\n\n\n\n20 soles\n10 soles\n\n\n\n\nabajo_corte\n0.047**\n0.066**\n\n\n\n(0.019)\n(0.026)\n\n\nNum.Obs.\n2799\n1654\n\n\n\n* p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\n[5 puntos] Regrese a una ventana de 20 soles como en la parte d., pero ahora permita un coeficiente distinto para el IFH antes y después del corte, y un polinomio de orden 2 para la variable de asignación. Interprete sus resultados.\nPermitiendo pendientes distintas y con un polinomio cuadrático de la variable de asignación obtenemos un efecto estimado de 6.8 puntos porcentuales:\n\nr3 &lt;- lm(hospinter ~ ifh_norm*abajo_corte + I(ifh_norm^2)*abajo_corte,\n       data=filter(salud, ifh_norm&gt;=-20 & ifh_norm &lt;=20))\n\n\n\nmodelsummary(models = list('20 soles'=r1,\n                           '10 soles'=r2,\n                           '20 soles diferentes pendientes'=r3\n                           ),\n          output = 'gt',\n          stars = c('***' = .01, '**' = .05, '*' = 0.1),\n          vcov = c(\"HC1\", \"HC1\", \"HC1\"),\n          fmt = 3,\n          coef_map = 'abajo_corte',\n          gof_map = \"nobs\")\n\n\n\n\n\n\n\n\n20 soles\n10 soles\n20 soles diferentes pendientes\n\n\n\n\nabajo_corte\n0.047**\n0.066**\n0.068**\n\n\n\n(0.019)\n(0.026)\n(0.030)\n\n\nNum.Obs.\n2799\n1654\n2799\n\n\n\n* p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\nComo nota, los autores estiman el siguiente modelo para obtener los resultados reportados en la tabla 1 del artículo de 7.8 puntos porcentuales. Ellos introducen una serie de controles, lo cual no es raro en los análisis de diseños con discontinuidades:\n\nr4 &lt;- lm(hospinter ~ ifh_norm + abajo_corte + ifh_norm*abajo_corte + mujer + edad + educ + mieperho + hhmujer + high*ifh_norm + high*abajo_corte ,\n       data=filter(salud, ifh_norm&gt;=-20 & ifh_norm &lt;=20))\n\n\n\nmodelsummary(models = list('20 soles'=r1,\n                           '10 soles'=r2,\n                           '20 soles diferentes pendientes'=r3,\n                           'Publicación'=r4),\n          output = 'gt',\n          stars = c('***' = .01, '**' = .05, '*' = 0.1),\n          vcov = c(\"HC1\", \"HC1\", \"HC1\", \"HC1\"),\n          fmt = 3,\n          coef_map = 'abajo_corte',\n          gof_map = \"nobs\")\n\n\n\n\n\n\n\n\n20 soles\n10 soles\n20 soles diferentes pendientes\nPublicación\n\n\n\n\nabajo_corte\n0.047**\n0.066**\n0.068**\n0.078***\n\n\n\n(0.019)\n(0.026)\n(0.030)\n(0.028)\n\n\nNum.Obs.\n2799\n1654\n2799\n2799\n\n\n\n* p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\n[5 puntos] Use rdrobust para estimar el efecto usando un polinomio de orden 2 y una regresión local no paramétrica. Use algún selector de ancho de banda óptimo.\nPodemos usar rdrobust para estimar el efecto con la selección óptima del ancho de ventana:\n\nsummary(rdrobust(y=salud$hospinter,\n                 x=salud$ifh,\n                 c=55,\n                 p=2,\n                 bwselect='mserd',\n                 vce = 'hc3'))\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 4161\nBW type                       mserd\nKernel                   Triangular\nVCE method                      HC3\n\nNumber of Obs.                 1786         2375\nEff. Number of Obs.             980         1528\nOrder est. (p)                    2            2\nOrder bias  (q)                   3            3\nBW est. (h)                  16.585       16.585\nBW bias (b)                  24.402       24.402\nrho (h/b)                     0.680        0.680\nUnique Obs.                     252          246\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional    -0.082     0.035    -2.313     0.021    [-0.151 , -0.012]    \n        Robust         -         -    -2.229     0.026    [-0.168 , -0.011]    \n=============================================================================\n\n\nEl efecto estimado es de 8.2 puntos porcentuales. La venta seleccionada de manera óptima es de 16.585 soles usando el criterio del error cuadrático medio."
  },
  {
    "objectID": "tareas/tarea-4-respuestas.html#pregunta-2",
    "href": "tareas/tarea-4-respuestas.html#pregunta-2",
    "title": "Respuestas a la tarea 4",
    "section": "Pregunta 2",
    "text": "Pregunta 2\nEl archivo data_germany.csv contiene los datos empleados por Abadie, Diamond y Hainmueller (2015) para estimar el efecto de la reunificación de Alemania en el PIB per cápita (gdp) usando el método de control sintético.\n\n[15 puntos] Estime el control sintético del PIB per cápita de Alemania del Oeste usando como grupo donador a los 21 países incluidos en los datos. Esto es, encuentre la matriz \\(W\\) que otorga pesos a las distintas regiones usando una serie de predictores observables. Para este propósito, use como predictores el promedio de las siguientes variables para el periodo 1981-1990:\n\nLa apertura comercial, trade\nLa tasa de inflación, infrate\n\nAdemás, use como predictores especiales los siguientes valores:\n\nEl promedio de la participación de la industria en el PIB, industry, de 1981 a 1990\nEl promedio de la escolaridad, schooling, de 1980 y 1985\nLa tasa de inversión, invest80, de 1980\n\nNote que Alemania Occidental está identificada con el número 7 de la columna index. Realice el procedimiento de optimización para minimizar las discrepancias entre la unidad tratada y su sintético usando el periodo 1960-1989.\n¿Qué regiones y con qué pesos contribuyen a construir la Alemania Occidental sintética? Use el procedimiento que vimos en clase, aunque no podrá replicar exactamente los resultados del artículo, por ahora. Notará esto en los valores que obtenga para \\(W\\).\nPreparamos los datos:\nImplementamos el método:\n\nsynth.out &lt;- synth(data.prep.obj = dataprep.out)\n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n\n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 7864.803 \n\nsolution.v:\n 0.8945633 0.0009508237 2.9249e-06 0.02077729 0.003490665 0.08021497 \n\nsolution.w:\n 0.1523837 0.05058415 0.4324535 0.006207241 0.006421631 0.007796306 0.009553204 0.007346295 0.02681235 0.1893084 0.07624671 0.005630577 0.005179397 0.00672163 0.009776595 0.007578245 \n\nsynth.tables &lt;- synth.tab(dataprep.res = dataprep.out,\n                          synth.res = synth.out)\n\nRecuperamos los pesos \\(V\\) y \\(W\\):\n\nprint(synth.tables)\n\n$tab.pred\n                              Treated Synthetic Sample Mean\ngdp                         15808.900 15807.087   13669.381\ntrade                          56.778    59.595      59.831\ninfrate                         2.595     4.239       7.617\nspecial.industry.1981.1990     34.538    34.435      33.794\nspecial.schooling.1980.1985    55.500    54.116      38.659\nspecial.invest80.1980          27.018    27.025      25.895\n\n$tab.v\n                            v.weights\ngdp                         0.895    \ntrade                       0.001    \ninfrate                     0        \nspecial.industry.1981.1990  0.021    \nspecial.schooling.1980.1985 0.003    \nspecial.invest80.1980       0.08     \n\n$tab.w\n   w.weights  unit.names unit.numbers\n1      0.152         USA            1\n2      0.051          UK            2\n3      0.432     Austria            3\n4      0.006     Belgium            4\n5      0.006     Denmark            5\n6      0.008      France            6\n8      0.010       Italy            8\n9      0.007 Netherlands            9\n10     0.027      Norway           10\n12     0.189 Switzerland           12\n14     0.076       Japan           14\n16     0.006      Greece           16\n18     0.005    Portugal           18\n19     0.007       Spain           19\n20     0.010   Australia           20\n21     0.008 New Zealand           21\n\n$tab.loss\n           Loss W   Loss V\n[1,] 6.177519e-05 7864.803\n\n\nLos autores obtienen resultados ligeramente diferentes en términos de \\(W\\) pues su forma de escoger \\(V\\) es también distinta. Sin embargo, cualitativamente, los resultados se sostienen.\n[10 puntos] Obtenga un gráfico en donde represente las series de tiempo del PIB per cápita de Alemania Occidental que efectivamente se realizó, la de su correspondiente control sintético y la del promedio simple del resto de países.\nRecuperamos las series originales y sintética del País Vasco:\n\nYs &lt;- dataprep.out$Y0plot %*% synth.out$solution.w\n\nY1 &lt;- dataprep.out$Y1plot\n\nPor otro lado, podemos calcular el promedio sobre todas las regiones de la matriz \\(Y0plot\\):\n\nY0media &lt;- matrix(rowMeans(dataprep.out$Y0plot))\n\nY ponemos todo en un data frame para graficarlo fácilmente:\n\ndata.plot &lt;- as.data.frame(cbind(Y1,Ys, Y0media))\n\ncolnames(data.plot) &lt;- c(\"Y1\",\"Ys\",\"Y0media\")\ndata.plot &lt;- data.plot %&gt;% \nmutate(year=seq(from=1960, to=2003))\n\n#Gráfico de series\ndata.plot %&gt;% \nggplot(aes(x=year))+\ngeom_line(aes(y=Y1, linetype = \"Alemania Occidental\")) +\ngeom_line(aes(y=Ys, linetype = \"Sintética\"))+\ngeom_line(aes(y=Y0media, linetype = \"Resto de países\"))+\ngeom_vline(xintercept=1990, color = \"black\", size=1, linetype=\"dashed\")+\nscale_x_continuous(breaks=seq(1960, 2003, 5))+\nlabs(x = \"Año\",\n    y = \"PIB per capita\",\n    linetype = \"Legend\") +\nscale_linetype_manual(values = c(\"Alemania Occidental\"=\"solid\", \"Sintética\"=\"dashed\", \"Resto de países\"=\"dotted\"))\n\n\n\n\n\n\n\n\nAlemania Occidental era más rica que el promedio países en el momento de la reunificación. Durante el periodo post a la reunificación, los demás países se acercaron a la trayectoria de Alemania Occidental.\n[10 puntos] Genere una gráfica de brecha que muestre el efecto del terrorismo sobre el PIB per cápita. La brecha es la diferencia entre la serie de tiempo realizada y su contraparte sintética.\nEl gráfico de brechas se obtiene fácilmente con las funciones de Synth:\n\ngaps.plot(synth.res = synth.out,\n      dataprep.res = dataprep.out,\n      tr.intake = 1990,\n      Ylab = c(\"GDP per capita\"),\n      Xlab = c(\"year\"), \n      Ylim = c(-4000,4000))\n\n\n\n\n\n\n\n\nEl gráfico de las trayectorias, en caso de requerirse, es:\n\npath.plot(synth.res = synth.out,\n      dataprep.res = dataprep.out,\n      tr.intake = 1960:2003,\n      Ylab = c(\"GDP per capita\"),\n      Xlab = c(\"year\"))\n\n\n\n\n\n\n\n\n[15 puntos] Ahora seguiremos la estrategia de estimación que siguen los autores en el artículo. Mostraremos que, con su método, podemos obtener el gráfico de placebo en el tiempo de la figura 4 del artículo.\nLos autores siguen un procedimiento de validación cruzada o cross-validation, muy usado también en ciencia de datos. Para ello, dividen la muestra pre intervención en un periodo de entrenamiento y otro de validación. La idea es obtener \\(V\\) en el periodo de entrenamiento y usar dicho vector como pesos en la estimación de \\(W\\) en el periodo de validación.\nPrimero, estime el control sintético para el periodo de validación, usando los siguientes predictores y periodos de optimización:\n\nspecial.predictors = list(\n  list(\"industry\",1971, c(\"mean\")),\n  list(\"schooling\",c(1960,1965), c(\"mean\")),\n  list(\"invest60\" ,1980, c(\"mean\")))\n\ntime.predictors.prior = 1960:1964\ntime.optimize.ssr = 1965:1975\ntime.plot = 1960:1990\n\nPosteriormente, use el vector \\(V\\) obtenido con el procedimiento de entrenamiento anterior para estimar el control sintético, pero ahora con los siguientes predictores y periodos de referencia (el periodo de validación). Para indicar una matriz \\(V\\) en específico explore las opciones de la función synth.\n\nspecial.predictors = list(\n      list(\"industry\" ,1971:1975, c(\"mean\")),\n      list(\"schooling\",c(1970,1975), c(\"mean\")),\n      list(\"invest70\" ,1980, c(\"mean\"))\n      )\n\ntime.predictors.prior = 1965:1975\ntime.optimize.ssr = 1960:1975\ntime.plot = 1960:1990\n\nFinalmente, obtenga el gráfico de trayectorias y compruebe que replica la figura 4 del artículo.\nUsando los predictores y periodos indicados estimamos el control sintético en el periodo de entrenamiento:\n\ndataprep.out &lt;-\n  dataprep(\n    foo = GDP,\n    predictors    = c(\"gdp\",\"trade\",\"infrate\"),\n    dependent     = \"gdp\",\n    unit.variable = 1,\n    time.variable = 3,\n    special.predictors = list(\n      list(\"industry\",1971, c(\"mean\")),\n      list(\"schooling\",c(1960,1965), c(\"mean\")),\n      list(\"invest60\" ,1980, c(\"mean\"))\n    ),\n    treatment.identifier = 7,\n    controls.identifier = setdiff(unique(GDP$index), 7),\n    time.predictors.prior = 1960:1964,\n    time.optimize.ssr = 1965:1975,\n    unit.names.variable = \"country\",\n    time.plot = 1960:1990\n  )\n\n\n Missing data- treated unit; predictor: infrate ; for period: 1960 \n We ignore (na.rm = TRUE) all missing values for predictors.op.\n\n Missing data - control unit: 1 ; predictor: infrate ; for period: 1960 \n We ignore (na.rm = TRUE) all missing values for predictors.op.\n\nsynth.out &lt;- synth(\n  data.prep.obj=dataprep.out\n)\n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n\n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 3242.413 \n\nsolution.v:\n 0.2193154 0.2646532 0.2342373 0.01563207 3.765e-07 0.2661616 \n\nsolution.w:\n 4.19742e-05 0.0003168 0.0001057279 0.03729636 2.5183e-06 3.95558e-05 0.3089249 2.606e-07 2.03e-08 0.1228327 0.003407046 8.4663e-06 6.1837e-06 3.30363e-05 0.5269763 8.2179e-06 \n\n\nCon la matriz \\(V\\) obtenida antes, resolvemos el problema para el periodo de validación. Notemos que en la función synth especificamos custom.v=as.numeric(synth.out$solution.v).\n\ndataprep.out &lt;-\n  dataprep(\n    foo = GDP,\n    predictors    = c(\"gdp\",\"trade\",\"infrate\"),\n    dependent     = \"gdp\",\n    unit.variable = 1,\n    time.variable = 3,\n    special.predictors = list(\n      list(\"industry\" ,1971:1975, c(\"mean\")),\n      list(\"schooling\",c(1970,1975), c(\"mean\")),\n      list(\"invest70\" ,1980, c(\"mean\"))\n    ),\n    treatment.identifier = 7,\n    controls.identifier = setdiff(unique(GDP$index), 7),\n    time.predictors.prior = 1965:1975,\n    time.optimize.ssr = 1960:1975,\n    unit.names.variable = \"country\",\n    time.plot = 1960:1990\n  )\n\nsynth.out &lt;- synth(\n  data.prep.obj=dataprep.out,\n  custom.v=as.numeric(synth.out$solution.v)\n)\n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n optimization over w weights: computing synthtic control unit \n\n\n\n**************** \n v weights supplied manually: computing synthtic control unit \n\n\n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 14206.42 \n\nsolution.v:\n 0.2193154 0.2646532 0.2342373 0.01563207 3.765e-07 0.2661616 \n\nsolution.w:\n 0.1488498 1.15e-08 0.659725 2e-10 3.29e-08 5.0562e-06 3.556e-07 4.6e-09 1.472e-07 0.1594838 0.03193434 6.431e-07 1.9e-09 4.8e-08 6.837e-07 4.46e-08 \n\n\nNotamos que el gráfico de trayectorias replica la figura 4 del artículo:\n\npath.plot(synth.res = synth.out,\n      dataprep.res = dataprep.out,\n      tr.intake = 1960:1990,\n      Ylab = c(\"GDP per capita\"),\n      Xlab = c(\"year\"))\n\n\n\n\n\n\n\n\nSi seguimos un procedimiento de validación cruzada para la estimación del control sintético con la muestra completa, podemos replicar el resultado principal del artículo."
  },
  {
    "objectID": "tareas/tarea-4-respuestas.html#footnotes",
    "href": "tareas/tarea-4-respuestas.html#footnotes",
    "title": "Respuestas a la tarea 4",
    "section": "Notas",
    "text": "Notas\n\n\nBernal, N., Carpio, M. A., & Klein, T. J. (2017). The effects of access to health insurance: evidence from a regression discontinuity design in Peru. Journal of Public Economics, 154, 122-136.↩︎"
  },
  {
    "objectID": "diapositivas/inferencia-estadistica.html",
    "href": "diapositivas/inferencia-estadistica.html",
    "title": "Clase 5. Inferencia estadística",
    "section": "",
    "text": "Clase 5. Inferencia estadística\n\nInferencia Causal\n\n\nIrvin Rojas\n rojasirvin.com\n\n\n\n\n \n\n \n\n\n\nCentro de Investigación y Docencia Económicas División de Economía\n\n\nAgenda\n\nEstudiaremos medidas de variabilidad de estimadores\nHaremos un breve recordatorio de la anatomía y las propiedades del estimador de MCO\n\n\n\nMedidas de variabilidad\n\n\nMedidas de variabilidad\n\nHaremos un breve recordatorio sobre la precisión de los estimadores que usamos para evaluar el efecto de un tratamiento\nComenzamos con medias pues, en algunos casos, basta con una diferencia de medias para estimar el efecto del tratamiento\nSin embargo, las ideas que veremos son fácilmente trasladables a los estimadores de MCO que resultan cuando usamos regresión\n\n\n\nAlgunas definiciones\n\nInsesgadez de la media muestral: \\(E(\\bar{y})=E(y_i)\\)\nLa insesgadez implica que, si obtuviéramos muestras repetidas de tamaño fijo, no habría desviaciones sistemáticas con respecto a \\(E(y_i)\\)\nNo confundir con LGN, que implican consistencia cuando \\(N\\to\\infty\\)\nVarianza poblacional: \\(V(y_i)=E((y_i-E(y_i))^2)=\\sigma_y^2\\)\nDesviación estándar: \\(\\sigma_y\\)\nVarianza muestral: \\(S(y_i)^2=\\frac{1}{n}\\sum_i(y_i-\\bar{y})^2\\)\n\n\n\n¿Cómo medimos la variabilidad de \\(\\bar{y}\\)\n\nAsumamos que las \\(y_i\\) son iid\nPor otro lado, reemplazando la definición:\n\n\\[\n\\begin{aligned}\nV(\\bar{y})&=V\\left(\\frac{1}{n}\\sum_i y_i\\right) \\\\\n&=\\frac{1}{n^2}V\\left(\\sum_i y_i\\right) \\\\\n&=\\frac{1}{n^2}n \\sigma^2_y  \\\\\n&=\\frac{1}{n}\\sigma^2_y\n\\end{aligned}\n\\] donde la última igualdad resulta de la independencia entre las \\(i\\) y dado que las \\(y_i\\) vienen de la misma población, entonces tienen la misma varianza\n\n\n¿Cómo medimos la variabilidad de \\(\\bar{y}\\)\n\nNotemos que la varianza de la media muestral depende de la varianza de \\(y_i\\), \\(\\sigma^2_y\\), pero también de \\(n\\)\nEs aquí donde una LGN tiene un papel, pues cuando \\(n\\to\\infty\\), la varianza de la media muestral tiende a cero\n\n\n\nEl error estándar queda definido como: \\(SE(\\bar{y})=\\sigma_y/\\sqrt{n}\\)\nTodos los estimadores que usamos tienen un error estándar, algunos con una forma más complicada que otra, pero todos ellos tienen la misma interpretación: resumen la variabilidad que surge por el muestreo aleatorio\n\n\n\n\nLa contraparte muestral del error estándar, formalmente llamado error estándar estimado de la media muestral es:\n\n\\[\\hat{SE}(\\bar{y})=\\frac{S(y_i)}{\\sqrt{n}}\\]\n\n\n\nEl estadístico \\(t\\)\n\nSupongamos que queremos probar la hipótesis de que \\(E(y_i)=\\mu\\)\nEl estadístico \\(t\\) se define como: \\[t(\\mu)=\\frac{\\bar{y}-\\mu}{\\hat{SE}(\\bar{y})}\\]\nA la hipótesis que queremos probar se le conoce como la hipótesis nula, \\(H_0\\)\nBajo \\(H_0\\): \\(\\mu=0\\), el estadístico es \\(t(\\mu)=\\frac{\\bar{y}}{\\hat{SE}(\\bar{y})}\\)\nUn TLC nos garantiza que \\(t(\\mu)\\) se distribuye normal en una muestra lo suficientemente grande, sin importar la distribución de \\(y_i\\)\nPor tanto, podemos tomar decisiones sobre la \\(H_0\\), basados en si \\(t(\\mu)\\) es consistente con lo que esperaríamos ver con una distribución normal\n\n\n\nDistribución normal\n\nLa conveniencia de la distribución normal es que conocemos muchas propiedades teóricas de esta\nPor ejemplo, grafiquemos una normal arbitraria con media 0 y desviación estándar 1:\n\n\nnormal_curve &lt;- ggplot(data.frame(x = c(-3, 3)),aes(x = x)) +\n  stat_function(fun = dnorm, args= list(0, 1))\n\nfuncShaded &lt;- function(x) {y &lt;- dnorm(x, mean = 0, sd = 1)\n    y[x &lt; (0 - 1.96 * 1) | x &gt; (0 + 1.96 * 1)] &lt;- NA\n    return(y)\n}\n\nnormal_curve &lt;-normal_curve+stat_function(fun=funcShaded, geom=\"area\", fill=\"black\", alpha=0.2)\n\n\n\nDistribución normal\n\n\n\n\n\n\n\n\n\n\n\n\n\nPor ejemplo, sabemos que el 95% de las realizaciones se encuentran en el intervalo \\([\\mu-1.96\\sigma, \\mu+1.96\\sigma]\\)\nDe aquí surge que, cuando trabajamos al 95% de confianza (típico en economía), se usa una regla de dedo de 2 para juzgar el valor de un estadístico \\(t\\)\nUn estadístico \\(t\\) mayor que \\(|2|\\) indica que la \\(H_0\\) de que \\(\\mu=0\\) es altamente improbable\n\n\n\n\n\nIntervalos de confianza\n\nEn vez de probar si en una muestra la \\(H_0\\) se rechaza o no, para muchos posibles valores de \\(\\mu\\), podemos construir el conjunto de todos los valores de \\(\\mu\\) que son consistentes con los datos\nA esto le llamamos intervalo de confianza de \\(E(y_i)\\)\n\n\n\nUn intervalo de confianza es el conjunto de valores consistente con los datos:\n\n\\[IC_{0.95}=\\{\\bar{y}-1.96\\times\\hat{SE}(\\bar{y}),\\bar{y}+1.96\\times\\hat{SE}(\\bar{y})\\}\\]\n\n\n\nSi tuviéramos acceso a muestras repetidas y en cada una calculáramos \\(\\bar{y}\\), esperamos que en el 95% de los casos \\(E(y_i)\\) está en el intervalo de confianza\nNoten que el IC no se interpreta como la probabilidad de que el parámetro se encuentre en cierto rango\nLa interpretación es más sutil, lo que sucedería si tuviéramos distintas muestras de la misma población\nRegularmente trabajamos con una muestra\n\n\n\n\nBreve nota sobre teoría asintótica de MCO\n\n\nPropiedades del estimador de MCO\n\nEn la práctica, no conocemos la FEC ni la función de regresión poblacional\nEn la clase anterior aprendimos que una forma de aproximar la FEC es usando regresión, es decir, quisiéramos conocer \\(\\beta=E(X_iX_i')^{-1}E(X_iy_i)\\), un objeto poblacional\nEn la práctica aproximamos \\(\\beta\\) con su análogo muestral: \\(\\hat{\\beta}_{MCO}=(X'X)^{-1}(X'Y)\\)\n\n\n\nCon algo de álgebra, escribimos el estimador de MCO como \\[\\hat{\\beta}_{MCO}=\\beta +\\left(\\sum x_ix_i'\\right)^{-1}\\left(\\sum x_i u_i\\right)\\]\nMultiplicando por \\((1/N)^{-1}(1/N)=1\\) el segundo término: \\[\\hat{\\beta}_{MCO}=\\beta +\\left(\\frac{1}{N}\\sum x_ix_i'\\right)^{-1}\\left(\\frac{1}{N}\\sum x_i u_i\\right)\\]\nEsta representación con promedios es útil para usar leyes de grandes números (LGN) y teoremas de límite central (TLC)\n\n\n\n\nDistribución asintótica\n\nLa teoría asintótica nos garantiza que, si \\(E(u_i|x_i)=0\\) la distribución asintótica del estimador de MCO es\n\n\\[\\hat{\\beta}_{MCO}\\stackrel{a}{\\sim}\\mathcal{N}\\left(\\beta,(X'X)^{-1}X'uu'X(X'X)^{-1}\\right)\\]\n\n\nEstos son resultados asintóticos, válidos cuando \\(N\\to \\infty\\)\nSon convenientes porque no asumimos forma distribucional sobre los errores\n\nEn los cursos introductorios de econometría asumíamos, entre otras cosas, errores normales y homocedásticos\nAquí tenemos menos supuestos\n\nLa distribución asintótica nos dice que el estimador de MCO tiene una distribución normal y que su varianza depende de la varianza de los errores\n\n\n\n\nEstimación de la varianza\n\nTenemos que estimar también la varianza del estimador de MCO\nEn un influyente artículo, White (1980) muestra que podemos estimar consistentemente \\(\\hat{V}(\\hat{\\beta}_{MCO})\\) usando:\n\n\\[\\hat{V}(\\hat{\\beta}_{MCO})=(X'X)^{-1}\\left(\\sum_i \\hat{u}_i^2x_ix_i'\\right)(X'X)^{-1}\\] - Esto es a lo que conocemos como la matriz de varianzas robusta a heterocedasticidad\n\nSon robutos porque no hacemos supuestos sobre la distribución de los errores\nEn muy raras ocasiones, si asumimos errores independientes e idénticamente distribuidos:\n\n\\[\\hat{V}^H(\\hat{\\beta}_{MCO})=\\hat{s}^2(X'X)^{-1}\\] donde \\(\\hat{s}\\) es la varianza muestral\n\n\nErrores estándar del estimador de MCO\n\nPartiendo del estimador de la matriz de varianzas del estimador de MCO propuesto por White (1980)\n\n\\[\\hat{V}(\\hat{\\beta}_{MCO})=(X'X)^{-1}\\left(\\sum_i\\hat{u}_i^2x_ix_i'\\right)(X'X)^{-1}\\]\nel error estándar de \\(\\hat{\\beta}_k\\) será la raíz cuadrada de la \\(k\\)-ésima entrada sobre la diagonal principal de \\(\\hat{V}(\\hat{\\beta}_{MCO})\\) y lo denominamos \\(\\hat{EER}(\\hat{\\beta}_k)\\) por venir de una matriz de varianzas robusta\n\nCon los mismos principios que para la media muestral, una estadístico \\(t\\) se define como:\n\n\\[t(\\beta_k)=\\frac{\\hat{\\beta}_k-\\beta_k}{\\hat{EER}(\\hat{\\beta}_k)}\\]\n\n\nPrueba de hipótess\n\nEn la sesión anterior motivamos el uso de regresión para estimar efectos de tratamiento:\n\n\\[y_i=\\alpha+\\beta T_i +\\gamma_1 x_1 + \\gamma_2 x_2 + \\ldots + \\gamma_{K-2} x_{K-2}  + u_i\\]\n\nSupongamos que el tratamiento fue asignado aleatoriamente y el diseño permaneció íntegro\nNos interesa entonces probar la hipótesis nula de que \\(\\beta=0\\)\n\n\n\nUn estadístico \\(t\\) para probar esta hipótesis tiene la forma:\n\n\\[t(\\beta)=\\frac{\\hat{\\beta}}{\\hat{EER}(\\hat{\\beta})}\\] - Bajo la \\(H_0\\), el estadístico \\(t\\) se distribuye asintóticamente normal\n\nPodemos comparar el valor \\(t(\\beta)\\) con la distribución normal teórica para decir qué tan probable es observar dicho valor del estadístico\n\n\n\n\nEl valor \\(p\\)\n\nLa otra cara de la moneda de los estadísticos de prueba es el valor \\(p\\)\nEl valor \\(p\\) es la probabilidad de observar un valor mayor que el estadístico cuando la \\(H_0\\) es verdadera\nUn valor \\(p\\) muy pequeño indica que es muy poco probable observar el estadístico de prueba bajo la \\(H_0\\), por lo que hay evidencia para rechazar la \\(H_0\\)\nOtra forma de intepretar el valor \\(p\\) es la probabilidad de que se observen efectos iguales o más grandes a los observados debido al error muestral (por suerte)\n\n\n\nValores \\(p\\)\n\nSupongamos que un programa incrementa los ingresos en 100 pesos mensuales en promedio, con un valor \\(p\\) de 0.07\nEntonces, si el programa no tuviera efecto, todavía sería posible ver incrementos en los ingresos de 100 pesos mensuales o más en el 7% de los estudios debido al error muestral\nEn este breve texto de Krzywinski & Altman (2013) pueden leer algunos otros detalles sobre el valor \\(p\\)\n\n\n\n\n\n\nFuente: Krzywinski & Altman (2013)\n\n\n\n\n\n\nValores \\(p\\)\n\n¿Qué tanto toleramos que nuestros resultados puedan ser por suerte?\nFijamos un nivel de significancia \\(\\alpha\\), definido como la probabilidad de rechazar la \\(H_0\\) dado que esta es verdadera\nEs decir, la probabilidad de cometer el error tipo 1 o falso positivo\nEn economía usamos frecuentemente los valores \\(\\alpha\\) de 0.10, 0.05 y 0.01 para juzgar la significancia de los estimadores\nEn evaluación, si el valor \\(p\\) es menor que \\(\\alpha\\) decimos que el efecto es estadísticamente significativo\n\n\n\nNota sobre los valores \\(t\\) críticos\n\n\n\nLos correspondientes valores del estadístico \\(t\\) en muestras grandes para \\(\\alpha\\) de 0.10, 0.05 y 0.01 son 2.56, 1.96 y 1.64\n¿Cómo puedo encontrar el valor \\(p\\) exacto de un estadístico \\(t\\) dado?\n\n\n(1-pnorm(abs(1.644854)))\n\n[1] 0.04999996\n\n\n\nO uno menos arbitrario\n\n\n(1-pnorm(abs(-1.3)))\n\n[1] 0.09680048\n\n\n\n\nY al revés, puedo siempre encontrar el estadístico \\(t\\) asociado a cierto valor \\(p\\)\n\n\nqnorm(1-(.1/2))\n\n[1] 1.644854\n\n\n\nEl 2 en las expresiones anteriores viene de que estamos en pruebas de dos colas con una distribución simétrica\n\n\n\n\n\nPrueba de hipótesis en evaluación\n\nUn camino típico:\n\nFormulamos una pregunta causal \\(D_i \\to y_i\\)\nTengo razones para asumir que \\(D_i\\) es independiente de \\(y_i\\) (por ejemplo, hice un experimento)\nDe la clase anterior, sé que una regresión me ayudará a hacer comparaciones:\n\n\\[y_i=\\alpha+\\beta D_i + B'X_i + u_i\\]\n\nFormulamos la \\(H_0\\): \\(\\beta=0\\), es decir, no hay efecto del tratamiento\nEstimo la regresión, obtengo \\(\\hat{\\beta}\\), y construyo \\(t=\\frac{\\hat{\\beta}}{\\hat{se}(\\hat{\\beta})}\\)\n\n\n\n\nPrueba de hipótesis en evaluación\n\n… un camino típico\n\nEl software me arroja: \\(\\hat{\\beta}\\), \\(t(\\hat{\\beta})\\) y \\(p\\)\n\\(t(\\hat{\\beta})\\) y \\(p\\) son dos caras de la misma moneda\nSi \\(p&gt;\\alpha\\), hay una probabilidad de observar \\(\\hat{\\beta}\\) debido al error muestral mayor que \\(\\alpha\\)\nO, en términos de \\(t\\), es altamente probable observar el estadístico bajo la \\(H_0\\), por lo que no se rechaza la \\(H_0\\)\n\n\n\n\nLas hipótesis no son exclusivamente de efectos de tratamiento\nOtras hipótesis:\n\nLas características observables están balanceadas\nLa atrición ocurrió al azar\n\n\n\n\n\nPróxima sesión\n\nHaré algunas definiciones de la literatura de efectos de tratamiento\n\nCT, Capítulo 25, Secciones 1 y 2\n\n\n\n\n\nPresentación creada usando el paquete xaringan en R.\nEl chakra viene de remark.js, knitr, y R Markdown.\nMaterial de clase en versión preliminar.\nNo reproducir, no distribuir, no citar."
  },
  {
    "objectID": "diapositivas/errores-estandar.knit.html",
    "href": "diapositivas/errores-estandar.knit.html",
    "title": "Errores estándar e inferencia",
    "section": "",
    "text": "Errores estándar e inferencia\n\nInferencia Causal\n\n\nIrvin Rojas\n rojasirvin.com\n\n\n\n\n \n\n \n\n\n\nCentro de Investigación y Docencia Económicas División de Economía\n\n\n\n\n\nErrores estándar no estándar\n\n\nErrores estándar robustos\n\nRecordemos que con errores homocedásticos, la matriz de varianzas del estimador de MCO puede ser estimada como:\n\n\\[\\hat{V}(\\beta_{MCO}^H)=\\hat{\\sigma}^2(X'X)^{-1}\\] donde \\(\\hat{\\sigma}^2=\\frac{1}{N-k}\\hat{u}_i^2\\) y \\(\\hat{u}_i^2=(y_i-X_i'\\hat{\\beta}_{MCO})^2\\)\n\n\nUna primera desviación respecto a los errores clásicos ocurre cuando relajamos el supuesto de homocedasticidad\nEn la clase 3 estudiamos de manera general las propiedades asintóticas del estimador de MCO\nLa varianza asintótica es:\n\n\\[V(\\hat{\\beta}_{MCO}^{R})=(X'X)^{-1}X'\\Omega X(X'X)^{-1}\\]\n\n\n\nErrores robustos a la heterocedasticidad\n\nUn estimador de la varianza del estimador de MCO que no asume homocedasticidad es el estimador propuesto por White (1980)\nSabemos que la matriz de varianzas del estimador de MCO robusta a la heterocedasticidad es: \\[\\hat{V}(\\beta_{MCO}^R)=(X'X)^{-1}\\left(\\sum_i\\hat{u}_i^2x_ix_i'\\right)(X'X)^{-1}\\]\nAquí un recordatorio de por qué podemos escribir \\(X'uu'X\\) como una sumatoria\nConsideremos la carnita del sándwich \\[\\sum_i\\hat{u}_i^2x_ix_i \\equiv \\sum_i \\hat{\\psi}_i x_ix_i'\\]\n\n\n\nErrores estándar robustos\n\nDependiendo de cómo se especifique \\(\\hat{\\psi}_i\\), obtenemos distintas versiones del estimador de varianzas robusto\nLa propuesta de White original es:\n\n\\[HC0:\\quad\\hat{\\psi}_i=\\hat{u}_i^2\\]\n\nEste estimador asintóticamente consistente\n\n\n\nEn muestras pequeñas, muchas veces se emplea la siguiente corrección:\n\n\\[HC1:\\quad\\hat{\\psi}_i=\\frac{N}{N-k}\\hat{u}_i^2\\]\n\n\n\nDesviación a la influencia\n\nUn par de resultados nos ayudarán a entender qué hacen las otras correcciones a la matriz robusta en el software\nDefinimos la influencia de la observación \\(i\\) como:\n\n\\[h_{ii}=X_i'(X'X)^{-1}X_i\\]\n\n\\(h_{ii}\\) nos dice qué tanto jala la observación \\(i\\) a la línea de regresión\nEn una regresión con un solo regresor \\(x\\), se puede mostrar que la influencia de la observación \\(i\\) es:\n\n\\[h_{ii}=\\frac{1}{N}+\\frac{(x_i-\\bar{x})^2}{\\sum(x_j-\\bar{x})^2}\\] es decir, que la influencia se incrementa cuando \\(x_i\\) se aleja de la media\n\nLa influencia es un número entre 0 y 1 y además \\(\\sum_i h_{ii}=k\\), siendo \\(k\\) el número de regresores\n\n\n\nErrores estándar robustos\n\nAlgunos autores sugieren usar la influencia en la matriz de varianzas robusta\nSe proponen algunas alternativas:\n\n\\[HC2:\\quad\\hat{\\psi}_i=\\frac{1}{1-h_{ii}}\\hat{u}_i^2\\]\n\\[HC3:\\quad\\hat{\\psi}_i=\\frac{1}{(1-h_{ii})^2}\\hat{u}_i^2\\]\n\n\nLong & Ervin (2000) realizaron un experimento de simulación y recomendaron usar \\(HC3\\) en muestras pequeñas, por lo que el paquete sandwich en R usa \\(HC3\\) por default\nEs importante tener en cuenta qué tipo de errores estándar piden que el software calcule\n\n\n\n\nErrores agrupados\n\n\nErrores agrupados\n\nSurgen naturalmente cuando las observaciones están agrupadas\n\nNiños en salones de clase\nHogares en localidades\nSolicitudes de empleo en una empresa\nAhorradoras en un banco\n\nEl supuesto de errores independientes claramente no se cumple\n\n\n\nPensemos en un problema simple para entender la intución:\n\n\\[y_{ig}=\\beta_0+\\beta_1 x_g+e_{ig}\\]\n\nAquí, \\(x_g\\) es un regresor que es el mismo para todos los miembros del grupo \\(g\\)\nAsumamos que todos los grupos tienen tamaño \\(n\\)\n\n\n\n\nErrores agrupados\n\nPodemos mostrar que la correlación de errores entre dos observaciones \\(i\\) y \\(j\\) que pertenecen a \\(g\\) es \\[E(e_{ig}e_{jg})=\\overbrace{\\rho_e}^{\\substack{\\text{coeficiente de correlación} \\\\ \\text{intraclase residual}}} \\underbrace{\\sigma_e^2}_{\\text{varianza residual}}\\]\nLe damos una estructura aditiva a los errores:\n\n\\[e_{ig}=\\nu_g+\\eta_{ig}\\] donde \\(\\nu_g\\) captura toda la correlación dentro del grupo\n\n\\(\\eta_{ig}\\) es un error idiosincrático con media cero e independiente de cualquier otro \\(\\eta_{jg}\\)\nComo queremos analizar el problema del agrupamiento, asumimos que tanto \\(v_g\\) y \\(\\eta_{ig}\\) son homocedásticos\n\n\n\nErrores agrupados\n\nCon esta estructura de errores, el coeficiente de correlación intraclase es:\n\n\\[\\rho_e=\\frac{\\sigma_{\\nu}^2}{\\sigma_{\\nu}^2+\\sigma_{\\eta}^2}\\] - Deberíamos calcular la matriz de varianzas \\(V_C(\\hat{\\beta})\\) tomando en cuenta esta estructura\n\n\n¿Qué pasa si hacemos MCO en el contexto de este problema?\nMoulton (1984) muestra que:\n\n\\[\\frac{V_C(\\hat{\\beta})}{V_{MCO}(\\hat{\\beta})}=1+(n-1)\\rho_e\\] - A \\(\\sqrt{\\frac{V_C(\\hat{\\beta})}{V_{MCO}(\\hat{\\beta})}}\\) se le conoce como el factor de Moulton\n\n\n\nFactor de Moulton\n\nEl factor de Moulton nos dice qué tanto sobrestimamos la precisión al ignorar la correlación intra-clase\nVisto de otro modo:\n\n\\[V_C(\\hat{\\beta})=\\left(1+(n-1)\\rho_e\\right)V_{MCO}(\\hat{\\beta})\\]\n\nEs decir entre más grande sea la correlación dentro de los grupos, más deberíamos inflar los errores de MCO\n\n\n\nConsideremos el caso extremo de que \\(\\rho_e=1\\), es decir, que todas las \\(y_{ig}\\) dentro del mismo \\(g\\) son iguales\nEntonces el factor de Moulton es simplemente \\(\\sqrt{n}\\)\nVisto de otro modo, la matriz de varianzas correcta se obtendría multiplicando por \\(n\\) la matriz \\(V_{MCO}(\\hat{\\beta})\\)\n\n\\[V_C(\\hat{\\beta})=n V_{MCO}(\\hat{\\beta})\\]\n\n\n\nErrores agrupados en general\n\nEn general, \\(x_{ig}\\) varía a nivel individual y tenemos grupos de tamaño \\(n_g\\)\nEn este caso, el factor de Moulton es la raíz cuadrada de:\n\n\\[\\frac{V_C(\\hat{\\beta})}{V_{MCO}(\\hat{\\beta})}=1+\\left(\\frac{V(n_g)}{\\bar{n}}+\\bar{n}-1\\right)\\rho_x\\rho_e\\] donde \\(\\bar{n}\\) es el tamaño promedio del grupo y \\(\\rho_x\\) es la correlación intraclase de \\(x_{ig}\\)\n\nNo es necesario asumir una forma para \\(\\rho_x\\) (se puede calcular)\n\n\n\nNoten que el error que cometemos es más grande entre más heterogéneo es el tamaño de grupos y entre más grande es \\(\\rho_x\\)\nPor tanto, cuando el tratamiento no varía entre grupos, este error es grande\n\n\n\n\nSoluciones para errores agrupados\n\nSolución paramétrica: calcular directamente el factor de Moulton e inflar los errores de MCO\nBootstrap por bloques: en vez de hacer muestras bootrstrap remuestreando individuos, se remuestrean grupos\nEstimar los errores agrupados (clustered standard errors)\n\n\n\nErrores estándar agrupados\n\nCon errores agrupados podemos escribir el estimador de MCO como\n\n\\[\n\\begin{aligned}\n\\hat{\\beta}&=\\beta+(X'X)^{-1}X'u \\\\\n&=(X'X)^{-1}\\left(\\sum_{g=1}^G X_gu_g\\right)\n\\end{aligned}\n\\] - Suponiendo independencia entre \\(g\\) y correlación dentro de cada grupo:\n\\[E(u_{ig}u_{jg'}|x_{ig}x_{jg'})=0\\] excepto cuando \\(g=g'\\)\n\nEn este caso, el estimador de MCO tiene una varianza asintótica dada por\n\n\\[V({\\hat{\\beta}}_{MCO})=(X'X)^{-1}\\left(\\sum_{g=1}^G X_g'u_gu_g'X\\right)(X'X)^{-1}\\]\n\n\nErrores estándar agrupados\n\nCon errores heterocedásticos, pero sin agrupamiento, la matriz de varianzas de White (1980) tiene una estructura como sigue:\n\n\\[\\hat{V}(\\hat{\\beta}_{R})=(X'X)^{-1}X'\\hat{\\Sigma} X (X'X)^{-1}\\]\n\nDonde\n\n\\[\\hat{\\Sigma}=\\left(\\begin{matrix} \\hat{u}_{1}^2 & 0  & 0  & \\ldots & 0 \\\\ 0 & \\hat{u}_{2}^2 & 0 & \\ldots & 0 \\\\ \\vdots & & & & \\\\ 0 & & &  \\ldots & \\hat{u}_{n}^2\\end{matrix}\\right)\\]\n\n\nErrores estándar agrupados\n\nPara estimar la varianza con errores agrupados empleamos una generalización de la propuesta de White para errores robustos\nSi \\(G\\to\\infty\\), el estimador de la matriz de errores agrupados robusta (CRVE) es consistente para estimar \\(V(\\hat{\\beta})\\):\n\n\\[\\hat{V}_{CR}(\\hat{\\beta})=(X'X)^{-1}\\left(\\sum_{g=1}^G X_g'\\hat{u}_g\\hat{u}_g'X_g\\right)(X'X)^{-1}\\] donde \\(\\hat{u}_g\\hat{u}_g'\\) es la matriz de varianzas para los individuos del grupo \\(g\\)\n\nDe manera compacta\n\n\\[\\hat{V}_{CR}(\\hat{\\beta})=(X'X)^{-1}X'\\hat{\\Sigma} X(X'X)^{-1}\\]\n\n\nErrores estándar agrupados\n\nY en este caso la matriz \\(\\hat{\\Sigma}\\) tiene una estructura agrupada\n\n\\[\\small \\hat{\\Sigma}=\\left(\\begin{matrix} \\hat{u}_{1,1}^2 & \\hat{u}_{1,1}\\hat{u}_{2,1} & \\ldots & \\hat{u}_{1,1} \\hat{u}_{n,1}& 0 & 0 & \\ldots &  0 & \\ldots & 0 & 0 & \\ldots &  0 \\\\ \\hat{u}_{2,1}\\hat{u}_{1,1} & \\hat{u}_{2,1}^2 & \\ldots & \\hat{u}_{2,1}\\hat{u}_{n,1} & 0 & 0 & \\ldots & 0 & \\ldots  & 0 & 0 & \\ldots &  0\\\\\n\\vdots & \\vdots  & & \\vdots & \\vdots & \\vdots  & &  \\vdots& & \\vdots & \\vdots &  &  \\vdots \\\\ \\hat{u}_{n,1}\\hat{u}_{1,1} & \\hat{u}_{n,1}\\hat{u}_{2,1}& \\ldots & \\hat{u}_{n,1}^2& 0 & 0 &\\ldots & 0 & \\ldots & 0 & 0 & \\ldots &  0 \\\\  0 & 0 & \\ldots &  0 & \\hat{u}_{1,2}^2 & \\hat{u}_{1,2}\\hat{u}_{2,2} & \\ldots & \\hat{u}_{1,2}\\hat{u}_{n,2} &\\ldots & 0 & 0 & \\ldots &  0  \\\\ 0 & 0 & \\ldots &  0 & \\hat{u}_{2,2}\\hat{u}_{1,2} & \\hat{u}_{2,2}^2 & \\ldots & \\hat{u}_{2,2}\\hat{u}_{n,2} &\\ldots & 0 & 0 & \\ldots &  0 \\\\ \\vdots & \\vdots  & & \\vdots & \\vdots & \\vdots  & &  \\vdots& & \\vdots & \\vdots &  &  \\vdots  \\\\ 0 & 0 & \\ldots &  0 & \\hat{u}_{n,2}\\hat{u}_{1,2} & \\hat{u}_{n,2}\\hat{u}_{2,2} & \\ldots & \\hat{u}_{n,2}^2 &\\ldots & 0 & 0 & \\ldots &  0 \\\\ \\vdots & \\vdots  & & \\vdots & \\vdots & \\vdots  & &  \\vdots& & \\vdots & \\vdots &  &  \\vdots \\\\ 0 & 0 & \\ldots &  0 & 0 &  0 & \\ldots & 0 &\\ldots & \\hat{u}_{1,G}^2 & \\hat{u}_{12,G}\\hat{u}_{2,G} & \\ldots &  \\hat{u}_{1,G}\\hat{u}_{n,G} \\\\  0 & 0 & \\ldots &  0 & 0 &  0 & \\ldots & 0 &\\ldots & \\hat{u}_{2,G}\\hat{u}_{1,G} & \\hat{u}_{2,G}^2 & \\ldots &  \\hat{u}_{2,G}\\hat{u}_{n,G} \\\\ \\vdots & \\vdots  & & \\vdots & \\vdots & \\vdots  & &  \\vdots& & \\vdots & \\vdots &  &  \\vdots \\\\  0 & 0 & \\ldots &  0 & 0 &  0 & \\ldots & 0 &\\ldots & \\hat{u}_{n,G}\\hat{u}_{1,G} & \\hat{u}_{n,G}\\hat{u}_{2,G} & \\ldots &  \\hat{u}_{n,G}^2 \\end{matrix}\\right)\\]\n\n\nErrores estándar agrupados\n\nEl resultado asintótico de consistencia depende de que \\(G\\to\\infty\\)\nSi \\(G\\) está fijo, no importa qué tan grande sea \\(N\\), \\(\\hat{V}_{CRVE}(\\hat{\\beta})\\) no será consistente\nAlgunos paquetes ajustan esta matriz de varianzas haciendo una corrección parecida a \\(HC1\\), pero ahora tomando en cuanta también \\(G\\) y no solo \\(N\\) (ver por ejemplo, vcovCR en R)\n\n\n\nCon pocos grupos, subestimamos los errores estándar y rechazamos la \\(H_0\\) más veces de lo que deberíamos (over-rejection)\nSi tenemos pocos grupos, recurrimos a otras soluciones (ver Cameron y Miller, 2015)\n\nInflar los errores con un corrector de sesgo\nBootstrap agrupado con refinamiento asintótico\n\nLa recomendación práctica es que se tomen en serio el problema de los pocos clusters\n¿Cuánto es poco? Cameron y Miller (2015) citan 50. (¡Qué raro, el número de estados en EUA!)\n\n\n\n\nBootstrap\n\n\nBootstrap\n\nA veces es difícil encontrar una expresión analítica de los errores estándar\nLa idea de las técnicas bootstrap es consutrir una distribución empírica del estimador de interés\nUna muestra bootstrap es una muestra tomada de los mismos datos\n\n\n\nEn las rutinas para errores bootstrap, pensamos en \\(\\{(y_1,x_1),\\ldots,(y_N,X_n)\\}\\) como la población\nUna muestra bootstrap es una muestra de tamaño \\(N\\) tomada de la muestra original\n\n\n\n\nEl procedimiento bootstrap más usado es el bootstrap no paramétrico o bootstrap en parejas (nos enfocaremos en este tipo de bootstrap en el curso)\nLa idea es remuestrear la pareja completa \\((y_i,x_i)\\)\n\n\n\n\nAlgoritmo para errores estándar bootstrap\n\nDada una muestra \\(W_1,\\ldots,W_N\\), obtener una muestra de tamaño \\(N\\), remuestreando de la muestra original con reemplazo\nCalcular el estadístico \\(\\hat{\\theta}_b\\) usado con la muestra bootstrap (coeficiente de regresión, diferencia de medias, función de coeficientes)\nRepetir los pasos 1 y 2 \\(B\\) veces, donde \\(B\\) es lo suficientemente grande (usualmente 1000 es suficiente)\nUsar las \\(B\\) repeticiones para obtener el error estándar del estadístico como la raíz cuadrada de \\(s^2_{\\hat{\\theta},B}\\):\n\n\\[s^2_{\\hat{\\theta},B}=\\frac{1}{B-1}\\sum_{b=1}^B(\\hat{\\theta}_{b}-\\bar{\\hat{\\theta}})^2\\] donde \\(\\bar{\\hat{\\theta}}=\\frac{1}{B}\\sum_{b=1}^B\\hat{\\theta}_b\\)\n\n\n¿Cómo hacer remuestreo en R?\n\nUsaremos estos datos en las tareas. Veamos cómo luce una variable de gasto total en la muestra original:\n\n\nset.seed(927)\n\ndata.morocco&lt;- read.csv(\"./crepon_morocco_analysis.csv\")%&gt;%\n  select(treatment,client,expense_total )\n\nobs &lt;- nrow(data.morocco)\nobs\n\n[1] 4934\n\n#En la muestra original\nmean(data.morocco$expense_total)\n\n[1] 23294.83\n\n\n\n\n¿Cómo hacer remuestreo en R?\n\nObtenemos una muestra bootstrap al obtener una muestra del tamaño original a partir de los datos originales, con remplazo:\n\n\n#Una muestra bootstrap\ndata.b &lt;-data.morocco[sample(nrow(data.morocco),obs, replace = TRUE),]\n\nmean(data.b$expense_total)\n\n[1] 24995.96\n\n#Otra muestra bootstrap\ndata.b &lt;-data.morocco[sample(nrow(data.morocco),obs, replace = TRUE),]\n\nmean(data.b$expense_total)\n\n[1] 25587.57\n\n\n\n\nAplicaciones comunes de bootstrap\n\nMétodos de varias etapas (por ejemplo, el estimador de dos etapas de Heckman)\nFunciones de estimadores (aunque aquí el método Delta también podría ser usado)\nDatos agrupados con pocos grupos\n\n\n\nEl consejo práctico es usar resultados teóricos cuando se puede (por ejemplo, las matrices robustas descritas antes)\nPensemos siempre en la estructura de los datos antes de hacer bootstrap\nUsar una semilla siempre para poder reproducir sus resultados\n\n\n\n\nBootstrap salvaje\n\nEn presencia de heterocedasticidad se prefiere usar bootstrap salvaje (wild bootstrap) (MacKinnon, 2012)\nPropuesto originalmente por Liu (1988), cada muestra bootstrap tiene la siguiente forma:\n\n\\[y_i^*=X_i\\hat{\\beta}+f(\\hat{u}_i)v_i^*\\]\n\nNoten que mantiene fijos los \\(X_i\\) en cada muestra bootstrap\n\n\n\nUna especificación comúnmente usada es hacer es \\(f(\\hat{u}_i)=\\hat{u}_i\\) y \\[v_i^*=\\begin{cases} 1 \\quad\\text{con probabilidad 0.5} \\\\ -1 \\quad\\text{con probabilidad 0.5} \\end{cases}\\]\n\\(\\hat{\\beta}\\) y \\(\\hat{u}_i\\) son estimados con la muestra original\n\n\n\n\nBootstrap salvaje\n\nEn cada una de las \\(B\\) muestras bootstrap, mantenemos a los mismos individuos (no hay remuestreo)\nTendremos \\(B\\) muestras bootstrap, pero ahora la aleatoriedad viene por \\(f(\\hat{u}_i)v_i^*\\)\nPueden usarse otras funciones más complicadas para \\(f(\\hat{u}_i)\\)\nLa ventaja de este método es que conserva la relación entre las varianzas residuales y las \\(X_i\\) observadas en los datos originales\nDavidson & Flachaire (2008) utilizan simulaciones para mostrar que con esta forma para \\(f(\\hat{u}_i)v_i^*\\) la inferencia es más confiable que con otras especificaciones\n\n\n\nRefinamiento asintótico\n\nUna aplicación de las técnicas bootstrap es el refinamiento asintótico de la prueba \\(t\\) de coeficientes de regresión\nSupongamos que \\(H_0:\\quad \\beta=0\\) y trabajamos con un nivel \\(\\alpha\\)\n\n\n\nEn cada repetición bootstrap el estadístico calculado es \\(t_b\\)\nOrdenamos los \\(B\\) estadísticos obtenidos\nRechazamos \\(H_0\\) si \\(|t|\\) está por encima del \\((1-\\alpha)\\)ésimo percentil de los \\(|t_b|\\) en la distribución bootstrap\n\n\n\n\nA pesar de sus propiedades teóricas, el refinamiento asintótico es poco usado\n\n\n\n\nOtras aplicaciones\n\nBootstrap jacknife (útil para problemas con errores agrupados y pocos grupos)\n\n\n\n\nMaterial de clase en versión preliminar.\nNo reproducir, no distribuir, no citar."
  },
  {
    "objectID": "diapositivas/late.html#fracasó-el-experimento",
    "href": "diapositivas/late.html#fracasó-el-experimento",
    "title": "Inferencia Causal 2025",
    "section": "¿Fracasó el experimento?",
    "text": "¿Fracasó el experimento?\n\nFrecuentemente nos encontraremos con intervenciones donde la aleatorización ocurre de manera íntegra, pero no todos aquellos asignados a cierto tratamiento efectivamente lo reciben\nNos tomaremos en serio la diferencia entre ser asignado al tratamiento y recibir el tratamiento\n\nAl evaluar un programa que asigna aleatoriamente a niños a escuelas de prestigio, nos interesa el efecto de efectivamente asistir a dichas escuelas y, quizás no tanto, el efecto de haber sido sorteado para asistir a dichas escuelas"
  },
  {
    "objectID": "diapositivas/late.html#fracasó-el-experimento-1",
    "href": "diapositivas/late.html#fracasó-el-experimento-1",
    "title": "Inferencia Causal 2025",
    "section": "¿Fracasó el experimento?",
    "text": "¿Fracasó el experimento?\n\nUsaremos un estimador de variables instrumentales (VI) para relacionar los efectos de la asignación con los efectos de la adopción\nLlegaremos al siguiente resultado:\n\n\\[\\text{Efecto de la asignación en } Y=(\\text{Efecto de la asignación en la adopción})\\times (\\text{Efecto de la adopción en }Y)\\]\n\nPor tanto:\n\n\\[\\text{Efecto de la adopción en }Y=\\frac{\\text{Efecto de la asignación en }Y}{\\text{Efecto de las asignación en la adopción}}\\]\n\nAhora derivaremos formalmente este resultado, pero la intución es importante: el efecto causal de la adopción es el efecto de la asignación, escalado por el efecto de la asignación en la adopción"
  },
  {
    "objectID": "diapositivas/late.html#identificación-de-efectos-causales-usando-vi",
    "href": "diapositivas/late.html#identificación-de-efectos-causales-usando-vi",
    "title": "Inferencia Causal 2025",
    "section": "Identificación de efectos causales usando VI",
    "text": "Identificación de efectos causales usando VI\n\nAngrist, Imbens & Rubin (1996)\nAsignación: \\(Z_i=\\begin{cases} 1 \\\\0 \\\\ \\end{cases}\\)\nCumplimiento: \\(D_i=\\begin{cases} 1 \\\\0 \\\\ \\end{cases}\\)\n\\(Y_i\\) variable de resultados\nNos importa el efecto de \\(D_i\\) sobre \\(Y_i\\)"
  },
  {
    "objectID": "diapositivas/late.html#efectos-causales-y-vi",
    "href": "diapositivas/late.html#efectos-causales-y-vi",
    "title": "Inferencia Causal 2025",
    "section": "Efectos causales y VI",
    "text": "Efectos causales y VI\n\n\\(D_i(Z)\\) es el indicador de cumplir, dada la asignación \\(Z\\)\nCon cumplimiento perfecto tendríamos \\(D_i(Z)=Z_i\\)\nEn general, hay asignados que no cumplen y no asignados que cumplen\n\\(Y_i(Z,D)\\) es la variable de interés de \\(i\\)\n\\(Y_i(Z,D)\\) y \\(D_i(Z)\\) son resultados potenciales"
  },
  {
    "objectID": "diapositivas/late.html#supuestos",
    "href": "diapositivas/late.html#supuestos",
    "title": "Inferencia Causal 2025",
    "section": "Supuestos",
    "text": "Supuestos\nSupuesto 1: Stable Unit Treatment Value Assumption (SUTVA)\n\nEste supuesto indica que los resultados potenciales de \\(i\\) no están correlacionados con los de los otros individuos\nPor tanto podemos escribir \\(Y_i(Z,D)=Y_i(Z_i,D_i)\\) y \\(D_i(Z)=D_i(Z_i)\\)\n\nSupuesto 2: asignación aleatoria\n\nLa asignación de \\(Z_i\\) es aleatoria, es decir, \\(P(Z=C)=P(Z=C')\\) para todo \\(C\\) y \\(C'\\)\n\n\n\nLos supuestos 1 y 2 nos permiten identificar los efectos causales de \\(Z\\) en \\(Y\\) y de \\(Z\\) en \\(D\\) calculando diferencias de medias por grupos de \\(Z\\):\n\n\\(ITT_Y\\) comparar las medias de \\(y\\) entre quienes \\(Z=1\\) y quienes \\(Z=0\\)\n\\(ITT_D\\) comparar las medias de \\(D\\) entre quienes \\(Z=1\\) y quienes \\(Z=0\\)\n\n\\(ITT\\) se conoce como intención a tratar o intention to treat"
  },
  {
    "objectID": "diapositivas/late.html#parada-para-reflexionar",
    "href": "diapositivas/late.html#parada-para-reflexionar",
    "title": "Inferencia Causal 2025",
    "section": "Parada para reflexionar",
    "text": "Parada para reflexionar\n\nHasta ahora el supuesto crítico es la asignación aleatoria de \\(Z\\)\n\\(D_i\\) puede no serlo y, en general, no lo es\nPor tanto, una comparación de \\(y\\) entre grupos de \\(D\\) es inapropiada\nNecesitamos algunos supuestos para decir algo del efecto causal de \\(D\\) sobre \\(Y\\)"
  },
  {
    "objectID": "diapositivas/late.html#más-supuestos",
    "href": "diapositivas/late.html#más-supuestos",
    "title": "Inferencia Causal 2025",
    "section": "Más supuestos",
    "text": "Más supuestos\nSupuesto 3: restricción de exclusión\n\\[Y(Z,D)=Y(Z',D)\\quad \\forall \\quad Z,Z',D\\]\n\nEste supuesto implica que podemos escribir:\n\n\\[Y_i(1,d)=Y_i(0,d) \\quad d=\\{0,1\\}\\]\n\nEs decir, resuleve el problema contrafactual\n\n\n\nCon el supuesto 3 podemos escribir: \\[Y(D)=Y(Z,D)=Y(Z',D)\\quad \\forall \\quad Z,Z',D\\]\n\n\n\n\nY por el supuesto 1: \\[Y_i(D_i)=Y_i(Z,D)\\]"
  },
  {
    "objectID": "diapositivas/late.html#más-supuestos-1",
    "href": "diapositivas/late.html#más-supuestos-1",
    "title": "Inferencia Causal 2025",
    "section": "Más supuestos",
    "text": "Más supuestos\nSupuesto 4: el efecto causal promedio de \\(Z\\) sobre \\(D\\) es distinto de cero\n\nEsto es, \\(E(D_i(1)-D_i(0))\\neq0\\)\nEn otras palabras, la asignación tiene efecto sobre el cumplimiento\n\n\nSupuesto 5: monotonicidad \\[D_i(1)\\geq D_i(0) \\quad \\forall\\quad i=1,\\ldots N\\]\n\nEste supuesto simplemente dice que no hay un individuo que:\n\nCuando se le asigna, no cumple\nCuando no se le asigna, cumple\n\nNoten que este supuesto se debe pensar en términos contrafactuales\nA un individuo que no cumple cuando se le asigna y cumple cuando no se le asigna se le conoce como retador o defier"
  },
  {
    "objectID": "diapositivas/late.html#variable-instrumental",
    "href": "diapositivas/late.html#variable-instrumental",
    "title": "Inferencia Causal 2025",
    "section": "Variable instrumental",
    "text": "Variable instrumental\n\n\\(Z\\) es una variable instrumental para el efecto causal de \\(D\\) sobre \\(Y\\) si se cumplen los supuestos 1 al 5"
  },
  {
    "objectID": "diapositivas/late.html#interpretación-del-estimador-de-vi",
    "href": "diapositivas/late.html#interpretación-del-estimador-de-vi",
    "title": "Inferencia Causal 2025",
    "section": "Interpretación del estimador de VI",
    "text": "Interpretación del estimador de VI\n\nComencemos escribiendo el efecto causal de \\(Z\\) en \\(Y\\), que por el supuesto de exclusión de \\(Z\\) es:\n\n\\[\n\\begin{aligned}\nY_i(1,D_i(1))-Y_i(0,D_i(0))=\\underbrace{Y_i(D_i(1))-Y_i(D_i(0))}_{A} \\\\\n\\end{aligned}\n\\]\n\n\nNotemos que el lado derecho, \\(A\\), puede calcularse siguiendo la notación de resultados potenciales: \\[\n\\begin{aligned}\nY(D)&=Y(0)+D(Z)(Y(1)-Y(0)) \\\\\nD(Z)&=D(0)+Z(D(1)-D(0))\\\\\n\\end{aligned}\n\\]\n\n\n\n\nSustituyendo \\(D\\) en \\(Y\\): \\[\n\\begin{aligned}\nY(D(Z))&=Y(0)+(D(0)+Z(D(1)-D(0)))(Y(1)-Y(0)) \\\\\n&=Y(0)D(0)(Y(1)-Y(0))+Z(D(1)-D(0))(Y(1)-Y(0))\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "diapositivas/late.html#interpretación-del-estimador-de-vi-1",
    "href": "diapositivas/late.html#interpretación-del-estimador-de-vi-1",
    "title": "Inferencia Causal 2025",
    "section": "Interpretación del estimador de VI",
    "text": "Interpretación del estimador de VI\n\nPodemos evaluar entonces los dos valores de \\(Z\\) y obtener:\n\n\\[\n\\begin{aligned}\nY(D(1))&=Y(0)+D(1)(Y(1)-Y(0)) \\\\\nY(D(0))&=Y(0)+D(0)(Y(1))-Y(0) \\\\\n\\end{aligned}\n\\]\n\n\nY entonces: \\[\n\\begin{aligned}\nA&=Y_i(D_i(1))-Y_i(D_i(0)) \\\\\n&=(Y_i(1)-Y_i(0))(D_i(1)-D_i(0))\\\\\n\\end{aligned}\n\\]\n\n\n\n\nEs decir, el efecto causal de \\(Z\\) sobre \\(Y\\) para \\(i\\) es el producto del efecto causal de \\(D\\) sobre \\(Y\\) y del efecto causal de \\(Z\\) sobre \\(D\\):\n\n\\[\n\\underbrace{Y_i(1,D_i(1))-Y_i(0,D_i(0))}_B=(Y_i(1)-Y_i(0))(D_i(1)-D_i(0))\n\\]"
  },
  {
    "objectID": "diapositivas/late.html#interpretación-causal-del-estimador-de-vi",
    "href": "diapositivas/late.html#interpretación-causal-del-estimador-de-vi",
    "title": "Inferencia Causal 2025",
    "section": "Interpretación causal del estimador de VI",
    "text": "Interpretación causal del estimador de VI\n\nConsideremos ahora \\(B\\) y obtengamos el valor esperado:\n\n\\[\n\\begin{aligned}\nE(Y_i(1,D_i(1))-Y_i(0,D_i(0)))&=E(Y_i(1)-Y_i(0))(D_i(1)-D_i(0))\\\\\n&=E(Y_i(1)-Y_i(0)|D_i(1)-D_i(0)=1)P(D_i(1)-D_i(0)=1)\\\\\n&+E(Y_i(1)-Y_i(0)|D_i(1)-D_i(0)=0)P(D_i(1)-D_i(0)=0)\\\\\n&+E(Y_i(1)-Y_i(0)|D_i(1)-D_i(0)=-1)P(D_i(1)-D_i(0)=-1)\\\\\n\\end{aligned}\n\\]\n\n\nLa intuición de este valor esperado es obtener el efecto en la variable de interés bajo los distintos posibles efectos de \\(Z\\) sobre \\(D\\)\nEl segundo término de la suma es cero y corresponde a aquellos para quienes la asignación no modificó el cumplimento, por lo que \\(E(Y_i(1)-Y_i(0)|D_i(1)-D_i(0)=0)=0\\)\nUsando el supuesto 5 de monotonicidad, sabemos \\(D_i(1)-D_i(0)\\) es igual a uno o cero, es decir, \\(P(D_i(1)-D_i(0)=-1)=0\\)"
  },
  {
    "objectID": "diapositivas/late.html#interpretación-causal-del-estimador-de-vi-1",
    "href": "diapositivas/late.html#interpretación-causal-del-estimador-de-vi-1",
    "title": "Inferencia Causal 2025",
    "section": "Interpretación causal del estimador de VI",
    "text": "Interpretación causal del estimador de VI\n\nPor tanto:\n\n\\[\n\\begin{aligned}\nE(Y_i(1,D_i(1))-Y_i(0,D_i(0)))=E(Y_i(1)-Y_i(0)|D_i(1)-D_i(0)=1)P(D_i(1)-D_i(0)=1)\n\\end{aligned}\n\\]\n\n\nEs decir, el efecto causal promedio de \\(Z\\) sobre \\(Y\\) es igual al producto del efecto causal promedio de \\(D\\) sobre \\(Y\\) en aquellos individuos que cuando se les asigna cumplen y cuando no se les asigna no cumplen, \\(D_i(0)=0\\) y \\(D_i(1)=1\\), y la proporción de estos individuos en la población"
  },
  {
    "objectID": "diapositivas/late.html#interpretación-causal-del-estimador-de-vi-2",
    "href": "diapositivas/late.html#interpretación-causal-del-estimador-de-vi-2",
    "title": "Inferencia Causal 2025",
    "section": "Interpretación causal del estimador de VI",
    "text": "Interpretación causal del estimador de VI\nProposición 1 en Angrist, Imbens & Rubin (1996): interpretación causal del estimador de VI\n\nSi los supuestos 1 a 5 se cumplen, el estimador de VI es:\n\n\\[E(Y_i(1)-Y_i(0)|D_i(1)-D_i(0)=1)=\\frac{E(Y_i(D_i(1),1))-Y_i(D_i(0),0)}{E(D_i(1)-D_i(0)}=\\lambda_{LATE}\\]\n\nAngrist y coautores llaman a este parámetro el efecto local promedio del tratamiento o LATE\nEl LATE es el efecto causal promedio del tratamiento en un conjunto de individuos cuyo estatus de tratamiento puede ser modificado por la asignación aleatoria\nA estos individuos se les conoce como cumplidores o compliers"
  },
  {
    "objectID": "diapositivas/late.html#tipos-de-individuos",
    "href": "diapositivas/late.html#tipos-de-individuos",
    "title": "Inferencia Causal 2025",
    "section": "Tipos de individuos",
    "text": "Tipos de individuos\n\nHay cuatro tipos de individuos:\n\n\n\n\n\n\n\n\n\n\n\n\nTipos de individuos\n\n\n\n\n\n\n\n\n\n\n\n\\(D_i(0)=0\\)\n\\(D_i(0)=1\\)\n\n\n\\(D_i(1)=0\\)\n\\(Y_i(1,0)-Y_i(0,0)=0\\)\n\\(Y_i(1,0)-Y_i(0,1)=-(Y_i(1)-Y_i(0))\\)\n\n\n\nNunca cumplidor\nRetador\n\n\n\n\n\n\n\n\n\n\n\n\n\\(D_i(1)=1\\)\n\\(Y_i(1,1)-Y_i(0,0)=Y_i(1)-Y_i(0)\\)\n\\(Y_i(1,1)-Y_i(0,1)=0\\)\n\n\n\nCumplidor\nSiempre adoptador\n\n\n\nNota:\n\n\n\n\n Adaptado de la tabla 1 en Angrist, Imbens & Rubin (1996)."
  },
  {
    "objectID": "diapositivas/late.html#tipos-de-individuos-1",
    "href": "diapositivas/late.html#tipos-de-individuos-1",
    "title": "Inferencia Causal 2025",
    "section": "Tipos de individuos",
    "text": "Tipos de individuos\n\nLos cumplidores cumplen con el tratamiento si se les asigna y no lo cumplen si no se les asigna\n\\(Z\\) es independiente de \\(D\\) para los nunca cumplidores y los siempre adoptadores y el efecto causal es 0 para ambos\nLos retadores hacen lo contrario a lo que les es asignado\n\nEl supuesto de monotonicidad descarta la existencia de retadores para la identificación del LATE\nEn la práctica, esperamos que sean pocos tal que podamos ignorarlos\n\nA la suma de nunca cumplidores, siempre adoptadores y retadores se le conoce como no cumplidores"
  },
  {
    "objectID": "diapositivas/late.html#late-y-tt",
    "href": "diapositivas/late.html#late-y-tt",
    "title": "Inferencia Causal 2025",
    "section": "LATE y TT",
    "text": "LATE y TT\n\nEn general el LATE y el TT (TOT o ATET) difieren\nPero recordemos que \\(TT=E(y_{1i}-y_{0i}|D_i=1)\\)\nNoten que en el conjunto con \\(D_i=1\\) se encuentran los cumplidores y los siempre adoptadores\nSi podemos asegurar que no hay siempre adoptadores, el LATE y el TT son iguales"
  },
  {
    "objectID": "diapositivas/late.html#resumiendo",
    "href": "diapositivas/late.html#resumiendo",
    "title": "Inferencia Causal 2025",
    "section": "Resumiendo",
    "text": "Resumiendo\n\nHemos mostrado que el efecto promedio de \\(Z\\) sobre \\(Y\\) es proporcional al efecto de \\(D\\) sobre \\(Y\\) para los cumplidores\nPor el supuesto 4, sabemos que la proporción de cumplidores es igual al efecto de \\(Z\\) sobre \\(D\\)\nDado que \\(Z\\) se asigna aleatoriamente, podemos estimar los dos ITT por separado para obtener \\(\\lambda=\\frac{ITT_Y}{ITT_D}\\)\n\n\n\nEn la práctica de evaluación recurrimos a la econometría con variables instrumentales"
  },
  {
    "objectID": "diapositivas/late.html#terminología",
    "href": "diapositivas/late.html#terminología",
    "title": "Inferencia Causal 2025",
    "section": "Terminología",
    "text": "Terminología\n\nPrimera etapa: es el efecto causal de la asignación sobre el cumplimento\n\n\\[\\phi=E(D_i|Z_i=1)-E(D_i|Z_i=0)\\]\n\nForma reducida: es la diferencia en \\(y\\) entre grupos de asignación\n\n\\[\\rho=E(y_i|Z_i=1)-E(y_i|Z_i=0)\\]\n\nLATE: es la diferencia en \\(y\\) entre a quienes se les asigna el tratamiento y quienes no, dividida por la diferencia en cumplimiento entre a quienes se les asigna el tratamiento y quienes no\n\n\\[\\lambda_{LATE}=\\frac{\\rho}{\\phi}\\]"
  },
  {
    "objectID": "diapositivas/late.html#variables-instrumentales-en-investigación-criminológica",
    "href": "diapositivas/late.html#variables-instrumentales-en-investigación-criminológica",
    "title": "Inferencia Causal 2025",
    "section": "Variables instrumentales en investigación criminológica",
    "text": "Variables instrumentales en investigación criminológica\n\nAngrist (2006) estudia un experimento bastante particular: aleatorizar la respuesta policíaca\n¿En qué consistió la intervención?\n\n\n\n\\(y_i\\): tasa de reincidencia en conductas de violencia doméstica\n\\(Z_i=\\begin{cases} 1\\quad \\text{si apercibido} \\\\ 0\\quad \\text{otro caso}\\ \\end{cases}\\)\n\n\n\n\nSe muestra como el ITT puede no reflejar la efectividad de la intervención debido al efecto de dilusión provocado, en este caso, por desviaciones con respecto a la forma de enfrentar un episodio policíaco"
  },
  {
    "objectID": "diapositivas/late.html#diferencias-en-las-respuestas-efectivas",
    "href": "diapositivas/late.html#diferencias-en-las-respuestas-efectivas",
    "title": "Inferencia Causal 2025",
    "section": "Diferencias en las respuestas efectivas",
    "text": "Diferencias en las respuestas efectivas\n\n\n\n\n\n\n\n\n\n\n\n\nTratamiento asignado y recibido en casos de violencia doméstica\n\n\n\n\n\nTramiento recibido:\n\n\n\n\n\n\n\n\n\n\n\n\n\nArrestado\nApercibido\n\n\n\nTratamiento asignado:\n\n\nTotal\n\n\nArrestar\n98.91 (91)\n1.09 (1)\n29.3 (92)\n\n\nApercibir\n20.27 (45)\n79.73 (177)\n70.7 (222)\n\n\nTotal\n43.1 (136)\n56.69 (178)\n100 (314)\n\n\n\nNota:  Adaptado de la tabla 1 en Angrist (2006).\n\n\n\n\n\n\n\n\n\n\n\nEn el estudio original, lo que llamamos apercibir tuvo en realidad dos componentes: aconsejar y separar, pero para facilitar el análisis usaremos solo arrestar por un lado y apercibir por el otro\n¿Qué observamos sobre a las desviaciones con respecto al tratamiento asignado?"
  },
  {
    "objectID": "diapositivas/late.html#diferencias-en-las-respuestas-efectivas-1",
    "href": "diapositivas/late.html#diferencias-en-las-respuestas-efectivas-1",
    "title": "Inferencia Causal 2025",
    "section": "Diferencias en las respuestas efectivas",
    "text": "Diferencias en las respuestas efectivas\n\nNoten que cuando el tratamiento asignado era arrestar, efectivamente se arrestó al 98.91% de los individuos\nEn cambio, noten que 20.27 % de los 222 asignados a ser apercibidos fueron en efecto arrestados\n¿Cómo ocurre el sesgo de selección en este caso?"
  },
  {
    "objectID": "diapositivas/late.html#sesgo-de-selección",
    "href": "diapositivas/late.html#sesgo-de-selección",
    "title": "Inferencia Causal 2025",
    "section": "Sesgo de selección",
    "text": "Sesgo de selección\n\nAlgunos individuos se comportaron violentos, por lo que fueron arrestados a pesar de ser asignados a apercibimiento\nPor tanto, si comparamos \\(y\\) entre aquellos individuos apercibidos y no apercibidos, no tomamos en cuenta que aquellos no apercibidos (por tanto, arrestados) pudieran ser más violentos, sobrestimando el efecto de la política de apercibimiento"
  },
  {
    "objectID": "diapositivas/late.html#late",
    "href": "diapositivas/late.html#late",
    "title": "Inferencia Causal 2025",
    "section": "LATE",
    "text": "LATE\n\nLa primera etapa es el efecto causal en la probabilidad de recibir el tratamiento de apercibimiento por el hecho de haber sido asignado a ese tratamiento: \\(E(D_i|Z_i=1)-E(D_i|Z_i=0)=0.797-0.011=0.786\\)\nLa forma reducida es el efecto causal de la asignación al tratamiento sobre la tasa de reincidencia: \\(E(y_i|Z_i=1)-E(y_i|Z_i=0)=0.211-0.097=0.114\\)\n\n\n\nEl ITT ignora el hecho de que algunos asignados a apercibimiento fueron arrestados\nSabemos que el LATE está dado por \\(\\lambda_{LATE}=\\frac{ITT_y}{ITT_D}=\\frac{0.114}{0.786}=0.145\\)\nLos datos de los autores reportan que si nos fijáramos solo en las diferencias por tipo de tratamiento obtendríamos, \\(E(y_i|D_i=1)-E(y_i|D_i=0)=0.216-0.129=0.087\\), es decir, casi la mitad del LATE\nPero como \\(D\\) no es aleatoria, dicha comparación no es correcta"
  },
  {
    "objectID": "diapositivas/late.html#motivación-con-un-estadístico-de-wald",
    "href": "diapositivas/late.html#motivación-con-un-estadístico-de-wald",
    "title": "Inferencia Causal 2025",
    "section": "Motivación con un estadístico de Wald",
    "text": "Motivación con un estadístico de Wald\n\nPensemos en un modelo con efectos constantes de tratamiento: \\(y_{1i}-y_{0i}=\\lambda\\)\nLa variable de resultados está determinada por \\(y_{0i}=\\alpha+\\varepsilon_i\\), donde \\(\\alpha=E(y_{0i})\\)\nEntonces, el modelo de resultados potenciales es:\n\n\\[y_i=\\alpha+\\lambda D_i+\\varepsilon_i\\]\n\nSi \\(D_i\\) no es independiente de \\(y_{0i}\\), es decir, \\(y_{0i}\\) no es independiente del error, entonces una diferencia de medias entre grupos de \\(D\\) no produce un estimador consistente de \\(\\lambda\\)"
  },
  {
    "objectID": "diapositivas/late.html#motivación-con-un-estadístico-de-wald-1",
    "href": "diapositivas/late.html#motivación-con-un-estadístico-de-wald-1",
    "title": "Inferencia Causal 2025",
    "section": "Motivación con un estadístico de Wald",
    "text": "Motivación con un estadístico de Wald\n\nAhora supongamos que tenemos un instrumento \\(z_i\\) tal que \\(z_i\\perp y_i\\), es decir, \\(E(\\varepsilon_i|z_i)=0\\)\n\n\n\nEvaluemos la esperanza de \\(y_i\\) cuando \\(z_i=1\\) y cuando \\(z_i=0\\): \\[\n\\begin{aligned}\nE(y_i|z_i=1)&=\\alpha+\\lambda E(D_i| z_i=1) \\\\\nE(y_i|z_i=0)&=\\alpha+\\lambda E(D_i| z_i=0) \\\\\n\\end{aligned}\n\\]\nRestando: \\[E(y_i|z_i=1)-E(y_i|z_i=0)=\\lambda(E(D_i| z_i=1)-E(D_i| z_i=0))\\]\nY despejando obtenemos \\[\\lambda=\\frac{E(y_i|z_i=1)-E(y_i|z_i=0)}{E(D_i| z_i=1)-E(D_i| z_i=0)}\\] que es conocido como un estadístico de Wald"
  },
  {
    "objectID": "diapositivas/late.html#mínimos-cuadrados-en-dos-etapas-mc2e",
    "href": "diapositivas/late.html#mínimos-cuadrados-en-dos-etapas-mc2e",
    "title": "Inferencia Causal 2025",
    "section": "Mínimos cuadrados en dos etapas (MC2E)",
    "text": "Mínimos cuadrados en dos etapas (MC2E)\n\nEn la práctica, podemos plantear un modelo econométrico en dos etapas:\nModelo estructural\n\n\\[y_i=X_i'\\beta+\\lambda D_i+\\varepsilon_i\\]\n\n\nPrimera etapa\n\n\\[D_i=X_i'\\phi_0+\\phi_1z_i+\\eta_i\\] donde \\(\\phi_i\\) es el efecto causal de la asignación sobre el cumplimiento - Cuado \\(D_i\\) y \\(z_i\\) son ambas dicotómicas, \\(\\phi_1\\) da la proporción de la población que son cumplidores"
  },
  {
    "objectID": "diapositivas/late.html#mínimos-cuadrados-en-dos-etapas-mc2e-1",
    "href": "diapositivas/late.html#mínimos-cuadrados-en-dos-etapas-mc2e-1",
    "title": "Inferencia Causal 2025",
    "section": "Mínimos cuadrados en dos etapas (MC2E)",
    "text": "Mínimos cuadrados en dos etapas (MC2E)\n\nPodemos concebir el problema como uno en el que primero se estima la primera etapa y se sustituyen los valores ajustados de \\(D_i\\) en el modelo estructural\nSustituyendo la primera etapa en el modelo estructural \\[y_i=X_i'\\beta+\\lambda \\hat{D}_i+\\varepsilon_i\\]\n\n\n\nEsta es la forma de pensar el procedimiento, pero en la práctica nunca hacemos esto manualmente\n\nNoten que \\(\\hat{D}_i\\) es estimada, por lo cual se ignora la variabilidad muestral de la primera etapa y los errores estándar serían inconsistentes\n\n\n\n\n\nNota: el estimador de Wald es igual al estimador de MC2E cuando no hay \\(X\\) y cuando \\(Z\\) y \\(D\\) son binarias"
  },
  {
    "objectID": "diapositivas/late.html#mínimos-cuadrados-en-dos-etapas-mc2e-2",
    "href": "diapositivas/late.html#mínimos-cuadrados-en-dos-etapas-mc2e-2",
    "title": "Inferencia Causal 2025",
    "section": "Mínimos cuadrados en dos etapas (MC2E)",
    "text": "Mínimos cuadrados en dos etapas (MC2E)\n\nForma reducida\n\n\\[\n\\begin{aligned}\ny_i&=X_i'\\beta+\\lambda(X_i'\\phi_0+\\phi_1z_1+\\eta_i)+\\varepsilon_i \\\\\n&=X_i'\\rho_0+\\rho_1z_i+\\nu_i\n\\end{aligned}\n\\] donde \\(\\rho_1=\\lambda\\phi_1\\) es el coeficiente de forma reducida sobre la variable de asignación\n\n\nNoten que esto implica que \\(\\lambda=\\rho_1/\\phi_1\\)\nEs decir, \\(\\lambda_{MC2E}\\) puede interpretarse como la versión reescalada del coeficiente de forma reducida usando el efecto causal de la primera etapa para reescalar"
  },
  {
    "objectID": "diapositivas/late.html#efectos-estimados",
    "href": "diapositivas/late.html#efectos-estimados",
    "title": "Inferencia Causal 2025",
    "section": "Efectos estimados",
    "text": "Efectos estimados\n\nRegresando a los resultados del experimento, ahora con econometría\n\nPrimera etapa\n\nVersión corta:\n\n\\[apercibido_i=\\phi_0+\\phi_1T_i+\\eta_i\\]\n\nCon controles: \\[apercibido_i=\\phi_0+\\phi_1T_i+X_i'\\Phi +\\eta_i\\]\nNoten que el 0.786 es exactamente lo que se encontraba al hacer las diferencias de medias\n\nForma reducida\n\nTambién conocido como ITT\n\n\\[reincidencia_i=\\rho_0+\\rho_1T_i+\\nu_i\\]"
  },
  {
    "objectID": "diapositivas/late.html#efectos-estimados-1",
    "href": "diapositivas/late.html#efectos-estimados-1",
    "title": "Inferencia Causal 2025",
    "section": "Efectos estimados",
    "text": "Efectos estimados\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrimera etapa y forma reducida\n\n\n\n\n\nPrimera etapa\n\n\nForma reducida\n\n\n\n\n\nVariable dep.: fue apercibido\n\n\nVariable dep.: reincidencia\n\n\n\n\n(1)\n(2)*\n(3)\n(4)*\n\n\n\n\nAsignado a ser apercibido (\\(T\\))\n0.786 (0.043)\n0.733 (0.043)\n0.114 (0.047)\n0.108 (0.041)\n\n\nArma\n\n-0.064 (0.045)\n\n-0.004 (0.042)\n\n\nInfluencia químicos\n\n-0.088 (0.040)\n\n0.052 (0.038)\n\n\nMedia variable dep.\n0.567\n0.567\n0.178\n0.178\n\n\n\nNota:  Tabla 2 en Angrist (2006). * Indica que se incluyen como variables de control indicadoras para año, trimestre, raza no blanca y raza mixta.\n\n\n\n\n\n\n\n\n\n\n\n\nHabíamos obtenido antes la columna (1), pero como una diferencia de medias: \\(E(D_i|Z_i=1)-E(D_i|Z_i=0)=0.797-0.011=0.786\\)\nMientras que también habíamos encontrado (3): \\(E(y_i|Z_i=1)-E(y_i|Z_i=0)=0.211-0.097=0.0.114\\)"
  },
  {
    "objectID": "diapositivas/late.html#efectos-estimados-2",
    "href": "diapositivas/late.html#efectos-estimados-2",
    "title": "Inferencia Causal 2025",
    "section": "Efectos estimados",
    "text": "Efectos estimados\nEfecto del tratamiento\n\nNoten que con nuestro estimador de MC2E obtenemos exactamente lo que antes habíamos calculado como \\(\\lambda_{LATE}=\\frac{ITT_y}{ITT_D}=\\frac{E(y_i|Z_i=1)-E(y_i|Z_i=0)}{E(D_i|Z_i=1)-E(D_i|Z_i=0)}=0.145\\)\nVean que al estimar la ecuación estructural por MCO obtenemos un coeficiente cercano a 0.070\nMás aún, sabemos que el coeficiente de MCO es inconsistente"
  },
  {
    "objectID": "diapositivas/late.html#efectos-estimados-3",
    "href": "diapositivas/late.html#efectos-estimados-3",
    "title": "Inferencia Causal 2025",
    "section": "Efectos estimados",
    "text": "Efectos estimados\n\n\n\n\n\n\n\n\n\n\n\n\n\nImpactos de ser apercibido en la reincidencia (MCO y LATE)\n\n\n\n\n\nMCO\n\n\nVI/MC2E\n\n\n\n\n\nVariable dep.: reincidencia\n\n\n\n\n(1)\n(2)*\n(3)\n(4)*\n\n\n\n\nApercibido\n0.087 (0.044)\n0.070 (0.038)\n0.145 (0.060)\n0.140 (0.053)\n\n\nArma\n\n0.010 (0.043)\n\n0.005 (0.043)\n\n\nInfluencia químicos\n\n0.057 (0.039)\n\n0.064 (0.039)\n\n\n\nNota:  Tabla 3 en Angrist (2006). * Indica que se incluyen como variables de control indicadoras para año, trimestre, raza no blanca y raza mixta.\n\n\n\n\n\n\n\n\n\n\n\n\nUsando el estimador de MC2E obtenemos exactamente lo que antes habíamos calculado como \\(\\lambda_{LATE}=\\frac{ITT_y}{ITT_D}=\\frac{E(y_i|Z_i=1)-E(y_i|Z_i=0)}{E(D_i|Z_i=1)-E(D_i|Z_i=0)}=0.145\\)\nAl estimar la ecuación estructural por MCO obtenemos un coeficiente cercano a 0.070\nPero sabemos que el coeficiente de MCO es inconsistente"
  },
  {
    "objectID": "diapositivas/late.html#late-es-igual-atet-en-este-caso",
    "href": "diapositivas/late.html#late-es-igual-atet-en-este-caso",
    "title": "Inferencia Causal 2025",
    "section": "LATE es igual ATET en este caso",
    "text": "LATE es igual ATET en este caso\n\nNoten que este estudio tiene lo que se conoce como no cumplidores de un solo lado\n\n\n\n\n\n\n\n\n\n\n\n\nTipos de individuos\n\n\n\n\n\n\n\n\n\n\n\n\\(D_i(0)=0\\)\n\\(D_i(0)=1\\)\n\n\n\\(D_i(1)=0\\)\n\\(Y_i(1,0)-Y_i(0,0)=0\\)\n\\(Y_i(1,0)-Y_i(0,1)=-(Y_i(1)-Y_i(0))\\)\n\n\n\nNunca cumplidor\nRetador\n\n\n\n\n\n\n\n\n\n\n\n\n\\(D_i(1)=1\\)\n\\(Y_i(1,1)-Y_i(0,0)=Y_i(1)-Y_i(0)\\)\n\\(Y_i(1,1)-Y_i(0,1)=0\\)\n\n\n\nCumplidor\nSiempre adoptador\n\n\n\nNota:\n\n\n\n\n Adaptado de la tabla 1 en Angrist, Imbens & Rubin (1996).\n\n\n\n\n\n\n\n\n\n\nCuando la asignación es apercibir, en el 20.27% de los casos la acción fue arrestar y en el 79.73% efectivamente fue apercibir\nEn cambio, cuando se indica no apercibir, es decir, arrestar, la adopción es casi perfecto (salvo un caso)\n\n\n\nEn otras palabras, en este caso no hay siempre cumplidores\nNo hay individuos que hayan sido apercibidos independientemente de la asignación"
  },
  {
    "objectID": "diapositivas/late.html#late-es-igual-atet-en-este-caso-1",
    "href": "diapositivas/late.html#late-es-igual-atet-en-este-caso-1",
    "title": "Inferencia Causal 2025",
    "section": "LATE es igual ATET en este caso",
    "text": "LATE es igual ATET en este caso\n\nRecordemos que el grupo de quienes reciben el tratamiento está compuesto de los cumplidores y los siempre adoptadores\nEn este caso en particular: \\[\\lambda_{LATE}=E(y_{1i}-y_{0i}|C_i=1)=E(y_{1i}-y_{0i}|D_i=1)=ATET\\]\n\n\n\nEsto ocurre en los casos en que:\n\nAlgunos de los asignados al tratamiento, \\(z_i=1\\) lo reciben mientras otros no\nNadie de los asignados al control, \\(z_i=0\\) tiene acceso al tratamiento"
  },
  {
    "objectID": "diapositivas/multiples-hipotesis.html#hipótesis-múltiples-2",
    "href": "diapositivas/multiples-hipotesis.html#hipótesis-múltiples-2",
    "title": "Inferencia Causal 2025",
    "section": "Hipótesis múltiples",
    "text": "Hipótesis múltiples\n\nError tipo I: concluir que hay un efecto de tratamiento cuando la \\(H_0\\) es verdadera, es decir, cuando \\(H_0:\\;\\beta_i=0\\)\nEn una investigación fijamos \\(\\alpha\\), la probabilidad de rechazar \\(H_0\\) cuando \\(H_0\\) es cierto\nEn economía trabajamos con \\(\\alpha=0.05\\) o \\(\\alpha=0.01\\)\nEl problema con probar múltiples hipótesis es que inflamos la tasa de error tipo I\n\n\n\nPor ejemplo, si tenemos 100 hipótesis y si usamos un valor estándar de \\(\\alpha=0.05\\), esperaríamos rechazar 5 hipótesis por suerte"
  },
  {
    "objectID": "diapositivas/multiples-hipotesis.html#hipótesis-múltiples-3",
    "href": "diapositivas/multiples-hipotesis.html#hipótesis-múltiples-3",
    "title": "Inferencia Causal 2025",
    "section": "Hipótesis múltiples",
    "text": "Hipótesis múltiples\n\n\n\nSi realizamos una prueba, la probabilidad de cometer un error es \\(\\alpha\\) y la de no cometer un error es \\(1-\\alpha\\)\nSi realizamos \\(n\\) pruebas, la probabilidad de no cometer un error es \\((1-\\alpha)^n\\) y la probabilidad de cometer al menos un error es \\(1-(1-\\alpha)^n\\)\nEs decir, la probabilidad de cometer al menos un error se incrementa exponencialmente\n\n\n\nalpha=0.05\nn &lt;- 1:1000\np &lt;- 1-(1-alpha)^n\n\nplot(p,n, xlab=\"n\", ylab=\"1-(1-alpha)^n\")"
  },
  {
    "objectID": "diapositivas/multiples-hipotesis.html#hipótesis-múltiples-4",
    "href": "diapositivas/multiples-hipotesis.html#hipótesis-múltiples-4",
    "title": "Inferencia Causal 2025",
    "section": "Hipótesis múltiples",
    "text": "Hipótesis múltiples\n\nDos estrategias que abordaremos son:\n\nControlar o ajustar \\(\\alpha\\)\nCrear índices que agreguen varias variables"
  },
  {
    "objectID": "diapositivas/multiples-hipotesis.html#control-del-error-tipo-i-1",
    "href": "diapositivas/multiples-hipotesis.html#control-del-error-tipo-i-1",
    "title": "Inferencia Causal 2025",
    "section": "Control del error tipo I",
    "text": "Control del error tipo I\n\nPopper (1995), Multiple Hypothesis Testing\nDefinimos familias de variables\nHaremos el ajuste hacia adentro de estas familias\nAntes habíamos estudiado de Banerjee et al. (2015)\n\nSeguridad alimentaria\nConsumo\nActivos\nSalud mental\n\nDentro de cada familia tenemos \\(n\\) hipótesis \\(H_i\\), con un valor \\(p\\) asociado \\(p_i\\)\nRecordemos que \\(p_i\\) es la probabilidad de que el estadístico \\(T_i\\) exceda el valor teórico \\(t_i\\)\nOrdenamos las hipótesis de menor a mayor,con \\(p_1\\) siendo el valor más pequeño: \\(p_1\\leq p_2\\ldots \\leq p_n\\)"
  },
  {
    "objectID": "diapositivas/multiples-hipotesis.html#método-de-bonferroni",
    "href": "diapositivas/multiples-hipotesis.html#método-de-bonferroni",
    "title": "Inferencia Causal 2025",
    "section": "Método de Bonferroni",
    "text": "Método de Bonferroni\n\nEl método propuesto por Bonferroni controla la tasa de error por familia (FEWR por family-wise error rate) definida como la probabilidad de cometer al menos un error tipo I\n\n\n\nConsiste en rechazar \\(H_i\\) si \\(p_i\\leq \\alpha_i\\), donde \\(\\alpha_i\\) se escoge de forma que \\(\\sum_i\\alpha_i=\\alpha\\)\nUsualmente se hace \\(\\alpha_i=\\frac{\\alpha}{n}\\)\n\n\n\n\nPor ejemplo, con dos tests y \\(\\alpha=0.05\\), \\(\\alpha_i^B=0.025\\)\n\n\n\n\nNoten que esta corrección es bastante conservadora\nTambién podemos ver este test como crear unos valores \\(p^B\\) ajustados: \\(p_i^B=p_i\\times n\\)"
  },
  {
    "objectID": "diapositivas/multiples-hipotesis.html#por-qué-preocuparnos-por-la-fwer",
    "href": "diapositivas/multiples-hipotesis.html#por-qué-preocuparnos-por-la-fwer",
    "title": "Inferencia Causal 2025",
    "section": "¿Por qué preocuparnos por la FWER?",
    "text": "¿Por qué preocuparnos por la FWER?\n\nLa idea de la FWER tiene sentido si nos preocupa tener incluso un solo falso positivo\nEn la práctica, podemos vivir con algunos falsos positivos"
  },
  {
    "objectID": "diapositivas/multiples-hipotesis.html#método-de-benjamini-y-hochberg",
    "href": "diapositivas/multiples-hipotesis.html#método-de-benjamini-y-hochberg",
    "title": "Inferencia Causal 2025",
    "section": "Método de Benjamini y Hochberg",
    "text": "Método de Benjamini y Hochberg\n\nEste método controla la tasa de falso descubrimiento\nSi \\(V\\) es el número de falsos rechazos (cuando rechazamos la \\(H_0\\) que es verdadera) y si \\(R\\) es el número total de rechazos, entonces \\(Q=V/R\\) es la proporción de falsos rechazos\nAl valor esperado de \\(Q\\) se le conoce como tasa de falsos rechazos (FDR por false discovery rate)\n\n\n\nSea \\(k\\) el más grande de los \\(i\\) tal que \\[p_i\\leq\\frac{i}{n}\\alpha\\] entonces rechazar todos los \\(H_i\\) para \\(i=1,2,\\ldots,k\\)\nEn la práctica usamos R"
  },
  {
    "objectID": "diapositivas/multiples-hipotesis.html#ejemplo-benjamini-hochberg-1995",
    "href": "diapositivas/multiples-hipotesis.html#ejemplo-benjamini-hochberg-1995",
    "title": "Inferencia Causal 2025",
    "section": "Ejemplo: Benjamini & Hochberg (1995)",
    "text": "Ejemplo: Benjamini & Hochberg (1995)\n\n\n\ndata.pvalues&lt;-read_csv(\"./data_benjamini_hochberg.csv\",\n                       locale = locale(encoding = \"latin1\"))  \nn &lt;- 15\nalpha &lt;- 0.05\n\n\n\ndata.pvalues\n\n# A tibble: 15 × 2\n   poriginal hipotesis\n       &lt;dbl&gt;     &lt;dbl&gt;\n 1    0.0001         1\n 2    0.0004         2\n 3    0.0019         3\n 4    0.0095         4\n 5    0.0201         5\n 6    0.0278         6\n 7    0.0298         7\n 8    0.0344         8\n 9    0.0459         9\n10    0.324         10\n11    0.426         11\n12    0.572         12\n13    0.653         13\n14    0.759         14\n15    1             15"
  },
  {
    "objectID": "diapositivas/multiples-hipotesis.html#ejemplo-bonferroni",
    "href": "diapositivas/multiples-hipotesis.html#ejemplo-bonferroni",
    "title": "Inferencia Causal 2025",
    "section": "Ejemplo: Bonferroni",
    "text": "Ejemplo: Bonferroni\n\n\n\n#Bonferroni\ndata.bonferroni &lt;- data.pvalues %&gt;% \n  mutate(bonferroni_alpha=alpha/n) %&gt;% \n  mutate(bonferrini_rechazar=ifelse(poriginal&lt;=bonferroni_alpha,1,0))\n\n\n\ndata.bonferroni\n\n# A tibble: 15 × 4\n   poriginal hipotesis bonferroni_alpha bonferrini_rechazar\n       &lt;dbl&gt;     &lt;dbl&gt;            &lt;dbl&gt;               &lt;dbl&gt;\n 1    0.0001         1          0.00333                   1\n 2    0.0004         2          0.00333                   1\n 3    0.0019         3          0.00333                   1\n 4    0.0095         4          0.00333                   0\n 5    0.0201         5          0.00333                   0\n 6    0.0278         6          0.00333                   0\n 7    0.0298         7          0.00333                   0\n 8    0.0344         8          0.00333                   0\n 9    0.0459         9          0.00333                   0\n10    0.324         10          0.00333                   0\n11    0.426         11          0.00333                   0\n12    0.572         12          0.00333                   0\n13    0.653         13          0.00333                   0\n14    0.759         14          0.00333                   0\n15    1             15          0.00333                   0"
  },
  {
    "objectID": "diapositivas/multiples-hipotesis.html#ejemplo-benjamini-hochberg",
    "href": "diapositivas/multiples-hipotesis.html#ejemplo-benjamini-hochberg",
    "title": "Inferencia Causal 2025",
    "section": "Ejemplo: Benjamini & Hochberg",
    "text": "Ejemplo: Benjamini & Hochberg\n\n\n\n#Benjamini & Hochberg\ndata.bh &lt;- data.pvalues %&gt;% \n  mutate(bh_alpha=alpha*hipotesis/n) %&gt;% \n  mutate(bh_rechazar=ifelse(poriginal&lt;=bh_alpha,1,0))\n\n\n\ndata.bh\n\n# A tibble: 15 × 4\n   poriginal hipotesis bh_alpha bh_rechazar\n       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;\n 1    0.0001         1  0.00333           1\n 2    0.0004         2  0.00667           1\n 3    0.0019         3  0.01              1\n 4    0.0095         4  0.0133            1\n 5    0.0201         5  0.0167            0\n 6    0.0278         6  0.02              0\n 7    0.0298         7  0.0233            0\n 8    0.0344         8  0.0267            0\n 9    0.0459         9  0.03              0\n10    0.324         10  0.0333            0\n11    0.426         11  0.0367            0\n12    0.572         12  0.04              0\n13    0.653         13  0.0433            0\n14    0.759         14  0.0467            0\n15    1             15  0.05              0"
  },
  {
    "objectID": "diapositivas/multiples-hipotesis.html#creación-de-z-scores",
    "href": "diapositivas/multiples-hipotesis.html#creación-de-z-scores",
    "title": "Inferencia Causal 2025",
    "section": "Creación de \\(z\\)-scores",
    "text": "Creación de \\(z\\)-scores\n\nOtra forma comúnmente usada de evitar el problema de las múltiples hipótesis es crear índices\nKling, Liebmand y Katz (2007) proponen el siguiente promedio de los \\(z\\)-score para generar un solo índice\n\nDefinir las familias y las variables que componen cada familia, donde \\(y_{ij}\\) es la \\(j\\)ésima variable en la familia con \\(J\\) variables\nDefinir las variables \\(y_{ij}\\) de tal forma que mayores valores se interpreten como mejora\nCrear \\(z_{ij}\\) como \\(z_{ij}=\\frac{y_{ij}-\\bar{y_j}^C}{sd(y_j)^C}\\sim(0,1)\\), es decir, estandarizar cada una de las \\(J\\) variables usando al grupo de control como referencia\nCrear \\(z_i\\), un solo índice para cada individuo que agregue los \\(J\\) índices creados antes\n\nEl procedimiento descrito en Banerjee et al. (2015) es bastante general, pues incluye el caso donde hay varias rondas de seguimiento y varios países"
  },
  {
    "objectID": "diapositivas/multiples-hipotesis.html#creación-de-z-scores-1",
    "href": "diapositivas/multiples-hipotesis.html#creación-de-z-scores-1",
    "title": "Inferencia Causal 2025",
    "section": "Creación de \\(z\\)-scores",
    "text": "Creación de \\(z\\)-scores\n\nPodemos escribir el índice descrito como\n\\[z_i=\\frac{(\\frac{1}{J}\\sum_j z_{ij})-\\bar{z}_j^C}{sd(z_j^C)}\\]\nEsta transformación tiene la ventaja de que en la siguiente regresión de efecto de tratamiento\n\n\\[z_i=\\alpha+\\beta T_i + X_i'\\gamma+\\varepsilon_i\\]\nel coeficiente \\(\\beta\\) se interpreta como el efecto del tratamiento medido en desviaciones estándar con respecto a la media del grupo de control\n\n\nNoten que todos las variables dentro de la familia pesan igual\nQuizás nos gustaría tomar en cuenta la correlación entre las variables dentro del índice"
  },
  {
    "objectID": "diapositivas/multiples-hipotesis.html#índice-de-anderson",
    "href": "diapositivas/multiples-hipotesis.html#índice-de-anderson",
    "title": "Inferencia Causal 2025",
    "section": "Índice de Anderson",
    "text": "Índice de Anderson\n\nAnderson (2008) propone el siguiente índice, que puede verse como una generalización del de Kling:\n\n\\[\\bar{s}_i=\\frac{1}{W_{i}}\\sum_{j\\in J} w_j z_{ij}\\]\n\n\\(w_j\\) es el peso para la variable \\(j\\) y \\(W_i=\\sum_{j\\in J}w_{j}\\)\nLos pesos son una función de la matriz de covarianzas entre las variables que conforman la familia"
  },
  {
    "objectID": "diapositivas/errores-estandar.html#errores-estándar-robustos",
    "href": "diapositivas/errores-estandar.html#errores-estándar-robustos",
    "title": "Inferencia Causal 2025",
    "section": "Errores estándar robustos",
    "text": "Errores estándar robustos\n\nRecordemos que con errores homocedásticos, la matriz de varianzas del estimador de MCO puede ser estimada como:\n\n\\[\\hat{V}(\\beta_{MCO}^H)=\\hat{\\sigma}^2(X'X)^{-1}\\] donde \\(\\hat{\\sigma}^2=\\frac{1}{N-k}\\hat{u}_i^2\\) y \\(\\hat{u}_i^2=(y_i-X_i'\\hat{\\beta}_{MCO})^2\\)\n\n\nUna primera desviación respecto a los errores clásicos ocurre cuando relajamos el supuesto de homocedasticidad\nEn la clase 3 estudiamos de manera general las propiedades asintóticas del estimador de MCO\nLa varianza asintótica es:\n\n\\[V(\\hat{\\beta}_{MCO}^{R})=(X'X)^{-1}X'\\Omega X(X'X)^{-1}\\]"
  },
  {
    "objectID": "diapositivas/errores-estandar.html#errores-robustos-a-la-heterocedasticidad",
    "href": "diapositivas/errores-estandar.html#errores-robustos-a-la-heterocedasticidad",
    "title": "Inferencia Causal 2025",
    "section": "Errores robustos a la heterocedasticidad",
    "text": "Errores robustos a la heterocedasticidad\n\nUn estimador de la varianza del estimador de MCO que no asume homocedasticidad es el estimador propuesto por White (1980)\nSabemos que la matriz de varianzas del estimador de MCO robusta a la heterocedasticidad es: \\[\\hat{V}(\\beta_{MCO}^R)=(X'X)^{-1}\\left(\\sum_i\\hat{u}_i^2x_ix_i'\\right)(X'X)^{-1}\\]\nAquí un recordatorio de por qué podemos escribir \\(X'uu'X\\) como una sumatoria\nConsideremos la carnita del sándwich \\[\\sum_i\\hat{u}_i^2x_ix_i \\equiv \\sum_i \\hat{\\psi}_i x_ix_i'\\]"
  },
  {
    "objectID": "diapositivas/errores-estandar.html#errores-estándar-robustos-1",
    "href": "diapositivas/errores-estandar.html#errores-estándar-robustos-1",
    "title": "Inferencia Causal 2025",
    "section": "Errores estándar robustos",
    "text": "Errores estándar robustos\n\nDependiendo de cómo se especifique \\(\\hat{\\psi}_i\\), obtenemos distintas versiones del estimador de varianzas robusto\nLa propuesta de White original es:\n\n\\[HC0:\\quad\\hat{\\psi}_i=\\hat{u}_i^2\\]\n\nEste estimador asintóticamente consistente\n\n\n\nEn muestras pequeñas, muchas veces se emplea la siguiente corrección:\n\n\\[HC1:\\quad\\hat{\\psi}_i=\\frac{N}{N-k}\\hat{u}_i^2\\]"
  },
  {
    "objectID": "diapositivas/errores-estandar.html#desviación-a-la-influencia",
    "href": "diapositivas/errores-estandar.html#desviación-a-la-influencia",
    "title": "Inferencia Causal 2025",
    "section": "Desviación a la influencia",
    "text": "Desviación a la influencia\n\nUn par de resultados nos ayudarán a entender qué hacen las otras correcciones a la matriz robusta en el software\nDefinimos la influencia de la observación \\(i\\) como:\n\n\\[h_{ii}=X_i'(X'X)^{-1}X_i\\]\n\n\\(h_{ii}\\) nos dice qué tanto jala la observación \\(i\\) a la línea de regresión\nEn una regresión con un solo regresor \\(x\\), se puede mostrar que la influencia de la observación \\(i\\) es:\n\n\\[h_{ii}=\\frac{1}{N}+\\frac{(x_i-\\bar{x})^2}{\\sum(x_j-\\bar{x})^2}\\] es decir, que la influencia se incrementa cuando \\(x_i\\) se aleja de la media\n\nLa influencia es un número entre 0 y 1 y además \\(\\sum_i h_{ii}=k\\), siendo \\(k\\) el número de regresores"
  },
  {
    "objectID": "diapositivas/errores-estandar.html#errores-estándar-robustos-2",
    "href": "diapositivas/errores-estandar.html#errores-estándar-robustos-2",
    "title": "Inferencia Causal 2025",
    "section": "Errores estándar robustos",
    "text": "Errores estándar robustos\n\nAlgunos autores sugieren usar la influencia en la matriz de varianzas robusta\nSe proponen algunas alternativas:\n\n\\[HC2:\\quad\\hat{\\psi}_i=\\frac{1}{1-h_{ii}}\\hat{u}_i^2\\]\n\\[HC3:\\quad\\hat{\\psi}_i=\\frac{1}{(1-h_{ii})^2}\\hat{u}_i^2\\]\n\n\nLong & Ervin (2000) realizaron un experimento de simulación y recomendaron usar \\(HC3\\) en muestras pequeñas, por lo que el paquete sandwich en R usa \\(HC3\\) por default\nEs importante tener en cuenta qué tipo de errores estándar piden que el software calcule"
  },
  {
    "objectID": "diapositivas/errores-estandar.html#errores-agrupados-1",
    "href": "diapositivas/errores-estandar.html#errores-agrupados-1",
    "title": "Inferencia Causal 2025",
    "section": "Errores agrupados",
    "text": "Errores agrupados\n\nSurgen naturalmente cuando las observaciones están agrupadas\n\nNiños en salones de clase\nHogares en localidades\nSolicitudes de empleo en una empresa\nAhorradoras en un banco\n\nEl supuesto de errores independientes claramente no se cumple\n\n\n\nPensemos en un problema simple para entender la intución:\n\n\\[y_{ig}=\\beta_0+\\beta_1 x_g+e_{ig}\\]\n\nAquí, \\(x_g\\) es un regresor que es el mismo para todos los miembros del grupo \\(g\\)\nAsumamos que todos los grupos tienen tamaño \\(n\\)"
  },
  {
    "objectID": "diapositivas/errores-estandar.html#errores-agrupados-2",
    "href": "diapositivas/errores-estandar.html#errores-agrupados-2",
    "title": "Inferencia Causal 2025",
    "section": "Errores agrupados",
    "text": "Errores agrupados\n\nPodemos mostrar que la correlación de errores entre dos observaciones \\(i\\) y \\(j\\) que pertenecen a \\(g\\) es \\[E(e_{ig}e_{jg})=\\overbrace{\\rho_e}^{\\substack{\\text{coeficiente de correlación} \\\\ \\text{intraclase residual}}} \\underbrace{\\sigma_e^2}_{\\text{varianza residual}}\\]\nLe damos una estructura aditiva a los errores:\n\n\\[e_{ig}=\\nu_g+\\eta_{ig}\\] donde \\(\\nu_g\\) captura toda la correlación dentro del grupo\n\n\\(\\eta_{ig}\\) es un error idiosincrático con media cero e independiente de cualquier otro \\(\\eta_{jg}\\)\nComo queremos analizar el problema del agrupamiento, asumimos que tanto \\(v_g\\) y \\(\\eta_{ig}\\) son homocedásticos"
  },
  {
    "objectID": "diapositivas/errores-estandar.html#errores-agrupados-3",
    "href": "diapositivas/errores-estandar.html#errores-agrupados-3",
    "title": "Inferencia Causal 2025",
    "section": "Errores agrupados",
    "text": "Errores agrupados\n\nCon esta estructura de errores, el coeficiente de correlación intraclase es:\n\n\\[\\rho_e=\\frac{\\sigma_{\\nu}^2}{\\sigma_{\\nu}^2+\\sigma_{\\eta}^2}\\] - Deberíamos calcular la matriz de varianzas \\(V_C(\\hat{\\beta})\\) tomando en cuenta esta estructura\n\n\n¿Qué pasa si hacemos MCO en el contexto de este problema?\nMoulton (1984) muestra que:\n\n\\[\\frac{V_C(\\hat{\\beta})}{V_{MCO}(\\hat{\\beta})}=1+(n-1)\\rho_e\\] - A \\(\\sqrt{\\frac{V_C(\\hat{\\beta})}{V_{MCO}(\\hat{\\beta})}}\\) se le conoce como el factor de Moulton"
  },
  {
    "objectID": "diapositivas/errores-estandar.html#factor-de-moulton",
    "href": "diapositivas/errores-estandar.html#factor-de-moulton",
    "title": "Inferencia Causal 2025",
    "section": "Factor de Moulton",
    "text": "Factor de Moulton\n\nEl factor de Moulton nos dice qué tanto sobrestimamos la precisión al ignorar la correlación intra-clase\nVisto de otro modo:\n\n\\[V_C(\\hat{\\beta})=\\left(1+(n-1)\\rho_e\\right)V_{MCO}(\\hat{\\beta})\\]\n\nEs decir entre más grande sea la correlación dentro de los grupos, más deberíamos inflar los errores de MCO\n\n\n\nConsideremos el caso extremo de que \\(\\rho_e=1\\), es decir, que todas las \\(y_{ig}\\) dentro del mismo \\(g\\) son iguales\nEntonces el factor de Moulton es simplemente \\(\\sqrt{n}\\)\nVisto de otro modo, la matriz de varianzas correcta se obtendría multiplicando por \\(n\\) la matriz \\(V_{MCO}(\\hat{\\beta})\\)\n\n\\[V_C(\\hat{\\beta})=n V_{MCO}(\\hat{\\beta})\\]"
  },
  {
    "objectID": "diapositivas/errores-estandar.html#errores-agrupados-en-general",
    "href": "diapositivas/errores-estandar.html#errores-agrupados-en-general",
    "title": "Inferencia Causal 2025",
    "section": "Errores agrupados en general",
    "text": "Errores agrupados en general\n\nEn general, \\(x_{ig}\\) varía a nivel individual y tenemos grupos de tamaño \\(n_g\\)\nEn este caso, el factor de Moulton es la raíz cuadrada de:\n\n\\[\\frac{V_C(\\hat{\\beta})}{V_{MCO}(\\hat{\\beta})}=1+\\left(\\frac{V(n_g)}{\\bar{n}}+\\bar{n}-1\\right)\\rho_x\\rho_e\\] donde \\(\\bar{n}\\) es el tamaño promedio del grupo y \\(\\rho_x\\) es la correlación intraclase de \\(x_{ig}\\)\n\nNo es necesario asumir una forma para \\(\\rho_x\\) (se puede calcular)\n\n\n\nNoten que el error que cometemos es más grande entre más heterogéneo es el tamaño de grupos y entre más grande es \\(\\rho_x\\)\nPor tanto, cuando el tratamiento no varía entre grupos, este error es grande"
  },
  {
    "objectID": "diapositivas/errores-estandar.html#soluciones-para-errores-agrupados",
    "href": "diapositivas/errores-estandar.html#soluciones-para-errores-agrupados",
    "title": "Inferencia Causal 2025",
    "section": "Soluciones para errores agrupados",
    "text": "Soluciones para errores agrupados\n\nSolución paramétrica: calcular directamente el factor de Moulton e inflar los errores de MCO\nBootstrap por bloques: en vez de hacer muestras bootrstrap remuestreando individuos, se remuestrean grupos\nEstimar los errores agrupados (clustered standard errors)"
  },
  {
    "objectID": "diapositivas/errores-estandar.html#errores-estándar-agrupados",
    "href": "diapositivas/errores-estandar.html#errores-estándar-agrupados",
    "title": "Inferencia Causal 2025",
    "section": "Errores estándar agrupados",
    "text": "Errores estándar agrupados\n\nCon errores agrupados podemos escribir el estimador de MCO como\n\n\\[\n\\begin{aligned}\n\\hat{\\beta}&=\\beta+(X'X)^{-1}X'u \\\\\n&=(X'X)^{-1}\\left(\\sum_{g=1}^G X_gu_g\\right)\n\\end{aligned}\n\\] - Suponiendo independencia entre \\(g\\) y correlación dentro de cada grupo:\n\\[E(u_{ig}u_{jg'}|x_{ig}x_{jg'})=0\\] excepto cuando \\(g=g'\\)\n\nEn este caso, el estimador de MCO tiene una varianza asintótica dada por\n\n\\[V({\\hat{\\beta}}_{MCO})=(X'X)^{-1}\\left(\\sum_{g=1}^G X_g'u_gu_g'X\\right)(X'X)^{-1}\\]"
  },
  {
    "objectID": "diapositivas/errores-estandar.html#errores-estándar-agrupados-1",
    "href": "diapositivas/errores-estandar.html#errores-estándar-agrupados-1",
    "title": "Inferencia Causal 2025",
    "section": "Errores estándar agrupados",
    "text": "Errores estándar agrupados\n\nCon errores heterocedásticos, pero sin agrupamiento, la matriz de varianzas de White (1980) tiene una estructura como sigue:\n\n\\[\\hat{V}(\\hat{\\beta}_{R})=(X'X)^{-1}X'\\hat{\\Sigma} X (X'X)^{-1}\\]\n\nDonde\n\n\\[\\hat{\\Sigma}=\\left(\\begin{matrix} \\hat{u}_{1}^2 & 0  & 0  & \\ldots & 0 \\\\ 0 & \\hat{u}_{2}^2 & 0 & \\ldots & 0 \\\\ \\vdots & & & & \\\\ 0 & & &  \\ldots & \\hat{u}_{n}^2\\end{matrix}\\right)\\]"
  },
  {
    "objectID": "diapositivas/errores-estandar.html#errores-estándar-agrupados-2",
    "href": "diapositivas/errores-estandar.html#errores-estándar-agrupados-2",
    "title": "Inferencia Causal 2025",
    "section": "Errores estándar agrupados",
    "text": "Errores estándar agrupados\n\nPara estimar la varianza con errores agrupados empleamos una generalización de la propuesta de White para errores robustos\nSi \\(G\\to\\infty\\), el estimador de la matriz de errores agrupados robusta (CRVE) es consistente para estimar \\(V(\\hat{\\beta})\\):\n\n\\[\\hat{V}_{CR}(\\hat{\\beta})=(X'X)^{-1}\\left(\\sum_{g=1}^G X_g'\\hat{u}_g\\hat{u}_g'X_g\\right)(X'X)^{-1}\\] donde \\(\\hat{u}_g\\hat{u}_g'\\) es la matriz de varianzas para los individuos del grupo \\(g\\)\n\nDe manera compacta\n\n\\[\\hat{V}_{CR}(\\hat{\\beta})=(X'X)^{-1}X'\\hat{\\Sigma} X(X'X)^{-1}\\]"
  },
  {
    "objectID": "diapositivas/errores-estandar.html#errores-estándar-agrupados-3",
    "href": "diapositivas/errores-estandar.html#errores-estándar-agrupados-3",
    "title": "Inferencia Causal 2025",
    "section": "Errores estándar agrupados",
    "text": "Errores estándar agrupados\n\nY en este caso la matriz \\(\\hat{\\Sigma}\\) tiene una estructura agrupada\n\n\\[\\small \\hat{\\Sigma}=\\left(\\begin{matrix} \\hat{u}_{1,1}^2 & \\hat{u}_{1,1}\\hat{u}_{2,1} & \\ldots & \\hat{u}_{1,1} \\hat{u}_{n,1}& 0 & 0 & \\ldots &  0 & \\ldots & 0 & 0 & \\ldots &  0 \\\\ \\hat{u}_{2,1}\\hat{u}_{1,1} & \\hat{u}_{2,1}^2 & \\ldots & \\hat{u}_{2,1}\\hat{u}_{n,1} & 0 & 0 & \\ldots & 0 & \\ldots  & 0 & 0 & \\ldots &  0\\\\\n\\vdots & \\vdots  & & \\vdots & \\vdots & \\vdots  & &  \\vdots& & \\vdots & \\vdots &  &  \\vdots \\\\ \\hat{u}_{n,1}\\hat{u}_{1,1} & \\hat{u}_{n,1}\\hat{u}_{2,1}& \\ldots & \\hat{u}_{n,1}^2& 0 & 0 &\\ldots & 0 & \\ldots & 0 & 0 & \\ldots &  0 \\\\  0 & 0 & \\ldots &  0 & \\hat{u}_{1,2}^2 & \\hat{u}_{1,2}\\hat{u}_{2,2} & \\ldots & \\hat{u}_{1,2}\\hat{u}_{n,2} &\\ldots & 0 & 0 & \\ldots &  0  \\\\ 0 & 0 & \\ldots &  0 & \\hat{u}_{2,2}\\hat{u}_{1,2} & \\hat{u}_{2,2}^2 & \\ldots & \\hat{u}_{2,2}\\hat{u}_{n,2} &\\ldots & 0 & 0 & \\ldots &  0 \\\\ \\vdots & \\vdots  & & \\vdots & \\vdots & \\vdots  & &  \\vdots& & \\vdots & \\vdots &  &  \\vdots  \\\\ 0 & 0 & \\ldots &  0 & \\hat{u}_{n,2}\\hat{u}_{1,2} & \\hat{u}_{n,2}\\hat{u}_{2,2} & \\ldots & \\hat{u}_{n,2}^2 &\\ldots & 0 & 0 & \\ldots &  0 \\\\ \\vdots & \\vdots  & & \\vdots & \\vdots & \\vdots  & &  \\vdots& & \\vdots & \\vdots &  &  \\vdots \\\\ 0 & 0 & \\ldots &  0 & 0 &  0 & \\ldots & 0 &\\ldots & \\hat{u}_{1,G}^2 & \\hat{u}_{12,G}\\hat{u}_{2,G} & \\ldots &  \\hat{u}_{1,G}\\hat{u}_{n,G} \\\\  0 & 0 & \\ldots &  0 & 0 &  0 & \\ldots & 0 &\\ldots & \\hat{u}_{2,G}\\hat{u}_{1,G} & \\hat{u}_{2,G}^2 & \\ldots &  \\hat{u}_{2,G}\\hat{u}_{n,G} \\\\ \\vdots & \\vdots  & & \\vdots & \\vdots & \\vdots  & &  \\vdots& & \\vdots & \\vdots &  &  \\vdots \\\\  0 & 0 & \\ldots &  0 & 0 &  0 & \\ldots & 0 &\\ldots & \\hat{u}_{n,G}\\hat{u}_{1,G} & \\hat{u}_{n,G}\\hat{u}_{2,G} & \\ldots &  \\hat{u}_{n,G}^2 \\end{matrix}\\right)\\]"
  },
  {
    "objectID": "diapositivas/errores-estandar.html#errores-estándar-agrupados-4",
    "href": "diapositivas/errores-estandar.html#errores-estándar-agrupados-4",
    "title": "Inferencia Causal 2025",
    "section": "Errores estándar agrupados",
    "text": "Errores estándar agrupados\n\nEl resultado asintótico de consistencia depende de que \\(G\\to\\infty\\)\nSi \\(G\\) está fijo, no importa qué tan grande sea \\(N\\), \\(\\hat{V}_{CRVE}(\\hat{\\beta})\\) no será consistente\nAlgunos paquetes ajustan esta matriz de varianzas haciendo una corrección parecida a \\(HC1\\), pero ahora tomando en cuanta también \\(G\\) y no solo \\(N\\) (ver por ejemplo, vcovCR en R)\n\n\n\nCon pocos grupos, subestimamos los errores estándar y rechazamos la \\(H_0\\) más veces de lo que deberíamos (over-rejection)\nSi tenemos pocos grupos, recurrimos a otras soluciones (ver Cameron y Miller, 2015)\n\nInflar los errores con un corrector de sesgo\nBootstrap agrupado con refinamiento asintótico\n\nLa recomendación práctica es que se tomen en serio el problema de los pocos clusters\n¿Cuánto es poco? Cameron y Miller (2015) citan 50. (¡Qué raro, el número de estados en EUA!)"
  },
  {
    "objectID": "diapositivas/bootstrap.html#introducción-a-bootstrap",
    "href": "diapositivas/bootstrap.html#introducción-a-bootstrap",
    "title": "Inferencia Causal 2025",
    "section": "Introducción a bootstrap",
    "text": "Introducción a bootstrap\n\nA veces es difícil encontrar una expresión analítica de los errores estándar\nLa idea de las técnicas bootstrap es consutrir una distribución empírica del estimador de interés\nUna muestra bootstrap es una muestra tomada de los mismos datos\nEn las rutinas para errores bootstrap, pensamos en \\(\\{(y_1,x_1),\\ldots,(y_N,X_n)\\}\\) como la población\nUna muestra bootstrap es una muestra de tamaño \\(N\\) tomada de la muestra original\nEl procedimiento bootstrap más usado es el bootstrap no paramétrico o boostrap en parejas (nos enfocaremos en este tipo de bootstrap en el curso)\nLa idea es remuestrear la pareja completa \\((y_i,x_i)\\)"
  },
  {
    "objectID": "diapositivas/bootstrap.html#algoritmo-para-errores-estándar-bootstrap",
    "href": "diapositivas/bootstrap.html#algoritmo-para-errores-estándar-bootstrap",
    "title": "Inferencia Causal 2025",
    "section": "Algoritmo para errores estándar bootstrap",
    "text": "Algoritmo para errores estándar bootstrap\n\nDada una muestra \\(W_1,\\ldots,W_N\\), obtener una muestra de tamaño \\(N\\), remuestreando de la muestra original con reemplazo\nCalcular el estadístico \\(\\hat{\\theta}_b\\) usado con la muestra bootstrap (coeficiente de regresión, diferencia de medias, función de coeficientes)\nRepetir los pasos 1 y 2 \\(B\\) veces, donde \\(B\\) es lo suficientemente grande (usualmente 1000 es suficiente)\nUsar las \\(B\\) repeticiones para obtener el error estándar del estadístico como la raíz cuadrada de \\(s^2_{\\hat{\\theta},B}\\):\n\n\\[s^2_{\\hat{\\theta},B}=\\frac{1}{B-1}\\sum_{b=1}^B(\\hat{\\theta}_{b}-\\bar{\\hat{\\theta}})^2\\] donde \\(\\bar{\\hat{\\theta}}=\\frac{1}{B}\\sum_{b=1}^B\\hat{\\theta}_b\\)"
  },
  {
    "objectID": "diapositivas/bootstrap.html#cómo-hacer-remuestreo-en-r",
    "href": "diapositivas/bootstrap.html#cómo-hacer-remuestreo-en-r",
    "title": "Inferencia Causal 2025",
    "section": "¿Cómo hacer remuestreo en R?",
    "text": "¿Cómo hacer remuestreo en R?\n\nset.seed(927)\n\ndata.morocco&lt;- read.csv(\"./crepon_morocco_analysis.csv\")%&gt;%\n  select(treatment,client,expense_total )\n\nobs &lt;- nrow(data.morocco)\nobs\n\n[1] 4934\n\n#En la muestra original\nmean(data.morocco$expense_total)\n\n[1] 23294.83"
  },
  {
    "objectID": "diapositivas/bootstrap.html#cómo-hacer-remuestreo-en-r-1",
    "href": "diapositivas/bootstrap.html#cómo-hacer-remuestreo-en-r-1",
    "title": "Inferencia Causal 2025",
    "section": "¿Cómo hacer remuestreo en R?",
    "text": "¿Cómo hacer remuestreo en R?\n\n#Una muestra bootstrap\ndata.b &lt;-data.morocco[sample(nrow(data.morocco),obs, replace = TRUE),]\n\nmean(data.b$expense_total)\n\n[1] 24995.96\n\n#Otra muestra bootstrap\ndata.b &lt;-data.morocco[sample(nrow(data.morocco),obs, replace = TRUE),]\n\nmean(data.b$expense_total)\n\n[1] 25587.57"
  },
  {
    "objectID": "diapositivas/bootstrap.html#aplicaciones-comunes-de-bootstrap",
    "href": "diapositivas/bootstrap.html#aplicaciones-comunes-de-bootstrap",
    "title": "Inferencia Causal 2025",
    "section": "Aplicaciones comunes de bootstrap",
    "text": "Aplicaciones comunes de bootstrap\n\nMétodos de varias etapas (por ejemplo, el estimador de dos etapas de Heckman)\nFunciones de estimadores (aunque aquí el método Delta también podría ser usado)\nDatos agrupados con pocos grupos (remuestrear grupos en vez de individuos)\nEl consejo práctico es usar resultados teóricos cuando se puede (por ejemplo, las matrices robustas descritas antes)\nPensemos siempre en la estructura de los datos antes de hacer boostrap\nUsar una semilla siempre para poder reproducir sus resultados"
  },
  {
    "objectID": "diapositivas/bootstrap.html#bootstrap-salvaje",
    "href": "diapositivas/bootstrap.html#bootstrap-salvaje",
    "title": "Inferencia Causal 2025",
    "section": "Bootstrap salvaje",
    "text": "Bootstrap salvaje\n\nEn presencia de heterocedasticidad se prefiere usar bootstrap salvaje (wild bootstrap) (MacKinnon, 2012)\nPropuesto originalmente por Liu (1988), cada muestra bootstrap tiene la siguiente forma:\n\n\\[y_i^*=X_i\\hat{\\beta}+f(\\hat{u}_i)v_i^*\\] - Noten que mantiene fijos los \\(X_i\\) en cada muestra bootstrap\n\nUna especificación comúnmente usada es hacer es \\(f(\\hat{u}_i)=\\hat{u}_i\\) y \\[v_i^*=\\begin{cases} 1 \\quad\\text{con probabilidad 0.5} \\\\ -1 \\quad\\text{con probabilidad 0.5} \\end{cases}\\]\n\\(\\hat{\\beta}\\) y \\(\\hat{u}_i\\) son estimados con la muestra original"
  },
  {
    "objectID": "diapositivas/bootstrap.html#bootstrap-salvaje-1",
    "href": "diapositivas/bootstrap.html#bootstrap-salvaje-1",
    "title": "Inferencia Causal 2025",
    "section": "Bootstrap salvaje",
    "text": "Bootstrap salvaje\n\nEn cada una de las \\(B\\) muestras bootstrap, mantenemos a los mismos individuos (no hay remuestreo)\nTendremos \\(B\\) muestras bootstrap, pero ahora la aleatoriedad viene por \\(f(\\hat{u}_i)v_i^*\\)\nPueden usarse otras funciones más complicadas para \\(f(\\hat{u}_i)\\)\nLa ventaja de este método es que conserva la relación entre las varianzas residuales y las \\(X_i\\) observadas en los datos originales\nDavidson & Flachaire (2008) utilizan simulaciones para mostrar que con esta forma para \\(f(\\hat{u}_i)v_i^*\\) la inferencia es más confiable que con otras especificaciones"
  },
  {
    "objectID": "diapositivas/bootstrap.html#refinamiento-asintótico",
    "href": "diapositivas/bootstrap.html#refinamiento-asintótico",
    "title": "Inferencia Causal 2025",
    "section": "Refinamiento asintótico",
    "text": "Refinamiento asintótico\n\nUna aplicación de las técnicas bootstrap es el refinamiento asintótico de la prueba \\(t\\) de coeficientes de regresión\nSupongamos que \\(H_0:\\quad \\beta=0\\) y trabajamos con un nivel \\(\\alpha\\)\nEn cada repetición bootstrap el estadístico calculado es \\(t_b\\)\nOrdenamos los \\(B\\) estadísticos obtenidos\nRechazamos \\(H_0\\) si \\(|t|\\) está por encima del \\((1-\\alpha)\\)ésimo percentil de los \\(|t_b|\\) en la distribución bootstrap\nA pesar de sus propiedades teóricas, el refinamiento asintótico es poco usado"
  },
  {
    "objectID": "diapositivas/bootstrap.html#jacknife",
    "href": "diapositivas/bootstrap.html#jacknife",
    "title": "Inferencia Causal 2025",
    "section": "Jacknife",
    "text": "Jacknife\n\nFormalmente no es un método bootstrap\nUna muestra jacknife es una muestra de tamaño \\(N-1\\) construida a partir de la muestra original donde una observación es eliminada a la vez\nEn cada muestra jacknife estimamos el estadístico de interés \\(\\hat{\\theta}_{(j)}\\) (tendremos \\(N\\) estadísticos)\nEl error estándar jacknife será\n\n\\[\\hat{se}(\\hat{\\theta})=\\left(\\frac{N-1}{N}\\sum_{j=1}^N\\left(\\hat{\\theta}_{(j)}-\\hat{\\theta}\\right)^2\\right)^{1/2}\\]\n\nFunciona bien para estadísticas suaves y funciones lineales\nSe puede hacer jacknife por bloques (Cameron y Miller, 2015)"
  },
  {
    "objectID": "diapositivas/did.html#introducción",
    "href": "diapositivas/did.html#introducción",
    "title": "Inferencia Causal 2025",
    "section": "Introducción",
    "text": "Introducción\n\n\n\nAngrist & Pischke (2014) describen lo sucedido con el sector bancario en Mississippi durante la Gran Depresión\nEn EUA, la FED tiene 12 bancos regionales y cada uno tiene autonomía para tomar ciertas decisiones de política monetaria\nEn particular, Mississippi tiene una parte del estado bajo el mando del distrito 6 (Atlanta) y la otra mitad en el distrito 8 (San Luis)"
  },
  {
    "objectID": "diapositivas/did.html#diferencia-en-diferencias-2",
    "href": "diapositivas/did.html#diferencia-en-diferencias-2",
    "title": "Inferencia Causal 2025",
    "section": "Diferencia en diferencias",
    "text": "Diferencia en diferencias\n\nLa estrategia de diferencia en diferencias especifica las condiciones bajo las cuales es posible identificar el efecto del tratamiento al comparar unidades tratadas y no tratadas, cuando se dispone de información antes y después de la intervención\nEsta estrategia es ampliamente utilizada para analizar el efecto de leyes y políticas que afectan a un grupo de individuos al mismo tiempo\nAdemás, constituye el fundamento para otro de los métodos en donde la investigación actual es muy activa, el control sintético"
  },
  {
    "objectID": "diapositivas/did.html#representación-gráfica",
    "href": "diapositivas/did.html#representación-gráfica",
    "title": "Inferencia Causal 2025",
    "section": "Representación gráfica",
    "text": "Representación gráfica\n\nGráficamente observamos"
  },
  {
    "objectID": "diapositivas/did.html#representación-gráfica-1",
    "href": "diapositivas/did.html#representación-gráfica-1",
    "title": "Inferencia Causal 2025",
    "section": "Representación gráfica",
    "text": "Representación gráfica\n\nDel distrito 8 (no tratado) podemos obtener la pendiente:\n\n\\[m_{NT}=\\frac{Y_{8,post}-Y_{8,pre}}{X_{8,post}-X_{8,pre}}=\\frac{132-165}{1931-1930}=-33\\]\n\nY entonces, podemos encontrar cuál hubiera sido el número de bancos en el distrio 6 (tratado) si hubiera seguido la pendiente del distrito 8:\n\n\\[m_T=\\frac{\\tilde{Y}_{6,post}-Y_{6,pre}}{X_{6,post}-X_{6,pre}}=\\frac{\\tilde{Y}_{6,post}-135}{1931-1930}=-33\\] - Por tanto, \\(\\tilde{Y}_{6,post}=102\\) es el número de bancos que el distrito 6 hubiera tenido si hubiera seguido una tendencia paralela a la del distrito 8"
  },
  {
    "objectID": "diapositivas/did.html#representación-gráfica-2",
    "href": "diapositivas/did.html#representación-gráfica-2",
    "title": "Inferencia Causal 2025",
    "section": "Representación gráfica",
    "text": "Representación gráfica\n\nPodemos contruir el contrafactual para el distrito 6 observando la pendiente del distrito 8"
  },
  {
    "objectID": "diapositivas/did.html#diferencia-en-diferencias-3",
    "href": "diapositivas/did.html#diferencia-en-diferencias-3",
    "title": "Inferencia Causal 2025",
    "section": "Diferencia en diferencias",
    "text": "Diferencia en diferencias\n\n\n\nAngrist & Pischke (2014) describen lo sucedido con el sector bancario en Mississippi durante la Gran Depresión\nEn EUA, la FED tiene 12 bancos regionales y cada uno tiene autonomía para tomar ciertas decisiones de política monetaria\nEn particular, Mississippi tiene una parte del estado bajo el mando del distrito 6 (Atlanta) y la otra mitad en el distrito 8 (San Luis)"
  },
  {
    "objectID": "diapositivas/did.html#diferencia-en-diferencias-4",
    "href": "diapositivas/did.html#diferencia-en-diferencias-4",
    "title": "Inferencia Causal 2025",
    "section": "Diferencia en diferencias",
    "text": "Diferencia en diferencias\n\nComo respuesta a las corridas bancarias que caracterizaron la crisis de 1929, los bancos comerciales en Mississippi se vieron expuestos a dos políticas distintas\n\n\\[\nT=\n\\begin{cases}\n1\\quad\\quad \\text{proveer liquidez adicional (distrito 6)} \\\\\n0\\quad\\quad \\text{dar igual o menos liquidez (distrito 8)} \\\\\n\\end{cases}\n\\]\n\nSi estamos interesados en la cantidad de bancos que sobrevivieron y decir algo sobre qué política es más efectiva, ¿qué podemos hacer?\nUna primera respuesta sería contar la diferencia después de la crisis:\n\n\n\n\nDistrito 8\nDistrito 6\nDiferencia\n\n\n\n\n\\(T=0\\)\n\\(T=1\\)\n\n\n\n132 bancos\n121 bancos\n11 bancos\n\n\n\n\nPareciera que la política de proveer liquidez, easy money, causó que quebraran más bancos\nSin embargo, esta comparación claramente ignora las condiciones iniciales"
  },
  {
    "objectID": "diapositivas/did.html#regresión-en-did",
    "href": "diapositivas/did.html#regresión-en-did",
    "title": "Inferencia Causal 2025",
    "section": "Regresión en DID",
    "text": "Regresión en DID\n\nEl método puede generalizarse a más periodos de tiempo\nAquí, una regresión nos permite identificar el efecto del tratamiento\nTenemos datos sobre el número de bancos en cada distrito en cada año (1929-1934)\n\n\\[y_{dt}=\\alpha+\\beta T_d+\\gamma POST_t + \\delta_{r,DID}(T_d\\times POST_t)+e_{dt}\\] - \\(T_d\\) es una dummy para los distritos tratados (distrito 6 en este caso)\n\nLes llamamos efectos fijos individuales y sirven para controlar diferencias entre distritos que no cambian en el tiempo\n\\(POST_t\\) es una dummy para los periodos post tratamiento (1931 en adelante)\nAl término \\(T_d\\times POST_t\\) se le conoce como el término de interacción, que es una dummy igual a 1 para los distritos tratados en los años post intervención\n\\(\\delta_{r,DID}\\) es el estimador de DID del efecto del tratamiento"
  },
  {
    "objectID": "diapositivas/did.html#regresión-en-did-1",
    "href": "diapositivas/did.html#regresión-en-did-1",
    "title": "Inferencia Causal 2025",
    "section": "Regresión en DID",
    "text": "Regresión en DID\n\nUsemos los datos del archivo banks_mm.csv que se utilizan en el libro\nEs una forma muy básica de datos en panel: cada fila representa un distrito en un periodo de tiempo\nPodemos identificar si cada fila pertenece a un distrito tratado o no o a un periodo posterior a al tratamiento o no\n\n\n\n# A tibble: 12 × 5\n    year distrito banks treatment  post\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1  1929 bib6       141         1     0\n 2  1930 bib6       135         1     0\n 3  1931 bib6       121         1     1\n 4  1932 bib6       113         1     1\n 5  1933 bib6       102         1     1\n 6  1934 bib6       102         1     1\n 7  1929 bib8       169         0     0\n 8  1930 bib8       165         0     0\n 9  1931 bib8       132         0     1\n10  1932 bib8       120         0     1\n11  1933 bib8       111         0     1\n12  1934 bib8       109         0     1"
  },
  {
    "objectID": "diapositivas/did.html#regresión-en-did-2",
    "href": "diapositivas/did.html#regresión-en-did-2",
    "title": "Inferencia Causal 2025",
    "section": "Regresión en DID",
    "text": "Regresión en DID\n\nEstimemos la regresión que acabamos de motivar usando todos los periodos en el panel\n\n\n\n\nCall:\nlm(formula = banks ~ treatment + post + treatment * post, data = banks)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.000 -7.125  0.000  3.125 14.000 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     167.000      6.190  26.980 3.83e-09 ***\ntreatment       -29.000      8.754  -3.313 0.010652 *  \npost            -49.000      7.581  -6.464 0.000195 ***\ntreatment:post   20.500     10.721   1.912 0.092224 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.754 on 8 degrees of freedom\nMultiple R-squared:  0.8906,    Adjusted R-squared:  0.8496 \nF-statistic: 21.71 on 3 and 8 DF,  p-value: 0.0003369"
  },
  {
    "objectID": "diapositivas/did.html#regresión-en-did-3",
    "href": "diapositivas/did.html#regresión-en-did-3",
    "title": "Inferencia Causal 2025",
    "section": "Regresión en DID",
    "text": "Regresión en DID\n\nNoten que si solo usamos dos años, obtenemos exactamente lo que obtendríamos haciendo las diferencias a mano\n\n\\[\\delta_{DiD}=(Y_{6,1931}-Y_{6,1930})-(Y_{8,1931}-Y_{8,1930})=19\\]\n\n\n\nCall:\nlm(formula = banks ~ treatment + post + treatment * post, data = filter(banks, \n    year == 1930 | year == 1931))\n\nResiduals:\nALL 4 residuals are 0: no residual degrees of freedom!\n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)         165        NaN     NaN      NaN\ntreatment           -30        NaN     NaN      NaN\npost                -33        NaN     NaN      NaN\ntreatment:post       19        NaN     NaN      NaN\n\nResidual standard error: NaN on 0 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:    NaN \nF-statistic:   NaN on 3 and 0 DF,  p-value: NA"
  },
  {
    "objectID": "diapositivas/did.html#violación-a-los-supuestos",
    "href": "diapositivas/did.html#violación-a-los-supuestos",
    "title": "Inferencia Causal 2025",
    "section": "Violación a los supuestos",
    "text": "Violación a los supuestos\n\n\n\nConsideremos cosas que podrían salir mal con respecto al supuesto de tendencias paralelas\nSupongamos que un tratamiento ocurre en el periodo marcado con la línea vertical, por ejemplo, un cambio en una legislación\nEn este ejemplo algo sucedió en Allatsea que produjo un cambio en la trayectoria de mortalidad antes del cambio en la legislación\nEl supuesto de tendencias paralelas sí se sostenía hasta antes de este cambio\nSin embargo, nuestra estrategia de DID atribuiría el efecto al cambio en la legislación cuando en realidad cuando ese cambio ocurrió ya nole pasó nada a Allatsea"
  },
  {
    "objectID": "diapositivas/did.html#violación-a-los-supuestos-1",
    "href": "diapositivas/did.html#violación-a-los-supuestos-1",
    "title": "Inferencia Causal 2025",
    "section": "Violación a los supuestos",
    "text": "Violación a los supuestos\n\n\n\nEn este segundo ejemplo, el supuesto de tendencias paralelas pre intervención se viola\nAunque en el momento del cambio de la política, la línea de Allatsea es más inclinada, estimar esta relación por DID de nuevo atribuiría a la política diferencias que ya existían antes de la intervención"
  },
  {
    "objectID": "diapositivas/did.html#violación-a-los-supuestos-2",
    "href": "diapositivas/did.html#violación-a-los-supuestos-2",
    "title": "Inferencia Causal 2025",
    "section": "Violación a los supuestos",
    "text": "Violación a los supuestos\n\n\n\nEn este tercer ejemplo hay tendencias que no son paralelas pre intervención\nSin embargo, después de la intervención, la trayectoria de Allatsea tiene una pendiente claramente más inclinada que antes de la intervención"
  },
  {
    "objectID": "diapositivas/did.html#adopción-escalonada-en-la-antiguedad",
    "href": "diapositivas/did.html#adopción-escalonada-en-la-antiguedad",
    "title": "Inferencia Causal 2025",
    "section": "Adopción escalonada en la antiguedad",
    "text": "Adopción escalonada en la antiguedad\n\nDID es uno de esos campos tan activos en la investigación que cosas que pensábamos superadas o completamente estudiadas se han modificado en los últimos años\nEn esta sección mostramos el tratamiento que MHE y MM dan a los problemas de adopción escalonada\nLa adopción escalonada ocurre cuando existen varios periodos de tratamiento y algunas unidades van siendo tratadas de forma desfasada\nPor ejemplo, en Méxio las leyes de despenalización del aborto o las que reconocen las uniones entre personas del mismo sexo son buenos ejemplos de tratamientos con adopción escalonada\nHasta los trabajos de Goodman-Bacon (2021) y Chaisemartin & D’Haultfœuille (2020), los problemas con adopción escalonada se abordaban econométricamente de la misma forma que hemos descrito hasta ahora, conocida como efectos fijos en bidireccionales (sí, suena horrible dicha traducción) o two-way fixed effects\nEsta sección presenta el tipo de tratamiento que hoy ya consideramos inapropiado\nMás adelante se presentan alternativas para los problemas de adopción escalonada"
  },
  {
    "objectID": "diapositivas/did.html#edad-legal-para-beber-en-eua",
    "href": "diapositivas/did.html#edad-legal-para-beber-en-eua",
    "title": "Inferencia Causal 2025",
    "section": "Edad legal para beber en EUA",
    "text": "Edad legal para beber en EUA\n\nDiferencias en la edad legal para beber en Estados Unidos\n¿Las restricciones a la edad mínima para comprar alcohol tienen un impacto en la mortalidad?\nAlabama redujo la edad legal a 19 en 1975, mientras que, por ejemplo, Arkansas mantuvo la edad en 21\nTenemos datos de mortalidad de 1970 a 1983 para personas de entre 18 y 20 años\nLo que hemos aprendido hasta ahora nos sugiere estimar el impacto por DID comos sigue\n\n\\[y_{st}=\\alpha+\\beta T_s+\\gamma POST_t+\\delta_{DID}(T_s\\times POST_t)+e_{st}\\] - \\(T_s\\) es una dummy igual a 0 para Arkansas en todos los periodos e igual a 1 para Alabama en todos los periodos\n\n\\(POST_t\\) es igual a cero para el periodo 1970-1975 e igual a 1 para el periodo 1976-1983\n\\(T_s\\times POST_t\\) es igual a 1 para las observaciones de Alabama en los años en los que la nueva política ya está en vigor"
  },
  {
    "objectID": "diapositivas/did.html#más-de-un-estado",
    "href": "diapositivas/did.html#más-de-un-estado",
    "title": "Inferencia Causal 2025",
    "section": "Más de un estado",
    "text": "Más de un estado\n\n¿Por qué quedarnos solo con la comparación con Arkansas?\nPodemos incluir más unidades que implementen cambios en la política en distintos momentos\nEn vez de \\(POST_t\\) usamos efectos fijos por año\nY en vez de una dummy de tratamiento, incluimos efectos fijos por unidad\nAdemás, en el cambio en la ley podría no ser el mismo\n\nAlgunos estados mueven la edad a 18, otros a 19 y otros a 20\nPodemos definir \\(LEGAL_{st}\\) como la proporción de individuos de entre 18 y 20 años autorizados para beber en el estado \\(s\\) y en el año \\(t\\)\n\n\n\\[y_{st}=\\alpha+\\delta_{DID}LEGAL_{st}+\\sum_k\\beta_k STATE_{ks}+\\sum_j \\gamma_j YEAR_{jt}+e_{st}\\]"
  },
  {
    "objectID": "diapositivas/did.html#estructura-de-datos-en-panel",
    "href": "diapositivas/did.html#estructura-de-datos-en-panel",
    "title": "Inferencia Causal 2025",
    "section": "Estructura de datos en panel",
    "text": "Estructura de datos en panel\n\nLos datos que acabamos de describir tienen una estructura de panel\nLa variable de panel es el estado \\(s\\) y la variable de tiempo es el año \\(t\\)\nEn nuestros datos, cada estado se encuentra presente en varios años, y para cada estado y año sabemos la mortalidad y la fracción de personas de 18 a 20 años que pueden beber\nEfectos fijos \\(STATE_{ks}\\): diferencias entre estados que no cambian con el tiempo\nEfectos año \\(YEAR_{jt}\\): factores que afectan a todas las unidades por igual en un momento del tiempo"
  },
  {
    "objectID": "diapositivas/did.html#interpretación",
    "href": "diapositivas/did.html#interpretación",
    "title": "Inferencia Causal 2025",
    "section": "Interpretación",
    "text": "Interpretación\n\n\n\nMuertes por 100,000 habs.:\n\\(\\hat{\\delta}_{DID}\\)\n\n\n\n\nTodas\n10.80\n\n\n\n(4.59)\n\n\nAccidentes en vehículos\n7.59\n\n\n\n(2.50)\n\n\nSuicidio\n0.59\n\n\n\n(0.59)\n\n\nCausas internas\n1.33\n\n\n\n(1.59)\n\n\n\n\nLa interpretación de los resultados es directa\nEl acceso a alcohol causa un incremento de casi 11 muertes adicionales por cada 100,000 habitantes y este efecto es estadísticamente significativo\nNo hay efectos donde no esperaríamos tenerlos"
  },
  {
    "objectID": "diapositivas/did.html#qué-hace-el-estimador-de-twfe",
    "href": "diapositivas/did.html#qué-hace-el-estimador-de-twfe",
    "title": "Inferencia Causal 2025",
    "section": "¿Qué hace el estimador de TWFE?",
    "text": "¿Qué hace el estimador de TWFE?\nConsideremos el siguiente problema de adopción escalonada\n\nObservamos \\(T\\) periodos\n\\(k\\) denota la unidad tratada temprano\n\\(l\\) denota la unidad tratada tarde\nDenotamos \\(\\bar{D}_k\\) al tiempo que \\(k\\) pasa tratado\nSimilarmente, \\(\\bar{D}_l\\)\n\\(n_k\\) es el número de unidades tratadas temprano\n\\(n_l\\) es el número de unidades tratadas tarde\n\\(n_U\\) es el número de unidades nunca tratadas\nPara cualesquiera dos grupos \\(a\\) y \\(b\\), \\(a_{ab}=\\frac{n_a}{n_a+n_b}\\)"
  },
  {
    "objectID": "diapositivas/did.html#qué-hace-el-estimador-de-twfe-1",
    "href": "diapositivas/did.html#qué-hace-el-estimador-de-twfe-1",
    "title": "Inferencia Causal 2025",
    "section": "¿Qué hace el estimador de TWFE?",
    "text": "¿Qué hace el estimador de TWFE?"
  },
  {
    "objectID": "diapositivas/did.html#qué-hace-el-estimador-de-twfe-2",
    "href": "diapositivas/did.html#qué-hace-el-estimador-de-twfe-2",
    "title": "Inferencia Causal 2025",
    "section": "¿Qué hace el estimador de TWFE?",
    "text": "¿Qué hace el estimador de TWFE?\nTenemos cuatro posibles comparaciones \\(2x2\\)\n\nLas comparaciones con las unidades nunca tratadas:\n\n\\[\\hat{\\beta}_{jU}=\\left(\\bar{y}_j^{POST(j)}-\\bar{y}_j^{PRE(j)}\\right)-\\left(\\bar{y}_U^{POST(j)}-\\bar{y}_U^{PRE(j)}\\right),\\;j=\\{k,l\\}\\]\n\nLa comparación entre \\(k\\) y \\(l\\) cuando \\(k\\) es tratada, usando los periodos antes de que \\(l\\) sea tratada\n\n\\[\\hat{\\beta}^{k}_{kl}=\\left(\\bar{y}_k^{MID(k,l)}-\\bar{y}_k^{PRE(k)}\\right)-\\left(\\bar{y}_l^{MID(k,l)}-\\bar{y}_l^{PRE(k)}\\right)\\]\n\nLa comparación entre \\(l\\) y \\(k\\) cuando \\(l\\) es tratada, usando los periodos después de que \\(k\\) fue tratada\n\n\\[\\hat{\\beta}^{l}_{kl}=\\left(\\bar{y}_l^{POST(l)}-\\bar{y}_l^{MID(k,l)}\\right)-\\left(\\bar{y}_k^{POST(l)}-\\bar{y}_k^{MID(k,l)}\\right)\\]"
  },
  {
    "objectID": "diapositivas/did.html#qué-hace-el-estimador-de-twfe-3",
    "href": "diapositivas/did.html#qué-hace-el-estimador-de-twfe-3",
    "title": "Inferencia Causal 2025",
    "section": "¿Qué hace el estimador de TWFE?",
    "text": "¿Qué hace el estimador de TWFE?"
  },
  {
    "objectID": "diapositivas/did.html#qué-hace-el-estimador-de-twfe-4",
    "href": "diapositivas/did.html#qué-hace-el-estimador-de-twfe-4",
    "title": "Inferencia Causal 2025",
    "section": "¿Qué hace el estimador de TWFE?",
    "text": "¿Qué hace el estimador de TWFE?\nDenotamos \\(D_{it}=1\\) cuando la unidad \\(i\\) es tratada en el periodo \\(0\\)\nPor el teorema de Frisch-Waugh-Lovell sabemos que podemos purgar de efectos fijos a la variable \\(D_{it}\\)\nEs decir, podemos estimar por MCO:\n\\[D_{it}=\\sum_t \\gamma_t P_t + \\sum_i \\pi S_i + \\varepsilon_{it}\\]\ndonde \\(P_t\\) son dummies temporales y \\(S_i\\) son dummies individuales\nLuego obtenemos\n\\[\\tilde{D}_{it}=D_{it}-\\hat{D}_{it}\\] Y entonces el estimador de TWFE puede escribirse como el coeficiente de una regresión bivariada:\n\\[\\hat{\\beta}_{DD}=\\frac{\\hat{C}(y_{it}, \\tilde{D}_{it})}{\\hat{V}^D}\\] \\(\\hat{V}^D\\) es la varianza de la variable de tratamiento purgada de efectos fijos"
  },
  {
    "objectID": "diapositivas/did.html#qué-hace-el-estimador-de-twfe-5",
    "href": "diapositivas/did.html#qué-hace-el-estimador-de-twfe-5",
    "title": "Inferencia Causal 2025",
    "section": "¿Qué hace el estimador de TWFE?",
    "text": "¿Qué hace el estimador de TWFE?\nGoodman-Bacon (2021) muestra que el estimador de TWFE puede descomponerse como:\n\\[\\hat{\\beta}_{DD}=s_{kU}\\hat{\\beta}_{kU}+s_{lU}\\hat{\\beta}_{lU}+s_{kl}^k\\hat{\\beta}_{kl}^k+s_{kl}^l\\hat{\\beta}_{kl}^l\\]"
  },
  {
    "objectID": "diapositivas/did.html#qué-son-los-pesos",
    "href": "diapositivas/did.html#qué-son-los-pesos",
    "title": "Inferencia Causal 2025",
    "section": "¿Qué son los pesos?",
    "text": "¿Qué son los pesos?\nGoodman-Bacon (2021) muestra que los pesos están dados por:\n\n\\(s_{kU}=\\frac{(n_k+n_U)^2\\hat{V}_{kU}^D}{\\hat{V}^D}\\)\n\\(s_{lU}=\\frac{(n_l+n_U)^2\\hat{V}_{lU}^D}{\\hat{V}^D}\\)\n\\(s_{kl}^k=\\frac{[(n_k+n_l)(1-\\bar{D}_l)]^2\\hat{V}_{kl}^{D,k}}{\\hat{V}^D}\\)\n\\(s_{kl}^l=\\frac{[(n_k+n_l)\\bar{D}_k]^2\\hat{V}_{kl}^{D,l}}{\\hat{V}^D}\\)"
  },
  {
    "objectID": "diapositivas/did.html#qué-son-los-pesos-1",
    "href": "diapositivas/did.html#qué-son-los-pesos-1",
    "title": "Inferencia Causal 2025",
    "section": "¿Qué son los pesos?",
    "text": "¿Qué son los pesos?\nLas varianzas del tratamiento en la submuestra tienen las siguientes formas:\n\n\\(s_{kU}=\\frac{(n_k+n_U)^2\\hat{V}_{kU}^D}{\\hat{V}^D}=\\frac{(n_k+n_U)^2n_{kU}(1-n_{kU})\\bar{D}_k(1-\\bar{D}_k)}{\\hat{V}^D}\\)\n\\(s_{lU}=\\frac{(n_l+n_U)^2\\hat{V}_{lU}^D}{\\hat{V}^D}=\\frac{(n_l+n_U)^2n_{lU}(1-n_{lU})\\bar{D}_l(1-\\bar{D}_l)}{\\hat{V}^D}\\)\n\\(s_{kl}^k=\\frac{[(n_k+n_l)(1-\\bar{D}_l)]^2\\hat{V}_{kl}^{D,k}}{\\hat{V}^D}=\\frac{[(n_k+n_l)(1-\\bar{D}_l)]^2n_{kl}(1-n_{kl}) \\frac{\\bar{D}_k-\\bar{D}_l}{1-\\bar{D}_l}\\frac{1-\\bar{D}_k}{1-\\bar{D}_l}}{\\hat{V}^D}\\)\n\\(s_{kl}^l=\\frac{[(n_k+n_l)\\bar{D}_k]^2\\hat{V}_{kl}^{D,l}}{\\hat{V}^D}=\\frac{[(n_k+n_l)\\bar{D}_k]^2n_{kl}(1-n_{kl})\\frac{\\bar{D}_l}{\\bar{D}_k}\\frac{\\bar{D}_k-\\bar{D}_l}{\\bar{D}_k}}{\\hat{V}^D}\\)"
  },
  {
    "objectID": "diapositivas/did.html#qué-son-los-pesos-2",
    "href": "diapositivas/did.html#qué-son-los-pesos-2",
    "title": "Inferencia Causal 2025",
    "section": "¿Qué son los pesos?",
    "text": "¿Qué son los pesos?\nPongamos atención a uno de los pesos, \\(s_{kU}\\) para ver la intuición\nVimos que:\n\\[s_{kU}=\\frac{(n_k+n_U)^2\\hat{V}_{kU}^D}{\\hat{V}^D}=\\frac{(n_k+n_U)^2n_{kU}(1-n_{kU})\\bar{D}_k(1-\\bar{D}_k)}{\\hat{V}^D}\\]\nPrimero, noten que el peso depende de \\((n_k+n_u)^2\\), es decir, la parte de la submuestra que se usa para estimar cada comparación \\(2x2\\)"
  },
  {
    "objectID": "diapositivas/did.html#qué-son-los-pesos-3",
    "href": "diapositivas/did.html#qué-son-los-pesos-3",
    "title": "Inferencia Causal 2025",
    "section": "¿Qué son los pesos?",
    "text": "¿Qué son los pesos?\nAhora veamos la varianza que entra en este peso:\n\\[\\hat{V}_{kU}^D=n_{kU}(1-n_{kU})\\bar{D}_k(1-\\bar{D}_k)\\] Una primer cosa que entra en juego es \\(n_{kU}=\\frac{n_k}{n_k+n_U}\\), el peso relativo del grupo tratado temprano en la submuestra\nRecordemos que \\(\\bar{D}_k\\) indica la fracción del tiempo del panel que \\(k\\) permanece tratado\nDado que \\(D_{it}\\) es binaria, \\(\\bar{D}_k(1-\\bar{D}_k)\\) es la varianza de \\(D_{it}\\)\n¿Qué es lo más grande que puede ser \\(\\bar{D}_k(1-\\bar{D}_k)\\)?\nClaramente esto es a lo más 0.5, es decir, la contribución se maximiza cuando el tratamiento ocurre lo más cercano a la mitad del panel"
  },
  {
    "objectID": "diapositivas/did.html#qué-son-los-pesos-4",
    "href": "diapositivas/did.html#qué-son-los-pesos-4",
    "title": "Inferencia Causal 2025",
    "section": "¿Qué son los pesos?",
    "text": "¿Qué son los pesos?\nEn resumen, los pesos están dados por\n\\[\\scriptsize  pesos = \\frac{(\\text{participación de la submuestra})^2(\\text{varianza del tratamiento purgada de efectos fijos en la submuestra})}{\\text{varianza del tratamiento purgada de efectos fijos en la muestra completa}}\\]"
  },
  {
    "objectID": "diapositivas/did.html#qué-nos-dice-la-descomposición",
    "href": "diapositivas/did.html#qué-nos-dice-la-descomposición",
    "title": "Inferencia Causal 2025",
    "section": "¿Qué nos dice la descomposición?",
    "text": "¿Qué nos dice la descomposición?\nTodos los grupos funcionan como controles (algunas veces)\nLos pesos en cada comparación \\(2 \\times 2\\) dependen del tamaño de la muestra usada para estimarlos y del tiempo que las unidades permanecen tratadas\nEl efecto estimado se modificaría solo por agregar más años al final del panel\nLos términos que dominen pueden incluso cambiar el signo del efecto estimado\nGoodman-Bacon (2021) muestra que, en general usar TWFE solo recupera un efecto de tratamiento bajo supuestos muy fuertes, el más crucial, bajo efectos de tratamiento que no varían en el tiempo (no hay efectos dinámicos)"
  },
  {
    "objectID": "diapositivas/did.html#estimador-de-callaway-santanna-1",
    "href": "diapositivas/did.html#estimador-de-callaway-santanna-1",
    "title": "Inferencia Causal 2025",
    "section": "Estimador de Callaway & Sant’Anna",
    "text": "Estimador de Callaway & Sant’Anna\nEl estimador de Callaway & Sant’Anna (2021) es una forma muy sencilla de explotar la información del desfase del tratamiento\nAdemás permite una presentación muy intuitiva de los efectos de tratamiento\nEsencialmente consiste en definir una serie de cohortes de unidades y estimar los impactos para cada cohorte\nLuego podemos agregar los impactos por cohorte o presentar la dinámica de los impactos de forma gráfica"
  },
  {
    "objectID": "diapositivas/did.html#definiciones",
    "href": "diapositivas/did.html#definiciones",
    "title": "Inferencia Causal 2025",
    "section": "Definiciones",
    "text": "Definiciones\n\n\\(G_i=\\min\\{t:D_{it}=1\\}\\) es el primer periodo en que \\(i\\) es tratado\n\\(G_i=\\infty\\) indoca que \\(i\\) nunca es tratado\n\\(t=1,\\ldots,T\\) son los periodos\n\\(D_{it}=1\\;\\forall\\;t\\geq G_i\\) indica tratamiento absorbente\n\nDefinamos el efecto del tratamiento al periodo \\(t\\) para el cohorte que empezó a ser tratado en \\(g\\):\n\\[ATT(g,t)=E(y_{it}(g)-y_{it}(\\infty)|G_i=g)\\] Por ejemplo, \\(ATT(2014,2016)\\) es el efecto del tratamiento en 2016 para aquellos tratados empezando en 2014"
  },
  {
    "objectID": "diapositivas/did.html#supuestos",
    "href": "diapositivas/did.html#supuestos",
    "title": "Inferencia Causal 2025",
    "section": "Supuestos",
    "text": "Supuestos\nTendencias paralelas en el contexto escalonado\n\\[E(y_{it}(\\infty)-y_{it'}(\\infty)|G_i=g)=E(y_{it}(\\infty)-y_{it'}(\\infty)|G_i=g')\\quad\\forall\\;t\\neq t',\\; g\\neq q'\\]\nEste supuesto indica que en el estado contrafactual de nunca haber sido tratados, dos grupos tratados en dos momentos diferentes \\(g\\) y \\(g'\\) habrían tenido una trayectoria igual entre los periodos \\(t\\) y \\(t'\\)\nTendencias paralelas en el contexto escalonado (a)\nModifica el supuesto anterior pero \\(\\forall \\;t,t'\\geq g_{min}-1\\) donde \\(g_{min}=\\min G\\) es el primer periodo en donde alguna unidad es tratada (Callaway y Sant’Anna solo usan este supuesto más débil)"
  },
  {
    "objectID": "diapositivas/did.html#supuestos-1",
    "href": "diapositivas/did.html#supuestos-1",
    "title": "Inferencia Causal 2025",
    "section": "Supuestos",
    "text": "Supuestos\nNo anticipación en el contexto escalonado\n\\[y_{it}(g)=y_{it}(\\infty)\\quad \\forall\\;i \\;\\text{y}\\;\\forall\\;t&lt;g\\]"
  },
  {
    "objectID": "diapositivas/did.html#estimador-de-callaway-santanna-2",
    "href": "diapositivas/did.html#estimador-de-callaway-santanna-2",
    "title": "Inferencia Causal 2025",
    "section": "Estimador de Callaway & Sant’Anna",
    "text": "Estimador de Callaway & Sant’Anna\nEl estimador de Callaway & Sant’Anna (2021) se define como:\n\\[ATT(g,t)=E(y_{it}-y_{i,g-1}|G_i=g)-E(y_{it}-y_{i,g-1}|G_i\\in\\mathcal{G}_{comp})\\] Queremos comparar el valor de la variable de impacto entre el periodo \\(g-1\\) y el \\(t\\) para el grupo que fue tratado en \\(g\\) con algún grupo de comparación denominado \\(\\mathcal{G}_{comp}\\)\nSustituyendo por el análogo muestral:\n\\[\\hat{ATT}(g,t)=\\frac{1}{N_g}\\sum_{i:\\;G_i=g}(y_{it}-y_{i,g-1})-\\frac{1}{N_{\\mathcal{G}_{comp}}}\\sum_{i\\;G_i\\in \\mathcal{G}_{comp}}(y_{it}-y_{i,g-1})\\]\n¿Qué es \\(\\mathcal{G}_{comp}\\)?\n\n\\(\\mathcal{G}_{comp}=\\{\\infty \\}\\): aquellas unidades nunca tratadas\n\\(\\mathcal{G}_{comp}=\\{g':g'&gt;t \\}\\): aquellas unidades aún no tratadas al periodo \\(t\\)"
  },
  {
    "objectID": "diapositivas/did.html#reportar-resultados",
    "href": "diapositivas/did.html#reportar-resultados",
    "title": "Inferencia Causal 2025",
    "section": "Reportar resultados",
    "text": "Reportar resultados\nSi tenemos pocos periodos y cohortes puede ser práctico reportar todos los \\(\\hat{ATT}(g,t)\\)\nTambién podemos construir medidas agregadas:\n\\[\\theta = \\sum_{g\\in\\mathcal{G}}\\sum_{t=2}^{\\mathcal{T}}w(g,t)ATT(g,t)\\]"
  },
  {
    "objectID": "diapositivas/did.html#formas-de-agregación",
    "href": "diapositivas/did.html#formas-de-agregación",
    "title": "Inferencia Causal 2025",
    "section": "Formas de agregación",
    "text": "Formas de agregación\nLa notación usada en el artículo es densa pero en resumen, algunas agregaciones posibles son:\nEfecto de tratamiento por duración de exposición\n\nPodemos calcular \\(\\theta(e)\\), el efecto promedio \\(e\\) periodos después del tratamiento, donde \\(e=t-g\\) es el tiempo que ocurre desde que se realizó el tratamiento\nPodemos hacer un gráfico de \\(\\theta(e)\\)\n\nEfecto de tratamiento por grupo o cohorte\n\nLo llamamos \\(\\theta(\\tilde{g})\\) y nos permite conocer si el efecto del tratamiento es distinto para cohortes que fueron tratados temprano o tarde\n\nEfecto de tratamiento acumulado\n\nLo llamamos \\(\\theta(\\tilde{t})\\) y lo definimos como el efecto promedio por participar en el tratamiento hasta una fecha dada \\(\\tilde{t}\\)"
  },
  {
    "objectID": "diapositivas/did.html#ventajas-del-estimador",
    "href": "diapositivas/did.html#ventajas-del-estimador",
    "title": "Inferencia Causal 2025",
    "section": "Ventajas del estimador",
    "text": "Ventajas del estimador\nToma en cuenta la heterogeneidad de los efectos de tratamiento\nLos pesos son especificados por el investigador y no mecánicamente con en TWFE\nHace explícito el grupo de comparación (nunca tratados o aún no tratados)"
  },
  {
    "objectID": "diapositivas/did.html#diferencia-en-diferencias-5",
    "href": "diapositivas/did.html#diferencia-en-diferencias-5",
    "title": "Inferencia Causal 2025",
    "section": "Diferencia en diferencias",
    "text": "Diferencia en diferencias\n\nPodemos dar así una primera definición de lo que es la diferencia en diferencias del número de bancos que sobrevivieron a la Gran Depresión en Mississippi\n\n\\[\n\\begin{aligned}\n\\delta_{DID}&=(Y_{6,post}-Y_{6,pre})-(Y_{8,post}-Y_{8,pre}) \\\\\n&=(Y_{6,1931}-Y_{6,1930})-(Y_{8,1931}-Y_{8,1930}) \\\\\n&=(121-135)-(132-165) \\\\\n&=-14+33 = 19\n\\end{aligned}\n\\]\n\nEl estimador de DID toma en cuenta las diferencias iniciales\nEn este caso, el distrito 8 ya tenía más bancos abiertos que el 6 antes de la crisis\nDID construye un contrafactual para las unidades tratadas usando la pendiente de las unidades no tratadas"
  },
  {
    "objectID": "diapositivas/did.html#diferencia-en-diferencias-6",
    "href": "diapositivas/did.html#diferencia-en-diferencias-6",
    "title": "Inferencia Causal 2025",
    "section": "Diferencia en diferencias",
    "text": "Diferencia en diferencias\n\nEl supuesto fundamental es el de tendencias comunes, es decir, que en ausencia del tratamiento, el grupo de tratamiento se hubiera comportado igual al grupo de control\nSi hay varios puntos pre intervención, el supuesto de tendencias comunes puede probarse empíricamente"
  },
  {
    "objectID": "tareas/tarea-2.html#preguntas",
    "href": "tareas/tarea-2.html#preguntas",
    "title": "Tarea 2",
    "section": "",
    "text": "Fecha de entrega: viernes 3 de octubre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los leguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-5",
    "href": "tareas/tarea-2.html#pregunta-5",
    "title": "Tarea 2",
    "section": "Pregunta 5",
    "text": "Pregunta 5\nNuevamente, use los datos del archivo STAR_public_use.csv. En este problema, replicará dos columnas del efecto de tratamiento de la Tabla 5. Note que de nuevo se deben usar solo las observaciones que tienen noshow igual a 0. Los autores también sustituyen los valores de gpa_year1 por NA cuando la variable grade_20059_fall es NA; y sustituyen grade_20059_fall por NA cuando la variable gpa_year1 es NA. Además, note que se usan las siguientes variables de control: sex, mtongue, hsgroup, numcourses_nov1, lastmin, mom_edn, y dad_edn, todas ellas categóricas.\n\n[10 puntos] Estime el efecto de cada tipo de tratamiento sobre el promedio o GPA, denotado gpa_year1 en los datos, para toda la muestra (Panel B, columna 1). Calcule correctamente los errores estándar. Interprete los resultados.\n[10 puntos] Estime el efecto sobre el GPA de recibir cada tipo de tratamiento, considerando los tratamientos SSP o SFP (de cualquier tipo) en las mujeres de la muestra (Panel B, columna 6). Esto es, considere el tratamiento SSP como un primer tipo de tratamiento y, ya sea SFP o SFSP, como un segundo tipo de tratamiento. Calcule correctamente los errores estándar. Interprete sus resultados."
  },
  {
    "objectID": "diapositivas/emparejamiento.html#sesgo-de-selección",
    "href": "diapositivas/emparejamiento.html#sesgo-de-selección",
    "title": "Inferencia Causal 2025",
    "section": "Sesgo de selección",
    "text": "Sesgo de selección\nLas razones que determinan la asignación del tratamiento pueden también determinar el valor de \\(Y\\). Entonces, una comparación observacional nos da el efecto del tratamiento más el sesgo de selección:\n\\[\n\\begin{aligned}\nE(y_i|D_i=1)-E(y_i|D_i=0)=&\\overbrace{ E(y_{1i}|D_i=1)-E(y_{0i}|D_i=1)}^{\\text{Efecto promedio en los tratados}}+\\\\& \\underbrace{E(y_{0i}|D_i=1)-E(y_{oi}|D_i=0)}_{\\text{Sesgo de selección}}\n\\end{aligned}\n\\]\nUna forma de eliminar el sesgo de selección es mediante la asignación aleatoria del tratamiento; sin embargo, esto no siempre es posible por lo que recurrimos a supuestos para eliminar el sesgo de selección."
  },
  {
    "objectID": "diapositivas/emparejamiento.html#supuesto-de-independencia",
    "href": "diapositivas/emparejamiento.html#supuesto-de-independencia",
    "title": "Inferencia Causal 2025",
    "section": "Supuesto de independencia",
    "text": "Supuesto de independencia\nEl supuesto de independencia condicional dice que al controlar por una serie de características \\(X_i\\), el tratamiento es como si fuera aleatorio:\n\\[\nE(Y(1)|D=1,X)=E(Y(1)|D=0,X)\n\\]\n\\[\nE(Y(0)|D=1,X)=E(Y(0)|D=0,X)\n\\]\nEsto es, los valores esperados de \\(Y(1)\\) y \\(Y(0)\\) son iguales cuando nos fijamos en cada valor de \\(X\\)."
  },
  {
    "objectID": "diapositivas/emparejamiento.html#matching-exacto-1",
    "href": "diapositivas/emparejamiento.html#matching-exacto-1",
    "title": "Inferencia Causal 2025",
    "section": "Matching exacto",
    "text": "Matching exacto\nUn estimador de matching exacto consiste en emparejar individuos tratados y no tratados para cada valor específico de las \\(X\\) y luego tomar el promedio ponderado de las diferencias.\nTenemos datos observacionales de individuos que recibieron y no recibieron un tratamiento y tenemos una serie de características discretizadas en \\(X_i\\).\nAsumimos que controlando por las características \\(X_i\\) podemos obtener diferencias causales y luego hacemos un promedio de dichas diferencias."
  },
  {
    "objectID": "diapositivas/emparejamiento.html#ejemplo-programa-hipotético-de-empleo",
    "href": "diapositivas/emparejamiento.html#ejemplo-programa-hipotético-de-empleo",
    "title": "Inferencia Causal 2025",
    "section": "Ejemplo: programa hipotético de empleo",
    "text": "Ejemplo: programa hipotético de empleo\nUsemos el ejemplo de MT (The Mixtape):"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#ejemplo-programa-hipotético-de-empleo-1",
    "href": "diapositivas/emparejamiento.html#ejemplo-programa-hipotético-de-empleo-1",
    "title": "Inferencia Causal 2025",
    "section": "Ejemplo: programa hipotético de empleo",
    "text": "Ejemplo: programa hipotético de empleo\n\n\nLos individuos tratados:\n\n\n# A tibble: 10 × 3\n   unit_treat age_treat earnings_treat\n        &lt;dbl&gt;     &lt;dbl&gt;          &lt;dbl&gt;\n 1          1        18           9500\n 2          2        29          12250\n 3          3        24          11000\n 4          4        27          11750\n 5          5        33          13250\n 6          6        22          10500\n 7          7        19           9750\n 8          8        20          10000\n 9          9        21          10250\n10         10        30          12500\n\n\n\nMientras que los no tratados:\n\n\n# A tibble: 20 × 3\n   unit_control age_control earnings_control\n          &lt;dbl&gt;       &lt;dbl&gt;            &lt;dbl&gt;\n 1            1          20             8500\n 2            2          27            10075\n 3            3          21             8725\n 4            4          39            12775\n 5            5          38            12550\n 6            6          29            10525\n 7            7          39            12775\n 8            8          33            11425\n 9            9          24             9400\n10           10          30            10750\n11           11          33            11425\n12           12          36            12100\n13           13          22             8950\n14           14          18             8050\n15           15          43            13675\n16           16          39            12775\n17           17          19             8275\n18           18          30             9000\n19           19          51            15475\n20           20          48            14800"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#comparación-observacional",
    "href": "diapositivas/emparejamiento.html#comparación-observacional",
    "title": "Inferencia Causal 2025",
    "section": "Comparación observacional",
    "text": "Comparación observacional\nSi hiciéramos diferencias simples obtendríamos:\n\nmean(data.treat$earnings_treat)\n\n[1] 11075\n\nmean(data.control$earnings_control)\n\n[1] 11101.25\n\n#Diferencia\nmean(data.treat$earnings_treat)- mean(data.control$earnings_control)\n\n[1] -26.25\n\n\nParece que en el grupo de control ganan más (efecto de tratamiento negativo).\nEl principal problema con esta diferencia es que sabemos que los ingresos crecen con la edad. Pero notemos que la muestra de no tratados tiene mayor edad promedio:\n\nmean(data.treat$age_treat)\n\n[1] 24.3\n\nmean(data.control$age_control)\n\n[1] 31.95\n\n#Diferencia\nmean(data.treat$age_treat)- mean(data.control$age_control)\n\n[1] -7.65\n\n\nEs decir, estaríamos confundiendo el efecto de la edad."
  },
  {
    "objectID": "diapositivas/emparejamiento.html#muestra-emparejada",
    "href": "diapositivas/emparejamiento.html#muestra-emparejada",
    "title": "Inferencia Causal 2025",
    "section": "Muestra emparejada",
    "text": "Muestra emparejada\nConstruyamos la muestra apareada: para cada individuo en el grupo tratado, buscaremos uno en el de control que tenga la misma edad. Cuando le encontramos un individuo no tratado al tratado con la misma edad decimos que esa pareja hizo match.\nPor ejemplo, la primera unidad tratada, con 18 años y un ingreso de 9500 estaría emparejada con la unidad 14 del grupo de control, que tiene también 18 años y un ingreso de 8050.\nPara dicho individuo de 18 años, su ingreso contrafactual sería 8050.\nCuando hay varias unidades en el grupo de control que pueden ser empatadas con la de tratamiento, podemos construir el ingreso contrafactual calculando el promedio.\nDel grupo de control, los individuos 10 y 18 tienen 30 años, con ingresos 10750 y 9000, por lo que usamos el promedio (9875) para crear el contrafactual del individuo tratado de 30 años de la fila 10."
  },
  {
    "objectID": "diapositivas/emparejamiento.html#muestra-emparejada-1",
    "href": "diapositivas/emparejamiento.html#muestra-emparejada-1",
    "title": "Inferencia Causal 2025",
    "section": "Muestra emparejada",
    "text": "Muestra emparejada\nLa muestra emparejada o contrafactual será:\n\n\n# A tibble: 10 × 3\n   unit_matched age_matched earnings_matched\n          &lt;dbl&gt;       &lt;dbl&gt;            &lt;dbl&gt;\n 1            1          18             8050\n 2            2          29            10525\n 3            3          24             9400\n 4            4          27            10075\n 5            5          33            11425\n 6            6          22             8950\n 7            7          19             8275\n 8            8          20             8500\n 9            9          21             8725\n10           10          30             9875"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#muestra-emparejada-2",
    "href": "diapositivas/emparejamiento.html#muestra-emparejada-2",
    "title": "Inferencia Causal 2025",
    "section": "Muestra emparejada",
    "text": "Muestra emparejada\nNoten que la edad es la misma entre los tratados y la muestra apareada:\n\n\nMuestra de tratados:\n\nmean(data.treat$age_treat)\n\n[1] 24.3\n\n\n\nMuestra emparejada:\n\nmean(data.matched$age_matched)\n\n[1] 24.3\n\n\n\nEn este caso, decimos que la edad está balanceada.\nY entonces podemos calcular el efecto de tratamiento como la diferencia de ingresos entre los tratados y los no tratados en la muestra emparejada:\n\n\n[1] 1695\n\n\nEn este caso, encontramos un efecto positivo del programa de 1695 unidades monetarias."
  },
  {
    "objectID": "diapositivas/emparejamiento.html#estimador-de-matching-exacto",
    "href": "diapositivas/emparejamiento.html#estimador-de-matching-exacto",
    "title": "Inferencia Causal 2025",
    "section": "Estimador de matching exacto",
    "text": "Estimador de matching exacto\nLo anterior nos permite definir el estimador de matching exacto del TOT como:\n\\[\\hat{\\delta}_{TOT}=\\frac{1}{N_T}\\sum_{D_i=1}\\left(Y_i-\\left(\\frac{1}{M}\\sum_{m=1}^{M}Y_{jm(i)}\\right)\\right)\\]"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#importancia-del-soporte-común",
    "href": "diapositivas/emparejamiento.html#importancia-del-soporte-común",
    "title": "Inferencia Causal 2025",
    "section": "Importancia del soporte común",
    "text": "Importancia del soporte común\nObservemos lo que ocurre con la distribución de edades en ambos grupos:\n\n\nPara los tratados:\n\n\n\n\n\n\n\n\n\n\nMientras que para los no tratados:\n\n\n\n\n\n\n\n\n\n\nEl supuesto de traslape débil para identificar el TOT significa que para cada unidad tratada, hay al menos un no tratado. De otra forma, no podemos hacer la comparación."
  },
  {
    "objectID": "diapositivas/emparejamiento.html#estimador-de-matching-exacto-1",
    "href": "diapositivas/emparejamiento.html#estimador-de-matching-exacto-1",
    "title": "Inferencia Causal 2025",
    "section": "Estimador de matching exacto",
    "text": "Estimador de matching exacto\n\nHasta aquí, solo hemos imputado el contrafactual para cada unidad en el grupo tratado\nSi podemos imputar también, para cada unidad no tratada, su correspondiente contrafactual tratado, podemos estimar el ATE\nY un estimador de matching exacto del ATE sería:\n\n\\[\\hat{\\delta}_{ATE}=\\frac{1}{N}\\sum_{i}^N(2D_i-1)\\left(Y_i-\\left(\\frac{1}{M}\\sum_{m=1}^{M}Y_{jm(i)}\\right)\\right)\\]"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#ejemplo-de-la-vida-real",
    "href": "diapositivas/emparejamiento.html#ejemplo-de-la-vida-real",
    "title": "Inferencia Causal 2025",
    "section": "Ejemplo de la vida real",
    "text": "Ejemplo de la vida real\n\nTenemos varias características en \\(X_i\\), no solo la edad\nEsto hace que cada valor \\(X_i=x_i\\) este representado por una celda\n\\(X_i\\) incluye, por ejemplo, raza, año de solicitud de ingreso al programa, escolaridad, calificación en examen de aptitud, año de nacimiento (son las características del ejemplo que vermeos más adelante)\nEstas características definen celdas y dentro de cada celda tenemos tratados y no tratados"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#efecto-del-tratamiento-con-matching-exacto",
    "href": "diapositivas/emparejamiento.html#efecto-del-tratamiento-con-matching-exacto",
    "title": "Inferencia Causal 2025",
    "section": "Efecto del tratamiento con matching exacto",
    "text": "Efecto del tratamiento con matching exacto\n\nEl TOT asumiendo inconfundibilidad:\n\n\\[\n\\begin{aligned}\n\\delta^M=TOT&=E\\left\\{ E(y_{1i}|X_i,D_i=1)-E(y_{0i}|X_i,D_i=0)|D_i=1\\right\\} \\\\\n&=E\\left\\{\\delta_X | D_i=1\\right\\}\n\\end{aligned}\n\\]\n\n\\(\\delta_X\\) es la diferencia de ingresos promedio entre estados de tratamiento para cada valor de \\(X_i\\)\nCon \\(X_i\\) discreta y con una muestra disponible:\n\n\\[\n\\delta^M=\\sum_{x} \\delta_x P(X_i=x|D_i=1)\n\\]"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#ejemplo-veteranos-de-guerra-en-estados-unidos",
    "href": "diapositivas/emparejamiento.html#ejemplo-veteranos-de-guerra-en-estados-unidos",
    "title": "Inferencia Causal 2025",
    "section": "Ejemplo: veteranos de guerra en Estados Unidos",
    "text": "Ejemplo: veteranos de guerra en Estados Unidos\n\nAngrist (1998), Estimating the Labor Market Impact of Voluntary Military Service Using Social Security Data on Military Applicants\nEl tratamiento es haber servido en el ejercito, algo que claramente tiene autoselección\nSe trata de estimar el efecto en el ingreso\nLos autores construyen celdas de acuerdo a las características antes mencionadas\n\nRaza, año de solicitud de ingreso al programa, escolaridad, calificación en examen de aptitud, año de nacimiento"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#ejemplo-veteranos-de-guerra-en-estados-unidos-1",
    "href": "diapositivas/emparejamiento.html#ejemplo-veteranos-de-guerra-en-estados-unidos-1",
    "title": "Inferencia Causal 2025",
    "section": "Ejemplo: veteranos de guerra en Estados Unidos",
    "text": "Ejemplo: veteranos de guerra en Estados Unidos\n\nEfectos estimados usando distintas metodologías\nLos impactos estimados usando el matching exacto se encuentran bajo la columna Controlled contrast"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#ejemplo-veteranos-de-guerra-en-estados-unidos-2",
    "href": "diapositivas/emparejamiento.html#ejemplo-veteranos-de-guerra-en-estados-unidos-2",
    "title": "Inferencia Causal 2025",
    "section": "Ejemplo: veteranos de guerra en Estados Unidos",
    "text": "Ejemplo: veteranos de guerra en Estados Unidos\n\nNoten que la columna (2) muestra lo que se hubiera concluido si solo se comparan diferencias de medias\nAntes de 1980, las diferencias eran muy pequeñas (cero en términos prácticos)\nEn esta aplicación esta comparación llevaría a conclusiones incorrectas\nAdemás, las diferencias para no-blancos y blancos son distintas\nHay un pico en los efectos alrededor de 1982\nEn esta aplicación, los resultados por matching y regresión son muy parecidos hasta 1984\nLa conclusión es que existe evidencia de efectos negativos en los ingresos por haber servido en el ejército en los blancos y efectos positivos para los individuos de otras razas"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#ejemplo-veteranos-de-guerra-en-estados-unidos-3",
    "href": "diapositivas/emparejamiento.html#ejemplo-veteranos-de-guerra-en-estados-unidos-3",
    "title": "Inferencia Causal 2025",
    "section": "Ejemplo: veteranos de guerra en Estados Unidos",
    "text": "Ejemplo: veteranos de guerra en Estados Unidos\n\n\nPara personas identificadas como blancas:\n\n\n\n\n\n\n\n\n\n\nPara personas identificadas como no blancas:"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#métodos-de-apareamiento-o-matching",
    "href": "diapositivas/emparejamiento.html#métodos-de-apareamiento-o-matching",
    "title": "Inferencia Causal 2025",
    "section": "Métodos de apareamiento o matching",
    "text": "Métodos de apareamiento o matching\n\nLos métodos apareamiento o matching recaen en el supuesto de independencia condicional\nAl controlar por una serie de características \\(X_i\\), el tratamiento es como si fuera aleatorio\nPodemos escribir\n\n\\[\nE(Y(1)|D=1,X)=E(Y(1)|D=0,X)\n\\]\n\\[\nE(Y(0)|D=1,X)=E(Y(0)|D=0,X)\n\\]\n\nEsto es, los valores esperados de \\(Y(1)\\) y \\(Y(0)\\) son iguales cuando nos fijamos en cada valor de \\(X\\)"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#supuestos-de-identificación-del-tot",
    "href": "diapositivas/emparejamiento.html#supuestos-de-identificación-del-tot",
    "title": "Inferencia Causal 2025",
    "section": "Supuestos de identificación del TOT",
    "text": "Supuestos de identificación del TOT\nSupuesto 1. Inconfundibilidad\n\\[\nY(0), Y(1) \\perp  D|X\n\\]\n\nDado un conjunto de variables \\(X\\), los resultados potenciales son independientes del tratamiento\n\\(X\\) debe incluir todas las variables que determinan el tratamiento y los resultados potenciales\n\nSupuesto 2: Traslape\n\\[\n0&lt; P(D=1|X) &lt; 1\n\\]\n\n\\(X\\) no predice \\(D\\) perfectamente\nPersonas con el mismo \\(X\\) tienen probabilidad positiva de ser tratados y no tratados"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#supuestos-de-identificación-del-tot-1",
    "href": "diapositivas/emparejamiento.html#supuestos-de-identificación-del-tot-1",
    "title": "Inferencia Causal 2025",
    "section": "Supuestos de identificación del TOT",
    "text": "Supuestos de identificación del TOT\n\nCuando se cumple Supuesto 1 \\(+\\) Supuesto 2 se conoce como ignorabilidad fuerte\nHeckman (1998) muestra que estás condiciones son demasiado estrictas\nPara identificar el \\(TOT\\) es suficiente:\nSupuesto 1a. Inconfundibilidad en el control\n\n\\[\nY(0) \\perp  D | X\n\\]\n\nSupuesto 2a. Traslape débil\n\n\\[\nP(D=1|X) &lt; 1\n\\]"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#matching-exacto-es-impráctico",
    "href": "diapositivas/emparejamiento.html#matching-exacto-es-impráctico",
    "title": "Inferencia Causal 2025",
    "section": "Matching exacto es impráctico",
    "text": "Matching exacto es impráctico\n\nEn la práctica es difícil manejar problemas en espacios de múltiples dimensiones: maldición de la dimensionalidad\nEl problema de la maldición de la dimensionalidad se exacerba con el tamaño limitado de las bases de datos\nSi \\(X\\) tuviera solo indicadores binarios, el número de posibles combinaciones sería \\(2^s\\)\nPor ejemplo, si solo tuviéramos \\(X_1=\\{\\text{menor de 35 años}, \\text{con 35 años o más}\\}\\), \\(X_2=\\{\\text{más que preparatoria}, \\text{menos que preparatoria}\\}\\), \\(X_3=\\{\\text{indígena}, \\text{no indígena}\\}\\), tendríamos que hacer ocho comparaciones:\n\nmenor de 35 años, más que preparatoria, indígena\nmenor de 35 años, más que preparatoria, no indígena\n…\ncon 35 años o más, menos que preparatoria, no indígena\n\nPero Si \\(X\\) incluye muchas variables, algunas tomando muchos valores, esto se vuelve imposible de realizar"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#maldición-de-la-dimensionalidad",
    "href": "diapositivas/emparejamiento.html#maldición-de-la-dimensionalidad",
    "title": "Inferencia Causal 2025",
    "section": "Maldición de la dimensionalidad",
    "text": "Maldición de la dimensionalidad\n\nEl requerimiento de soporte común significa que debemos tener tratados y no tratados para cada valor de \\(X_i\\) para hacer comparaciónes\nCuando \\(X_i\\) tiene muchas dimensiones, resulta un problema de escasez o sparseness\nAlgunas celdas estarán vacías, o solo tendrán tratados, o solo tendrán no tratados\nSi tenemos unidades en todas las celdas de control, aún podemos estimar el TOT\n\nNoten que cuando completamos la fase pareada en el ejemplo hipotético, siempre encontramos a alguien en el grupo de control para asignárselo a un tratado\nPero al revés, no siempre es posible: por ejemplo, no hay ningún tratado de 48 años"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#teorema-del-ps-rosenbaum-y-rubin-1983",
    "href": "diapositivas/emparejamiento.html#teorema-del-ps-rosenbaum-y-rubin-1983",
    "title": "Inferencia Causal 2025",
    "section": "Teorema del PS (Rosenbaum y Rubin, 1983)",
    "text": "Teorema del PS (Rosenbaum y Rubin, 1983)\n\nCorolario 1. Inconfundibilidad dado el propensity score\nEl Supuesto 1 implica:\n\n\\[\nY(0), Y(1) \\perp  D|P(X)\n\\]\ndonde \\(P(X)=P(D=1|X)\\) es la probabilidad de ser tratado dado un conjunto de covariables \\(X\\), el propensity score o PS"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#efecto-del-tratamiento",
    "href": "diapositivas/emparejamiento.html#efecto-del-tratamiento",
    "title": "Inferencia Causal 2025",
    "section": "Efecto del tratamiento",
    "text": "Efecto del tratamiento\n\nEl efecto del tratamiento, bajo el supuesto de inconfundibilidad dado el propensity score, es:\n\n\\[\nTOT^{PSM}=E_{P(X)|D=1} \\left(E(Y(1)|D=1, P(X))-E(Y(0)|D=0,P(X)) \\right)\n\\]\n\nEl \\(TOT\\) es la diferencia en la variable de resultados de los tratados y los no tratados pesada por la distribución del PS en los tratados"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#estimación",
    "href": "diapositivas/emparejamiento.html#estimación",
    "title": "Inferencia Causal 2025",
    "section": "Estimación",
    "text": "Estimación\n\nDebemos por tanto primero calcular el PS\nSe empatan o se hace match de unidades que fueron tratadas con unidades que no lo fueron usando el PS\nSe mide la diferencia en la variable de resultados entre estos grupos\nSe hace un promedio ponderado de las diferencias"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#implementación",
    "href": "diapositivas/emparejamiento.html#implementación",
    "title": "Inferencia Causal 2025",
    "section": "Implementación",
    "text": "Implementación\n\nEstimación del PS\nEscoger el algoritmo de matching\nComprobar la calidad del matching\nEstimar el \\(TOT\\)"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#especificar-el-modelo-del-ps",
    "href": "diapositivas/emparejamiento.html#especificar-el-modelo-del-ps",
    "title": "Inferencia Causal 2025",
    "section": "Especificar el modelo del PS",
    "text": "Especificar el modelo del PS\n\nSe usa un modelo probit o logit\n\nPrueba y error. Maximizar la tasa clasificación de tratamientos y controles usando \\(\\bar{P}\\), la proporción de tratamientos en la muestra\nSignificancia estadística. Usar solo las variables estadísticamente significativas, comenzando con un modelo muy básico\nValidación cruzada. Comenzar con un modelo simple y agregar grupos de variables comparando las que reduzcan el error cuadrático promedio\n\nEl propósito del PS es sobre todo generar balance de las variables en \\(X\\)"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#vecino-más-cercano",
    "href": "diapositivas/emparejamiento.html#vecino-más-cercano",
    "title": "Inferencia Causal 2025",
    "section": "Vecino más cercano",
    "text": "Vecino más cercano\n\nA cada individuo del grupo tratado se le asigna uno del grupo de comparación en términos del PS\nPuede hacerse con remplazo o sin remplazo\nPuede emplearse también sobremuestreo (oversampling), es decir, asignar más de un individuo del grupo de comparación\nPor ejemplo, NN 5 significa que a cada individuo tratado se le asignan los cinco individuos del grupo no tratado con los PS estimados más cercanos"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#vecino-más-cercano-1",
    "href": "diapositivas/emparejamiento.html#vecino-más-cercano-1",
    "title": "Inferencia Causal 2025",
    "section": "Vecino más cercano",
    "text": "Vecino más cercano\n\n\n\n\n\nTratados\n\\(\\hat{p}\\)\n\n\n\n\na\n0.031\n\n\nb\n0.042\n\n\nc\n0.07\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\n\n\n\n\nNo tratados\n\\(\\hat{p}\\)\n\n\n\n\nA\n0.034\n\n\nB\n0.068\n\n\nC\n0.21\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\n\n\nCon vecino más cercano, el individuo \\(a\\) tratado estaría emparejado con el \\(A\\) no tratado\nSi el emparejamiento es con reemplazo, \\(A\\) podría ser usado otra vez y \\(b\\) también sería emparejado con \\(A\\)\nPero si el emparejamiento es sin reemplazo, \\(A\\) ya no puede ser usado y a \\(b\\) se le emparejaría con \\(B\\)\nCuando hacemos el pareamiento sin reemplazo, debemos tener una muestra lo suficientemente grande\nEl pareamiento sin reemplazo depende del orden en que se realice el procedimiento"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#caliper-y-radio",
    "href": "diapositivas/emparejamiento.html#caliper-y-radio",
    "title": "Inferencia Causal 2025",
    "section": "Caliper y radio",
    "text": "Caliper y radio\n\nEl método de vecino más cercano puede generar malos emparejamientos si el vecino más cercano está muy lejos en términos del PS\nEspecificar un caliper consiste en definir una vecindad aceptable de matching (el caliper) y elegir solo el vecino más cercano dentro del caliper\nCon las funciones de R que usaremos más adelante, el radio consiste en definir cuántos individuos deberán ser apareados dado que están dentro del caliper"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#caliper",
    "href": "diapositivas/emparejamiento.html#caliper",
    "title": "Inferencia Causal 2025",
    "section": "Caliper",
    "text": "Caliper\n\n\n\n\n\nTratados\n\\(\\hat{p}\\)\n\n\n\n\na\n0.031\n\n\nb\n0.042\n\n\nc\n0.07\n\n\nd\n0.11\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\n\n\n\n\nNo tratados\n\\(\\hat{p}\\)\n\n\n\n\nA\n0.034\n\n\nB\n0.068\n\n\nC\n0.21\n\n\nD\n0.40\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\n\n\nEl primer paso es fijar el caliper, por ejemplo, de 0.1\nEl caliper implica buscar al vecino más cercano dentro de una vecindad de 0.1\nEn este ejemplo \\(c\\) podría ser solo emparejado con \\(B\\) si \\(B\\) aún está disponible (porque no ha sido emparejado con nadie o porque, aunque haya sido emparejado, el procedimiento se hace con reemplazo)"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#caliper-con-sobremuestreo",
    "href": "diapositivas/emparejamiento.html#caliper-con-sobremuestreo",
    "title": "Inferencia Causal 2025",
    "section": "Caliper con sobremuestreo",
    "text": "Caliper con sobremuestreo\n\n\n\n\n\nTratados\n\\(\\hat{p}\\)\n\n\n\n\nd\n0.31\n\n\ne\n0.39\n\n\nf\n0.44\n\n\ng\n0.52\n\n\nh\n0.55\n\n\ni\n0.62\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\n\n\n\n\nNo tratados\n\\(\\hat{p}\\)\n\n\n\n\nR\n0.27\n\n\nS\n0.29\n\n\nT\n0.33\n\n\nU\n0.49\n\n\nV\n0.57\n\n\nW\n0.61\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\n\n\nSi el caliper se realiza con sobremuestreo, con un caliper de 0.10 y 2 vecinos a \\(g\\) se le asignarían \\(U\\) y \\(V\\) (si estuvieran disponibles)\nEs decir, dentro del caliper, los dos individuos con el PS más cercano"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#radio",
    "href": "diapositivas/emparejamiento.html#radio",
    "title": "Inferencia Causal 2025",
    "section": "Radio",
    "text": "Radio\n\n\n\n\n\nTratados\n\\(\\hat{p}\\)\n\n\n\n\nd\n0.31\n\n\ne\n0.39\n\n\nf\n0.44\n\n\ng\n0.52\n\n\nh\n0.55\n\n\ni\n0.62\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\n\n\n\n\nNo tratados\n\\(\\hat{p}\\)\n\n\n\n\nR\n0.27\n\n\nS\n0.29\n\n\nT\n0.33\n\n\nU\n0.49\n\n\nV\n0.57\n\n\nW\n0.61\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\n\n\nPero si ahora implementamos radio con un caliper de 0.10, a \\(g\\) se le asignarían \\(U\\), \\(V\\) y \\(W\\) (si estuvieran disponibles)\nEs decir, todos los individuos dentro del caliper"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#estratificación",
    "href": "diapositivas/emparejamiento.html#estratificación",
    "title": "Inferencia Causal 2025",
    "section": "Estratificación",
    "text": "Estratificación\n\nPartir la región de soporte común en bloques de acuerdo al PS\nEstimar el efecto de tratamiento dentro de cada bloque\nNo hay una regla sobre cuántos estratos usar. Se aconsajan generalmente cinco\nDentro de cada estrato debe haber balance de los covariables"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#kernel-y-métodos-no-paramétricos",
    "href": "diapositivas/emparejamiento.html#kernel-y-métodos-no-paramétricos",
    "title": "Inferencia Causal 2025",
    "section": "Kernel y métodos no paramétricos",
    "text": "Kernel y métodos no paramétricos\n\nLos métodos anteriores escogen solo unas cuantas unidades del grupo de comparación\nPodemos escoger usar muchas o incluso todas las observaciones del grupo de comparación y pesarlas apropiadamente\nSe reduce la varianza pues usamos más información, pero se sacrifica precisión pues se usan observaciones potencialmente muy distantes\nSe le otorga más peso a las observaciones más cercanas y menos a las más distantes"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#kernel",
    "href": "diapositivas/emparejamiento.html#kernel",
    "title": "Inferencia Causal 2025",
    "section": "Kernel",
    "text": "Kernel\n\n\n\n\n\nTratados\n\\(\\hat{p}\\)\n\n\n\n\nd\n0.31\n\n\ne\n0.39\n\n\nf\n0.44\n\n\ng\n0.52\n\n\nh\n0.55\n\n\ni\n0.62\n\n\n\n\n\n\n\nNo tratados\n\\(\\hat{p}\\)\n\n\n\n\nR\n0.27\n\n\nS\n0.29\n\n\nT\n0.33\n\n\nU\n0.49\n\n\nV\n0.57\n\n\nW\n0.61\n\n\n\n\n\nSupongamos que estos son todos nuestros datos\nCon un emparejamiento por kernel, a \\(d\\) lo compararemos con todos los individuos, desde \\(R\\) hasta \\(W\\)\nLa función kernel le dará más peso a \\(R\\), un poco menos a \\(S\\) y así hasta darle muy poco o casi nada de peso a \\(W\\)"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#qué-método-usar",
    "href": "diapositivas/emparejamiento.html#qué-método-usar",
    "title": "Inferencia Causal 2025",
    "section": "¿Qué método usar?",
    "text": "¿Qué método usar?\n\nNo hay un método claramente superior a todos los demás\nMás aún, el desempeño de cada método depende de cada aplicación\nLa ruta más seguida es usar varios algoritmos y mostrar la robustez de los resultados a esta elección"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#comprobar-empíricamente-los-supuestos",
    "href": "diapositivas/emparejamiento.html#comprobar-empíricamente-los-supuestos",
    "title": "Inferencia Causal 2025",
    "section": "Comprobar empíricamente los supuestos",
    "text": "Comprobar empíricamente los supuestos\n\nEl parámetro \\(TOT\\) solo se calcula sobre la región de sporte común por lo que se debe verificar el traslape del PS calculado para los tratados y no tratados\nOtro de los teoremas de Rosenbaum y Rubin (1983) implica que\n\n\\[\nX \\perp  D|P(X)\n\\]\n\nEsto es, que al controlar por el PS, las variables \\(X\\) no deben proveer información sobre \\(D\\)\nSe recomienda también hacer una prueba de estratificación\n\nDividir el rango del soporte común en bloques\nHacer una prueba de medias del PS entre grupos dentro de cada bloque\nHacer una prueba de medias de cada variable en \\(X_i\\) entre grupos dentro de cada bloque"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#ilustración-del-soporte-común",
    "href": "diapositivas/emparejamiento.html#ilustración-del-soporte-común",
    "title": "Inferencia Causal 2025",
    "section": "Ilustración del soporte común",
    "text": "Ilustración del soporte común"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#paquetes",
    "href": "diapositivas/emparejamiento.html#paquetes",
    "title": "Inferencia Causal 2025",
    "section": "Paquetes",
    "text": "Paquetes\nUsaremos dos paquetes nuevos: MatchIt y cobalt, que pueden descargar como cualquier otro paquete desde CRAN."
  },
  {
    "objectID": "diapositivas/emparejamiento.html#datos-no-experimentales-de-una-muestra-de-mujeres",
    "href": "diapositivas/emparejamiento.html#datos-no-experimentales-de-una-muestra-de-mujeres",
    "title": "Inferencia Causal 2025",
    "section": "Datos no experimentales de una muestra de mujeres",
    "text": "Datos no experimentales de una muestra de mujeres\nLos datos en cattaneo_smoking.csv (Cattaneo, 2010) son de una muestra de mujeres que incluye un indicador de si la madre fumó durante el embarazo. El propósito es evaluar el efecto de fumar sobre el peso de los bebés al nacer. Se incluyen una serie de covariables que usaremos para modelar el propensity score."
  },
  {
    "objectID": "diapositivas/emparejamiento.html#matchit-para-realizar-los-emparejamientos",
    "href": "diapositivas/emparejamiento.html#matchit-para-realizar-los-emparejamientos",
    "title": "Inferencia Causal 2025",
    "section": "matchit para realizar los emparejamientos",
    "text": "matchit para realizar los emparejamientos\nLa función que usaremos para hacer los emparejamientos es matchit de la librería MatchIt. Antes de hacer los emparejamientos, construimos la dummy de tratamiento, smoke, una dummy para mujeres casadas, married, y una dummy para si el caso en cuestión es el primer bebé, firstbaby:"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#comparación-observacional-1",
    "href": "diapositivas/emparejamiento.html#comparación-observacional-1",
    "title": "Inferencia Causal 2025",
    "section": "Comparación observacional",
    "text": "Comparación observacional\nNotemos que, si solo comparamos a las mujeres que fuman con las que no fuman, estamos comparando personas muy diferentes:\n\n\n \n\n  \n    \n    \n    tinytable_1lsywiap0udluzc6gvjv\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n \n0\n1\n \n \n\n        Pruebas de balance\n              \n                 \n                Mean\n                Std. Dev.\n                Mean\n                Std. Dev.\n                Diff. in Means\n                p\n              \n        \n        Fuente: Cattaneo (2009)\n        \n                \n                  married  \n                  0.75 \n                  0.43\n                  0.47 \n                  0.50 \n                  -0.28\n                  0.00\n                \n                \n                  firstbaby\n                  0.45 \n                  0.50\n                  0.37 \n                  0.48 \n                  -0.08\n                  0.00\n                \n                \n                  medu     \n                  12.93\n                  2.53\n                  11.64\n                  2.17 \n                  -1.29\n                  0.00\n                \n                \n                  nprenatal\n                  10.96\n                  3.52\n                  9.86 \n                  4.21 \n                  -1.10\n                  0.00\n                \n                \n                  foreign  \n                  0.06 \n                  0.24\n                  0.03 \n                  0.16 \n                  -0.03\n                  0.00\n                \n                \n                  mhisp    \n                  0.04 \n                  0.19\n                  0.02 \n                  0.15 \n                  -0.01\n                  0.05\n                \n                \n                  fage     \n                  27.84\n                  8.79\n                  24.74\n                  11.15\n                  -3.10\n                  0.00"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#estimación-del-ps",
    "href": "diapositivas/emparejamiento.html#estimación-del-ps",
    "title": "Inferencia Causal 2025",
    "section": "Estimación del PS",
    "text": "Estimación del PS\nUna manera de hacer más eficiente el uso de las fórmulas es usando as.formula:\n\n\nsmoke ~ married + firstbaby + medu + nprenatal + foreign + mhisp + \n    fage\n\n\nUsamos matchit para estimar el PS y realizar los emparejamientos con el algoritmo que indiquemos:"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#estimación-del-ps-1",
    "href": "diapositivas/emparejamiento.html#estimación-del-ps-1",
    "title": "Inferencia Causal 2025",
    "section": "Estimación del PS",
    "text": "Estimación del PS\nEl resumen del procedimiento da bastante información sobre el pareamiento:\n\n\n\nCall:\nmatchit(formula = ps, data = data.smoking, method = \"nearest\", \n    distance = \"logit\", replace = FALSE, ratio = 1)\n\nSummary of Balance for All Data:\n          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\ndistance         0.2568        0.1700          0.6673     1.4475    0.2002\nmarried          0.4734        0.7515         -0.5569          .    0.2781\nfirstbaby        0.3715        0.4531         -0.1689          .    0.0816\nmedu            11.6389       12.9299         -0.5955     0.7316    0.0717\nnprenatal        9.8623       10.9629         -0.2616     1.4301    0.0376\nforeign          0.0255        0.0598         -0.2181          .    0.0344\nmhisp            0.0243        0.0363         -0.0776          .    0.0120\nfage            24.7431       27.8444         -0.2782     1.6070    0.0468\n          eCDF Max\ndistance    0.3329\nmarried     0.2781\nfirstbaby   0.0816\nmedu        0.2549\nnprenatal   0.1259\nforeign     0.0344\nmhisp       0.0120\nfage        0.1377\n\nSummary of Balance for Matched Data:\n          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\ndistance         0.2568        0.2564          0.0033     1.0110    0.0005\nmarried          0.4734        0.4769         -0.0070          .    0.0035\nfirstbaby        0.3715        0.3981         -0.0551          .    0.0266\nmedu            11.6389       11.6019          0.0171     0.7064    0.0161\nnprenatal        9.8623        9.8588          0.0008     1.1543    0.0059\nforeign          0.0255        0.0174          0.0514          .    0.0081\nmhisp            0.0243        0.0231          0.0075          .    0.0012\nfage            24.7431       24.5799          0.0146     1.0787    0.0124\n          eCDF Max Std. Pair Dist.\ndistance    0.0093          0.0046\nmarried     0.0035          0.2202\nfirstbaby   0.0266          0.4575\nmedu        0.0417          0.5168\nnprenatal   0.0185          0.7039\nforeign     0.0081          0.2425\nmhisp       0.0012          0.2781\nfage        0.0556          0.6457\n\nSample Sizes:\n          Control Treated\nAll          3778     864\nMatched       864     864\nUnmatched    2914       0\nDiscarded       0       0"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#verificación-del-balance",
    "href": "diapositivas/emparejamiento.html#verificación-del-balance",
    "title": "Inferencia Causal 2025",
    "section": "Verificación del balance",
    "text": "Verificación del balance\n\n\nGráfico de nube:\n\n\n\n\n\n\n\n\n\nTo identify the units, use first mouse button; to stop, use second.\n\n\n\nHistograma:"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#muestra-emparejada-3",
    "href": "diapositivas/emparejamiento.html#muestra-emparejada-3",
    "title": "Inferencia Causal 2025",
    "section": "Muestra emparejada",
    "text": "Muestra emparejada\nPodemos guardar un objeto con la muestra emparejada usando match.data y observar quién hace match con quién:\n\n\n   [,1]  \n11 \"4130\"\n20 \"2234\"\n25 \"1740\"\n43 \"2857\"\n47 \"305\" \n49 \"1442\""
  },
  {
    "objectID": "diapositivas/emparejamiento.html#muestra-emparejada-4",
    "href": "diapositivas/emparejamiento.html#muestra-emparejada-4",
    "title": "Inferencia Causal 2025",
    "section": "Muestra emparejada",
    "text": "Muestra emparejada\nUna propuesta para determinar si el emparejamiento fue exitoso es observar las diferencias promedio estandarizadas (SMD) entre los grupos tratados y no tratados, antes y después del emparejamiento.\n\\[SMD_X=\\frac{\\bar{X}_T-\\bar{X}_{NT}}{\\sqrt{S^2_T+S^2_{NT}}}\\]\nTambién vale la pena no perder de vista la razón de varianzas (VR). Se espera que este ratio no sea muy distinto de 1 después de hacer el emparejamiento:\n\\[VR=\\frac{S^2_T}{S^2_{NT}}\\]\nComo regla de dedo, una diferencia de 0.1 o menos en el SMD se considera un buen balance. Por ejemplo, la escolaridad de la madre tenía un SDM de -0.5955 en la muestra en bruto, pero con el emparejamiento el SDM se vuelve de solo 0.0171."
  },
  {
    "objectID": "diapositivas/emparejamiento.html#loveplot",
    "href": "diapositivas/emparejamiento.html#loveplot",
    "title": "Inferencia Causal 2025",
    "section": "Loveplot",
    "text": "Loveplot\nUsando la librería cobalt podemos construir un love plot que representa gráficamente las diferencias antes y después del emparejamiento"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#efecto-de-tratamiento",
    "href": "diapositivas/emparejamiento.html#efecto-de-tratamiento",
    "title": "Inferencia Causal 2025",
    "section": "Efecto de tratamiento",
    "text": "Efecto de tratamiento\nExisten muchas maneras de explotar la muestra emparejada. Aquí veremos la más sencilla. Simplemente consideremos a la muestra emparejada como si viniera de un experimento. Sin embargo, debemos poner especial atención a la forma de hacer inferencia pues no debemos ignorar que el PS es estimado.\nDependiendo de si el emparejamiento ocurre con o sin reemplazo, y de la naturaleza de la variable dependiente, se recomiendan distintas maneras de estimar el efecto del tratamiento y hacer inferencia. Una buena guía está en la documentación de MatchIt.\nPor ejemplo, cuando se realiza el emparejamiento sin reemplazo, Abadie & Spiess (2019) muestran que podemos estimar los errores estándar simplemente agrupando a nivel de pareja (o grupo) emparejado (subclass es una columna que enumera a las parejas o grupos emparejados y es construida automáticamente por matchit)."
  },
  {
    "objectID": "diapositivas/emparejamiento.html#efecto-de-tratamiento-1",
    "href": "diapositivas/emparejamiento.html#efecto-de-tratamiento-1",
    "title": "Inferencia Causal 2025",
    "section": "Efecto de tratamiento",
    "text": "Efecto de tratamiento\nUsando una regresión con la muestra emparejada\n\n\n\nt test of coefficients:\n\n            Estimate Std. Error  t value  Pr(&gt;|t|)    \n(Intercept) 3331.473     21.424 155.5033 &lt; 2.2e-16 ***\nsmoke       -193.814     28.137  -6.8882 7.889e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "diapositivas/emparejamiento.html#efecto-de-tratamiento-2",
    "href": "diapositivas/emparejamiento.html#efecto-de-tratamiento-2",
    "title": "Inferencia Causal 2025",
    "section": "Efecto de tratamiento",
    "text": "Efecto de tratamiento\nAlgunos autores incluyen los covariables en su estimación:\n\n\n\nt test of coefficients:\n\n              Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept) 2984.54803   76.55850 38.9839 &lt; 2.2e-16 ***\nsmoke       -195.50844   27.96378 -6.9915 3.879e-12 ***\nmarried      113.92672   30.76389  3.7033 0.0002196 ***\nfirstbaby    -62.70697   30.19829 -2.0765 0.0379953 *  \nmedu           0.12530    5.38318  0.0233 0.9814333    \nnprenatal     32.29921    4.49984  7.1779 1.049e-12 ***\nforeign       25.99372  109.26081  0.2379 0.8119829    \nmhisp        111.67360   85.14066  1.3116 0.1898179    \nfage          -0.21788    1.43015 -0.1523 0.8789301    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCuando el emparejamiento es con reemplazo, las unidades no tratadas son emparejadas varias veces (aparecen repetidas en la muestra emparejada), lo cual debe ser considerado para estimar los efectos del tratamiento y hacer inferencia. Por ejemplo, se puede usar bootstrap para obtener el error estándar del efecto del tratamiento cuando la variable de impacto es continua."
  },
  {
    "objectID": "diapositivas/emparejamiento.html#recomendaciones-prácticas",
    "href": "diapositivas/emparejamiento.html#recomendaciones-prácticas",
    "title": "Inferencia Causal 2025",
    "section": "Recomendaciones prácticas",
    "text": "Recomendaciones prácticas\n\nLas características \\(X\\) que determinan la probabilidad de tratamiento deben ser observables\nLas variables usadas para calcular el PS no deben haber sido afectadas por el tratamiento\nIdealmente usamos variables \\(X\\) pre-intervención\nCuando no hay \\(X\\) pre-intervención, a veces se puede obtener el PS con variables post-intervención siempre y cuando estas no hayan sido afectadas por el tratamiento (pocas veces recomendado)\nSe recomienda ampliamente ver:\n\nCaliendo, M., & Kopeinig, S. (2008). Some practical guidance for the implementation of propensity score matching. Journal of Economic Surveys, 22(1), 31-72."
  },
  {
    "objectID": "diapositivas/emparejamiento.html#conclusión",
    "href": "diapositivas/emparejamiento.html#conclusión",
    "title": "Inferencia Causal 2025",
    "section": "Conclusión",
    "text": "Conclusión\n\nLas técnicas de PSM dependen de varios supuestos teoricos fuertes\nLa implementación implica que las variables en \\(X\\) son aquellas que permiten hacer los supuestos de inconfundibilidad dado el PS\nEn la estimación del PS se toma la decisión sobre la forma funcional\nLos efectos de tratamiento pueden ser distintos entre diferentes algoritmos de emparejamiento y la especificación del PS\nLa crítica más importante es que la mayoría de las veces nos preocupa más la autoselección basada en no observables que en observables\nPero muchas veces es todo lo que tenemos a la mano\nHay que hacer análisis de sensibilidad a las distintas decisiones\nPresentar resultados transparentes"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#ejemplo-edad-legal-para-tomar-en-eu",
    "href": "diapositivas/discontinuidades.html#ejemplo-edad-legal-para-tomar-en-eu",
    "title": "Inferencia Causal 2025",
    "section": "Ejemplo: edad legal para tomar en EU",
    "text": "Ejemplo: edad legal para tomar en EU\n\n\n\nEn Estados Unidos la edad legal para tomar es de 21 años\n¿Por qué tenemos una ley para prohibir el consumo de alcohol antes de los 21 (o 18) años?\nLa ley genera una discontinuidad en el acceso a alcohol justo a los 21 años\nPodemos evaluar la efectividad de la política"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#qué-pasa-en-el-cumpleaños-21",
    "href": "diapositivas/discontinuidades.html#qué-pasa-en-el-cumpleaños-21",
    "title": "Inferencia Causal 2025",
    "section": "¿Qué pasa en el cumpleaños 21?",
    "text": "¿Qué pasa en el cumpleaños 21?\n\n\n\n¿Efecto fiesta?\nHay una tendendencia a la baja a ambos lados de la discotinuidad\nSin embargo, hay un claro salto en el número de muertes a los 21 años"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#discontinuidades-nítidas-1",
    "href": "diapositivas/discontinuidades.html#discontinuidades-nítidas-1",
    "title": "Inferencia Causal 2025",
    "section": "Discontinuidades nítidas",
    "text": "Discontinuidades nítidas\n\n\\(D_a\\) es el estado del tratamiento\n\n\\[\nD_a =\n\\begin{cases}\n1  & \\text{si } a \\geq 21 \\\\\n0  & \\text{si } a &lt; 21\n\\end{cases}\n\\]\n\n\\(a\\) es conocida como running variable, score, variable de selección, variable de asignación, etc.\nEl tratamiento es una función determinística de \\(a\\)\n\nSi conocemos \\(a\\) entonces conocemos \\(D_a\\)\n\nEl tratamiento es discontinuo sobre \\(a\\)\n\nNo importa qué tanto nos acercamos al corte, el estatus de tratamiento es el mismo hasta \\(a\\)"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#discontinuidades-nítidas-y-regresión",
    "href": "diapositivas/discontinuidades.html#discontinuidades-nítidas-y-regresión",
    "title": "Inferencia Causal 2025",
    "section": "Discontinuidades nítidas y regresión",
    "text": "Discontinuidades nítidas y regresión\n\nMuchas cosas cambian con la edad\nRiesgo de enfermedades, muerte por otras causas\nUsamos regresión para aislar los efectos de la regla\n\n\\[\n\\bar{M}_a=\\alpha+\\rho D_a + \\gamma a + \\epsilon_a\n\\]\n\n\\(\\bar{M}_a\\) es la tasa de mortalidad en el mes \\(a\\)\n\\(\\rho\\) captura el salto en la mortalidad a los 21 años\n\\(\\hat{\\rho}=7.66\\) : número de muertes adicionales a los 21 años"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#diferencia-con-otros-diseños",
    "href": "diapositivas/discontinuidades.html#diferencia-con-otros-diseños",
    "title": "Inferencia Causal 2025",
    "section": "Diferencia con otros diseños",
    "text": "Diferencia con otros diseños\n\nA diferencia de los métodos de regresión o pareamiento donde controlamos por un vector \\(X\\) y esperamos que el tratamiento sea aleatorio controlando por \\(X\\)\nAquí no hay valores de \\(a\\) para los que observemos individuos en ambos estados del tratamiento\nLa interpretación de la RD es en la vecindad de la discontinuidad"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#no-linealidad-vs-discontinuidad",
    "href": "diapositivas/discontinuidades.html#no-linealidad-vs-discontinuidad",
    "title": "Inferencia Causal 2025",
    "section": "No linealidad vs discontinuidad",
    "text": "No linealidad vs discontinuidad\n\n\n\nEstimar el modelo de RD cuando la relación entre \\(E[Y|X]\\) es como en el tercer panel nos llevaría a inferir un salto donde no existe\nAl usar RD debemos asegurarnos que estamos identificando una discontinuidad\n\nModelar la no linealidad (enfoque antiguo)\nConcentrarnos solo en una ventana cercana a \\(a_0\\) (enfoque más moderno)"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#no-linealidades",
    "href": "diapositivas/discontinuidades.html#no-linealidades",
    "title": "Inferencia Causal 2025",
    "section": "No linealidades",
    "text": "No linealidades\n\nPodemos usar polinomios de \\(a\\)\nIdealmente, las conclusiones no deberían cambiar de acuerdo al grado del polinomio usado\nEl consejo es intentar varias especificaciones y no solo la que se ajuste más a nuestras expectativas de los resultados\nLa Figura 4.2 parece tener una leve curvatura a la derecha de \\(a\\)\nPodemos ajustar directamente un polinomio de la edad:\n\n\\[\n\\bar{M}_a=\\alpha+\\rho D_a + \\gamma_1 a + \\gamma_2 a^2 + \\epsilon_a\n\\]"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#no-linealidades-1",
    "href": "diapositivas/discontinuidades.html#no-linealidades-1",
    "title": "Inferencia Causal 2025",
    "section": "No linealidades",
    "text": "No linealidades\n\nO podemos espcificar un coeficiente diferente para \\(a\\) antes y después de \\(a_0\\):\n\n\\[\n\\bar{M}_a=\\alpha+\\rho D_a + \\gamma(a-a_0) + \\delta[(a-a_0)D_a] + \\epsilon_a\n\\]\n\nNotemos que en este caso el efecto del tratamiento es:\n\n\\[\n\\rho+\\delta(a-a_0)\n\\]\n\nEs decir, un efecto que depende de la distancia con \\(a_0\\)\nSin embargo, ¿qué tan válido es evaluar el efecto en, digamos, \\(a=30\\)? ¿O en \\(a=10\\)?"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#no-linealidades-2",
    "href": "diapositivas/discontinuidades.html#no-linealidades-2",
    "title": "Inferencia Causal 2025",
    "section": "No linealidades",
    "text": "No linealidades\n\nPodemos emplear una combinación de no linealidades y cambios en pendiente:\n\n\\[\n\\begin{aligned}\n\\bar{M}_a&=\\alpha+\\rho D_a + \\gamma_1(a-a_0) +\\gamma_2(a-a_0)^2+\\delta_1[(a-a_0)D_a]+ \\delta_2[(a-a_0)^2D_a] + \\epsilon_a\n\\end{aligned}\n\\]\n\nEn esta especificación los términos lineal y cuadrático cambian en \\(a_0\\)\nY el efecto del tratamiento en este caso es:\nNotemos que en este caso el efecto del tratamiento es:\n\n\\[\n\\rho+\\delta_1(a-a_0)+\\delta_2(a-a_0)^2\n\\]\n\nEn los dos casos anteriores, regularmente se interpreta solo a \\(\\rho\\) como el efecto del tratamiento"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#no-linealidades-3",
    "href": "diapositivas/discontinuidades.html#no-linealidades-3",
    "title": "Inferencia Causal 2025",
    "section": "No linealidades",
    "text": "No linealidades\n\n\n\n\\(\\hat{\\rho}=9.55\\)\nModelo más elaborado con mejor ajuste\nEs evidente gráficamente que hay un salto a los 21 años y una caída suave después\n¿Qué tan robustos son los resultados?"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#efectos-estimados",
    "href": "diapositivas/discontinuidades.html#efectos-estimados",
    "title": "Inferencia Causal 2025",
    "section": "Efectos estimados",
    "text": "Efectos estimados"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#efectos-estimados-1",
    "href": "diapositivas/discontinuidades.html#efectos-estimados-1",
    "title": "Inferencia Causal 2025",
    "section": "Efectos estimados",
    "text": "Efectos estimados"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#discontinuidades-nítidas-resumen",
    "href": "diapositivas/discontinuidades.html#discontinuidades-nítidas-resumen",
    "title": "Inferencia Causal 2025",
    "section": "Discontinuidades nítidas: resumen",
    "text": "Discontinuidades nítidas: resumen\n\nRD nítida se usa cuando el tratamiento es una función determinística de una variable \\(x\\)\n\n\\[\nD_i =\n\\begin{cases}\n1  & \\mbox{if } x_i \\geq x_0 \\\\\n0  & \\mbox{if } x_i &lt; x_0\n\\end{cases}\n\\]\n\n\\(x_0\\) es el umbral o corte\n\\(D_i\\) es una función determinística de \\(x_i\\) pues una vez que conocemos \\(x_i\\) entonces conocemos \\(D_i\\)\n\\(D_i\\) es una función discontinua en \\(x_i\\) pues no importa que tanto nos acerquemos por la izquierda o por la derecha a \\(x_0\\), el estado del tratamiento no cambia"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#discontinuidades-nítidas-resumen-1",
    "href": "diapositivas/discontinuidades.html#discontinuidades-nítidas-resumen-1",
    "title": "Inferencia Causal 2025",
    "section": "Discontinuidades nítidas: resumen",
    "text": "Discontinuidades nítidas: resumen\n\nA diferencia de los modelos de regresión o de pareamiento, no hay valor de \\(x_i\\) en el que observemos a individuos tratados y no tratados\nLa interpretación del efecto estimado por RD es un efecto local en la vecindad de \\(x_0\\), donde podemos tener confianza que los individuos tratados y no tratados son similares en todas las dimensiones excepto en su posición respecto a \\(x_0\\)\nUna especificación flexible permite no confundir una discontinuidad con una no linealidad\nEn la práctica, el polinomio de \\(x_i\\) puede ser tan complejo como se desee pero se espera que los resultados no sean muy sensibles a especificaciones de este\nEl método no paramétrico consiste en la estimación de \\(\\rho\\) en vecindades cada vez más pequeñas alrededor de \\(x_0\\)"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#la-ilusión-de-la-élite",
    "href": "diapositivas/discontinuidades.html#la-ilusión-de-la-élite",
    "title": "Inferencia Causal 2025",
    "section": "La ilusión de la élite",
    "text": "La ilusión de la élite\n\nEscuelas de élite, exam schools, altamente competitivas en Nueva York y Boston\nBajas tasas de admisión\n¿Cómo diferenciar el valor agregado de la escuela del hecho de que la acta selectividad hace que a estas escuelas asistan solo los alumnos más brillantes?\n¡Ojalá pudiéramos asignar alumnos al azar!\nLos estudiantes en estas escuelas de élite comparten clases con estudiantes aventajados"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#la-regla-de-asignación",
    "href": "diapositivas/discontinuidades.html#la-regla-de-asignación",
    "title": "Inferencia Causal 2025",
    "section": "La regla de asignación",
    "text": "La regla de asignación\n\n\n\nCada escuela tiene un corte de puntaje de admisión\nEn la escuela más competitiva de Boston aquellos estudiantes debajo del corte nunca asisten a dicha escuela\nLos que están arriba del corte casi siempre acaban en la BLS"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#la-regla-de-asignación-1",
    "href": "diapositivas/discontinuidades.html#la-regla-de-asignación-1",
    "title": "Inferencia Causal 2025",
    "section": "La regla de asignación",
    "text": "La regla de asignación\n\n\n\nSin embargo, aquellos que no alcanzan el puntaje mínimo de la BLS acaban de cualquier forma en una escuela de élite"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#la-regla-de-asignación-2",
    "href": "diapositivas/discontinuidades.html#la-regla-de-asignación-2",
    "title": "Inferencia Causal 2025",
    "section": "La regla de asignación",
    "text": "La regla de asignación\n\n\n\nHay una dimensión que genera una discontinuidad: efectos de pares o peer effects\nEs una de las preocupaciones más importantes de política educativa en casi cualquier país\nTener buenos (malos) compañeros afecta los resultados del individuo \\(i\\)\nQuienes ingresan a la BLS (séptimo grado) tuvieron compañeros con mejor desempeño en matemáticas cuando iban en cuarto grado"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#modelo-de-efectos-de-pares",
    "href": "diapositivas/discontinuidades.html#modelo-de-efectos-de-pares",
    "title": "Inferencia Causal 2025",
    "section": "Modelo de efectos de pares",
    "text": "Modelo de efectos de pares\n\nUn modelo de efectos de pares:\n\n\\[Y_i=\\theta_0+\\theta_1\\bar{X}_{(i)}+\\theta_2 X_i + u_i\\]\n\n\\(Y_i\\) es el resultado de un examen de matemáticas en el séptimo año del individuo \\(i\\)\n\\(X_i\\) es el resultado de un examen de matemáticas en el cuarto año del individuo \\(i\\)\n\\(\\bar{X}_{(i)}\\) es el resultado promedio de un examen de matemáticas en el cuarto año de los compañeros de \\(i\\) sin incluir \\(i\\)\nOtra notación en la literatura escribe esto como \\(\\bar{X}_{(-i)}\\)\nLos resultados están estandarizados por lo que los coeficientes se interpretan en términos de desviaciones estándar: \\(\\hat{\\theta}_1=0.25\\sigma\\)"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#rd-difuso-vi",
    "href": "diapositivas/discontinuidades.html#rd-difuso-vi",
    "title": "Inferencia Causal 2025",
    "section": "RD difuso + VI",
    "text": "RD difuso + VI\n\nProblemas\n\nSabemos que en la discontinuidad, la calidad de los pares cambia drásticamente\nCaracterísticas de los hogares (habilidad de los padres)\nDoble causalidad: \\(i\\) afecta a \\(j\\) pero \\(j\\) afecta a \\(i\\) a la vez\n\n\n\n\nVariables instrumentales:\n\nQueremos conocer el efecto de la calidad de los pares en el desempeño de matemáticas\nUsamos el corte mínimo para ser aceptado en BLS como instrumento de la calidad de los pares"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#forma-reducida",
    "href": "diapositivas/discontinuidades.html#forma-reducida",
    "title": "Inferencia Causal 2025",
    "section": "Forma reducida",
    "text": "Forma reducida\n\n\n\nSi solo usamos el corte para ser aceptado en BLS:\n\n\\[Y_i=\\alpha_0+\\rho D_i + \\beta_0 R_i + \\epsilon_i\\]\n\nSe obtiene \\(\\hat{\\rho}=-0.02\\), \\(s.e.=0.10\\)\nEste es un modelo de forma reducida (variable de interés en función de la posición respecto al corte)\nEs el efecto causal de estar antes o después del corte"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#modelo-de-vi",
    "href": "diapositivas/discontinuidades.html#modelo-de-vi",
    "title": "Inferencia Causal 2025",
    "section": "Modelo de VI",
    "text": "Modelo de VI\n\nModelo estructural:\n\n\\[Y_i=\\alpha_2+\\lambda \\bar{X}_{(i)} + \\beta_2 R_i + \\epsilon_{2i}\\]\n\nCon una primera etapa\n\n\\[\\bar{X}_{(i)}=\\alpha_1 + \\phi D_i + \\beta_1 R_i + \\epsilon_{1i}\\]\n\nEn la primera etapa \\(\\hat{\\phi}=0.80\\sigma\\), como lo habíamos visto ya en la Figura 4.8\nEn la segunda etapa \\(\\hat{\\lambda}=-0.023\\), \\((s.e.=0.13)\\)"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#modelo-de-vi-1",
    "href": "diapositivas/discontinuidades.html#modelo-de-vi-1",
    "title": "Inferencia Causal 2025",
    "section": "Modelo de VI",
    "text": "Modelo de VI"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#la-ilusión",
    "href": "diapositivas/discontinuidades.html#la-ilusión",
    "title": "Inferencia Causal 2025",
    "section": "La ilusión",
    "text": "La ilusión\n\nNo hay tal ganancia por compartir clase con alumnos brillantes\nLa gente sigue percibiendo que sus hijos ganan al ir a escuelas de élite\nPosiblemente los egresados de estas escuelas tengan mayores ingresos\nLas ganancias que se puedan obtener no son vía el efecto de pares o un mejor rendimiento cognitivo"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#rd-difusa-resumen",
    "href": "diapositivas/discontinuidades.html#rd-difusa-resumen",
    "title": "Inferencia Causal 2025",
    "section": "RD difusa: resumen",
    "text": "RD difusa: resumen\n\nRD difusa explota discontinuidades en la probabilidad o valor esperado del tratamiento condicional en una variable\nEl resultado es que la discontinuidad se convierte en una VI para el estado del tratamiento en vez de una variable que se prende y apaga\n\n\\[\nP(D_i =1|x_i)=\n\\begin{cases}\ng_1(x_i)  & \\mbox{if } x_i \\geq x_0 \\\\\ng_0(x_i)  & \\mbox{if } x_i &lt; x_0\n\\end{cases}\n\\]\n\nLas funciones \\(g_0\\) u \\(g_1\\) difieren en \\(x_0\\)\nSupongamos que \\(g_1(x_0)&gt;g_0(x_0)\\), es decir, \\(x_i\\geq x_0\\) hace el tratamiento más probable"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#rd-difusa-resumen-1",
    "href": "diapositivas/discontinuidades.html#rd-difusa-resumen-1",
    "title": "Inferencia Causal 2025",
    "section": "RD difusa: resumen",
    "text": "RD difusa: resumen\n\nLa relación entre el estado de tratamiento y \\(x_i\\) puede ser escrita como:\n\n\\[E(D_i|x_i)=P(D_i=1|x_i)=g_0(x_i)+[g_1(x_i)-g_0(x_i)]T_i\\]\ncon \\(T_i=\\mathcal{I}(x_i\\geq x_0)\\)\n\nEscribiendo las funciones \\(g_0\\) y \\(g_1\\) como polinomios flexibles de \\(x_i\\)\n\n\\[E(D_i|x_i)=\\gamma_{00}+\\gamma_{01}x_i+\\gamma_{02}x_i+\\ldots+\\gamma_{0p}x_i^p +\\pi T_i + \\gamma_{1}^{*}x_i T_i+ \\gamma_{2}^{*}x_i^2 T_i+\\ldots+ \\gamma_{p}^{*}x_i^p T_i\\]"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#rd-difusa-resumen-2",
    "href": "diapositivas/discontinuidades.html#rd-difusa-resumen-2",
    "title": "Inferencia Causal 2025",
    "section": "RD difusa: resumen",
    "text": "RD difusa: resumen\n\nEn la primera etapa podríamos usar \\(\\{x_iTi, x_i^2 T_i,...,x_i^p T_i\\}\\) como instrumentos para \\(D_i\\)\nUna primera etapa con interacciones sugeriría emplear una segunda etapa también con interacciones\nLa versión más simple solo usa \\(T_i\\) como instrumento\nLa primera etapa será\n\n\\[D_i=\\gamma_0+\\gamma_1 x_i + \\gamma_2 x_i^2 + \\ldots + \\gamma_p x_i^p + \\rho T_i + \\xi_{i}\\]\n\nLa forma reducida o ITT de este modelo es:\n\n\\[y_i=\\beta_0+\\beta_1 x_i + \\beta_2 x_i^2 + \\ldots + \\beta_p x_i^p + \\delta\\ T_i + u_{i}\\] - Mientras que la ecuación estructural\n\\[y_i=\\pi_0+\\pi_1 x_i + \\pi_2 x_i^2 + \\ldots + \\pi_p x_i^p + \\lambda\\ D_i + u_{i}\\] se estima por MC2E usando \\(T_i\\) como instrumento de \\(D_i\\)"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#transferencias-gubernamentales-y-apoyo-político",
    "href": "diapositivas/discontinuidades.html#transferencias-gubernamentales-y-apoyo-político",
    "title": "Inferencia Causal 2025",
    "section": "Transferencias gubernamentales y apoyo político",
    "text": "Transferencias gubernamentales y apoyo político\n\nManacorda, M., E. Miguel y A. Vigorito (2011), Government Transfers and Political Support\n¿Los programas gubernamentales generan lealtades?\nPrograma Nacional de Emergencia Social (PANES) basado en un índice de pobreza\nExiste una discontinudad en el acceso al programa"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#contexto",
    "href": "diapositivas/discontinuidades.html#contexto",
    "title": "Inferencia Causal 2025",
    "section": "Contexto",
    "text": "Contexto\n\n¿Qué pasó en Uruguay?\nCrisis económica a inicios de los 2000\nEn abril de 2005 el Frente Amplio toma el poder\nExpansión del gasto público contra la pobreza (0.41% del PIB)\nPANES\n\nIngreso ciudadano: US$70\nOtros componentes: alimenticio, empleo, salud, etc.\nAlcanzó al 10% de los hogares y 14% de la población"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#regla-de-asignación",
    "href": "diapositivas/discontinuidades.html#regla-de-asignación",
    "title": "Inferencia Causal 2025",
    "section": "Regla de asignación",
    "text": "Regla de asignación\n\n¿Cómo se decidió quién recibiría el PANES?\nFocalizado a los más pobres\nModelo probit de ingreso ajustado\nEl ingreso observado puede ser un indicador muy ruidoso\nSe asignó el programa solo a aquellos por debajo de un umbral de ingreso ajustado"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#datos",
    "href": "diapositivas/discontinuidades.html#datos",
    "title": "Inferencia Causal 2025",
    "section": "Datos",
    "text": "Datos\n\n\n\nSe recolectó información de los hogares alrededor de la discontinuidad (tratados y no tratados)\nSe realizaron dos rondas de seguimiento en 2006-07 y en 2008\nVariable de interés: apoyo político al gobierno en turno"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#cómo-medir-el-apoyo-político",
    "href": "diapositivas/discontinuidades.html#cómo-medir-el-apoyo-político",
    "title": "Inferencia Causal 2025",
    "section": "¿Cómo medir el apoyo político?",
    "text": "¿Cómo medir el apoyo político?\n\nConstrucción de un índice del 0 al 1\nLos hogares que reciben PANES tenían un apoyo político cercano a 0.90\nLos no elegibles mostraban un apoyo de 0.77\nEsto implica un incremento de 13 puntos porcentuales"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#evidencia-gráfica",
    "href": "diapositivas/discontinuidades.html#evidencia-gráfica",
    "title": "Inferencia Causal 2025",
    "section": "Evidencia gráfica",
    "text": "Evidencia gráfica"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#resultados-de-regresión",
    "href": "diapositivas/discontinuidades.html#resultados-de-regresión",
    "title": "Inferencia Causal 2025",
    "section": "Resultados de regresión",
    "text": "Resultados de regresión\n\n\\(E\\) es el umbral de elegibilidad de PANES\n\\(N_i=S_i-E\\) es el score normalizado\n\n\\[\ny_i=\\beta_0+\\beta_1 \\mathcal{I}(N_i&lt;0) + f_1(N_i) + \\mathcal{I}f_2(N_i)+u_i\n\\]\n\n\\(\\beta_1\\) captura el impacto del programa"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#efectos-estimados-2",
    "href": "diapositivas/discontinuidades.html#efectos-estimados-2",
    "title": "Inferencia Causal 2025",
    "section": "Efectos estimados",
    "text": "Efectos estimados"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#evidencia-gráfica-en-2008",
    "href": "diapositivas/discontinuidades.html#evidencia-gráfica-en-2008",
    "title": "Inferencia Causal 2025",
    "section": "Evidencia gráfica en 2008",
    "text": "Evidencia gráfica en 2008"
  },
  {
    "objectID": "diapositivas/discontinuidades.html#robustez",
    "href": "diapositivas/discontinuidades.html#robustez",
    "title": "Inferencia Causal 2025",
    "section": "Robustez",
    "text": "Robustez"
  }
]