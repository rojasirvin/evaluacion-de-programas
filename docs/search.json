[
  {
    "objectID": "tareas/tarea-3.html",
    "href": "tareas/tarea-3.html",
    "title": "Tarea 3",
    "section": "",
    "text": "Fecha de entrega: 9 de noviembre a las 20:00\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los leguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-3.html#pregunta-1",
    "href": "tareas/tarea-3.html#pregunta-1",
    "title": "Tarea 3",
    "section": "Pregunta 1",
    "text": "Pregunta 1\nStevenson, B. & Wolfers, J. (2006)1 estudian los efectos de la introducción de leyes que permiten el divorcio unilateral en los Estados Unidos. La librería bacondecomp incluye los datos usados en dicho artículo (debe instalar y cargar la librería). Usaremos los datos de 1964 a 1996 para mostrar cómo impactan las leyes de divorcio express (unilateral) a la tasa de suicidios en mujeres.\nAl correr el pedazo de código siguiente, obtendrá un objeto de datos wd en donde la variable de impacto es la tasa de suicidios en mujeres, suicide_rate, st identifica a los estados, year identifica a los años y divyear es el año en que se introdujo la legislación del divorcio unilateral. La última fila del código crea el indicador de tratamiento unilaterial, que toma el valor de 1 para los estados tratados en los periodos post tratamiento.\n\nwd &lt;- divorce %&gt;% \nfilter(year&gt;=1964 & year&lt;=1996 & sex==2) %&gt;% \nmutate(suicide_rate=suicide*1000000/(stpop*fshare),\n   year=as.numeric(year),\n   divyear = ifelse(divyear&gt;1996, Inf, divyear),\n   unilateral=ifelse(year&gt;divyear, 1, 0))\n\n\n[5 puntos] ¿Por qué decimos que esta es una aplicación de la estimación de efectos de tratamiento con adopción escalonada?\n[10 puntos] Como punto de partida, estime el efecto del tratamiento sobre suicide_rate usando efectos fijos por estado y año (TWFE) y empleando una librería específica para efectos fijos, como felm. Tome en cuenta la agrupación de los errores. Interprete sus resultados.\n[10 puntos] Compruebe que puede obtener el mismo resultado con una regresión lineal usando el paquete lm e incluyendo, además de la variable de tratamiento, dummies de estado y de año.\n[10 puntos] Realice la descomposición de Goodman-Bacon (2021). Construya un gráfico donde muestre en el eje \\(x\\) el peso otorgado a cada comparación 2x2 que el estimador de TWFE realiza mecánicamente y en el eje \\(y\\) el efecto estimado correspondiente a cada comparación. Interprete el gráfico obtenido.\n[10 puntos] Implemente el estimador de Callaway & Sant’Anna (2021) para estimar los efectos del tratamiento específicos para cada cohorte, usando el paquete did. Utilice como grupo de comparación los estados nunca tratados. La columna stid es un identificador numérico de los estados (lo requerirá cuando use att_gt del paquete did).\n[10 puntos] Reporte los resultados agregados obtenidos a partir del estimador Callaway & Sant’Anna (2021), usando una agregación dinámica que muestre los efectos promedio para cada periodo antes y después del tratamiento. Grafique los resultados.\n[10 puntos] ¿Cuáles son las ventajas del estimador de Callaway & Sant’Anna (2021) respecto al estimador de TWFE?"
  },
  {
    "objectID": "tareas/tarea-3.html#pregunta-2",
    "href": "tareas/tarea-3.html#pregunta-2",
    "title": "Tarea 3",
    "section": "Pregunta 2",
    "text": "Pregunta 2\nLa ENIGH 2020 incluyó un módulo para la evaluación del Programa Jóvenes Construyendo el futuro. Se buscó que la cobertura de la encuesta pudiera incluir suficientes participantes del programa para poder compararlos con los no participantes. Los datos en datos_jcf_analisis.csv fueron construidos a partir de dicha encuesta. En este ejercicio estimaremos el efecto de participar en el programa sobre el ingreso trimestral, ingtot_tri, usando métodos de matching.\nLas siguientes variables están incluidas en el archivo de datos: mujer (dummy de sexo), indigena (dummy de pertenencia a una etnia), rural (dummy del ámbito rural), escoacum (años de escolaridad), casadounion (dummy para casados o en unión libre), jefehog (dummy para jefes del hogar), haymenores (dummy para la presencia de menores de edad en el hogar), proggob (dummy para beneficiarios de programas de gobierno), y tot_integ (número de miembros del hogar). También se incluye la clave de las entidades, cve_ent.\n\n[10 puntos] Considere la comparación para el ingreso trimestral, ingtot_tri, entre beneficiarios y su grupo de comparación, que serán los jóvenes que no asisten a la escuela y no están empleados. Los beneficiarios tienen jcf2==1 y los jóvenes que no asisten a la escuela y no están empleados tienen jcf2==0. Muestra qué tan similares o qué tan diferentes son los individuos en ambos grupos en términos de las características indicadas anteriormente y del ingreso trimestral.\n[10 puntos] Estime el TOT (TT o ATT) del programa en el ingreso trimestral, ingtot_tri usando el algoritmo de vecino más cercano. Para estimar el impacto en el ingreso trimestral se comparan a los beneficiarios de JCF con los jóvenes que no asisten a la escuela y no están empleados. Los beneficiarios tienen jcf2==1 y los jóvenes que no asisten a la escuela y no están empleados tienen jcf2==0. Escoja la especificación del propensity score que más le parezca adecuada. Realice la inferencia estadística con errores agrupados a nivel grupo de emparejamiento. ¿De qué tamaño es el TOT estimado y es este efecto estadísticamente significativo?\n[5 puntos] En el matching de la parte b., evalúe qué tan bueno es el procedimiento en balancear las características observadas una vez realizado el matching. Cree un love plot para evaluar qué tan bueno es el procedimiento de matching para obtener una muestra balanceada.\n[5 puntos] Estime ahora el TOT en el ingreso trimestral, como en la parte b., pero usando un caliper de 0.1 y 3 vecinos a ser emparejados. ¿Cómo cambian sus resultados respecto a los de la parte b.?\n[5 puntos] ¿Qué ventajas y desventajas encuentra en la estimación de los efectos de tratamiento usando matching?"
  },
  {
    "objectID": "tareas/tarea-3.html#footnotes",
    "href": "tareas/tarea-3.html#footnotes",
    "title": "Tarea 3",
    "section": "Notas",
    "text": "Notas\n\n\nStevenson, B. & Wolfers, J. (2006). Bargaining in the Shadow of the Law: Divorce Laws and Family Distress. The Quarterly Journal of Economics, 121(1), 267-288.↩︎"
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html",
    "href": "tareas/tarea-2-respuestas.html",
    "title": "Respuestas a la tarea 2",
    "section": "",
    "text": "knitr::opts_chunk$set(echo = TRUE,\n                      warning = FALSE,\n                      message = FALSE,\n                      indent = \"   \")\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(janitor)\nlibrary(readr)\nlibrary(kableExtra)\nlibrary(stargazer)\nlibrary(sandwich)\nlibrary(clubSandwich)\nlibrary(lmtest)\nlibrary(AER)"
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#pregunta-1",
    "href": "tareas/tarea-2-respuestas.html#pregunta-1",
    "title": "Respuestas a la tarea 2",
    "section": "Pregunta 1",
    "text": "Pregunta 1\nEn Crepon et al. (2015)1 se estudia una intervención en Marruecos en la que se analiza el efecto de la adopción de microfinanzas, a través de un experimento de campo. En 81 de 162 localidades estudiadas se introdujo aleatoriamente una empresa de microfinanzas. Para seleccionar las localidades de tratamiento, primero se emparejaron localidades de acuerdo a características observables y, para cada pareja se asignó a tratamiento y otra a control. La base de datos crepon_morocco_balance.csv contiene los datos de este estudio usados para mostrar la integridad del diseño. La variable treatment es la variable de asignación aleatoria, mientras que la variable client es la variable de adopción\n\n[3 puntos] Primero recordaremos cómo mostrar que el tratamiento efectivamente fue asignado de manera aleatoria. El siguiente código lee los datos que debemos usar y se queda con las observaciones de la línea base. Con estos datos, mostraremos que la variable nchildren_resid_bl, que indica el número de niños que viven en cada hogar está balanceado entre los grupos asignados a tratamiento y control. Noten que la media del número de niños que viven en el hogar en el grupo de control es 1.68 (d.e. 1.64) y que hay 2,266 hogares en dicho grupo de control. Esto es exactamente lo que se reporta en la primera fila correspondiente a Number children (&lt;16 years old) en la tabla 1 del artículo.\n\ndata.morocco&lt;-read_csv(\"../files/crepon_morocco_balance.csv\",\n                       locale = locale(encoding = \"latin1\")) %&gt;% \n  clean_names() %&gt;% \n  filter(merge_indicator!=1)\n\n\ndata.morocco %&gt;% \n  group_by(treatment) %&gt;%\n  summarize(mean=mean(nchildren_resid_bl, na.rm=T),\n            std=sd(nchildren_resid_bl, na.rm=T),\n            n=n()) %&gt;% \n  ungroup()\n\n# A tibble: 2 × 4\n  treatment  mean   std     n\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1         0  1.68  1.64  2266\n2         1  1.69  1.64  2199\n\n\nObtenga ahora el valor de la diferencia entre el grupo de tratamiento y el de control, así como su valor \\(p\\) (últimas dos columnas). Para ello, estime una regresión en la que la variable dependiente sea número de niños que vive en el hogar nchildren_resid_bl, en función de la variable de asignación treatment y variables dummy de pareja de localidad (la variable paire indica cuáles son las parejas). La regresión permite recuperar la diferencia de 0.01 niños que se reporta en la fila correspondiente en la tabla 1. Para recuperar el valor \\(p\\), estime errores agrupados usando la variable demi_paire, que es la clave de las distintas localidades, como variable de agrupación. Una forma de realizar esto es con la función coef_test del paquete clubSandwich.2\n\ndif_members &lt;- lm(nchildren_resid_bl ~ treatment + factor(paire),\n   data=data.morocco)\n\nsummary(dif_members)$coef[1:7,]\n\n                   Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)     1.313048243 0.19816551  6.6260180 3.865649e-11\ntreatment       0.007236848 0.04599191  0.1573505 8.749759e-01\nfactor(paire)2  0.492156863 0.27004402  1.8225060 6.844634e-02\nfactor(paire)3  0.255020364 0.28328679  0.9002198 3.680528e-01\nfactor(paire)4 -1.316666667 0.29878450 -4.4067436 1.074441e-05\nfactor(paire)5  0.510117240 0.28886400  1.7659426 7.747509e-02\nfactor(paire)6  1.552126474 0.27721212  5.5990571 2.286898e-08\n\nnobs(dif_members)\n\n[1] 4465\n\ncoef_test(dif_members,\n          vcov = \"CR1S\", \n          cluster = data.morocco$demi_paire)[1:2,]\n\n       Coef. Estimate     SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)  1.31305 0.0389 33.724        1.03       0.0172    *\n   treatment  0.00724 0.0407  0.178       76.54       0.8593     \n\n\nObtenemos un coeficiente de 0.00724, que se redonde a 0.01 en la tabla. El valor \\(p\\) de 0.859 es exactamente el reportado en la última columa. Aquí lo clave es calcular los errores agrupados.\n[2 puntos] Ahora mostremos que efectivamente este es un ejemplo de una intervención con cumplimiento imperfecto. Genere un cuadro que indique: 1) cuántas personas que fueron asignadas a recibir el tratamiento efectivamente fueron clientes; 2) cuántas personas que fueron asignadas a recibir el tratamiento no se convirtieron en clientes; 3) cuántas personas que no fueron asignadas a recibir el tratamiento sí se convirtieron en clientes; y 4) cuántas personas que no fueron asignadas a recibir el tratamiento tampoco se convirtieron en clientes.\n\ndata.morocco %&gt;%\n  mutate(treatment=factor(treatment, levels=c(0,1),labels=c(\"Control\", \"Tratamiento\"))) %&gt;%\n      mutate(client=factor(client, levels=c(0,1),labels=c(\"No cliente\", \"Cliente\"))) %&gt;% \n  tabyl(treatment, client,\n        show_na = F)\n\n   treatment No cliente Cliente\n     Control       2101       0\n Tratamiento       1753     251\n\n\nEste es un ejemplo de una intervención con incumplimiento de un solo lado. De aquellos asignados al tratamiento, 251 se convirtieron en clientes y 1,753 no. De aquellos asignados al control, ninguno tuvo acceso a microfinanzas. En otras palabras, podemos descartar la presencia de siempre cumplidores (always-takers). Por tanto, en este tipo de aplicaciones, el efecto del tratamiento en los tratados (támbien llamado TOT, ATET o TT) es igual al LATE.\n[5 puntos] Ahora mostraremos que la adopción, es decir, convertirse en cliente, no es independiente de las características de los hogares. Considere las variables members_resid_bl y act_number_bl, que indican el número de miembros del hogar y el número de actividades económicas del hogar. Para cada una de estas dos variables, utilice la misma especificación que en la parte a., pero ahora usando la variable cliente como regresor. ¿Qué concluye?\nPara el número de miembros del hogar:\n\nr1 &lt;- lm(members_resid_bl ~ client + factor(paire),\n                         data=data.morocco)\ncoef_test(r1,\n          vcov = \"CR1S\", \n          cluster = data.morocco$demi_paire)[1:2,]\n\n       Coef. Estimate    SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)     4.18 0.128  32.70         1.0       0.0195    *\n      client     0.43 0.180   2.38        45.4       0.0214    *\n\n\nPara el número de actividades económicas del hogar:\n\nr2 &lt;- lm(act_number_bl ~ client + factor(paire),\n                            data=data.morocco)\ncoef_test(r2,\n          vcov = \"CR1S\", \n          cluster = data.morocco$demi_paire)[1:2,]\n\n       Coef. Estimate     SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)    1.109 0.2330   4.76         1.0      0.13185     \n      client    0.191 0.0687   2.78        45.4      0.00787   **\n\n\nLa adopción no es independiente de las características de los hogares. Parece ser que los hogares que se convierten en clientes son más grandes y tienen más actividades económicas. Por tanto, comparar las variables de impacto entre quienes adoptarony no adoptaron implicaría un sesgo de selección.\n[5 puntos] Con estos elementos estamos convencidos de que es necesario emplear lo que sabemos sobre cumplimiento imperfecto. Usaremos ahora los datos en crepon_morocco_analysis.csv, que contiene los datos empleados para evaluar el impacto de la adopción. Estos datos están listos para analizarse. Estime la forma reducida del efecto de ser asignado al tratamiento sobre gasto total, expense_total. Comente los resultados, en particular, comente sobre la magnitud y la significancia estadística de la variable treatment. Aquí y en adelante, incluya los siguientes controles en la regresión: members_resid_bl, nadults_resid_bl, head_age_bl, act_livestock_bl, act_business_bl, borrowed_total_bl, members_resid_d_bl, nadults_resid_d_bl, head_age_d_bl, act_livestock_d_bl, act_business_d_bl, borrowed_total_d_bl, ccm_resp_activ, other_resp_activ, ccm_resp_activ_d y other_resp_activ_d. Además, incluya efectos fijos por pareja introduciendo la variable paire como factor. Use los mismos errores estándar que en la parte a. Con esto deberá poder recuperar el coeficiente y el error estándar de la columna (3) de la tabla 3.\nLa forma reducida estima la relación causal entre la variable de gasto y la asignación aleatoria. Se estima un efecto de 4057 unidades monetarias en el gasto, estadísticamente significativo al 5%. Este es el efecto de ser asignado al tratamiento o ITT.\n\ndata.morocco&lt;-read_csv(\"../files/crepon_morocco_analysis.csv\")   %&gt;% \n  clean_names() \n\nres_fr&lt;- lm(expense_total ~ treatment +\n              members_resid_bl + nadults_resid_bl +\n              head_age_bl + act_livestock_bl + act_business_bl +\n              borrowed_total_bl + members_resid_d_bl +\n              nadults_resid_d_bl + head_age_d_bl + act_livestock_d_bl +\n              act_business_d_bl + borrowed_total_d_bl +\n              ccm_resp_activ + other_resp_activ + ccm_resp_activ_d + \n              other_resp_activ_d + factor(paire),\n            data=data.morocco)\n\ncoef_test(res_fr,\n          vcov = \"CR1S\",\n          cluster = data.morocco$demi_paire)[1:2,]\n\n       Coef. Estimate   SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)   -18493 6735  -2.75         2.1        0.105     \n   treatment     4057 1721   2.36        74.4        0.021    *\n\n\nEste efecto estimado tiene una interpretación causal. Sin embargo, lo que nos está diciendo es la diferencia en el gasto en hogares donde el programa fue ofrecido y donde no. Pero no la diferencia en el efectivamente usar microfinanzas, que puede ser el parámetro de mayor interés. En otras palabras, el ITT es como un efecto del tratamiento, diluido por el no cumplimiento.\n[5 puntos] Estime ahora la primera etapa, es decir, estime por MCO el efecto causal de la asignación sobre la adopción. Comente sobre la magnitud, la significancia estadística y la interpretación de la variable treatment en términos del comportamiento de los cumplidores. Debería poder replicar el coeficiente y el error estándar de la columna 1 en la tabla 2 del artículo.\nLa primera etapa muestra un aumento de 16.7% en la probabilidad de ser cliente debido al tratamiento. Este efecto es estadísticamente significativo al 10%. En otras palabras, 16.7% de los individuos en la muestra son cumplidores, es decir, se vuelven clientes solo porque se les ofreció el tratamiento.\n\nres_fs&lt;- lm(client ~ treatment +\n              members_resid_bl + nadults_resid_bl +\n                head_age_bl + act_livestock_bl + act_business_bl +\n                borrowed_total_bl + members_resid_d_bl +\n                nadults_resid_d_bl + head_age_d_bl + act_livestock_d_bl +\n                act_business_d_bl + borrowed_total_d_bl +\n                ccm_resp_activ + other_resp_activ + ccm_resp_activ_d + \n                other_resp_activ_d + factor(paire),\n            data=data.morocco)\n\ncoef_test(res_fs,\n          vcov = \"CR1S\", \n          cluster = data.morocco$demi_paire)[1:2,]\n\n       Coef. Estimate     SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)  -0.0988 0.0549   -1.8         2.1        0.208     \n   treatment   0.1672 0.0118   14.2        74.4       &lt;0.001  ***\n\n\n[5 puntos] Considere la columna 3 del panel A en la Tabla 9 del artículo. Aquí se reporta la estimación por MCO de la relación entre client y gasto total, con los mismos controles y tipo de errores que antes. Replique este resultado. ¿Se puede interpretar de forma causal el coeficiente sobre client?\nNoten que para replicar la entrada la clave está en condicionar a aquellos asignados al tratamiento (como se indica en la tabla del artículo). No se puede interpretar de manera causal la relación de 11934 unidades monetarias más en el gasto en los clientes con respecto a los no clientes pues es muy posible que haya sesgo de selección. Por ejemplo, si los hogares más educados deciden adoptar en mayor medida los productos de microfinanzas, es posible pensar que esos mismos hogares hubieran tenido mayor gasto incluso sin microfinanzas. Estaríamos entonces sobreestimando el efecto del tratamiento.\n\nres_mco &lt;- lm(expense_total ~ client +\n                members_resid_bl + nadults_resid_bl +\n                head_age_bl + act_livestock_bl + act_business_bl +\n                borrowed_total_bl + members_resid_d_bl +\n                nadults_resid_d_bl + head_age_d_bl + act_livestock_d_bl +\n                act_business_d_bl + borrowed_total_d_bl +\n                ccm_resp_activ + other_resp_activ + ccm_resp_activ_d + \n                other_resp_activ_d + factor(paire),\n              data=filter(data.morocco,treatment==1))\n\ncoef_test(res_mco,\n          vcov = \"CR1S\", \n          cluster =filter(data.morocco,treatment==1)$demi_paire)[1:2,]\n\n       Coef. Estimate   SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)   -12718 9447  -1.35        65.8       0.1828     \n      client    11934 5580   2.14        41.1       0.0384    *\n\n\n[5 puntos] ¿Cuáles son los dos supuestos econométricos que permiten la estimación del Local Average Treatment Effect (LATE) en el contexto de este problema? Comente sobre la evidencia que respalda el supuesto de que los instrumentos no son débiles en este problema.\nLos supuestos necesarios son:\nRelevancia del instrumento. Se requiere que la asignación aleatoria del tratamiento efectivamente afecte la probabilidad de ser cliente. La evidencia que respalda este requerimiento es el resultado de la primera etapa. El estadístico \\(F\\) de la primera etapa es 10.86, apenas arriba de la regla de dedo de 10 que comúnmente se usa para decir que no hay presencia de instrumentos débiles.\nExclusión. Se requiere que el instrumento no pertenezca a la ecuación estructural. Esto se garantiza por la asignación aleatoria del tratamiento.\n[5 puntos] Estime el efecto del cumplimiento sobre el gasto total, usando la asignación aleatoria como instrumento del cumplimiento. Es decir, estime el LATE. Use los mismos controles y tipo de errores que en c. Este resultado se reporta en la columna 3 del panel B en la Tabla 9. ¿Cuál es la interpretación del coeficiente de la variable client? En R, la función ivreg del paquete AER le permite hacer la estimación de MC2E.\nEl LATE estimado es de 24263 monetarias adicionales de gasto debido a ser cliente. Esta cifra es considerablemente mayor que las 4057 unidades monetarias estimada en la forma reducida. Este es un efecto local pues solo considera el cambio en el gasto debido a ser cliente de la microfinanciera, en aquellos individuos que cambiaron su comportamiento debido a la asignación aleatoria del tratamiento. Noten también que en todas las regresiones se incluye errores agrupados a nivel pareja o paire.\n\nres_iv &lt;- ivreg(expense_total ~ client + members_resid_bl + nadults_resid_bl\n     + head_age_bl + act_livestock_bl + act_business_bl \n     + borrowed_total_bl + members_resid_d_bl + nadults_resid_d_bl\n     + head_age_d_bl + act_livestock_d_bl + act_business_d_bl \n     + borrowed_total_d_bl + ccm_resp_activ + other_resp_activ \n     + ccm_resp_activ_d  + other_resp_activ_d + factor(paire) |\n       treatment +  members_resid_bl + nadults_resid_bl\n     + head_age_bl + act_livestock_bl + act_business_bl \n     + borrowed_total_bl + members_resid_d_bl + nadults_resid_d_bl\n     + head_age_d_bl + act_livestock_d_bl + act_business_d_bl \n     + borrowed_total_d_bl + ccm_resp_activ + other_resp_activ \n     + ccm_resp_activ_d  + other_resp_activ_d + factor(paire),\n     data=data.morocco)\n\nsummary(res_iv)$coefficients[1:2,]\n\n             Estimate Std. Error   t value   Pr(&gt;|t|)\n(Intercept) -16095.68   11033.49 -1.458802 0.14468442\nclient       24263.46   12419.55  1.953651 0.05080007\n\ncoef_test(res_iv,\n          vcov = \"CR1S\", \n          cluster = data.morocco$demi_paire)[1:2,]\n\n       Coef. Estimate   SE t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)   -16096 7144  -2.25        2.11       0.1464     \n      client    24263 9944   2.44       74.45       0.0171    *"
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#pregunta-2",
    "href": "tareas/tarea-2-respuestas.html#pregunta-2",
    "title": "Respuestas a la tarea 2",
    "section": "Pregunta 2",
    "text": "Pregunta 2\n\n[5 puntos] Sea una variable de resultados \\(y_i\\), una variable de asignación aleatoria \\(Z_i\\) y una variable de adopción \\(D_i\\). El estimador de Wald se define como:\n\\[\\hat{\\beta}_{Wald}=\\frac{\\bar{Y}_{Z_i=1}-\\bar{Y}_{Z_i=0}}{\\bar{D}_{Z_i=1}-\\bar{D}_{Z_i=0}}\\]\nEn esta pregunta mostraremos cómo el estimador de Wald es equivalente al estimador de VI cuando no hay controles. Use nuevamente los datos en crepon_morocco_analysis.csv. Obtenga el estimador de Wald como el cociente de la diferencia en gasto total promedio entre los hogares asignados a tratamiento y control dividido por la diferencia en la probabilidad de adopción entre los hogares asignados a tratamiento y control. Recuerde que la variable del gasto total es expense_total.\nObtenemos el estadístico de Wald, usando la definición:\n\ndata.morocco&lt;-read_csv(\"../files/crepon_morocco_analysis.csv\")   %&gt;% \n  clean_names() \n\nmean_cliente&lt;-data.morocco %&gt;%\n  group_by(treatment) %&gt;% \n  summarize(p_cliente=mean(client, na.rm=F)) %&gt;% \n  ungroup()\n\nmean_gasto&lt;-data.morocco %&gt;%\n  group_by(treatment) %&gt;% \n  summarize(m_gasto=mean(expense_total, na.rm=F)) %&gt;% \n  ungroup()\n\n#Neceistamos la diferencia de gastos y de probabilidad de ser cliente\ndif_gasto &lt;- mean_gasto[2,2]-mean_gasto[1,2]\ndif_cliente &lt;- mean_cliente[2,2]-mean_cliente[1,2]\n\nWald &lt;- as.numeric(dif_gasto / dif_cliente)\nWald\n\n[1] 22869.23\n\n\n[5 puntos] Ahora estime por MC2E el efecto de la adopción sobre el gasto total, usando la variable de asignación como instrumento para la adopción. ¿Qué ventaja observa con respecto al estimador de Wald?\nNotemos que obtenemos lo mismo al hacer una estimación de variables instrumentales. El coeficiente sobre la variable client es igual al estadístico de Wald. El estadístico de Wald es idéntico al estimador de variables instrumentales cuando el instrumento es binario. La mayor ventaja de realizar la estimación de esta manera es que podemos obtener errores estándar, lo cual nos permite hacer inferencia estadística sobre el tamaño del efecto de ser cliente en el gasto.\n\nWald_vi &lt;- ivreg(expense_total ~ client  | treatment,\n                data=data.morocco)\n\n#Notemos que obtenemos directamente el error estándar\nsummary(Wald_vi)\n\n\nCall:\nivreg(formula = expense_total ~ client | treatment, data = data.morocco)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n -44264  -21394  -17064   -4804 1305816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    21395       1496  14.298   &lt;2e-16 ***\nclient         22869      12684   1.803   0.0714 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 74610 on 4932 degrees of freedom\nMultiple R-Squared: 0.00651, Adjusted R-squared: 0.006309 \nWald test: 3.251 on 1 and 4932 DF,  p-value: 0.07144"
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#pregunta-3",
    "href": "tareas/tarea-2-respuestas.html#pregunta-3",
    "title": "Respuestas a la tarea 2",
    "section": "Pregunta 3",
    "text": "Pregunta 3\nEn la Pregunta 2, parte a, obtuvo el estimador de Wald para aproximar el efecto de la adopción en el gasto total. Considere dicho cálculo sin controles para lo que resta de esta pregunta.\n\n[5 puntos] Utilice un procedimiento bootstrap a mano para estimar el error estándar del estimador de Wald usando 30 repeticiones. Es decir, debe realizar un remuestreo de los datos originales y para cada muestra obtener el estimador de Wald. Luego, obtenga la desviación estándar de los 30 estadísticos calculados. Utilice una semilla para poder replicar sus resultados.\nYa sabemos calcular un estadístico de Wald, como en la Pregunta 2, parte a. La idea ahora es repetir dicho proceso B veces, pero en cada repetición con una muestra bootstrap a la mano:\nFijamos los parámetros para el remuestreo, fijamos una semilla e inicializamos un vector donde iremos coleccionando los estadísticos estimados:\n\ndata.morocco&lt;-read_csv(\"../files/crepon_morocco_analysis.csv\")   %&gt;% \n  clean_names() \n\nobs &lt;- nrow(data.morocco)\n\nset.seed(923)\n\nB=30\n\nWrep30_1 &lt;- data.frame(W=matrix(ncol = 1, nrow = B))\n\nRealizamos el procedimiento de remuestreo y, para cada muestra a la mano, estimamos el estadístico de Wald. Guardamos cada estadístico en la posición correspondiente del vector que previamente inicializamos.\n\nfor (i in 1:B)\n{\n  data.b &lt;-data.morocco[sample(nrow(data.morocco),obs, replace = TRUE),]\n\n  mean_cliente&lt;-data.b %&gt;%\n    group_by(treatment) %&gt;% \n    summarize(p_cliente=mean(client, na.rm=F)) %&gt;% \n    ungroup()\n\n  mean_gasto&lt;-data.b %&gt;%\n    group_by(treatment) %&gt;% \n    summarize(m_gasto=mean(expense_total, na.rm=F)) %&gt;% \n    ungroup()\n\n  dif_gasto &lt;- mean_gasto[2,2]-mean_gasto[1,2]\n  dif_cliente &lt;- mean_cliente[2,2]-mean_cliente[1,2]\n\n  Wrep30_1[i,1] &lt;- as.numeric(dif_gasto / dif_cliente)\n}\n\n*Estimamos el error estándar como la desviación estándar de los \\(B\\) estadísticos estimados. #El error estimado es simplemente la desviación estándar de los B estadísticos estimados\n\nsd(Wrep30_1$W)\n\n[1] 12080.76\n\n\n[5 puntos] Reemplace la semilla de la parte a. por una nueva semilla y estime nuevamente el error estándar del estimador de Wald con 30 repeticiones. Comente sobre la diferencia entre este error estándar y el de la parte a.\nEl cambio que observamos en el error estándar estimado por bootstrap entre esta parte y la parte a. es que al cambiar la semilla, los números aleatorios generados son distitnos y, por tanto, cada muestra bootstrap tiene distintos individuos.\n\nset.seed(9232)\n\nB=50\n\nWrep30_2 &lt;- data.frame(W=matrix(ncol = 1, nrow = B))\n\nfor (i in 1:B)\n{\n  data.b &lt;-data.morocco[sample(nrow(data.morocco),obs, replace = TRUE),]\n\n  mean_cliente&lt;-data.b %&gt;%\n    group_by(treatment) %&gt;% \n    summarize(p_cliente=mean(client, na.rm=F)) %&gt;% \n    ungroup()\n\n  mean_gasto&lt;-data.b %&gt;%\n    group_by(treatment) %&gt;% \n    summarize(m_gasto=mean(expense_total, na.rm=F)) %&gt;% \n    ungroup()\n\n  dif_gasto &lt;- mean_gasto[2,2]-mean_gasto[1,2]\n  dif_cliente &lt;- mean_cliente[2,2]-mean_cliente[1,2]\n\n  Wrep30_2[i,1] &lt;- as.numeric(dif_gasto / dif_cliente)\n}\n\nsd(Wrep30_2$W)\n\n[1] 14864.09\n\n\n[5 puntos] Regrese el valor de la semilla al usado en a. y estime nuevamente el error estándar del estimador de Wald, esta vez usando 2000 repeticiones. Comente sobre la diferencia entre este error estándar y el de la parte a.\nAhora las diferencias en el error estimado surgen porque tenemos muchas más repeticiones bootstrap. Lo más importante de estos procedimientos es que pueda implementarlos a otros contextos. Por ejemplo, podemos hacer obtener errores bootstrap para el vector de coeficientes de una estimación de MC2E, para el producto de dos coeficientes, etc.\n\nset.seed(923)\n\nB=2000\n\nWrep2000 &lt;- data.frame(W=matrix(ncol = 1, nrow = B))\n\nfor (i in 1:B)\n{\n  data.b &lt;-data.morocco[sample(nrow(data.morocco),obs, replace = TRUE),]\n\n  mean_cliente&lt;-data.b %&gt;%\n    group_by(treatment) %&gt;% \n    summarize(p_cliente=mean(client, na.rm=F)) %&gt;% \n    ungroup()\n\n  mean_gasto&lt;-data.b %&gt;%\n    group_by(treatment) %&gt;% \n    summarize(m_gasto=mean(expense_total, na.rm=F)) %&gt;% \n    ungroup()\n\n  dif_gasto &lt;- mean_gasto[2,2]-mean_gasto[1,2]\n  dif_cliente &lt;- mean_cliente[2,2]-mean_cliente[1,2]\n\n  Wrep2000[i,1] &lt;- as.numeric(dif_gasto / dif_cliente)\n}\n\n\nsd(Wrep2000$W)\n\n[1] 12382.39\n\n\nEl error estándar estimado por bootstrap con 2,000 repeticiones es 12,382. Cuando usamos regresión para estimar el estimador de Wald obtuvimos un error estándar estimado de 12,684."
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#pregunta-4",
    "href": "tareas/tarea-2-respuestas.html#pregunta-4",
    "title": "Respuestas a la tarea 2",
    "section": "Pregunta 4",
    "text": "Pregunta 4\nConsidere nuevamente la base STAR_public_use.csv usada en la Tarea 1 del artículo Angrist, Lang y Oreopoulos (2009)3. En esta pregunta nos concentraremos en los efectos de la intervención en el año 2, mostrados en la columna (4) de la Tabla 6, sobre dos variables, el promedio de calificaciones gpa_year2 y los créditos completados credits_earned2.\nEl propósito de esta pregunta es mostrar la función de los \\(z\\)-scores en el análisis de efectos de tratamiento. De nuevo, puede quedarse solo con las observaciones que tienen noshow igual a 0. Antes de comenzar su análisis, sustituya por NA los valores en credits_earned2 para aquellas observaciones que tienen \\(NA\\) en la variable prob_year1.\n\n[5 puntos] Para tener un punto de comparación, estime la ecuación del efecto de tratamiento para gpa_year2 usando la misma especificación que en la pregunta 5 de la Tarea 1. Use también errores robustos. Deberá poder replicar los coeficientes y errores estándar del panel A, columna (4). ¿Cómo se interpretan el coeficiente sobre la variable ssp?\nUsando la misma especificación que usamos en la Tarea 1, obtenemos los coeficientes en el artículo.\n\ndata.angrist&lt;-read_csv(\"../files/STAR_public_use.csv\",\n                 locale = locale(encoding = \"latin1\"))   %&gt;% \n  clean_names()\n\ndata.angrist&lt;-data.angrist %&gt;% \n  filter(noshow==0) %&gt;% \n  mutate(credits_earned2=ifelse(is.na(prob_year1),NA,credits_earned2)) \n\n\nr1 &lt;-lm(gpa_year2 ~ ssp + sfp+ sfsp+\n             factor(sex)+\n             factor(mtongue)+\n             factor(hsgroup)+\n             factor(numcourses_nov1)+\n             factor(lastmin)+\n             factor(mom_edn)+\n             factor(dad_edn),\n           data.angrist)\ncoeftest(r1, vcov = vcovHC(r1, \"HC1\"))[1:4,]\n\n               Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)  2.87240513 0.45314003  6.3388908 3.261488e-10\nssp          0.05018813 0.07423854  0.6760388 4.991454e-01\nsfp         -0.01807372 0.06618352 -0.2730848 7.848347e-01\nsfsp         0.07158763 0.09081195  0.7883063 4.306722e-01\n\n\n[5 puntos] Genere un \\(z\\)-score para la variable gpa_year2 al que llame gpa_year2_sd. Para ello, calcule la media y desviación estándar de gpa_year2 para el grupo de control y luego genere gpa_year2_sd restándole a gpa_year2 la media obtenida y dividiendo esta diferencia por la desviación estándar obtenida. Compruebe que si calcula la media y la desviación estándar de gpa_year2_sd, en el grupo de control estas deberían ser 0 y 1, respectivamente.\nCreamos un z-score:\n\ngpa_year2_stats &lt;- data.angrist %&gt;% \n    filter(control==1) %&gt;% \n    summarize(media=mean(gpa_year2,na.rm=T),\n              desvest=sd(gpa_year2,na.rm=T))\n\ndata.angrist &lt;- data.angrist %&gt;% \n    mutate(gpa_year2_sd=(gpa_year2-gpa_year2_stats$media)/gpa_year2_stats$desvest)\n\nTiene media igual a 0:\n\ndata.angrist %&gt;%\n  filter(control==1) %&gt;% \n  summarize(media=mean(gpa_year2_sd,na.rm=T))\n\n# A tibble: 1 × 1\n     media\n     &lt;dbl&gt;\n1 1.60e-16\n\n\nY desviación estándar igual a 1:\n\ndata.angrist %&gt;%\n  filter(control==1) %&gt;% \n  summarize(desvest=sd(gpa_year2_sd,na.rm=T)) \n\n# A tibble: 1 × 1\n  desvest\n    &lt;dbl&gt;\n1       1\n\n\n[5 puntos] Realice la misma estimación que en la parte a., pero ahora use como variable dependiente gpa_year2_sd. ¿Cómo se interpreta el coeficiente sobre ssp? ¿Qué es diferente y qué es igual entre los resultados obtenidos en esta parte y los obtenidos en la parte a.?\nRealizamos la estimación, pero con la variable dependiente estandarizada:\n\nr2 &lt;-lm(gpa_year2_sd ~ ssp + sfp+ sfsp+\n             factor(sex)+\n             factor(mtongue)+\n             factor(hsgroup)+\n             factor(numcourses_nov1)+\n             factor(lastmin)+\n             factor(mom_edn)+\n             factor(dad_edn),\n           data.angrist)\n\ncoeftest(r2, vcov = vcovHC(r2, \"HC1\"))[1:4,]\n\n               Estimate Std. Error    t value   Pr(&gt;|t|)\n(Intercept)  0.94640721 0.50806908  1.8627530 0.06273961\nssp          0.05627187 0.08323764  0.6760388 0.49914542\nsfp         -0.02026459 0.07420621 -0.2730848 0.78483470\nsfsp         0.08026539 0.10182006  0.7883063 0.43067220\n\n\nLos coeficientes estimados son diferentes. Ahora el coeficiente sobre ssp es el efecto que tiene el programa en el z-score del promedio de calificaciones, es decir, el SSP tiene un efecto de 0.056 desviaciones estándar en el z-score del promedio de calificaciones, aunque este efecto no es estadísticamente significativo. La magnitud del error estándar también es diferente, pues ahora las variables están en distintas unidades. Noten, en cambio, que el estadístico t asociado a SSP es exactamente igual al de la parte a., por lo que en ambos casos no se rechaza la \\(H_0\\).\n\ncoeftest(r1, vcov = vcovHC(r1, \"HC1\"))[1:4,]\n\n               Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)  2.87240513 0.45314003  6.3388908 3.261488e-10\nssp          0.05018813 0.07423854  0.6760388 4.991454e-01\nsfp         -0.01807372 0.06618352 -0.2730848 7.848347e-01\nsfsp         0.07158763 0.09081195  0.7883063 4.306722e-01\n\n\n[5 puntos] Ahora realizaremos un índice de mejora en educación, al agregar los resultados de estos dos indicadores en una sola variable, como se describe en Banerjee et al. (2015)4. Para ello, primero genere credits_earned2_sd, que será la versión estandarizada de credits_earned2, siguiendo el mismo procedimiento que en la parte b. En seguida, genere una nueva variable llamada indice_escolar, que será el promedio de credits_earned2_sd y gpa_year2_sd. Luego, calcule la media y la desviación estándar de indice_escolar en el grupo de control. Finalmente, genere una nueva variable indice_escolar_sd restándole a indice_escolar la media antes calculada y dividiendo esta diferencia por la desviación estándar antes calculada. Muestre que la variable indice_escolar_sd tiene media 0 y desviación estándar 1 en el grupo de control.\nPrimero creamos la versión estandarizada de la variable de créditos:\n\ncredits_earned2_stats &lt;- data.angrist %&gt;% \n  filter(control==1) %&gt;% \n  summarize(media=mean(credits_earned2,na.rm=T),\n            desvest=sd(credits_earned2,na.rm=T))\n\ndata.angrist &lt;- data.angrist %&gt;% \n  mutate(credits_earned2_sd=(credits_earned2-credits_earned2_stats$media)/credits_earned2_stats$desvest)\n\nLuego calculamos la media de las dos variables estandarizadas:\n\ndata.angrist &lt;- data.angrist %&gt;% \n  mutate(indice_escolar=rowMeans(select(.,credits_earned2_sd,gpa_year2_sd)))\n\nAhora obtenemos la media y la desviación estándar en el grupo de control del promedio antes calculado:\n\nindice_escolar_stats &lt;- data.angrist %&gt;% \n  filter(control==1) %&gt;% \n  summarize(media=mean(indice_escolar,na.rm=T),\n            desvest=sd(indice_escolar,na.rm=T))\n\ndata.angrist &lt;- data.angrist %&gt;% \n  mutate(indice_escolar_sd=(indice_escolar-indice_escolar_stats$media)/indice_escolar_stats$desvest)\n\nEfectivamente tiene media igual a 0:\n\ndata.angrist %&gt;%\n  filter(control==1) %&gt;% \n  summarize(media=mean(indice_escolar_sd,na.rm=T))\n\n# A tibble: 1 × 1\n      media\n      &lt;dbl&gt;\n1 -1.33e-17\n\n\nY desviación estándar igual a 1:\n\ndata.angrist %&gt;%\n  filter(control==1) %&gt;% \n  summarize(desvest=sd(indice_escolar_sd,na.rm=T)) \n\n# A tibble: 1 × 1\n  desvest\n    &lt;dbl&gt;\n1       1\n\n\n[5 puntos] Estime ahora el efecto de tratamiento sobre indice_escolar_sd, siguiendo la misma especificación econométrica que en la parte a. y usando errores robustos. ¿Qué concluye?\nEstimamos usando la misma especificación, pero ahora con el índice compuesto como variable de impacto:\n\nr3 &lt;-lm(indice_escolar_sd ~ ssp + sfp+ sfsp+\n                             factor(sex)+\n                             factor(mtongue)+\n                             factor(hsgroup)+\n                             factor(numcourses_nov1)+\n                             factor(lastmin)+\n                             factor(mom_edn)+\n                             factor(dad_edn),\n                           data.angrist)\n\ncoeftest(r3, vcov = vcovHC(r3, \"HC1\"))[1:4,]\n\n               Estimate Std. Error    t value  Pr(&gt;|t|)\n(Intercept)  0.49452306 0.46650249  1.0600652 0.2893277\nssp          0.02805373 0.08261358  0.3395778 0.7342338\nsfp         -0.02543190 0.07385703 -0.3443396 0.7306511\nsfsp         0.03404990 0.09616572  0.3540753 0.7233445\n\n\nLa ventaja de este procedimiento es que solo probamos una hipótesis en lugar de dos. Si tuviéramos muchas variables de impacto, tendríamos que probar múltiples hipótesis, incrementando la probabilidad de falsos rechazos. La construcción de índices es una alternativa para enfrentar este problema."
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#pregunta-5",
    "href": "tareas/tarea-2-respuestas.html#pregunta-5",
    "title": "Respuestas a la tarea 2",
    "section": "Pregunta 5",
    "text": "Pregunta 5\nConsidere los valores \\(p\\) del archivo pvalues.csv. Cada valor \\(p_i\\) está asociado a una prueba de hipótesis \\(i\\). La variable familia denota tres grupos de hipótesis sobre las cuales estamos interesados en hacer correcciones de múltiples hipótesis. La investigación en cuestión emplea \\(\\alpha=0.05\\).\n\n[5 puntos] Para cada una de las pruebas de hipótesis, genere un cuadro como el que se presenta a continuación y diga si se rechaza o no la hipótesis nula, bajo los siguientes criterios:\n\n\n\n\n\n\n\n\n\n\nHipótesis sin corrección\nControlando la tasa de errores en la familia (FWER) usando el método de Bonferroni\nControlando la tasa de falso descubrimiento (FDR) dentro de la familia usando el método de Benjamini y Hochberg\n\n\n\n\n1\n\n\n\n\n\n\\(\\vdots\\)\n\n\n\n\n\n15\n\n\n\n\n\n\nEn este problema lo único posiblemente complicado era operacionalizar los procedimientos. Aquí les pongo mi propuesta. La columna regla_sincorr indica qué \\(H_0\\) se rechazaría con el valor \\(p\\) reportado originalmente en el estudio con \\(\\alpha=0.05\\). La columna regla_bonferroni indica qué \\(H_0\\) se rechazaría con la correción de Bonferroni, tomando en cuenta el agrupamiento con las familias en su definición original. Lo mismo sucede con regla_bh para la correción de Benjamini & Hochberg.\nEste fue mi procedimiento. Leemos los datos:\n\ndata.pvalues&lt;-read_csv(\"../files/pvalues.csv\",\n                       locale = locale(encoding = \"latin1\"))  \n\nalpha &lt;- 0.05\n\nConstruyo un objeto con los valores \\(p\\) y los ordeno de menor a mayor:\n\ndata.fam.or &lt;- data.pvalues %&gt;% \n  arrange(familia,p) \n\ndata.fam.or &lt;- data.fam.or %&gt;% \n  group_by(familia) %&gt;% \n  mutate(posicion=seq(along.with = familia)) %&gt;% \n  mutate(numerohipotesis=max(posicion)) %&gt;% \n  ungroup()\n\ndata.fam.or\n\n# A tibble: 15 × 6\n   hipotesis       p familia familia_corregida posicion numerohipotesis\n       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;             &lt;dbl&gt;    &lt;int&gt;           &lt;int&gt;\n 1         4 0.00210       1                 1        1               5\n 2         1 0.0145        1                 1        2               5\n 3         5 0.0401        1                 1        3               5\n 4         3 0.0678        1                 1        4               5\n 5         2 0.230         1                 1        5               5\n 6         7 0.0018        2                 4        1               3\n 7         6 0.322         2                 4        2               3\n 8         8 0.513         2                 4        3               3\n 9        15 0.0018        3                 4        1               7\n10         9 0.0034        3                 4        2               7\n11        11 0.0211        3                 4        3               7\n12        13 0.0273        3                 4        4               7\n13        12 0.0412        3                 4        5               7\n14        14 0.120         3                 4        6               7\n15        10 0.176         3                 4        7               7\n\n\nConstruyo los valores contra los que compararé el valor \\(p\\) original. En el caso del método de Bonferroni, calculo \\(\\alpha_i=\\frac{\\alpha}{\\text{número de hipótesis en la familia}}\\). Para el caso de la corrección de Benjamini y Hochberg, calculo \\(q=\\frac{\\text{orden descendente de la hipótesis}}{\\text{número de hipótesis en la familia}}\\alpha\\)\n\ndata.fam.or &lt;- data.fam.or %&gt;% \n  mutate(alpha_bonferroni=alpha/numerohipotesis) %&gt;% \n  mutate(corrector_bh=posicion/numerohipotesis) %&gt;% \n  mutate(q=corrector_bh*alpha)\n\ndata.fam.or\n\n# A tibble: 15 × 9\n   hipotesis       p familia familia_corregida posicion numerohipotesis\n       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;             &lt;dbl&gt;    &lt;int&gt;           &lt;int&gt;\n 1         4 0.00210       1                 1        1               5\n 2         1 0.0145        1                 1        2               5\n 3         5 0.0401        1                 1        3               5\n 4         3 0.0678        1                 1        4               5\n 5         2 0.230         1                 1        5               5\n 6         7 0.0018        2                 4        1               3\n 7         6 0.322         2                 4        2               3\n 8         8 0.513         2                 4        3               3\n 9        15 0.0018        3                 4        1               7\n10         9 0.0034        3                 4        2               7\n11        11 0.0211        3                 4        3               7\n12        13 0.0273        3                 4        4               7\n13        12 0.0412        3                 4        5               7\n14        14 0.120         3                 4        6               7\n15        10 0.176         3                 4        7               7\n# ℹ 3 more variables: alpha_bonferroni &lt;dbl&gt;, corrector_bh &lt;dbl&gt;, q &lt;dbl&gt;\n\n\nFinalmente, especificamos las reglas de decisión:\n\ndata.fam.or &lt;- data.fam.or %&gt;% \n  mutate(regla_sincorr=ifelse(p&lt;.05,1,0)) %&gt;% \n  mutate(regla_bonferroni=ifelse(p&lt;alpha_bonferroni,1,0)) %&gt;% \n  mutate(regla_bh=ifelse(p&lt;q,1,0))\n\ndata.fam.or &lt;- data.fam.or %&gt;% \n  arrange(hipotesis)\n\nEstos son los resultados:\n\ndata.fam.or %&gt;% \n  select(hipotesis,familia,regla_sincorr,regla_bonferroni,regla_bh)\n\n# A tibble: 15 × 5\n   hipotesis familia regla_sincorr regla_bonferroni regla_bh\n       &lt;dbl&gt;   &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;    &lt;dbl&gt;\n 1         1       1             1                0        1\n 2         2       1             0                0        0\n 3         3       1             0                0        0\n 4         4       1             1                1        1\n 5         5       1             1                0        0\n 6         6       2             0                0        0\n 7         7       2             1                1        1\n 8         8       2             0                0        0\n 9         9       3             1                1        1\n10        10       3             0                0        0\n11        11       3             1                0        1\n12        12       3             1                0        0\n13        13       3             1                0        1\n14        14       3             0                0        0\n15        15       3             1                1        1\n\n\nSin corrección se rechazan las hipótesis 1, 4, 5, 7, 9, 11, 12, 13 y 15 (nueve hipótesis en total). Al agrupar con la definición de familia dada por la variable familia solo se rechazan cuatro hipótesis siguiendo el método de Bonferroni, es decir, la corrección fue muy conservadora. Con el método de Benjamini y Hochberg se rechazan siete hipótesis.\n[5 puntos] Suponga que encuentra buenas razones conceptuales para afirmar que las familias 2 y 3 deben ser consideraras una sola familia. Tendríamos ahora solo dos familias, la familia 1 original y una nueva familia numerada como 4, como se indica en la variable familia_corregida. ¿Cómo cambian sus conclusiones respecto a la parte a. de esta pregunta? Genere un nuevo cuadro con esta redefinición.\nRepetimos el mismo procedimiento, solo que con la columna familia_corregida como la que indica a qué familia pertenece cada hipótesis:\n\ndata.fam.corr &lt;- data.pvalues %&gt;% \n      arrange(familia_corregida,p)\n\ndata.fam.corr &lt;- data.fam.corr %&gt;% \n  group_by(familia_corregida) %&gt;% \n  mutate(posicion=seq(along.with = familia_corregida)) %&gt;% \n  mutate(numerohipotesis=max(posicion)) %&gt;% \n  ungroup()\n\ndata.fam.corr &lt;- data.fam.corr %&gt;% \n  mutate(alpha_bonferroni=alpha/numerohipotesis) %&gt;% \n  mutate(corrector_bh=posicion/numerohipotesis) %&gt;% \n  mutate(q=corrector_bh*alpha) %&gt;% \n  mutate(regla_sincorr=ifelse(p&lt;.05,1,0)) %&gt;% \n  mutate(regla_bonferroni=ifelse(p&lt;alpha_bonferroni,1,0)) %&gt;% \n  mutate(regla_bh=ifelse(p&lt;q,1,0))\n\ndata.fam.corr &lt;- data.fam.corr %&gt;% \n  arrange(hipotesis)\n\ndata.fam.corr %&gt;% \n  select(hipotesis,familia_corregida,regla_sincorr,regla_bonferroni,regla_bh)\n\n# A tibble: 15 × 5\n   hipotesis familia_corregida regla_sincorr regla_bonferroni regla_bh\n       &lt;dbl&gt;             &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;    &lt;dbl&gt;\n 1         1                 1             1                0        1\n 2         2                 1             0                0        0\n 3         3                 1             0                0        0\n 4         4                 1             1                1        1\n 5         5                 1             1                0        0\n 6         6                 4             0                0        0\n 7         7                 4             1                1        1\n 8         8                 4             0                0        0\n 9         9                 4             1                1        1\n10        10                 4             0                0        0\n11        11                 4             1                0        0\n12        12                 4             1                0        0\n13        13                 4             1                0        0\n14        14                 4             0                0        0\n15        15                 4             1                1        1\n\n\nAhora solo tenemos dos familias, pero la familia 1 se mantiene igual. Entonces, no debe haber cambios en qué hipótesis se rechazan dentro de la familia 1 sin importar el método, lo cual ocurre en este caso. Al reagrupar las familias, ahora se rechazan en total cuatro hipótesis con el método de Bonferroni y cinco con el de Benjamini y Hochberg.\n[5 puntos] Suponga que su asistente de investigación olvidó el concepto de familia y realiza las correcciones por pruebas de múltiples hipótesis ignorando las familias. ¿Qué concluiría en este caso? Genere un nuevo cuadro bajo esta circunstancia. Comente sobre la diferencia en las conclusiones entre las partes b. y c.\nFinalmente, podemos ver esta parte como si hubiera una sola gran familia. En este caso, usando el método de Bonferroni se rechazarían solo tres hipótesis. Usando el método de Benjamini y Hochberg se rechazan cinco hipótesis.\nEn esta pregunta comprobamos que el procedimiento de Bonferroni es demasiado conservador, así como no agrupar por familias lo es también. El cómo decidamos agrupar las variables en familias tiene importantes consecuencias al momento de realizar las correcciones. El procedimiento de Benjamini y Hochberg es ampliamente usado en la literatura de evaluación, como lo hemos visto en varias de las aplicaciones de clase.\n\ndata.nofam &lt;- data.pvalues %&gt;% \n      arrange(p)\n\n#Hago esto para usar mi mismo código\ndata.nofam &lt;- data.nofam %&gt;% \n  mutate(granfamilia=1)\n\ndata.nofam &lt;- data.nofam %&gt;% \n  group_by(granfamilia) %&gt;% \n  mutate(posicion=seq(along.with = granfamilia)) %&gt;% \n  mutate(numerohipotesis=max(posicion)) %&gt;% \n  ungroup()\n\ndata.nofam &lt;- data.nofam %&gt;% \n  mutate(regla_sincorr=ifelse(p&lt;.05,1,0)) %&gt;% \n  mutate(alpha_bonferroni=alpha/numerohipotesis) %&gt;% \n  mutate(corrector_bh=posicion/numerohipotesis) %&gt;% \n  mutate(q=corrector_bh*alpha) %&gt;% \n  mutate(regla_bonferroni=ifelse(p&lt;alpha_bonferroni,1,0)) %&gt;% \n  mutate(regla_bh=ifelse(p&lt;q,1,0))\n\ndata.nofam &lt;- data.nofam %&gt;% \n  arrange(hipotesis)\n\ndata.nofam %&gt;% \n  select(hipotesis,regla_sincorr,regla_bonferroni,regla_bh)\n\n# A tibble: 15 × 4\n   hipotesis regla_sincorr regla_bonferroni regla_bh\n       &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;    &lt;dbl&gt;\n 1         1             1                0        1\n 2         2             0                0        0\n 3         3             0                0        0\n 4         4             1                1        1\n 5         5             1                0        0\n 6         6             0                0        0\n 7         7             1                1        1\n 8         8             0                0        0\n 9         9             1                0        1\n10        10             0                0        0\n11        11             1                0        0\n12        12             1                0        0\n13        13             1                0        0\n14        14             0                0        0\n15        15             1                1        1"
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#footnotes",
    "href": "tareas/tarea-2-respuestas.html#footnotes",
    "title": "Respuestas a la tarea 2",
    "section": "Notas",
    "text": "Notas\n\n\nPor ejemplo, suponga que estima un modelo al que llame modelo1. Entonces, si ejecuta\n\ncoef_test(modelo1,\n      vcov=\"CR1S\",\n      cluster=mis_datos$demi_paire)[1:2,]\n\nobtendrá los coeficientes con los errores agrupados requeridos. La opción CR1S toma en cuenta el número de grupos o clusters para realizar inferencia. Puede leer más al respecto en la ayuda al ejecutar ?vcovCR. Este es el tipo de ajuste de muestras finitas que usan los autores. Esta corrección consiste en multiplicar la matriz de sándwich agrupada CR0 por \\(\\frac{G(N-1)}{(G-1)(N-p)}\\), donde \\(G\\) es el número de grupos, \\(N\\) es el número total de observaciones y \\(p\\) es el número de regresores.↩︎\nCrépon, B., Devoto, F., Duflo, E., & Parienté, W. (2015). Estimating the impact of microcredit on those who take it up: Evidence from a randomized experiment in Morocco. American Economic Journal: Applied Economics, 7(1), 123-50.↩︎\nAngrist, J., Lang, D., y Oreopoulos, P. (2009). Incentives and services for college achievement: Evidence from a randomized trial. American Economic Journal: Applied Economics, 1(1), 136-63.↩︎\nBanerjee, A. et al. (2015). A multifaceted program causes lasting progress for the very poor: Evidence from six countries. Science, 348(6236).↩︎"
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html",
    "href": "tareas/tarea-1-respuestas.html",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Suponga que para un experimento en un laboratorio de economía experimental se asignó a la mitad de los participantes a un grupo de tratamiento y la otra mitad al grupo de control. Se busca estudiar el efecto del tratamiento \\(T_i\\) sobre el desempeño en un juego estratégico, medido por la variable \\(y_i\\) (a más puntaje, mejor desempeño). Antes de comenzar el experimento se recolectaron una serie de características \\(x_{ji}\\), \\(j=1,\\ldots 10\\), de cada jugador. En el experimento, se trabaja con \\(\\alpha=0.10\\).\n\n[5 puntos] El investigador A quedó a cargo de comprobar el balance de la asignación del tratamiento y le reporta lo siguiente:\nPara verificar que la aleatorización fue exitosa, tomé la serie de variables pre-intervención y la dummy de asignación al tratamiento \\(T_i\\) para correr la siguiente regresión: \\[T_i=\\alpha+\\sum_{j=1}^{10}x_{ji}'\\beta +\\varepsilon_i\\]\nDespués realicé una prueba \\(F\\) de significancia conjunta sobre los coeficientes \\(\\beta_j\\) que resultó tener un valor \\(p\\) de 0.02.\nExplique cuál es la hipótesis nula en la prueba realizada y qué se esperaría de haberse logrado una aleatorización exitosa del tratamiento.\nLa \\(H_0\\) es que \\(\\beta_1=\\beta_2=\\ldots=\\beta_{10}=0\\), es decir, que las características observadas no predicen el status de tratamiento. Si efectivamente hubo una aleatorización exitosa, esperaríamos que este fuera el caso.\n[5 puntos] ¿Qué concluye a partir de lo que le reporta el investigador A?\nEl valor \\(p\\) indica que es muy poco probable observar el estadístico \\(F\\) bajo la hipótesis nula, por lo que la rechazamos. Es decir, hay evidencia que señala que las características predicen la asignación al tratamiento.\n[5 puntos] Por otro lado, el investigador B le reporta lo siguiente:\nYo realicé un análisis para determinar el balance en la asignación del tratamiento. Para cada una de las características \\(x_{ji}\\) corrí la siguiente regresión: \\[x_{ji}=\\gamma+\\pi T_i+u_i\\] A continuación, le reporto una tabla con los valores \\(p\\) asociados al coeficiente estimado de \\(\\pi\\) en cada una de las 10 regresiones.\n\n\n\n\n\n\n\n\n\n\nCaracterística\nValor \\(p\\)\n\nCaracterística\nValor \\(p\\)\n\n\n\n\n\\(x_{1i}\\)\n0.05\n\n\\(x_{6i}\\)\n0.03\n\n\n\\(x_{2i}\\)\n0.02\n\n\\(x_{7i}\\)\n0.19\n\n\n\\(x_{3i}\\)\n0.07\n\n\\(x_{8i}\\)\n0.85\n\n\n\\(x_{4i}\\)\n0.00\n\n\\(x_{9i}\\)\n0.01\n\n\n\\(x_{5i}\\)\n0.42\n\n\\(x_{10i}\\)\n0.03\n\n\n\nExplique la hipótesis nula detrás de las pruebas que realizó el investigador B y qué se esperaría de haberse logrado una aleatorización exitosa del tratamiento.\nEn cada caso, la \\(H_0\\) es que \\(\\pi=0\\), es decir, que no existen diferencias significativas en la variable \\(x_{ij}\\) entre tratados y no tratados. Si el tratamiento fue correctamente aleatorizado, esperaríamos que esto se cumpliera para la mayoría de las características recolectadas.\n[5 puntos] Explique qué concluye sobre la validez interna del estudio en cuestión. ¿Qué propiedades estadísticas tendría el estimador de diferencia de medias de la variable de desempeño en el juego entre el grupo tratado y el de control?\nEn cinco de las 10 características hay diferencias significativas entre tratados y no tratados. Esto es consistente con lo encontrado en la parte a. Es decir, parece que los individuos en el grupo de tratamiento son distintos a los del grupo de control. Esto nos haría dudar del caracter causal de la diferencia de medias de la variable de desempeño como un estimador del efecto del tratamiento. No sabemos si es el tratamiento o las diferencias en las características observables lo que explican las diferencias que se encuentren o no se encuentren en la variable de desempeño en el juego. Este es un ejemplo de cómo luciría un experimento cuya integridad está comprometida.\n\n\n\n\nSuponga que está interesado en conocer el impacto que tiene el acceso a las microfinanzas en un indicador de seguridad alimentaria \\(y_i\\) de las familias. La idea detrás es que el acceso al crédito podría mejorar la habilidad de los hogares para suavizar el consumo. Afortunadamente, usted recibe el respaldo de una microfinanciera que le ofrece una base de datos para con información para construir \\(y_i\\), recolecatada a partir de una encuesta en los hogares de sus clientes con más de un año de antiguedad. Además, le da acceso a datos de otra encuesta complementaria realizada en hogares que no son clientes y que no tienen acceso a microfinanzas para construir el mismo indicador de seguridad alimentaria. Al final, tendría una muestra de varios miles de hogares con y sin acceso a microfinanzas.\nSuponga que con estos datos descubre que la seguridad alimentaria es 25% más alta en los hogares con clientes de la microfinanciera, en comparación con la seguridad alimentaria de los hogares sin acceso a las microfinanzas.\n\n[10 puntos] ¿Cómo valora el diseño del estudio descrito? ¿Qué fortalezas y/o debilidades encuentra?\nA pesar de que se cuenta con una cantidad notable de información, la situación que se describe no deja de ser un ejemplo de una comparación observacional. Usted tendría acceso a información de personas que tomaron la decisión de ser clientes de la microfinanciera, o que la microfinanciera ya decidió atender con publicidad y con atención personalizada para que se volvieran clientes. Es decir, estas personas son distintas en características observadas, pero sobre todo, no observadas, de quienes no son clientes. Las razones por las que se volvieron clientes o no de la microfinanciera pueden estar correlacionadas también con tener una mejor o peor seguridad alimentaria, por lo que tenemos un ejemplo de sesgo de selección. En general, el diseño de este estudio no permitiría obtener conclusiones sobre el efecto causal de tener acceso a microfinanzas. La debilidad principal se encuentra en la presencia del sesgo de selección.\n[10 puntos] ¿De qué signo esperaría que fuera el sesgo de selección, en caso de existir? Explique sus razones.\nMuchas historias son posibles. Por ejemplo, suponiendo que las personas con mayor educación e información tendrían mejor acceso a productos financieros, pero también tendrían un mejor manejo de los recursos del hogar, entonces aquellas familias con acceso a microfinanzas hubieran podido tener una mejor seguridad alimentaria incluso sin haber tenido acceso a dichos productos financieros. En otras palabras, familias con mayor educación e información tendrían mejorar seguridad alimentaria sin importar su acceso a productos financieros, por lo que esperariamos un sesgo de selección positivo, por lo que tenderíamos a sobreestimar el impacto de las microfinanzas.\n\n\n\n\n\n[10 puntos] Replique el ejercicio en MHE que ejemplifica el teorema de la regresión de la FEC. Para esto use el archivo de datos muestra-enoe-123.csv, que contiene una muestra del primer trimestre de 2023 de la ENOE e incluye personas que trabajan y reciben un ingreso. lingreso es el log del ingreso mensual y escolaridad son los años de educación. Primero, estime una regresión de lingreso en función de escolaridad usando los microdatos. Luego, obtenga la media de lingreso para cada nivel de escolaridad y estime una regresión de las medias en función de escolaridad, pesando por el número de observaciones usadas para construir cada media. Compare los coeficientes estimados.\nCorramos la regresión con los microdatos:\n\ndf &lt;- read_csv(\"../files/muestra-enoe-123.csv\") \n\nsummary(lm(lingreso ~ escolaridad,\n        data = df))\n\n\nCall:\nlm(formula = lingreso ~ escolaridad, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.6859 -0.3123  0.0462  0.4179  3.0679 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 8.216881   0.024243  338.94   &lt;2e-16 ***\nescolaridad 0.060347   0.002105   28.67   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6973 on 6554 degrees of freedom\nMultiple R-squared:  0.1115, Adjusted R-squared:  0.1113 \nF-statistic: 822.1 on 1 and 6554 DF,  p-value: &lt; 2.2e-16\n\n\nAhora calculemos la media del ingreso por cada año de educación, asegurándonos de conservar también el número de observaciones empleada para hacer dicho cálculo:\n\ndf.agregada &lt;- df %&gt;% \n  group_by(escolaridad) %&gt;% \n  summarise(lingreso = mean(lingreso, na.rm=T),\n            n = n())\n\nCorremos la regresión con los datos agregados, pensando por el número de observaciones en cada grupo:\n\nsummary(lm(lingreso ~ escolaridad,\n           data = df.agregada,\n           weights = n))\n\n\nCall:\nlm(formula = lingreso ~ escolaridad, data = df.agregada, weights = n)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-2.7905 -0.1961  0.3220  1.1960  3.8566 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 8.216881   0.056804  144.65  &lt; 2e-16 ***\nescolaridad 0.060347   0.004932   12.24 1.86e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.634 on 19 degrees of freedom\nMultiple R-squared:  0.8874, Adjusted R-squared:  0.8815 \nF-statistic: 149.7 on 1 and 19 DF,  p-value: 1.861e-10\n\n\nEl coeficiente estimado de los años de escolaridad es exactamente el mismo.\n\n\n\n\nUse los datos del archivo STAR_public_use.csv para este problema. En este problema replicará la fila correspondiente a la variable High scool GPA (calificación en la preparatoria) de la Tabla 1 en Angrist et al. (2009).1\n\n[5 puntos] Obtenga la media y la desviación estándar de la calificación en la preparatoria, gpa0, en el grupo de control (columna 1), restringiendo la muestra a aquellos individuos con noshow igual a 0.\nDespués de eliminar a lo sindividuos que tienen noshow igual a 1, obtenemos la media y desviación estándar reportadas en la tabla. Noten que deben restringir al grupo de control para obtener dichas cifras. La columna del tamaño de la muestra se obtiene sin restringir al grupo de control, aunque esto no se pedía en la pregunta.\n\ndata.angrist &lt;- read_csv(\"../files/STAR_public_use.csv\",\n                       locale = locale(encoding = \"latin1\"))   %&gt;% \n  clean_names() %&gt;% \n  filter(noshow==0)\n\n#Media y desviación estándar\ndata.angrist %&gt;% \n  filter(control==1) %&gt;% \n  summarize(media=mean(gpa0),\n            desvest=sd(gpa0))\n\n# A tibble: 1 × 2\n  media desvest\n  &lt;dbl&gt;   &lt;dbl&gt;\n1  78.7    4.22\n\n#N\ndata.angrist %&gt;% \n  summarize(n())\n\n# A tibble: 1 × 1\n  `n()`\n  &lt;int&gt;\n1  1571\n\n\n[10 puntos] Usando una regresión lineal, muestre que la calificación en la preparatoria no está correlacionada con la asignación a los tratamientos (ssp, sfp y sfsp). De nuevo, debe restringir la muestra quienes tienen noshow igual a 0. Reporte los coeficientes y los errores estándar (columnas 2 a 4).\nLa regresión es:\n\nsummary(balance &lt;- lm(gpa0 ~ ssp + sfp+ sfsp,\n            data = data.angrist))\n\n\nCall:\nlm(formula = gpa0 ~ ssp + sfp + sfsp, data = data.angrist)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.6567  -3.4567  -0.1567   3.3433   8.6612 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 78.65672    0.13718 573.377   &lt;2e-16 ***\nssp          0.16997    0.30779   0.552    0.581    \nsfp          0.23795    0.30372   0.783    0.433    \nsfsp        -0.01787    0.38433  -0.047    0.963    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.233 on 1567 degrees of freedom\nMultiple R-squared:  0.0005287,  Adjusted R-squared:  -0.001385 \nF-statistic: 0.2763 on 3 and 1567 DF,  p-value: 0.8425\n\n\nNoten que aquí los autores no utilizan errores robustos. Yo hubiera estimado errores robustos.\n[5 puntos] Realice una prueba de significancia conjunta de los coeficientes obtenidos en el punto b. Reporte el estadístico \\(F\\) y el valor \\(p\\) asociado (columna 5).\nEl estadístico \\(F\\) ya es calculado con la regresión. Basta con pedirlo:\n\nsummary(balance)$fstatistic\n\n       value        numdf        dendf \n   0.2762878    3.0000000 1567.0000000 \n\n\n¿Pero cómo puedo calcular el valor \\(p\\)? Basta usar la definición, es la probabilidad de observar un valor más extremo que el estadístico, bajo la distribución teórica. En este caso, la distribución teórica es una \\(F\\) y debemos especificar los grados de libertad en el numerador y en el denominador:\n\npf(q = summary(balance)$fstatistic[1],\n   df1 = summary(balance)$fstatistic[2],\n   df2 = summary(balance)$fstatistic[3],\n   lower.tail=FALSE)\n\n    value \n0.8425407 \n\n\n[10 puntos] ¿Cuál es el propósito de la prueba F realizada en el punto c.? ¿Qué hipótesis nula prueban los autores?\nAquí se busca probar que la asignación a los tres tipos de tratamiento no está correlacionada con la calificación en preparatoria, que es una medida del desempeño escolar justo al momento de iniciar el experimento. La \\(H_0\\) es que \\(\\beta_{SSP}=\\beta_{SFP}=\\beta_{SFSP}=0\\). Si rechazamos la hipótesis nula concluiríamos que hay diferencias entre grupos en la calificación de preparatoria. En este caso, el estadístico \\(F\\) es pequeño y su valor \\(p\\) indica que es muy probable de observarlo bajo la hipótesis nula por lo que no hay bases para rechazarla.\n\n\n\n\nNuevamente, use los datos del archivo STAR_public_use.csv para este problema. En este problema, replicará dos columnas del efecto de tratamiento de la Tabla 5. Note que de nuevo se deben usar solo las observaciones que tienen noshow igual a 0. Además, note que se usan las siguientes variables de control: sex, mtongue, hsgroup, numcourses_nov1, lastmin, mom_edn, y dad_edn, todas ellas categóricas.\n\n[10 puntos] Estime el efecto de cada tipo de tratamiento sobre la calificación del trimestre de otoño, grade_20059_fall, para toda la muestra (Panel A, columna 1). Calcule correctamente los errores estándar. Interprete los resultados.\nHaciendo la sustitución sugerida por los autores, estimamos:\n\ndata.angrist &lt;- data.angrist %&gt;% \n      mutate(gpa_year1=ifelse(is.na(grade_20059_fall),NA,gpa_year1),\n             grade_20059_fall=ifelse(is.na(gpa_year1),NA,grade_20059_fall))\n\nreg1&lt;-lm(grade_20059_fall ~ ssp + sfp+ sfsp+\n           factor(sex)+\n           factor(mtongue)+\n           factor(hsgroup)+\n           factor(numcourses_nov1)+\n           factor(lastmin)+\n           factor(mom_edn)+\n           factor(dad_edn),\n         data=data.angrist)\n\nNoten que los coeficientes estimados son correctos, pero no los errores estándar:\n\nsummary(reg1)$coef[1:4,]\n\n              Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept) 66.3735025  6.3907155 10.3859267 2.840799e-24\nssp          0.3492964  0.9084654  0.3844906 7.006818e-01\nsfp          1.8241268  0.8963916  2.0349665 4.206972e-02\nsfsp         2.7020874  1.1768042  2.2961232 2.183745e-02\n\n\nLos errores estándar correctos son los robustos:\n\ncoeftest(reg1, vcov = vcovHC(reg1, \"HC1\"))[1:4,]\n\n              Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept) 66.3735025  3.8631593 17.1811456 1.981996e-59\nssp          0.3492964  0.9173865  0.3807516 7.034537e-01\nsfp          1.8241268  0.8465341  2.1548179 3.137099e-02\nsfsp         2.7020874  1.1244211  2.4030920 1.640541e-02\n\n\nFinalmente, lo que se reporta en la tabla como la media del grupo de control no es la constante en la regresión, sino la media y desviación estándar. Noten que se usa la muestra que efectivamente se usa en la regresión, es decir, sin valores faltantes.\n\ndata.angrist %&gt;%\n    filter(!is.na(gpa_year1) & !is.na(grade_20059_fall)\n     & !is.na(ssp)\n     & !is.na(sfp)\n     & !is.na(sfsp)\n     & !is.na(sex)\n     & !is.na(mtongue)\n     & !is.na(hsgroup)\n     & !is.na(numcourses_nov1)\n     & !is.na(lastmin)\n     & !is.na(mom_edn)\n     & !is.na(dad_edn)\n     & control==1) %&gt;%\n  summarize(media=mean(grade_20059_fall,\n                       na.rm=TRUE),\n            desvest=sd(grade_20059_fall,\n                       na.rm=TRUE))\n\n# A tibble: 1 × 2\n  media desvest\n  &lt;dbl&gt;   &lt;dbl&gt;\n1  64.2    11.9\n\ndata.angrist %&gt;%\n  filter(!is.na(gpa_year1) & !is.na(grade_20059_fall)\n     & !is.na(ssp)\n     & !is.na(sfp)\n     & !is.na(sfsp)\n     & !is.na(sex)\n     & !is.na(mtongue)\n     & !is.na(hsgroup)\n     & !is.na(numcourses_nov1)\n     & !is.na(lastmin)\n     & !is.na(mom_edn)\n     & !is.na(dad_edn)) %&gt;%\n  summarize(numero=n())\n\n# A tibble: 1 × 1\n  numero\n   &lt;int&gt;\n1   1255\n\n\n[10 puntos] Estime el efecto de recibir cada tipo de tratamiento, considerando los tratamientos SSP o SFP (de cualquier tipo) en los hombres de la muestra (Panel A, columna 5). Esto es, considere el tratamiento SSP como un primer tipo de tratamiento y, ya sea SFP o SFSP, como un segundo tipo de tratamiento. Calcule correctamente los errores estándar. Interprete sus resultados.\nDefinimos la variable de recibir el tratamiento SFP o SFSP. Luego estimamos:\n\ndata.angrist &lt;- data.angrist %&gt;%\n      mutate(sspany = ifelse(sfp == 1 | sfsp == 1, 1, \n    0))\n\nreg2&lt;-lm(grade_20059_fall ~ ssp + sspany+\n           factor(mtongue)+\n           factor(hsgroup)+\n           factor(numcourses_nov1)+\n           factor(lastmin)+\n           factor(mom_edn)+\n           factor(dad_edn),\n         data=filter(data.angrist,\n                     female==0))\n\nLos coeficientes con los errores correctos son:\n\ncoeftest(reg2, vcov = vcovHC(reg2, \"HC1\"))[1:3,]\n\n               Estimate Std. Error     t value     Pr(&gt;|t|)\n(Intercept) 63.82375619   5.837643 10.93313826 4.530618e-25\nssp         -0.01375880   1.331848 -0.01033060 9.917617e-01\nsspany       0.01615914   1.163865  0.01388403 9.889281e-01\n\n\nLa media en el control:\n\ndata.angrist %&gt;%\n  filter(!is.na(gpa_year1) & !is.na(grade_20059_fall)\n     & !is.na(ssp)\n     & !is.na(sfp)\n     & !is.na(sfsp)\n     & !is.na(sex)\n     & !is.na(mtongue)\n     & !is.na(hsgroup)\n     & !is.na(numcourses_nov1)\n     & !is.na(lastmin)\n     & !is.na(mom_edn)\n     & !is.na(dad_edn)\n     & control==1\n     & female==0) %&gt;%\n  summarize(media=mean(grade_20059_fall,\n                       na.rm=TRUE),\n            desvest=sd(grade_20059_fall,\n                       na.rm=TRUE))\n\n# A tibble: 1 × 2\n  media desvest\n  &lt;dbl&gt;   &lt;dbl&gt;\n1  65.9    11.3\n\ndata.angrist %&gt;%\n  filter(!is.na(gpa_year1) & !is.na(grade_20059_fall)\n     & !is.na(ssp)\n     & !is.na(sfp)\n     & !is.na(sfsp)\n     & !is.na(sex)\n     & !is.na(mtongue)\n     & !is.na(hsgroup)\n     & !is.na(numcourses_nov1)\n     & !is.na(lastmin)\n     & !is.na(mom_edn)\n     & !is.na(dad_edn)\n     & female==0) %&gt;%\n  summarize(numero=n())\n\n# A tibble: 1 × 1\n  numero\n   &lt;int&gt;\n1    526"
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-1",
    "href": "tareas/tarea-1-respuestas.html#pregunta-1",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Suponga que para un experimento en un laboratorio de economía experimental se asignó a la mitad de los participantes a un grupo de tratamiento y la otra mitad al grupo de control. Se busca estudiar el efecto del tratamiento \\(T_i\\) sobre el desempeño en un juego estratégico, medido por la variable \\(y_i\\) (a más puntaje, mejor desempeño). Antes de comenzar el experimento se recolectaron una serie de características \\(x_{ji}\\), \\(j=1,\\ldots 10\\), de cada jugador. En el experimento, se trabaja con \\(\\alpha=0.10\\).\n\n[5 puntos] El investigador A quedó a cargo de comprobar el balance de la asignación del tratamiento y le reporta lo siguiente:\nPara verificar que la aleatorización fue exitosa, tomé la serie de variables pre-intervención y la dummy de asignación al tratamiento \\(T_i\\) para correr la siguiente regresión: \\[T_i=\\alpha+\\sum_{j=1}^{10}x_{ji}'\\beta +\\varepsilon_i\\]\nDespués realicé una prueba \\(F\\) de significancia conjunta sobre los coeficientes \\(\\beta_j\\) que resultó tener un valor \\(p\\) de 0.02.\nExplique cuál es la hipótesis nula en la prueba realizada y qué se esperaría de haberse logrado una aleatorización exitosa del tratamiento.\nLa \\(H_0\\) es que \\(\\beta_1=\\beta_2=\\ldots=\\beta_{10}=0\\), es decir, que las características observadas no predicen el status de tratamiento. Si efectivamente hubo una aleatorización exitosa, esperaríamos que este fuera el caso.\n[5 puntos] ¿Qué concluye a partir de lo que le reporta el investigador A?\nEl valor \\(p\\) indica que es muy poco probable observar el estadístico \\(F\\) bajo la hipótesis nula, por lo que la rechazamos. Es decir, hay evidencia que señala que las características predicen la asignación al tratamiento.\n[5 puntos] Por otro lado, el investigador B le reporta lo siguiente:\nYo realicé un análisis para determinar el balance en la asignación del tratamiento. Para cada una de las características \\(x_{ji}\\) corrí la siguiente regresión: \\[x_{ji}=\\gamma+\\pi T_i+u_i\\] A continuación, le reporto una tabla con los valores \\(p\\) asociados al coeficiente estimado de \\(\\pi\\) en cada una de las 10 regresiones.\n\n\n\n\n\n\n\n\n\n\nCaracterística\nValor \\(p\\)\n\nCaracterística\nValor \\(p\\)\n\n\n\n\n\\(x_{1i}\\)\n0.05\n\n\\(x_{6i}\\)\n0.03\n\n\n\\(x_{2i}\\)\n0.02\n\n\\(x_{7i}\\)\n0.19\n\n\n\\(x_{3i}\\)\n0.07\n\n\\(x_{8i}\\)\n0.85\n\n\n\\(x_{4i}\\)\n0.00\n\n\\(x_{9i}\\)\n0.01\n\n\n\\(x_{5i}\\)\n0.42\n\n\\(x_{10i}\\)\n0.03\n\n\n\nExplique la hipótesis nula detrás de las pruebas que realizó el investigador B y qué se esperaría de haberse logrado una aleatorización exitosa del tratamiento.\nEn cada caso, la \\(H_0\\) es que \\(\\pi=0\\), es decir, que no existen diferencias significativas en la variable \\(x_{ij}\\) entre tratados y no tratados. Si el tratamiento fue correctamente aleatorizado, esperaríamos que esto se cumpliera para la mayoría de las características recolectadas.\n[5 puntos] Explique qué concluye sobre la validez interna del estudio en cuestión. ¿Qué propiedades estadísticas tendría el estimador de diferencia de medias de la variable de desempeño en el juego entre el grupo tratado y el de control?\nEn cinco de las 10 características hay diferencias significativas entre tratados y no tratados. Esto es consistente con lo encontrado en la parte a. Es decir, parece que los individuos en el grupo de tratamiento son distintos a los del grupo de control. Esto nos haría dudar del caracter causal de la diferencia de medias de la variable de desempeño como un estimador del efecto del tratamiento. No sabemos si es el tratamiento o las diferencias en las características observables lo que explican las diferencias que se encuentren o no se encuentren en la variable de desempeño en el juego. Este es un ejemplo de cómo luciría un experimento cuya integridad está comprometida."
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-2",
    "href": "tareas/tarea-1-respuestas.html#pregunta-2",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Suponga que está interesado en conocer el impacto que tiene el acceso a las microfinanzas en un indicador de seguridad alimentaria \\(y_i\\) de las familias. La idea detrás es que el acceso al crédito podría mejorar la habilidad de los hogares para suavizar el consumo. Afortunadamente, usted recibe el respaldo de una microfinanciera que le ofrece una base de datos para con información para construir \\(y_i\\), recolecatada a partir de una encuesta en los hogares de sus clientes con más de un año de antiguedad. Además, le da acceso a datos de otra encuesta complementaria realizada en hogares que no son clientes y que no tienen acceso a microfinanzas para construir el mismo indicador de seguridad alimentaria. Al final, tendría una muestra de varios miles de hogares con y sin acceso a microfinanzas.\nSuponga que con estos datos descubre que la seguridad alimentaria es 25% más alta en los hogares con clientes de la microfinanciera, en comparación con la seguridad alimentaria de los hogares sin acceso a las microfinanzas.\n\n[10 puntos] ¿Cómo valora el diseño del estudio descrito? ¿Qué fortalezas y/o debilidades encuentra?\nA pesar de que se cuenta con una cantidad notable de información, la situación que se describe no deja de ser un ejemplo de una comparación observacional. Usted tendría acceso a información de personas que tomaron la decisión de ser clientes de la microfinanciera, o que la microfinanciera ya decidió atender con publicidad y con atención personalizada para que se volvieran clientes. Es decir, estas personas son distintas en características observadas, pero sobre todo, no observadas, de quienes no son clientes. Las razones por las que se volvieron clientes o no de la microfinanciera pueden estar correlacionadas también con tener una mejor o peor seguridad alimentaria, por lo que tenemos un ejemplo de sesgo de selección. En general, el diseño de este estudio no permitiría obtener conclusiones sobre el efecto causal de tener acceso a microfinanzas. La debilidad principal se encuentra en la presencia del sesgo de selección.\n[10 puntos] ¿De qué signo esperaría que fuera el sesgo de selección, en caso de existir? Explique sus razones.\nMuchas historias son posibles. Por ejemplo, suponiendo que las personas con mayor educación e información tendrían mejor acceso a productos financieros, pero también tendrían un mejor manejo de los recursos del hogar, entonces aquellas familias con acceso a microfinanzas hubieran podido tener una mejor seguridad alimentaria incluso sin haber tenido acceso a dichos productos financieros. En otras palabras, familias con mayor educación e información tendrían mejorar seguridad alimentaria sin importar su acceso a productos financieros, por lo que esperariamos un sesgo de selección positivo, por lo que tenderíamos a sobreestimar el impacto de las microfinanzas."
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-3",
    "href": "tareas/tarea-1-respuestas.html#pregunta-3",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "[10 puntos] Replique el ejercicio en MHE que ejemplifica el teorema de la regresión de la FEC. Para esto use el archivo de datos muestra-enoe-123.csv, que contiene una muestra del primer trimestre de 2023 de la ENOE e incluye personas que trabajan y reciben un ingreso. lingreso es el log del ingreso mensual y escolaridad son los años de educación. Primero, estime una regresión de lingreso en función de escolaridad usando los microdatos. Luego, obtenga la media de lingreso para cada nivel de escolaridad y estime una regresión de las medias en función de escolaridad, pesando por el número de observaciones usadas para construir cada media. Compare los coeficientes estimados.\nCorramos la regresión con los microdatos:\n\ndf &lt;- read_csv(\"../files/muestra-enoe-123.csv\") \n\nsummary(lm(lingreso ~ escolaridad,\n        data = df))\n\n\nCall:\nlm(formula = lingreso ~ escolaridad, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.6859 -0.3123  0.0462  0.4179  3.0679 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 8.216881   0.024243  338.94   &lt;2e-16 ***\nescolaridad 0.060347   0.002105   28.67   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6973 on 6554 degrees of freedom\nMultiple R-squared:  0.1115, Adjusted R-squared:  0.1113 \nF-statistic: 822.1 on 1 and 6554 DF,  p-value: &lt; 2.2e-16\n\n\nAhora calculemos la media del ingreso por cada año de educación, asegurándonos de conservar también el número de observaciones empleada para hacer dicho cálculo:\n\ndf.agregada &lt;- df %&gt;% \n  group_by(escolaridad) %&gt;% \n  summarise(lingreso = mean(lingreso, na.rm=T),\n            n = n())\n\nCorremos la regresión con los datos agregados, pensando por el número de observaciones en cada grupo:\n\nsummary(lm(lingreso ~ escolaridad,\n           data = df.agregada,\n           weights = n))\n\n\nCall:\nlm(formula = lingreso ~ escolaridad, data = df.agregada, weights = n)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-2.7905 -0.1961  0.3220  1.1960  3.8566 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 8.216881   0.056804  144.65  &lt; 2e-16 ***\nescolaridad 0.060347   0.004932   12.24 1.86e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.634 on 19 degrees of freedom\nMultiple R-squared:  0.8874, Adjusted R-squared:  0.8815 \nF-statistic: 149.7 on 1 and 19 DF,  p-value: 1.861e-10\n\n\nEl coeficiente estimado de los años de escolaridad es exactamente el mismo."
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-4",
    "href": "tareas/tarea-1-respuestas.html#pregunta-4",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Use los datos del archivo STAR_public_use.csv para este problema. En este problema replicará la fila correspondiente a la variable High scool GPA (calificación en la preparatoria) de la Tabla 1 en Angrist et al. (2009).1\n\n[5 puntos] Obtenga la media y la desviación estándar de la calificación en la preparatoria, gpa0, en el grupo de control (columna 1), restringiendo la muestra a aquellos individuos con noshow igual a 0.\nDespués de eliminar a lo sindividuos que tienen noshow igual a 1, obtenemos la media y desviación estándar reportadas en la tabla. Noten que deben restringir al grupo de control para obtener dichas cifras. La columna del tamaño de la muestra se obtiene sin restringir al grupo de control, aunque esto no se pedía en la pregunta.\n\ndata.angrist &lt;- read_csv(\"../files/STAR_public_use.csv\",\n                       locale = locale(encoding = \"latin1\"))   %&gt;% \n  clean_names() %&gt;% \n  filter(noshow==0)\n\n#Media y desviación estándar\ndata.angrist %&gt;% \n  filter(control==1) %&gt;% \n  summarize(media=mean(gpa0),\n            desvest=sd(gpa0))\n\n# A tibble: 1 × 2\n  media desvest\n  &lt;dbl&gt;   &lt;dbl&gt;\n1  78.7    4.22\n\n#N\ndata.angrist %&gt;% \n  summarize(n())\n\n# A tibble: 1 × 1\n  `n()`\n  &lt;int&gt;\n1  1571\n\n\n[10 puntos] Usando una regresión lineal, muestre que la calificación en la preparatoria no está correlacionada con la asignación a los tratamientos (ssp, sfp y sfsp). De nuevo, debe restringir la muestra quienes tienen noshow igual a 0. Reporte los coeficientes y los errores estándar (columnas 2 a 4).\nLa regresión es:\n\nsummary(balance &lt;- lm(gpa0 ~ ssp + sfp+ sfsp,\n            data = data.angrist))\n\n\nCall:\nlm(formula = gpa0 ~ ssp + sfp + sfsp, data = data.angrist)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.6567  -3.4567  -0.1567   3.3433   8.6612 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 78.65672    0.13718 573.377   &lt;2e-16 ***\nssp          0.16997    0.30779   0.552    0.581    \nsfp          0.23795    0.30372   0.783    0.433    \nsfsp        -0.01787    0.38433  -0.047    0.963    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.233 on 1567 degrees of freedom\nMultiple R-squared:  0.0005287,  Adjusted R-squared:  -0.001385 \nF-statistic: 0.2763 on 3 and 1567 DF,  p-value: 0.8425\n\n\nNoten que aquí los autores no utilizan errores robustos. Yo hubiera estimado errores robustos.\n[5 puntos] Realice una prueba de significancia conjunta de los coeficientes obtenidos en el punto b. Reporte el estadístico \\(F\\) y el valor \\(p\\) asociado (columna 5).\nEl estadístico \\(F\\) ya es calculado con la regresión. Basta con pedirlo:\n\nsummary(balance)$fstatistic\n\n       value        numdf        dendf \n   0.2762878    3.0000000 1567.0000000 \n\n\n¿Pero cómo puedo calcular el valor \\(p\\)? Basta usar la definición, es la probabilidad de observar un valor más extremo que el estadístico, bajo la distribución teórica. En este caso, la distribución teórica es una \\(F\\) y debemos especificar los grados de libertad en el numerador y en el denominador:\n\npf(q = summary(balance)$fstatistic[1],\n   df1 = summary(balance)$fstatistic[2],\n   df2 = summary(balance)$fstatistic[3],\n   lower.tail=FALSE)\n\n    value \n0.8425407 \n\n\n[10 puntos] ¿Cuál es el propósito de la prueba F realizada en el punto c.? ¿Qué hipótesis nula prueban los autores?\nAquí se busca probar que la asignación a los tres tipos de tratamiento no está correlacionada con la calificación en preparatoria, que es una medida del desempeño escolar justo al momento de iniciar el experimento. La \\(H_0\\) es que \\(\\beta_{SSP}=\\beta_{SFP}=\\beta_{SFSP}=0\\). Si rechazamos la hipótesis nula concluiríamos que hay diferencias entre grupos en la calificación de preparatoria. En este caso, el estadístico \\(F\\) es pequeño y su valor \\(p\\) indica que es muy probable de observarlo bajo la hipótesis nula por lo que no hay bases para rechazarla."
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-5",
    "href": "tareas/tarea-1-respuestas.html#pregunta-5",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Nuevamente, use los datos del archivo STAR_public_use.csv para este problema. En este problema, replicará dos columnas del efecto de tratamiento de la Tabla 5. Note que de nuevo se deben usar solo las observaciones que tienen noshow igual a 0. Además, note que se usan las siguientes variables de control: sex, mtongue, hsgroup, numcourses_nov1, lastmin, mom_edn, y dad_edn, todas ellas categóricas.\n\n[10 puntos] Estime el efecto de cada tipo de tratamiento sobre la calificación del trimestre de otoño, grade_20059_fall, para toda la muestra (Panel A, columna 1). Calcule correctamente los errores estándar. Interprete los resultados.\nHaciendo la sustitución sugerida por los autores, estimamos:\n\ndata.angrist &lt;- data.angrist %&gt;% \n      mutate(gpa_year1=ifelse(is.na(grade_20059_fall),NA,gpa_year1),\n             grade_20059_fall=ifelse(is.na(gpa_year1),NA,grade_20059_fall))\n\nreg1&lt;-lm(grade_20059_fall ~ ssp + sfp+ sfsp+\n           factor(sex)+\n           factor(mtongue)+\n           factor(hsgroup)+\n           factor(numcourses_nov1)+\n           factor(lastmin)+\n           factor(mom_edn)+\n           factor(dad_edn),\n         data=data.angrist)\n\nNoten que los coeficientes estimados son correctos, pero no los errores estándar:\n\nsummary(reg1)$coef[1:4,]\n\n              Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept) 66.3735025  6.3907155 10.3859267 2.840799e-24\nssp          0.3492964  0.9084654  0.3844906 7.006818e-01\nsfp          1.8241268  0.8963916  2.0349665 4.206972e-02\nsfsp         2.7020874  1.1768042  2.2961232 2.183745e-02\n\n\nLos errores estándar correctos son los robustos:\n\ncoeftest(reg1, vcov = vcovHC(reg1, \"HC1\"))[1:4,]\n\n              Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept) 66.3735025  3.8631593 17.1811456 1.981996e-59\nssp          0.3492964  0.9173865  0.3807516 7.034537e-01\nsfp          1.8241268  0.8465341  2.1548179 3.137099e-02\nsfsp         2.7020874  1.1244211  2.4030920 1.640541e-02\n\n\nFinalmente, lo que se reporta en la tabla como la media del grupo de control no es la constante en la regresión, sino la media y desviación estándar. Noten que se usa la muestra que efectivamente se usa en la regresión, es decir, sin valores faltantes.\n\ndata.angrist %&gt;%\n    filter(!is.na(gpa_year1) & !is.na(grade_20059_fall)\n     & !is.na(ssp)\n     & !is.na(sfp)\n     & !is.na(sfsp)\n     & !is.na(sex)\n     & !is.na(mtongue)\n     & !is.na(hsgroup)\n     & !is.na(numcourses_nov1)\n     & !is.na(lastmin)\n     & !is.na(mom_edn)\n     & !is.na(dad_edn)\n     & control==1) %&gt;%\n  summarize(media=mean(grade_20059_fall,\n                       na.rm=TRUE),\n            desvest=sd(grade_20059_fall,\n                       na.rm=TRUE))\n\n# A tibble: 1 × 2\n  media desvest\n  &lt;dbl&gt;   &lt;dbl&gt;\n1  64.2    11.9\n\ndata.angrist %&gt;%\n  filter(!is.na(gpa_year1) & !is.na(grade_20059_fall)\n     & !is.na(ssp)\n     & !is.na(sfp)\n     & !is.na(sfsp)\n     & !is.na(sex)\n     & !is.na(mtongue)\n     & !is.na(hsgroup)\n     & !is.na(numcourses_nov1)\n     & !is.na(lastmin)\n     & !is.na(mom_edn)\n     & !is.na(dad_edn)) %&gt;%\n  summarize(numero=n())\n\n# A tibble: 1 × 1\n  numero\n   &lt;int&gt;\n1   1255\n\n\n[10 puntos] Estime el efecto de recibir cada tipo de tratamiento, considerando los tratamientos SSP o SFP (de cualquier tipo) en los hombres de la muestra (Panel A, columna 5). Esto es, considere el tratamiento SSP como un primer tipo de tratamiento y, ya sea SFP o SFSP, como un segundo tipo de tratamiento. Calcule correctamente los errores estándar. Interprete sus resultados.\nDefinimos la variable de recibir el tratamiento SFP o SFSP. Luego estimamos:\n\ndata.angrist &lt;- data.angrist %&gt;%\n      mutate(sspany = ifelse(sfp == 1 | sfsp == 1, 1, \n    0))\n\nreg2&lt;-lm(grade_20059_fall ~ ssp + sspany+\n           factor(mtongue)+\n           factor(hsgroup)+\n           factor(numcourses_nov1)+\n           factor(lastmin)+\n           factor(mom_edn)+\n           factor(dad_edn),\n         data=filter(data.angrist,\n                     female==0))\n\nLos coeficientes con los errores correctos son:\n\ncoeftest(reg2, vcov = vcovHC(reg2, \"HC1\"))[1:3,]\n\n               Estimate Std. Error     t value     Pr(&gt;|t|)\n(Intercept) 63.82375619   5.837643 10.93313826 4.530618e-25\nssp         -0.01375880   1.331848 -0.01033060 9.917617e-01\nsspany       0.01615914   1.163865  0.01388403 9.889281e-01\n\n\nLa media en el control:\n\ndata.angrist %&gt;%\n  filter(!is.na(gpa_year1) & !is.na(grade_20059_fall)\n     & !is.na(ssp)\n     & !is.na(sfp)\n     & !is.na(sfsp)\n     & !is.na(sex)\n     & !is.na(mtongue)\n     & !is.na(hsgroup)\n     & !is.na(numcourses_nov1)\n     & !is.na(lastmin)\n     & !is.na(mom_edn)\n     & !is.na(dad_edn)\n     & control==1\n     & female==0) %&gt;%\n  summarize(media=mean(grade_20059_fall,\n                       na.rm=TRUE),\n            desvest=sd(grade_20059_fall,\n                       na.rm=TRUE))\n\n# A tibble: 1 × 2\n  media desvest\n  &lt;dbl&gt;   &lt;dbl&gt;\n1  65.9    11.3\n\ndata.angrist %&gt;%\n  filter(!is.na(gpa_year1) & !is.na(grade_20059_fall)\n     & !is.na(ssp)\n     & !is.na(sfp)\n     & !is.na(sfsp)\n     & !is.na(sex)\n     & !is.na(mtongue)\n     & !is.na(hsgroup)\n     & !is.na(numcourses_nov1)\n     & !is.na(lastmin)\n     & !is.na(mom_edn)\n     & !is.na(dad_edn)\n     & female==0) %&gt;%\n  summarize(numero=n())\n\n# A tibble: 1 × 1\n  numero\n   &lt;int&gt;\n1    526"
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#footnotes",
    "href": "tareas/tarea-1-respuestas.html#footnotes",
    "title": "Respuestas a la tarea 1",
    "section": "Notas",
    "text": "Notas\n\n\nAngrist, J., Lang, D., y Oreopoulos, P. (2009). Incentives and services for college achievement: Evidence from a randomized trial. American Economic Journal: Applied Economics, 1(1), 136-63.↩︎"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Example schedule:\n\n\n\n\n\n\n\n\n\nMorning\nAfternoon\n\n\n\n\nL\nIntro + Data manipulation\ngit / GitHub\n\n\nM\nGeneralised Linear Models\nData visualisation\n\n\nX\nMixed models / GAM / Bayes\nFunctional programming + Students work\n\n\nJ\nMultivariate analyses\nReproducible workflows\n\n\nV\nUsing R as GIS + Students work\nProject presentations"
  },
  {
    "objectID": "programa.html",
    "href": "programa.html",
    "title": "Programa",
    "section": "",
    "text": "Identificar las condiciones que permiten la implementación de una evaluación de impacto.\nConocer los fundamentos teóricos sobre los que se sustentan las metodologías de las evaluaciones de impacto.\nImplementar los métodos de evaluación empleando software, interpretar los resultados y reportar las conclusiones en forma de artículos científicos y/o reportes de política.\nConocer e implementar buenas prácticas en el uso de software, orientadas a la transparencia y la replicabilidad en la investigación.\nConocer los temas que conforman la literatura actual de evaluaciones de impacto."
  },
  {
    "objectID": "programa.html#objetivos",
    "href": "programa.html#objetivos",
    "title": "Programa",
    "section": "",
    "text": "Identificar las condiciones que permiten la implementación de una evaluación de impacto.\nConocer los fundamentos teóricos sobre los que se sustentan las metodologías de las evaluaciones de impacto.\nImplementar los métodos de evaluación empleando software, interpretar los resultados y reportar las conclusiones en forma de artículos científicos y/o reportes de política.\nConocer e implementar buenas prácticas en el uso de software, orientadas a la transparencia y la replicabilidad en la investigación.\nConocer los temas que conforman la literatura actual de evaluaciones de impacto."
  },
  {
    "objectID": "programa.html#referencias",
    "href": "programa.html#referencias",
    "title": "Programa",
    "section": "Referencias",
    "text": "Referencias\nEl curso se basa en los siguientes textos:\n\n(MHE) Angrist, J.D. y Pischke, J.S. (2013). Mostly Harmless Econometrics: An Empiricists Companion. Princeton University Press.\n\nAngrist, J.D. y Pischke, J.S. (2014). Mastering ’Metrics: The Path from Cause to Effect. Princeton University Press.\n\n(CT) Cameron, A.C. y P.K. Trivedi. (2005). Microeconometrics: Methods and applications. Oxford University Press.\n(MT) Cunningham, S. (2021). Causal inference: The mixtape. Yale University Press. Disponible en: https://mixtape.scunning.com/index.html.\nHuntington-Klein, N. (2021). The effect: An introduction to research design and causality. Chapman and Hall/CRC.\nDiNardo, J. y D.S. Lee. (2011). Program Evaluation and Research Designs. En Handbook of Labor Economics, 4A: 463-536.\n(GMPRV) Gertler, P.J., S. Martinez, P. Premand, L.B., Rawlings, y C.M.J. Vermeersch. (2011). La evaluación de impacto en la práctica. Banco Interamericano de Desarrollo y Banco Mundial, segunda edición. Disponible en: https://publications.iadb.org/publications/spanish/document/La-evaluaci%C3%B3n-de-impacto-en-la-pr%C3%A1ctica-Segunda-edici%C3%B3n.pdf."
  },
  {
    "objectID": "programa.html#contenido-temático",
    "href": "programa.html#contenido-temático",
    "title": "Programa",
    "section": "Contenido temático",
    "text": "Contenido temático\nUnidad 1. Introducción\n\nFundamentos de la evaluación de impacto\n\nInferencia causal\nRevisión de métodos de regresión\n\nReplicabilidad y transparencia en la evaluación\n\nRMardkown para la generación de reportes científicos\n\n\nUnidad 2. Métodos de evaluación\n\nEvaluación experimental\n\nAsignación aleatoria\nErrores estándar\nLATE y variables instrumentales\nCorrección por prueba de múltiples hipótesis\nAplicaciones de métodos experimentales\n\nDiferencia en diferencias\n\nSupuestos fundamentales\nEfectos fijos individuales\nDID desfasado\nANCOVA\nAplicaciones de DID\n\nMétodos de pareamiento\n\nSupuestos fundamentales\nPareamiento exacto\nPareamiento por puntaje de propensión (PSM)\nAplicaciones del PSM\n\nDiseños con discontinuidades\n\nSupuestos fundamentales\nDiscontinuidades nítidas y difusas\nDiscontinuidades geográficas\nPliegues en la regresión\nAplicaciones diseños con discontinuidades\n\nMétodo del control sintético\n\nSupuestos fundamentales\nInferencia basada en placebos\nAplicaciones de control sintético\n\n\nUnidad 3. Temas actuales de evaluación\n\nExtensiones I\n\nAprendizaje automatizado y big data en la evaluación de impacto"
  },
  {
    "objectID": "programa.html#evaluación-del-curso",
    "href": "programa.html#evaluación-del-curso",
    "title": "Programa",
    "section": "Evaluación del curso",
    "text": "Evaluación del curso\n\nExamen parcial: 20%\nExamen final: 30%\nProyecto final: 20%\nTareas (4): 20% (5% cada una)\nExposición: 10% (7% presentación y 3% folleto)"
  },
  {
    "objectID": "programa.html#tareas",
    "href": "programa.html#tareas",
    "title": "Programa",
    "section": "Tareas",
    "text": "Tareas\nCuatro tareas teórico-prácticas. Las tareas deben entregarse de manera individual, pero se recomienda ampliamente colaborar en grupos de estudio. Para evitar confusiones, escriban en su tarea con quiénes colaboraron. Las tareas deberán entregarse en Teams antes de la fecha y hora señalada. No se aceptarán tareas fuera de tiempo. Por favor, no comprima los archivos en carpetas comprimidas. Las tareas deberán contener dos archivos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los leguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "programa.html#software",
    "href": "programa.html#software",
    "title": "Programa",
    "section": "Software",
    "text": "Software\nR será el paquete standard usado en las sesiones prácticas. Más aún, el uso de cualquier software es aceptado siempre que se cumplan con los requisitos de replicabilidad y reportes de las tareas y exámenes. Habrá una sesión especial para introducir el uso de Quarto para la generación de reportes científicos."
  },
  {
    "objectID": "programa.html#exámenes",
    "href": "programa.html#exámenes",
    "title": "Programa",
    "section": "Exámenes",
    "text": "Exámenes\n\nExamen parcial: miércoles 11 de octubre en el horario de clase.\nExamen final: por definir."
  },
  {
    "objectID": "programa.html#exposiciones",
    "href": "programa.html#exposiciones",
    "title": "Programa",
    "section": "Exposiciones",
    "text": "Exposiciones\nCada alumno realizará una presentación de uno los artículos aplicados marcados con “+” en la lista de lecturas. Cada presentación deberá ser de máximo 15 minutos y debe incluir el contenido que el presentador considere relevante. La presentación deberá abordar, mínimamente: 1) el problema a investigar, 2) la metodología empleada, 3) la pertinencia de la metodología y la teoría vista en el curso, 4) los datos empleados, 5) los principales resultados, y 6) una crítica sobre la validez y las conclusiones del estudio. La presentación deberá acompañarse de un breve folleto que resuma los puntos anteriores, para ser distribuido con el resto de la clase."
  },
  {
    "objectID": "programa.html#proyecto-final",
    "href": "programa.html#proyecto-final",
    "title": "Programa",
    "section": "Proyecto final",
    "text": "Proyecto final\nEl proyecto final consistirá en un protocolo de investigación de una evaluación de impacto. El tema y la metodología es libre, pero se evaluará el potencial para realizarse en el corto plazo. Se aconseja seleccionar un tema para el que se empleen datos de libre acceso. El protocolo deberá incluir, mínimamente: 1) una revisión de literatura, 2) un bosquejo de las motivaciones teóricas del problema, 3) la metodología empírica a emplear, 4) la fuente de datos a usar, y 5) los resultados preliminares. El proyecto debe presentarse en formato escrito con una extensión máxima de 20 cuartillas. Se recomienda ampliamente dar seguimiento al proyecto en horas de oficina para recibir retroalimentación respecto a los avances y resolver posibles dudas y dificultades.\nEntrega: fecha por definir, a través de Teams."
  },
  {
    "objectID": "programa.html#lista-de-lecturas",
    "href": "programa.html#lista-de-lecturas",
    "title": "Programa",
    "section": "Lista de lecturas",
    "text": "Lista de lecturas\nLas lecturas obligatorias (marcadas con “*”) permiten una discusión informada en la clase. Las lecturas que serán presentadas en exposiciones también son obligatorias y están marcadas con “+”. El resto de las lecturas no serán cubiertas en clase, pero son ampliamente recomendables. En las sesiones de exposiciones se espera que el resto de la clase tenga el conocimiento suficiente sobre el material presentado para participar en la discusión. La lista de lecturas está disponible aquí."
  },
  {
    "objectID": "materiales.html",
    "href": "materiales.html",
    "title": "Materiales",
    "section": "",
    "text": "Datasets\nSlides"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Evaluación de Programas 2023",
    "section": "",
    "text": "Profesor: Irvin Rojas (irvin.rojas@cide.edu).\nHorario de clases: lunes y miércoles (8:00 a 9:30).\nPlataforma del curso: Microsoft Teams.\nHorario de oficina: por definir.\n\n¡Bienvenidas, bienvenidos!\nEste es un sitio para las y los estudiantes del curso de Evaluación de Programas de la Licenciatura y Maestría en Economía del CIDE. Sin embargo, otras personas pueden encontrar útiles los recursos de este sitio, como el programa del curso, las tareas y la lista de lecturas."
  },
  {
    "objectID": "lecturas.html",
    "href": "lecturas.html",
    "title": "Lecturas",
    "section": "",
    "text": "Las lecturas obligatorias (marcadas con “*”) permiten una discusión informada en la clase. Las lecturas que serán presentadas en exposiciones también son obligatorias y están marcadas con “+”. El resto de las lecturas no serán cubiertas en clase, pero son ampliamente recomendables. En las sesiones de exposiciones se espera que el resto de la clase tenga el conocimiento suficiente sobre el material presentado para participar en la discusión."
  },
  {
    "objectID": "lecturas.html#semana-1",
    "href": "lecturas.html#semana-1",
    "title": "Lecturas",
    "section": "Semana 1",
    "text": "Semana 1\n\nDiseño y econometría\n\n* Freedman, D. A. (1991). Statistical models and shoe leather. Sociological methodology, 291-313.\n* Athey, S., y Imbens, G. W. (2017). The state of applied econometrics: Causality and policy evaluation. Journal of Economic Perspectives, 31(2), 3-32.\nHeckman, J. J. (2001). Micro data, heterogeneity, and the evaluation of public policy: Nobel lecture. Journal of political Economy, 109(4), 673-748.\n\nHeckman, J. J., y Vytlacil, E. J. (2007). Econometric evaluation of social programs, part I: Causal models, structural models and econometric policy evaluation. Handbook of econometrics, 6, 4779-4874.\n\nInferencia causal\n\nGMPRV, Capítulo 3\n\n* MHE, Capítulo 2 (The Experimental Ideal)\nMT, Capítulo 4 (Potential Outcomes Model)"
  },
  {
    "objectID": "lecturas.html#semana-2",
    "href": "lecturas.html#semana-2",
    "title": "Lecturas",
    "section": "Semana 2",
    "text": "Semana 2\n\nEvaluación por métodos experimentales\n\n* CT, Capítulo 25, Secciones 1, 2\n\nGMPRV, Capítulo 4\n\nCT, Capítulo 25, Sección 3\n\nRevisión de métodos de regresión\n\n* MHE, Capítulo 3 (Making Regression Make Sense)\nMM, Capítulo 2 (Regression)\n\nTransparencia y replicabilidad\n\n* Christensen, G., & Miguel, E. (2018). Transparency, reproducibility, and the credibility of economics research. Journal of Economic Literature, 56(3), 920-80."
  },
  {
    "objectID": "lecturas.html#semana-3",
    "href": "lecturas.html#semana-3",
    "title": "Lecturas",
    "section": "Semana 3",
    "text": "Semana 3\n\nInferencia estadística\n\n* MM, Capítulo 1 (Randomized Trials), Apéndice (Mastering Inference)\nMT, Capítulo 2 (Probability and Regression Review)\n\nAplicaciones de evaluaciones experimentales\n\n+ Arceo-Gomez, E. O., & Campos-Vazquez, R. M. (2014). Race and marriage in the labor market: A discrimination correspondence study in a developing country. American Economic Review, 104(5), 376-80.\n\nBaird, S., McIntosh, C., & Özler, B. (2011). Cash or condition? Evidence from a cash transfer experiment. The Quarterly journal of economics, 126(4), 1709-1753.\n\n* Banerjee, A., Duflo, E., Goldberg, N., Karlan, D., Osei, R., Parienté, W., Shapiro, J., Thuysbaert, B. & Udry, C. (2015). A multifaceted program causes lasting progress for the very poor: Evidence from six countries. Science, 348(6236), 1260799.\nBlattman, C., Emeriau, M., & Fiala, N. (2018). Do anti-poverty programs sway voters? Experimental evidence from Uganda. Review of Economics and Statistics, 100(5), 891-905.\n+ Bruhn, M., Karlan, D., & Schoar, A. (2018). The impact of consulting services on small and medium enterprises: Evidence from a randomized trial in Mexico. Journal of Political Economy, 126(2), 635-687.\n+ De La O, A. L., Fernández-Vázquez, P. & García, F. M. (2023). Federal and state audits do not increase compliance with a grant program to improve municipal infrastructure: A pre-registered field experiment. Journal of Development Economics, 162, 103043.\nDuflo, E., Dupas, P., & Kremer, M. (2015). Education, HIV, and early fertility: Experimental evidence from Kenya. American Economic Review, 105(9), 2757-97.\n\nDupas, P. (2011). Do teenagers respond to HIV risk information? Evidence from a field experiment in Kenya. American Economic Journal: Applied Economics, 3(1), 1-34.\n\n+ Gertler, P. (2004). Do conditional cash transfers improve child health? Evidence from PROGRESA’s control randomized experiment. American economic review, 94(2), 336-341.\nLondoño-Vélez, J., & Querubin, P. (2022). The Impact of Emergency Cash Assistance in a Pandemic: Experimental Evidence from Colombia. The Review of Economics and Statistics, 1-27\nMartínez A, C., Puentes, E., & Ruiz-Tagle, J. (2018). The effects of micro-entrepreneurship programs on labor market performance: experimental evidence from Chile. American Economic Journal: Applied Economics, 10(2), 101-24.\nMousa, S. (2019). Creating Coexistence: Intergroup Contact and Soccer in Post-ISIS Iraq. Unpublished manuscript. Stanford University.\n\nPoertner, M. (2023). Does Political Representation Increase Participation? Evidence from Party Candidate Lotteries in Mexico. American Political Science Review, 117(2), 537-556.\n+ Seira, E., Elizondo, A., & Laguna-Müggenburg, E. (2017). Are information disclosures effective? evidence from the credit card market. American Economic Journal: Economic Policy, 9(1), 277-307.\n\n+ Tagliati, F. (2022). Welfare effects of an in-kind transfer program: Evidence from Mexico. Journal of Development Economics, 154, 102753."
  },
  {
    "objectID": "lecturas.html#semana-4",
    "href": "lecturas.html#semana-4",
    "title": "Lecturas",
    "section": "Semana 4",
    "text": "Semana 4\n\nErrores estándar no estándar\n\n* MHE, Capítulo 8 (Nonstandard Standard Errors Issues)\nCameron, A. C., y Miller, D. L. (2015). A practitioner’s guide to cluster-robust inference. Journal of Human Resources, 50(2), 317-372.\nStock, J. H. (2010). The other transformation in econometric practice: Robust tools for inference. Journal of Economic Perspectives, 24(2), 83-94."
  },
  {
    "objectID": "lecturas.html#semana-5",
    "href": "lecturas.html#semana-5",
    "title": "Lecturas",
    "section": "Semana 5",
    "text": "Semana 5\n\nLATE y variables instrumentales\n\nCT, Capítulo 25, Sección 7\n\nGMPRV, Capítulo 5\n\nMHE, Capítulo 4 (Instrumental Variables in Action)\n\n* MM, Capítulo 3 (Instrumental Variables)\nMT, Capítulo 7 (Instrumental Variables)\n\nAplicaciones LATE\n\nAngrist, J. D. (1990). Lifetime earnings and the Vietnam era draft lottery: evidence from social security administrative records. The American Economic Review, 313-336.\n\n* Angrist, J. D. (2006). Instrumental variables methods in experimental criminological research: what, why and how. Journal of Experimental Criminology, 2(1), 23-44.\n\nAngrist, J. D., Imbens, G., & Rubin, D. B. (1996). Identification of causal effects using instrumental variables. Journal of the American statistical Association, 91(434), 444-455.\n\n* Crépon, B., Devoto, F., Duflo, E., & Parienté, W. (2015). Estimating the impact of microcredit on those who take it up: Evidence from a randomized experiment in Morocco. American Economic Journal: Applied Economics, 7(1), 123-50.\n\nDevoto, F., Duflo, E., Dupas, P., Parienté, W., & Pons, V. (2012). Happiness on tap: Piped water adoption in urban Morocco. American Economic Journal: Economic Policy, 4(4), 68-99.\n+ De La O, A. L. (2013). Do conditional cash transfers affect electoral behavior? Evidence from a randomized experiment in Mexico. American Journal of Political Science, 57(1), 1-14.\n\n+ Gonzalez-Navarro, M., & Quintana-Domeque, C. (2016). Paving streets for the poor: Experimental analysis of infrastructure effects. Review of Economics and Statistics, 98(2), 254-267.\nHeckman, J. J., & Vytlacil, E. J. (2007). Econometric evaluation of social programs, part II: Using the marginal treatment effect to organize alternative econometric estimators to evaluate social programs, and to forecast their effects in new environments. Handbook of econometrics, 6, 4875-5143.\n\nImbens, G. W., & Angrist, J. D. (1994). Identification and estimation of local average treatment effects. Econometrica (1986-1998), 62(2), 467.\nKling, J. R., Liebman, J. B., & Katz, L. F. (2007). Experimental analysis of neighborhood effects. Econometrica, 75(1), 83-119."
  },
  {
    "objectID": "lecturas.html#semana-6",
    "href": "lecturas.html#semana-6",
    "title": "Lecturas",
    "section": "Semana 6",
    "text": "Semana 6\n\nDiferencia en diferencias\n\nCT, Capítulo 25, Sección 25.5\nGMPRV, Capítulo 7\n\n* MM, Capítulo 5 (Differences-in-differences)\nMT, Capítulo 9 (Difference in differences), secciones 1 a 5\n\nDID desfasado\n\n* MT, Capítulo 9 (Difference in differences), sección\nBaker, A. C., Larcker, D. F., & Wang, C. C. (2022). How much should we trust staggered difference-in-differences estimates?. Journal of Financial Economics, 144(2), 370-395.\nCallaway, B., & Sant’Anna, P. H. (2021). Difference-in-differences with multiple time periods. Journal of Econometrics, 225(2), 200-230.\nGoodman-Bacon, A. (2021). Difference-in-differences with variation in treatment timing. Journal of Econometrics, 225(2), 254-277.\nMarcus, M., & Sant’Anna, P. H. (2021). The role of parallel trends in event study settings: An application to environmental economics. Journal of the Association of Environmental and Resource Economists, 8(2), 235-275.\n* Roth, J., Sant’Anna, P. H., Bilinski, A., & Poe, J. (2023). What’s Trending in Difference-in-Differences? A Synthesis of the Recent Econometrics Literature. Journal of Econometrics, 235(2), 2218-2244."
  },
  {
    "objectID": "lecturas.html#semana-7",
    "href": "lecturas.html#semana-7",
    "title": "Lecturas",
    "section": "Semana 7",
    "text": "Semana 7\n\nCorrección por prueba de múltiples hipótesis\n\n* Angelucci, M., Karlan, D., & Zinman, J. (2015). Microcredit impacts: Evidence from a randomized microcredit program placement experiment by Compartamos Banco. American Economic Journal: Applied Economics, 7(1), 151-82.\n* Benjamini, Y., & Hochberg, Y. (1995). Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the royal statistical society. Series B (Methodological), 289-300.\n\nBrodeur, A., Lé, M., Sangnier, M., & Zylberberg, Y. (2016). Star Wars: The empirics strike back. American Economic Journal: Applied Economics, 8(1), 1-32.\n\nSavin, N. E. (1984). Multiple hypothesis testing. Handbook of econometrics, 2, 827-879.\n\n* Shaffer, J. P. (1995). Multiple hypothesis testing. Annual review of psychology, 46(1), 561-584.\n\nANCOVA\n\n* McKenzie, D. (2012). Beyond baseline and follow-up: The case for more T in experiments. Journal of development Economics, 99(2), 210-221.\nRojas Valdes, R.I., Wydick, B., & Lybbert, T.J. (2021). Can Hope Elevate Microfinance? Evidence from Oaxaca, Mexico. Oxford Economic Papers.\n\nAplicaciones de DID\n\n* Bertrand, M., Duflo, E., & Mullainathan, S. (2004). How much should we trust differences-in-differences estimates? The Quarterly journal of economics, 119(1), 249-275.\n+ Boruchowicz, C., Parker, S. W., & Robbins, L. (2022). Time use of youth during a pandemic: Evidence from Mexico. World Development, 149, 105687.\n+ Cabrera-Hernández, F., Padilla-Romo, M., & Peluffo, C. (2023). Full-time schools and educational trajectories: Evidence from high-stakes exams. Economics of Education Review, 96, 102443.\nCampos, R. M., Esquivel, G., & Santillán, A. S. (2017). El impacto del salario mínimo en los ingresos y el empleo en México. Revista CEPAL.\n* Card, D. (1990). The impact of the Mariel boatlift on the Miami labor market. ILR Review, 43(2), 245-257.\n+ Djourelova, M. (2023). Persuasion through Slanted Language: Evidence from the Media Coverage of Immigration. American Economic Review, 113(3), 800-835.\n+ Conti, G., & Ginja, R. (2023). Who Benefits from Free Health Insurance?: Evidence from Mexico. Journal of Human Resources, 58(1), 146-182.\n* Card, D., & Krueger, A. B. (2000). Minimum wages and employment: a case study of the fast-food industry in New Jersey and Pennsylvania: reply. American Economic Review, 0(5), 1397-1420.\nChen, H., Qian, W., & Wen, Q. (2021). The impact of the COVID-19 pandemic on consumption: Learning from high-frequency transaction data. AEA Papers and Proceedings, 111, 307-11.\n+ Clarke, D., & Mühlrad, H. (2021). Abortion laws and women’s health. Journal of Health Economics, 76, 102413.\n+ Gutiérrez Vázquez, E. Y., & Parrado, E. A. (2016). Abortion legalization and childbearing in Mexico. Studies in family planning, 47(2), 113-128.\n\nQian, N. (2008). Missing women and the price of tea in China: The effect of sex-specific earnings on sex imbalance. The Quarterly Journal of Economics, 123(3), 1251-1285.\nWolfers, J. (2006). Did unilateral divorce laws raise divorce rates? A reconciliation and new results. American Economic Review, 96(5), 1802-1820.\nZhang, R., Li, Y., Zhang, A. L., Wang, Y., & Molina, M. J. (2020). Identifying airborne transmission as the dominant route for the spread of COVID-19. Proceedings of the National Academy of Sciences."
  },
  {
    "objectID": "lecturas.html#semana-8",
    "href": "lecturas.html#semana-8",
    "title": "Lecturas",
    "section": "Semana 8",
    "text": "Semana 8\nSemana de examen parcial."
  },
  {
    "objectID": "lecturas.html#semana-9",
    "href": "lecturas.html#semana-9",
    "title": "Lecturas",
    "section": "Semana 9",
    "text": "Semana 9\n\nMétodos de pareamiento\n\nGMPRV, Capítulo 8\n* MH, Capítulo 3, Sección 3.3\n* MT, Capítulo 5\n\nAplicaciones del PSM\n\nAbadie, A., & Imbens, G. W. (2016). Matching on the estimated propensity score. Econometrica, 84(2), 781-807.\n\nAngrist, J., Estimating the Labor Market Impact of Voluntary Military Service Using Social Security Data on Military Applicants, Econometrica 66(2), 1998, 249-288.\n+ Becerril, J., & Abdulai, A. (2010). The impact of improved maize varieties on poverty in Mexico: a propensity score-matching approach. World development, 38(7), 1024-1035.\n* Caliendo, M., & Kopeinig, S. (2008). Some practical guidance for the implementation of propensity score matching. Journal of economic surveys, 22(1), 31-72.\n\n+ Chang, A., Miranda-Moreno, L., Cao, J., & Welle, B. (2017). The effect of BRT implementation and streetscape redesign on physical activity: A case study of Mexico City. Transportation Research Part A: Policy and Practice, 100, 337-347.\n\n* Dehejia, R. H., & Wahba, S. (1999). Causal effects in nonexperimental studies: Reevaluating the evaluation of training programs. Journal of the American statistical Association, 94(448), 1053-1062.\n+ Diaz, J. J., & Handa, S. (2006). An assessment of propensity score matching as a nonexperimental impact estimator evidence from Mexico’s PROGRESA program. Journal of human resources, 41(2), 319-345.\n+ Espinosa, V., & Rubin, D. B. (2015). Did the military interventions in the Mexican drug war increase violence?. The American Statistician, 69(1), 17-27.\n+ García-Díaz, R., Sosa-Rubí, S. G., Serván-Mori, E., & Nigenda, G. (2018). Welfare effects of health insurance in Mexico: The case of Seguro Popular de Salud. PloS one, 13(7), e0199876.\n\n* LaLonde, R. J. (1986). Evaluating the econometric evaluations of training programs with experimental data. The American economic review, 604-620.\nWellalage, N. H., & Locke, S. (2020). Remittance and financial inclusion in refugee migrants: inverse probability of treatment weighting using the propensity score. Applied Economics, 52(9), 929-950."
  },
  {
    "objectID": "lecturas.html#semana-10",
    "href": "lecturas.html#semana-10",
    "title": "Lecturas",
    "section": "Semana 10",
    "text": "Semana 10\n\nDiseños con discontinuidades\n\nGMPRV, Capítulo 6\n\nDiscontinuidades nítidas y difusas\n\nMHE, Capítulo 6\n\n* MM, Capítulo 4\n* MT, Capítulo 6"
  },
  {
    "objectID": "lecturas.html#semana-11",
    "href": "lecturas.html#semana-11",
    "title": "Lecturas",
    "section": "Semana 11",
    "text": "Semana 11\n\nAplicaciones de diseños con discontinuidades\n\nAbdulkadiroğlu, A., Angrist, J., & Pathak, P. (2014). The elite illusion: Achievement effects at Boston and New York exam schools. Econometrica, 82(1), 137-196.\n+ Aguilar, A., Gutierrez, E., & Seira, E. (2021). The effectiveness of sin food taxes: Evidence from Mexico. Journal of Health Economics, 77, 102455.\n+ Alix-Garcia, J., McIntosh, C., Sims, K. R., & Welch, J. R. (2013). The ecological footprint of poverty alleviation: evidence from Mexico’s Oportunidades program. Review of Economics and Statistics, 95(2), 417-435.\nAnagol, S., & Fujiwara, T. (2016). The runner-up effect. Journal of Political Economy, 124(4), 927-991.\nAngrist, J. D., & Lavy, V. (1999). Using Maimonides’ rule to estimate the effect of class size on scholastic achievement. The Quarterly Journal of Economics, 114(2), 533-575.\nBagues, M., & Campa, P. (2021). Can gender quotas in candidate lists empower women? Evidence from a regression discontinuity design. Journal of Public Economics, 194, 104315.\nBosch, M., & Schady, N. (2019). The effect of welfare payments on work: Regression discontinuity evidence from Ecuador. Journal of Development Economics, 139, 17-27.\n\nCalonico, S., Cattaneo, M. D., Farrell, M. H., & Titiunik, R. (2019). Regression discontinuity designs using covariates. Review of Economics and Statistics, 101(3), 442-451.\n\n+ Cañedo, A. P., Fabregas, R., & Gupta, P. (2023). Emergency cash transfers for informal workers: Impact evidence from Mexico. Journal of Public Economics, 219, 104820.\n\nCard, D., Dobkin, C., & Maestas, N. (2009). Does Medicare save lives? The quarterly journal of economics, 124(2), 597-636.\n\nCarpenter, C., & Dobkin, C. (2009). The effect of alcohol consumption on mortality: regression discontinuity evidence from the minimum drinking age. American Economic Journal: Applied Economics, 1(1), 164-82.\n\nCook, T. D., & Wong, V. C. (2008). Empirical tests of the validity of the regression discontinuity design. Annales d’Economie et de Statistique, 127-150.\n\n+ Davis, L. W. (2008). The effect of driving restrictions on air quality in Mexico City. Journal of Political Economy, 116(1), 38-81.\n\n+ Davis, L. W. (2017). Saturday driving restrictions fail to improve air quality in Mexico City. Scientific Reports, 7, 41652.\n+ Del Valle, A., de Janvry, A., & Sadoulet, E. (2020). Rules for recovery: Impact of indexed disaster funds on shock coping in Mexico. American Economic Journal: Applied Economics, 12(4), 164-95.\n+ Dell, M. (2015). Trafficking networks and the Mexican drug war. American Economic Review, 105(6), 1738-79.\n+ Goodwin, M. B., Gonzalez, F., & Fontenla, M. (2023). The impact of daylight saving time in Mexico. Applied Economics, 1-11.\n* Lee, D. S., & Lemieux, T. (2010). Regression discontinuity designs in economics. Journal of economic literature, 48(2), 281-355.\nMacPherson, C., & Sterck, O. (2021). Empowering refugees through cash and agriculture: A regression discontinuity design. Journal of Development Economics, 149, 102614.\nMakarin, A., Pique, R., & Aragón, F. (2020). National or sub-national parties: Does party geographic scope matter? Journal of Development Economics, 102516.\n\n* Manacorda, M., Miguel, E., & Vigorito, A. (2011). Government transfers and political support. American Economic Journal: Applied Economics, 3(3), 1-28.\n\nMoussa, W., Salti, N., Irani, A., Al Mokdad, R., Jamaluddine, Z., Chaaban, J., & Ghattas, H. (2022). The impact of cash transfers on Syrian refugee children in Lebanon. World Development, 150, 105711.\nSohn, H., & Lee, S. W. (2019). Causal Impact of Having a College Degree on Women’s Fertility: Evidence From Regression Kink Designs. Demography, 56(3), 969-990.\nTakaku, R., & Yokoyama, I. (2021). What the COVID-19 school closure left in its wake: evidence from a regression discontinuity analysis in Japan. Journal of Public Economics, 195, 104364.\nTuttle, C. (2019). Snapping Back: Food Stamp Bans and Criminal Recidivism. American Economic Journal: Economic Policy, 11(2), 301-27.\n\nAplicaciones de discontinuidades geográficas\n\nGonzalez, R. M. (2021). Cell Phone Access and Election Fraud: Evidence from a Spatial Regression Discontinuity Design in Afghanistan. American Economic Journal: Applied Economics, 13(2), 1-51.\n* Keele, L. J., & Titiunik, R. (2015). Geographic boundaries as regression discontinuities. Political Analysis, 23(1), 127-155.\nKeele, L., & Titiunik, R. (2016). Natural experiments based on geography. Political Science Research and Methods, 4(1), 65-95.\n\nPliegues en la regresión\n\nGamba, S., Jakobsson, N., & Svensson, M. (2022). The impact of cost-sharing on prescription drug demand: evidence from a double-difference regression kink design. The European Journal of Health Economics, 1-9.\nCard, D., Lee, D. S., Pei, Z., & Weber, A. (2017). Regression kink design: Theory and practice. NBER Working Paper 22781.\n\nLurie, I. Z., Sacks, D. W., & Heim, B. (2021). Does the individual mandate affect insurance coverage? Evidence from tax returns. American Economic Journal: Economic Policy, 13(2), 378-407."
  },
  {
    "objectID": "lecturas.html#semana-12",
    "href": "lecturas.html#semana-12",
    "title": "Lecturas",
    "section": "Semana 12",
    "text": "Semana 12\n\nControl sintético\n\n* MT, Capítulo 10\n* Abadie, A. (2019). Using synthetic controls: Feasibility, data requirements, and methodological aspects. Journal of Economic Literature.\n* Abadie, A., Diamond, A., & Hainmueller, J. (2010). Synthetic control methods for comparative case studies: Estimating the effect of California’s tobacco control program. Journal of the American statistical Association, 105(490), 493-505.\n+ Abadie, A., Diamond, A., & Hainmueller, J. (2015). Comparative politics and the synthetic control method. American Journal of Political Science, 59(2), 495-510."
  },
  {
    "objectID": "lecturas.html#semana-13",
    "href": "lecturas.html#semana-13",
    "title": "Lecturas",
    "section": "Semana 13",
    "text": "Semana 13\n\nAplicaciones de control sintético\n\nAbsher, S., Grier, K., & Grier, R. (2020). The economic consequences of durable left-populist regimes in Latin America. Journal of Economic Behavior & Organization, 177, 787-817.\n\n* Acemoglu, D., Johnson, S., Kermani, A., Kwak, J., & Mitton, T. (2016). The value of connections in turbulent times: Evidence from the United States. Journal of Financial Economics, 121(2), 368-391.\nAlfano, V., Ercolano, S., & Cicatiello, L. (2021). School openings and the COVID-19 outbreak in Italy. A provincial-level analysis using the synthetic control method. Health Policy.\nArkhangelsky, D., Athey, S., Hirshberg, D. A., Imbens, G. W., & Wager, S. (2021). Synthetic difference-in-differences. American Economic Review, 111(12), 4088-4118.\n+ Boly, M., & Sanou, A. (2022). Biofuels and food security: Evidence from Indonesia and Mexico. Energy Policy, 163, 112834.\nBotosaru, I., & Ferman, B. (2019). On the role of covariates in the synthetic control method. The Econometrics Journal, 22(2), 117-130.\n\nCalderón, G., Robles, G., Díaz-Cayeros, A., & Magaloni, B. (2015). The beheading of criminal organizations and the dynamics of violence in Mexico. Journal of Conflict Resolution, 59(8), 1455-1485.\n\n+ Campos-Vazquez, R. M., & Esquivel, G. (2020). The effect of doubling the minimum wage and decreasing taxes on inflation in Mexico. Economics Letters, 109051.\n\n+ Campos-Vazquez, R. M., & Esquivel, G. (2023). The Effect of the Minimum Wage on Poverty: Evidence from a Quasi-Experiment in Mexico. The Journal of Development Studies, 59(3), 360-380.\n+ Cepeda-Francese, C. A., & Ramírez-Álvarez, A. A. (2023). Reforming justice under a security crisis: The case of the criminal justice reform in Mexico. World Development, 163, 106148.\nGeloso, V., & Pavlik, J. B. (2021). The Cuban revolution and infant mortality: A synthetic control approach. Explorations in Economic History, 80, 101376.\nGrier, K., & Maynard, N. (2016). The economic consequences of Hugo Chavez: A synthetic control analysis. Journal of Economic Behavior & Organization, 125, 1-21.\nMitze, T., Kosfeld, R., Rode, J., & Wälde, K. (2020). Face masks considerably reduce COVID-19 cases in Germany. Proceedings of the National Academy of Sciences, 117(51), 32293-32301.\nPeri, G., & Yasenov, V. (2019). The Labor Market Effects of a Refugee Wave Synthetic Control Method Meets the Mariel Boatlift. Journal of Human Resources, 54(2), 267-309."
  },
  {
    "objectID": "lecturas.html#semana-14",
    "href": "lecturas.html#semana-14",
    "title": "Lecturas",
    "section": "Semana 14",
    "text": "Semana 14\n\nAprendizaje automático y big data\n\nAthey, S. (2017). Beyond prediction: Using big data for policy problems. Science, 355(6324), 483-485.\n\n* Athey, S., & Imbens, G. W. (2019). Machine learning methods that economists should know about. Annual Review of Economics, 11.\n+ Baiardi, A., & Naghi, A. A. (2021). The value added of machine learning to causal inference: Evidence from revisited studies. arXiv preprint arXiv:2101.00878.\nChetty, R. (2021). Improving equality of opportunity: New insights from big data. Contemporary Economic Policy, 39(1), 7-41.\nChernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W., & Robins, J. (2018). Double/debiased machine learning for treatment and structural parameters. Econometrics Journal, 21(1), pp. C1–C68.\n+ Chernozhukov, V., Demirer, M., Duflo, E., & Fernandez-Val, I. (2018). Generic machine learning inference on heterogeneous treatment effects in randomized experiments, with an application to immunization in India. Woring Paper No. w24678. National Bureau of Economic Research.\nCole, M. A., Elliott, R. J., & Liu, B. (2020). The impact of the Wuhan Covid-19 lockdown on air pollution and health: a machine learning and augmented synthetic control approach. Environmental and Resource Economics, 76(4), 553-580.\nNaimi, A. I., Mishler, A. E., & Kennedy, E. H. (2017). Challenges in obtaining valid causal effect estimates with machine learning algorithms. ArXiv preprint 1711.07137.\nStorm, H., Baylis, K., & Heckelei, T. (2020). Machine learning in agricultural and applied economics. European Review of Agricultural Economics, 47(3), 849-892.\nTorrats-Espinosa, G. (2021). Using machine learning to estimate the effect of racial segregation on COVID-19 mortality in the United States. Proceedings of the National Academy of Sciences, 118(7).\n+ Wager, S., & Athey, S. (2018). Estimation and inference of heterogeneous treatment effects using random forests. Journal of the American Statistical Association, 113(523), 1228-1242.\n* Varian, H. R. (2014). Big data: New tricks for econometrics. Journal of Economic Perspectives, 28(2), 3-28"
  },
  {
    "objectID": "lecturas.html#otras-lecturas-sobre-temas-no-cubiertos-en-el-curso",
    "href": "lecturas.html#otras-lecturas-sobre-temas-no-cubiertos-en-el-curso",
    "title": "Lecturas",
    "section": "Otras lecturas sobre temas no cubiertos en el curso",
    "text": "Otras lecturas sobre temas no cubiertos en el curso\n\nMás allá de los experimentos\n\nBarrett, C. B., & Carter, M. R. (2010). The power and pitfalls of experiments in development economics: Some non-random reflections. Applied economic perspectives and policy, 32(4), 515-548.\n\nBarrett, C. B., & Carter, M. R. (2020). Finding our balance? Revisiting the randomization revolution in development economics ten years further on. World Development, 127, 104789.\n\nHjort, J., Moreira, D., Rao, G., & Santini, J. F. (2021). How research affects policy: Experimental evidence from 2,150 Brazilian municipalities. American Economic Review, 111(5), 1442-80.\nDeaton, A., Case. (2019). Randomization in the tropics revisited: a theme and eleven variations. In Randomized controlled trials in the field of development: A critical perspective. Oxford University Press. Forthcoming.\n\nRavallion, Martin. (2020). Should the randomistas (continue to) rule? National Bureau of Economic Research, Working Paper 27554.\n\nModelos estructurales en evaluación\n\nAbbring, J. H., & Heckman, J. J. (2007). Econometric evaluation of social programs, part III: Distributional treatment effects, dynamic treatment effects, dynamic discrete choice, and general equilibrium policy evaluation. Handbook of econometrics, 6, 5145-5303.\n\nAttanasio, O. P., Meghir, C., & Santiago, A. (2011). Education choices in Mexico: using a structural model and a randomized experiment to evaluate Progresa. The Review of Economic Studies, 79(1), 37-66.\n\nDuflo, E., Hanna, R., & Ryan, S. P. (2012). Incentives work: Getting teachers to come to school. American Economic Review, 102(4), 1241-78.}\nHamilton, B. H., Hincapié, A., Miller, R. A., & Papageorge, N. W. (2018). Innovation and Diffusion of Medical Treatment. National Bureau of Economic Working Paper 24577.\n\nKeane, M. P. (2010). A structural perspective on the experimentalist school. Journal of Economic Perspectives, 24(2), 47-58.\nKeane, M. P., Todd, P. E., & Wolpin, K. I. (2011). The structural estimation of behavioral models: Discrete choice dynamic programming methods and applications. In Handbook of labor economics (Vol. 4, pp. 331-461). Elsevier.\n\nLow, H., & Meghir, C. (2017). The use of structural models in econometrics. Journal of Economic Perspectives, 31(2), 33-58.\nMa, X., Lawell, C. Y. L., & Rozelle, S. (2020). Peer effects and the use of subsidized goods: A structural econometric model of a health promotion program in rural China. Working paper, Cornell University.\n\nNevo, A., & Whinston, M. D. (2010). Taking the dogma out of econometrics: Structural modeling and credible inference. Journal of Economic Perspectives, 24(2), 69-82.\n\nTodd, P. E., & Wolpin, K. I. (2010). Structural estimation and policy evaluation in developing countries. Annu. Rev. Econ., 2(1), 21-50.\nWolpin, K. I. (2013). The limits of inference without theory. MIT Press.\n\nEvaluaciones de impacto a nivel de economía local (LEWIE)\n\nTaylor, J. E., Dyer, G. A., Stewart, M., Yunez-Naude, A., & Ardila, S. (2003). The economics of ecotourism: A Galápagos Islands economy-wide perspective. Economic Development and Cultural Change, 51(4), 977-997.\nTaylor, J. E., & Filipski, M. J. (2014). Beyond experiments in development economics: Local economy-wide impact evaluation. Oxford University Press.\nTaylor, J. E., Filipski, M. J., Alloush, M., Gupta, A., Rojas Valdes, R.I., & Gonzalez-Estrada, E. (2016). Economic impact of refugees. Proceedings of the National Academy of Sciences, 201604566.\n\nCombinación de metodologías no experimentales\n\nCattaneo, M. D., Frandsen, B. R., & Titiunik, R. (2015). Randomization inference in the regression discontinuity design: An application to party advantages in the US Senate. Journal of Causal Inference, 3(1), 1-24.\n\nDonohue III, J. J., & Ho, D. E. (2007). The Impact of Damage Caps on Malpractice Claims: Randomization Inference with Difference‐in‐Differences. Journal of Empirical Legal Studies, 4(1), 69-102.\n\nKeele, L., Titiunik, R., & Zubizarreta, J. R. (2015). Enhancing a geographic regression discontinuity design through matching to estimate the effect of ballot initiatives on voter turnout. Journal of the Royal Statistical Society. Series A (Statistics in Society), 223-239.\n\nLevasseur, P. (2019). Can social programs break the vicious cycle between poverty and obesity? Evidence from urban Mexico. World Development, 113, 143-156.\n\nMacKinnon, J. G., & Webb, M. D. (2020). Randomization inference for difference-in-differences with few treated clusters. Journal of Econometrics.\n\nParker, S. W., Saenz, J., & Wong, R. (2018). Health insurance and the aging: Evidence from the Seguro Popular program in Mexico. Demography, 55(1), 361-386.\nSant’Anna, P. H., & Zhao, J. (2020). Doubly robust difference-in-differences estimators. Journal of Econometrics, 219(1), 101-122.\n\nImpactos de largo plazo\n\nAthey, S., Chetty, R., Imbens, G. W., & Kang, H. (2019). The surrogate index: Combining short-term proxies to estimate long-term treatment effects more rapidly and precisely, National Bureau of Economic Research, Working Paper 26463.\nHamory, J., Miguel, E., Walker, M., Kremer, M., & Baird, S. (2021). Twenty-year economic impacts of deworming. Proceedings of the National Academy of Sciences, 118(14).\nDupas, P., Duflo, E. & Kremer, M. (2021). The Impact of Free Secondary Education: Experimental Evidence from Ghana. Stanford University Working Paper.\n\nParker, S. W., & Vogl, T. (2018). Do conditional cash transfers improve economic outcomes in the next generation? Evidence from Mexico (No. w24303). National Bureau of Economic Research.\n\nEtica\n\nHumphreys, M. (2015). Reflections on the ethics of social experimentation. Journal of Globalization and Development, 6(1), 87-112.\nLewis, J. (2020). Experimental Design: Ethics, Integrity, and the Scientific Method. Handbook of Research Ethics and Scientific Integrity, 459-474.\nRayzberg, M. S. (2019). Fairness in the field: The ethics of resource allocation in randomized controlled field experiments. Science, Technology, & Human Values, 44(3), 371-398.\n\nCredibilidad e inferencia estadística\n\nAmrhein, V., Greenland, S., & McShane, B. (2019). Scientists rise up against statistical significance. Nature. 567, 305-307.\n\nAngrist, J. D., & Pischke, J. S. (2010). The credibility revolution in empirical economics: How better research design is taking the con out of econometrics. Journal of economic perspectives, 24(2), 3-30.\n\nGreenland, S., Senn, S. J., Rothman, K. J., Carlin, J. B., Poole, C., Goodman, S. N., & Altman, D. G. (2016). Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations. European journal of epidemiology, 31(4), 337-350.\nLeamer, E. E. (1983). Let’s take the con out of econometrics. The American Economic Review, 73(1), 31-43.\nLeamer, E. E. (2010). Tantalus on the Road to Asymptopia. Journal of Economic Perspectives, 24(2), 31-46.\nNuzzo, R. (2014). Scientific method: statistical errors. Nature News, 506(7487), 150.\nSims, C. A. (2010). But economics is not an experimental science. Journal of Economic Perspectives, 24(2), 59-68.\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129-133.\n\nInferencia por aleatorización\n\nAbadie, A., Athey, S., Imbens, G. W., & Wooldridge, J. M. (2020). Sampling‐Based versus Design‐Based Uncertainty in Regression Analysis. Econometrica, 88(1), 265-296.\n\nAthey, S., & Imbens, G. W. (2017). The econometrics of randomized experiments. In Handbook of economic field experiments (Vol. 1, pp. 73-140). North-Holland.\n\nHo, D. E., & Imai, K. (2006). Randomization inference with natural experiments: An analysis of ballot effects in the 2003 California recall election. Journal of the American Statistical Association, 101(475), 888-900.\n\nKerwin, J. T., & Thornton, R. L. (2020). Making the grade: The sensitivity of education program effectiveness to input choices and outcome measures. Review of Economics and Statistics, 1-45."
  },
  {
    "objectID": "presentaciones.html",
    "href": "presentaciones.html",
    "title": "Presentaciones",
    "section": "",
    "text": "Por favor, seleccione una de las lecturas marcadas con una “+” de la lista de lecturas y envíe un correo al profesor para que se le asigne una fecha de presentación.\n\n\n\n\n\n\n\n\n\nAutores\nTema\nPresentador o presentadora\nFecha de exposición\n\n\n\n\nArceo-Gomez & Campos-Vazquez (2014)\nExperimental\nRigoberto Mendoza\n6 de septiembre\n\n\nBruhn et al. (2018)\nExperimental\nBrian Roque\n6 de septiembre\n\n\nGertler (2004)\nExperimental\nMariana Ruiz\n6 de septiembre\n\n\nGonzalez-Navarro et al. (2016)\nLATE\nMiguel Rosales\n20 de septiembre\n\n\nDe la O (2013)\nLATE\nJuan Carlos Muñoz\n20 de septiembre\n\n\nBoruchowicz et al. (2022)\nDID\nRodrigo Gutiérrez\n4 de octubre\n\n\nConti et al. (2023)\nDID\nJosé Valencia\n4 de octubre\n\n\nClarke & Mühlrad (2021)\nDID\nPaola Guarneros\n4 de octubre\n\n\nEspinosa & Rubin (2015)\nPSM\nSamuel Martínez\n18 de octubre\n\n\nBecerril et al. (2010)\nPSM\nStephanie Neri\n18 de octubre\n\n\nGarcía-Díaz et al. (2018)\nPSM\nFrancisco Vinicio\n18 de octubre\n\n\nAguilar et al. (2021)\nDiscontinuidades\nYorlyn Funez\n1 de noviembre\n\n\nDel Valle et al. (2020)\nDiscontinuidades\nWolfgang Reséndiz\n1 de noviembre\n\n\nDavis (2008)\nDiscontinuidades\nAlan Loera\n1 de noviembre\n\n\nCampos-Vázquez & Esquivel (2023)\nControl sintético\nClaudia Alemán\n13 de noviembre\n\n\nAbadie et al. (2015)\nControl sintético\nMarcos Pérez\n13 de noviembre\n\n\nCampos-Vázquez & Esquivel (2020)\nControl sintético\nVíctor Garcías\n13 de noviembre\n\n\nChernozhukov et al. (2018)\nMachine Learning\nJair García\n27 de noviembre\n\n\nBaiardi et al. (2021)\nMachine Learning\nRaúl Cepeda\n27 de noviembre\n\n\nWager & Athey (2018)\nMachine Learning\nAndro Asatashvili\n27 de noviembre"
  },
  {
    "objectID": "reglas.html",
    "href": "reglas.html",
    "title": "Reglas",
    "section": "",
    "text": "No se tolerarán actos de discriminación. Se procura un ambiente de respeto entre todos los miembros de la clase.\nToda la comunicación relativa al curso se dará por medio del correo institucional del CIDE.\nLas tareas y exámenes se entregarán a través de Teams.\nLos participantes en la sesión deberán procurar que haya un ambiente silencioso para el desarrollo de la clase.\nSe aplicarán estrictamente los lineamientos generales contenidos en el código de ética del CIDE en términos de plagio y fraude en tareas, exámenes y proyecto final."
  },
  {
    "objectID": "tareas/index.html",
    "href": "tareas/index.html",
    "title": "Tareas",
    "section": "",
    "text": "Tarea 1\n\nFecha de entrega: 18 de septiembre a las 20:00 en Teams\nPreguntas\nRespuestas\n\n\n\n\nTarea 2\n\nFecha de entrega: 9 de octubre a las 20:00 en Teams\nPreguntas\nRespuestas\n\n\n\n\nTarea 3\n\nFecha de entrega: 9 de noviembre a las 20:00 en Teams\nPreguntas\nRespuestas\n\n\n\n\nTarea 4\n\nFecha de entrega: 4 de diciembre a las 20:00 en Teams\nPreguntas"
  },
  {
    "objectID": "tareas/tarea-1.html",
    "href": "tareas/tarea-1.html",
    "title": "Tarea 2",
    "section": "",
    "text": "Fecha de entrega: 9 de octubre a las 20:00\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los leguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-1.html#preguntas",
    "href": "tareas/tarea-1.html#preguntas",
    "title": "Tarea 2",
    "section": "",
    "text": "Fecha de entrega: 9 de octubre a las 20:00\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los leguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-1.html#datos",
    "href": "tareas/tarea-1.html#datos",
    "title": "Tarea 2",
    "section": "Datos",
    "text": "Datos"
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-1",
    "href": "tareas/tarea-1.html#pregunta-1",
    "title": "Tarea 2",
    "section": "Pregunta 1",
    "text": "Pregunta 1\nSuponga que para un experimento en un laboratorio de economía experimental se asignó a la mitad de los participantes a un grupo de tratamiento y la otra mitad al grupo de control. Se busca estudiar el efecto del tratamiento \\(T_i\\) sobre el desempeño en un juego estratégico, medido por la variable \\(y_i\\) (a más puntaje, mejor desempeño). Antes de comenzar el experimento se recolectaron una serie de características \\(x_{ji}\\), \\(j=1,\\ldots 10\\), de cada jugador. En el experimento, se trabaja con \\(\\alpha=0.10\\).\n\n[5 puntos] El investigador A quedó a cargo de comprobar el balance de la asignación del tratamiento y le reporta lo siguiente:\nPara verificar que la aleatorización fue exitosa, tomé la serie de variables pre-intervención y la dummy de asignación al tratamiento \\(T_i\\) para correr la siguiente regresión: \\[T_i=\\alpha+\\sum_{j=1}^{10}x_{ji}'\\beta +\\varepsilon_i\\]\nDespués realicé una prueba \\(F\\) de significancia conjunta sobre los coeficientes \\(\\beta_j\\) que resultó tener un valor \\(p\\) de 0.02.\nExplique cuál es la hipótesis nula en la prueba realizada y qué se esperaría de haberse logrado una aleatorización exitosa del tratamiento.\n[5 puntos] ¿Qué concluye a partir de lo que le reporta el investigador A?\n[5 puntos] Por otro lado, el investigador B le reporta lo siguiente:\nYo realicé un análisis para determinar el balance en la asignación del tratamiento. Para cada una de las características \\(x_{ji}\\) corrí la siguiente regresión: \\[x_{ji}=\\gamma+\\pi T_i+u_i\\] A continuación, le reporto una tabla con los valores \\(p\\) asociados al coeficiente estimado de \\(\\pi\\) en cada una de las 10 regresiones.\n\n\n\n\n\n\n\n\n\n\nCaracterística\nValor \\(p\\)\n\nCaracterística\nValor \\(p\\)\n\n\n\n\n\\(x_{1i}\\)\n0.05\n\n\\(x_{6i}\\)\n0.03\n\n\n\\(x_{2i}\\)\n0.02\n\n\\(x_{7i}\\)\n0.19\n\n\n\\(x_{3i}\\)\n0.07\n\n\\(x_{8i}\\)\n0.85\n\n\n\\(x_{4i}\\)\n0.00\n\n\\(x_{9i}\\)\n0.01\n\n\n\\(x_{5i}\\)\n0.42\n\n\\(x_{10i}\\)\n0.03\n\n\n\nExplique la hipótesis nula detrás de las pruebas que realizó el investigador B y qué se esperaría de haberse logrado una aleatorización exitosa del tratamiento,\n[5 puntos] Explique qué concluye sobre la validez interna del estudio en cuestión. ¿Qué propiedades estadísticas tendría el estimador de diferencia de medias de la variable de desempeño en el juego entre el grupo tratado y el de control?"
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-2",
    "href": "tareas/tarea-1.html#pregunta-2",
    "title": "Tarea 2",
    "section": "Pregunta 2",
    "text": "Pregunta 2\nSuponga que está interesado en conocer el impacto que tiene el acceso a las microfinanzas en un indicador de seguridad alimentaria \\(y_i\\) de las familias. La idea detrás es que el acceso al crédito podría mejorar la habilidad de los hogares para suavizar el consumo. Afortunadamente, usted recibe el respaldo de una microfinanciera que le ofrece una base de datos para con información para construir \\(y_i\\), recolecatada a partir de una encuesta en los hogares de sus clientes con más de un año de antiguedad. Además, le da acceso a datos de otra encuesta complementaria realizada en hogares que no son clientes y que no tienen acceso a microfinanzas para construir el mismo indicador de seguridad alimentaria. Al final, tendría una muestra de varios miles de hogares con y sin acceso a microfinanzas.\nSuponga que con estos datos descubre que la seguridad alimentaria es 25% más alta en los hogares con clientes de la microfinanciera, en comparación con la seguridad alimentaria de los hogares sin acceso a las microfinanzas.\n\n[10 puntos] ¿Cómo valora el diseño del estudio descrito? ¿Qué fortalezas y/o debilidades encuentra?\n[10 puntos] ¿De qué signo esperaría que fuera el sesgo de selección, en caso de existir? Explique sus razones."
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-3",
    "href": "tareas/tarea-1.html#pregunta-3",
    "title": "Tarea 2",
    "section": "Pregunta 3",
    "text": "Pregunta 3\n[10 puntos] Replique el ejercicio en MHE que ejemplifica el teorema de la regresión de la FEC. Para esto use el archivo de datos muestra-enoe-123.csv, que contiene una muestra del primer trimestre de 2023 de la ENOE e incluye personas que trabajan y reciben un ingreso. lingreso es el log del ingreso mensual y escolaridad son los años de educación. Primero, estime una regresión de lingreso en función de escolaridad usando los microdatos. Luego, obtenga la media de lingreso para cada nivel de escolaridad y estime una regresión de las medias en función de escolaridad, pesando por el número de observaciones usadas para construir cada media. Compare los coeficientes estimados."
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-4",
    "href": "tareas/tarea-1.html#pregunta-4",
    "title": "Tarea 2",
    "section": "Pregunta 4",
    "text": "Pregunta 4\nUse los datos del archivo STAR_public_use.csv para este problema. En este problema replicará la fila correspondiente a la variable High scool GPA (calificación en la preparatoria) de la Tabla 1 en Angrist et al. (2009).1\n\n[5 puntos] Obtenga la media y la desviación estándar de la calificación en la preparatoria, gpa0, en el grupo de control (columna 1), restringiendo la muestra a aquellos individuos con noshow igual a 0.\n[10 puntos] Usando una regresión lineal, muestre que la calificación en la preparatoria no está correlacionada con la asignación a los tratamientos (ssp, sfp y sfsp). De nuevo, debe restringir la muestra quienes tienen noshow igual a 0. Reporte los coeficientes y los errores estándar (columnas 2 a 4).\n[5 puntos] Realice una prueba de significancia conjunta de los coeficientes obtenidos en el punto b. Reporte el estadístico \\(F\\) y el valor \\(p\\) asociado (columna 5).\n[10 puntos] ¿Cuál es el propósito de la prueba F realizada en el punto c.? ¿Qué hipótesis nula prueban los autores?"
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-5",
    "href": "tareas/tarea-1.html#pregunta-5",
    "title": "Tarea 2",
    "section": "Pregunta 5",
    "text": "Pregunta 5\nNuevamente, use los datos del archivo STAR_public_use.csv para este problema. En este problema, replicará dos columnas del efecto de tratamiento de la Tabla 5. Note que de nuevo se deben usar solo las observaciones que tienen noshow igual a 0. Además, note que se usan las siguientes variables de control: sex, mtongue, hsgroup, numcourses_nov1, lastmin, mom_edn, y dad_edn, todas ellas categóricas.\n\n[10 puntos] Estime el efecto de cada tipo de tratamiento sobre la calificación del trimestre de otoño, grade_20059_fall, para toda la muestra (Panel A, columna 1). Calcule correctamente los errores estándar. Interprete los resultados.\n[10 puntos] Estime el efecto de recibir cada tipo de tratamiento, considerando los tratamientos SSP o SFP (de cualquier tipo) en los hombres de la muestra (Panel A, columna 5). Esto es, considere el tratamiento SSP como un primer tipo de tratamiento y, ya sea SFP o SFSP, como un segundo tipo de tratamiento. Calcule correctamente los errores estándar. Interprete sus resultados."
  },
  {
    "objectID": "tareas/tarea-1.html#footnotes",
    "href": "tareas/tarea-1.html#footnotes",
    "title": "Tarea 2",
    "section": "Notas",
    "text": "Notas\n\n\nAngrist, J., Lang, D., y Oreopoulos, P. (2009). Incentives and services for college achievement: Evidence from a randomized trial. American Economic Journal: Applied Economics, 1(1), 136-63.↩︎"
  },
  {
    "objectID": "tareas/tarea-2.html",
    "href": "tareas/tarea-2.html",
    "title": "Tarea 2",
    "section": "",
    "text": "Fecha de entrega: 9 de octubre a las 20:00\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los leguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad.\n\n\n\ncrepon_morocco_balance.csv\ncrepon_morocco_analysis.csv\nSTAR_public_use.csv\npvalues.csv\n\n\n\nEn Crepon et al. (2015)1 se estudia una intervención en Marruecos en la que se analiza el efecto de la adopción de microfinanzas, a través de un experimento de campo. En 81 de 162 localidades estudiadas se introdujo aleatoriamente una empresa de microfinanzas. Para seleccionar las localidades de tratamiento, primero se emparejaron localidades de acuerdo a características observables y, para cada pareja se asignó a tratamiento y otra a control. La variable que identifica a las parejas es paire. La base de datos crepon_morocco_balance.csv contiene los datos de este estudio usados para mostrar la integridad del diseño. La variable treatment es la variable de asignación aleatoria, mientras que la variable client es la variable de adopción\n\n[3 puntos] Primero recordaremos cómo mostrar que el tratamiento efectivamente fue asignado de manera aleatoria. El siguiente código lee los datos que debemos usar y se queda con las observaciones de la línea base. Con estos datos, mostraremos que la variable nchildren_resid_bl, que indica el número de niños que viven en cada hogar está balanceado entre los grupos asignados a tratamiento y control. Noten que la media del número de niños que viven en el hogar en el grupo de control es 1.68 (d.e. 1.64) y que hay 2,266 hogares en dicho grupo de control. Esto es exactamente lo que se reporta en la primera fila correspondiente a Number children (&lt;16 years old) en la tabla 1 del artículo.\n\ndata.morocco&lt;-read_csv(\"../files/crepon_morocco_balance.csv\",\n                       locale = locale(encoding = \"latin1\")) %&gt;% \n  clean_names() %&gt;% \n  filter(merge_indicator!=1)\n\ndata.morocco %&gt;% \n  group_by(treatment) %&gt;%\n  summarize(mean=mean(nchildren_resid_bl, na.rm=T),\n            std=sd(nchildren_resid_bl, na.rm=T),\n            n=n()) %&gt;% \n  ungroup()\n\n# A tibble: 2 × 4\n  treatment  mean   std     n\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1         0  1.68  1.64  2266\n2         1  1.69  1.64  2199\n\n\nObtenga ahora el valor de la diferencia entre el grupo de tratamiento y el de control, así como su valor \\(p\\) (últimas dos columnas). Para ello, estime una regresión en la que la variable dependiente sea número de niños que vive en el hogar nchildren_resid_bl, en función de la variable de asignación treatment y variables dummy de pareja de localidad (la variable paire indica cuáles son las parejas). La regresión permite recuperar la diferencia de 0.01 niños que se reporta en la fila correspondiente en la tabla 1. Para recuperar el valor \\(p\\), estime errores agrupados usando la variable demi_paire, que es la clave de las distintas localidades, como variable de agrupación. Una forma de realizar esto es con la función coef_test del paquete clubSandwich.2\n[2 puntos] Ahora mostremos que efectivamente este es un ejemplo de una intervención con cumplimiento imperfecto. Genere un cuadro que indique: 1) cuántas personas que fueron asignadas a recibir el tratamiento efectivamente fueron clientes; 2) cuántas personas que fueron asignadas a recibir el tratamiento no se convirtieron en clientes; 3) cuántas personas que no fueron asignadas a recibir el tratamiento sí se convirtieron en clientes; y 4) cuántas personas que no fueron asignadas a recibir el tratamiento tampoco se convirtieron en clientes.\n[5 puntos] Ahora mostraremos que la adopción, es decir, convertirse en cliente, no es independiente de las características de los hogares. Considere las variables members_resid_bl y act_number_bl, que indican el número de miembros del hogar y el número de actividades económicas del hogar. Para cada una de estas dos variables, utilice la misma especificación que en la parte a., pero ahora usando la variable cliente como regresor. ¿Qué concluye?\n[5 puntos] Con estos elementos estamos convencidos de que es necesario emplear lo que sabemos sobre cumplimiento imperfecto. Usaremos ahora los datos en crepon_morocco_analysis.csv, que contiene los datos empleados para evaluar el impacto de la adopción. Estos datos están listos para analizarse. Estime la forma reducida del efecto de ser asignado al tratamiento sobre gasto total, expense_total. Comente los resultados, en particular, comente sobre la magnitud y la significancia estadística de la variable treatment. Aquí y en adelante, incluya los siguientes controles en la regresión: members_resid_bl, nadults_resid_bl, head_age_bl, act_livestock_bl, act_business_bl, borrowed_total_bl, members_resid_d_bl, nadults_resid_d_bl, head_age_d_bl, act_livestock_d_bl, act_business_d_bl, borrowed_total_d_bl, ccm_resp_activ, other_resp_activ, ccm_resp_activ_d y other_resp_activ_d. Además, incluya efectos fijos por pareja introduciendo la variable paire como factor. Use los mismos errores estándar que en la parte a. Con esto deberá poder recuperar el coeficiente y el error estándar de la columna (3) de la tabla 3.\n[5 puntos] Estime ahora la primera etapa, es decir, estime por MCO el efecto causal de la asignación sobre la adopción. Comente sobre la magnitud, la significancia estadística y la interpretación de la variable treatment en términos del comportamiento de los cumplidores. Debería poder replicar el coeficiente y el error estándar de la columna 1 en la tabla 2 del artículo.\n[5 puntos] Considere la columna 3 del panel A en la Tabla 9 del artículo. Aquí se reporta la estimación por MCO de la relación entre client y gasto total, con los mismos controles y tipo de errores que antes. Replique este resultado. ¿Se puede interpretar de forma causal el coeficiente sobre client?\n[5 puntos] ¿Cuáles son los dos supuestos econométricos que permiten la estimación del Local Average Treatment Effect (LATE) en el contexto de este problema? Comente sobre la evidencia que respalda el supuesto de que los instrumentos no son débiles en este problema.\n[5 puntos] Estime el efecto del cumplimiento sobre el gasto total, usando la asignación aleatoria como instrumento del cumplimiento. Es decir, estime el LATE. Use los mismos controles y tipo de errores que en c. Este resultado se reporta en la columna 3 del panel B en la Tabla 9. ¿Cuál es la interpretación del coeficiente de la variable client? En R, la función ivreg del paquete AER le permite hacer la estimación de MC2E.\n\n\n\n\n\n[5 puntos] Sea una variable de resultados \\(y_i\\), una variable de asignación aleatoria \\(Z_i\\) y una variable de adopción \\(D_i\\). El estimador de Wald se define como:\n\\[\\hat{\\beta}_{Wald}=\\frac{\\bar{Y}_{Z_i=1}-\\bar{Y}_{Z_i=0}}{\\bar{D}_{Z_i=1}-\\bar{D}_{Z_i=0}}\\]\nEn esta pregunta mostraremos cómo el estimador de Wald es equivalente al estimador de VI cuando no hay controles. Use nuevamente los datos en crepon_morocco_analysis.csv. Obtenga el estimador de Wald como el cociente de la diferencia en gasto total promedio entre los hogares asignados a tratamiento y control dividido por la diferencia en la probabilidad de adopción entre los hogares asignados a tratamiento y control. Recuerde que la variable del gasto total es expense_total.\n[5 puntos] Ahora estime por MC2E el efecto de la adopción sobre el gasto total, usando la variable de asignación como instrumento para la adopción. ¿Qué ventaja observa con respecto al estimador de Wald?\n\n\n\n\nEn la Pregunta 2, parte a, obtuvo el estimador de Wald para aproximar el efecto de la adopción en el gasto total. Considere dicho cálculo sin controles para lo que resta de esta pregunta.\n\n[5 puntos] Utilice un procedimiento bootstrap a mano para estimar el error estándar del estimador de Wald usando 30 repeticiones. Es decir, debe realizar un remuestreo de los datos originales y para cada muestra obtener el estimador de Wald. Luego, obtenga la desviación estándar de los 30 estadísticos calculados. Utilice una semilla para poder replicar sus resultados.\n[5 puntos] Reemplace la semilla de la parte a. por una nueva semilla y estime nuevamente el error estándar del estimador de Wald con 30 repeticiones. Comente sobre la diferencia entre este error estándar y el de la parte a.\n[5 puntos] Regrese el valor de la semilla al usado en a. y estime nuevamente el error estándar del estimador de Wald, esta vez usando 2000 repeticiones. Comente sobre la diferencia entre este error estándar y el de la parte a.\n\n\n\n\nConsidere nuevamente la base STAR_public_use.csv usada en la Tarea 1 del artículo Angrist, Lang y Oreopoulos (2009)3. En esta pregunta nos concentraremos en los efectos de la intervención en el año 2, mostrados en la columna (4) de la Tabla 6, sobre dos variables, el promedio de calificaciones gpa_year2 y los créditos completados credits_earned2.\nEl propósito de esta pregunta es mostrar la función de los \\(z\\)-scores en el análisis de efectos de tratamiento. De nuevo, puede quedarse solo con las observaciones que tienen noshow igual a 0. Antes de comenzar su análisis, sustituya por NA los valores en credits_earned2 para aquellas observaciones que tienen \\(NA\\) en la variable prob_year1.\n\n[5 puntos] Para tener un punto de comparación, estime la ecuación del efecto de tratamiento para gpa_year2 usando la misma especificación que en la pregunta 5 de la Tarea 1. Use también errores robustos. Deberá poder replicar los coeficientes y errores estándar del panel A, columna (4). ¿Cómo se interpretan el coeficiente sobre la variable ssp?\n[5 puntos] Genere un \\(z\\)-score para la variable gpa_year2 al que llame gpa_year2_sd. Para ello, calcule la media y desviación estándar de gpa_year2 para el grupo de control y luego genere gpa_year2_sd restándole a gpa_year2 la media obtenida y dividiendo esta diferencia por la desviación estándar obtenida. Compruebe que si calcula la media y la desviación estándar de gpa_year2_sd, en el grupo de control estas deberían ser 0 y 1, respectivamente.\n[5 puntos] Realice la misma estimación que en la parte a., pero ahora use como variable dependiente gpa_year2_sd. ¿Cómo se interpreta el coeficiente sobre ssp? ¿Qué es diferente y qué es igual entre los resultados obtenidos en esta parte y los obtenidos en la parte a.?\n[5 puntos] Ahora realizaremos un índice de mejora en educación, al agregar los resultados de estos dos indicadores en una sola variable, como se describe en Banerjee et al. (2015)4. Para ello, primero genere credits_earned2_sd, que será la versión estandarizada de credits_earned2, siguiendo el mismo procedimiento que en la parte b. En seguida, genere una nueva variable llamada indice_escolar, que será el promedio de credits_earned2_sd y gpa_year2_sd. Luego, calcule la media y la desviación estándar de indice_escolar en el grupo de control. Finalmente, genere una nueva variable indice_escolar_sd restándole a indice_escolar la media antes calculada y dividiendo esta diferencia por la desviación estándar antes calculada. Muestre que la variable indice_escolar_sd tiene media 0 y desviación estándar 1 en el grupo de control.\n[5 puntos] Estime ahora el efecto de tratamiento sobre indice_escolar_sd, siguiendo la misma especificación econométrica que en la parte a. y usando errores robustos. ¿Qué concluye?\n\n\n\n\nConsidere los valores \\(p\\) del archivo pvalues.csv. Cada valor \\(p_i\\) está asociado a una prueba de hipótesis \\(i\\). La variable familia denota tres grupos de hipótesis sobre las cuales estamos interesados en hacer correcciones de múltiples hipótesis. La investigación en cuestión emplea \\(\\alpha=0.05\\).\n\n[5 puntos] Para cada una de las pruebas de hipótesis, genere un cuadro como el que se presenta a continuación y diga si se rechaza o no la hipótesis nula, bajo los siguientes criterios:\n\n\n\n\n\n\n\n\n\n\nHipótesis sin corrección\nControlando la tasa de errores en la familia (FWER) usando el método de Bonferroni\nControlando la tasa de falso descubrimiento (FDR) dentro de la familia usando el método de Benjamini y Hochberg\n\n\n\n\n1\n\n\n\n\n\n\\(\\vdots\\)\n\n\n\n\n\n15\n\n\n\n\n\n\n[5 puntos] Suponga que encuentra buenas razones conceptuales para afirmar que las familias 2 y 3 deben ser consideraras una sola familia. Tendríamos ahora solo dos familias, la familia 1 original y una nueva familia numerada como 4, como se indica en la variable familia_corregida. ¿Cómo cambian sus conclusiones respecto a la parte a. de esta pregunta? Genere un nuevo cuadro con esta redefinición.\n[5 puntos] Suponga que su asistente de investigación olvidó el concepto de familia y realiza las correcciones por pruebas de múltiples hipótesis ignorando las familias. ¿Qué concluiría en este caso? Genere un nuevo cuadro bajo esta circunstancia. Comente sobre la diferencia en las conclusiones entre las partes b. y c."
  },
  {
    "objectID": "tareas/tarea-2.html#instrucciones",
    "href": "tareas/tarea-2.html#instrucciones",
    "title": "Tarea 2",
    "section": "",
    "text": "Fecha de entrega: 9 de octubre a las 20:00\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los leguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-2.html#datos",
    "href": "tareas/tarea-2.html#datos",
    "title": "Tarea 2",
    "section": "",
    "text": "crepon_morocco_balance.csv\ncrepon_morocco_analysis.csv\nSTAR_public_use.csv\npvalues.csv"
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-1",
    "href": "tareas/tarea-2.html#pregunta-1",
    "title": "Tarea 2",
    "section": "",
    "text": "En Crepon et al. (2015)1 se estudia una intervención en Marruecos en la que se analiza el efecto de la adopción de microfinanzas, a través de un experimento de campo. En 81 de 162 localidades estudiadas se introdujo aleatoriamente una empresa de microfinanzas. Para seleccionar las localidades de tratamiento, primero se emparejaron localidades de acuerdo a características observables y, para cada pareja se asignó a tratamiento y otra a control. La variable que identifica a las parejas es paire. La base de datos crepon_morocco_balance.csv contiene los datos de este estudio usados para mostrar la integridad del diseño. La variable treatment es la variable de asignación aleatoria, mientras que la variable client es la variable de adopción\n\n[3 puntos] Primero recordaremos cómo mostrar que el tratamiento efectivamente fue asignado de manera aleatoria. El siguiente código lee los datos que debemos usar y se queda con las observaciones de la línea base. Con estos datos, mostraremos que la variable nchildren_resid_bl, que indica el número de niños que viven en cada hogar está balanceado entre los grupos asignados a tratamiento y control. Noten que la media del número de niños que viven en el hogar en el grupo de control es 1.68 (d.e. 1.64) y que hay 2,266 hogares en dicho grupo de control. Esto es exactamente lo que se reporta en la primera fila correspondiente a Number children (&lt;16 years old) en la tabla 1 del artículo.\n\ndata.morocco&lt;-read_csv(\"../files/crepon_morocco_balance.csv\",\n                       locale = locale(encoding = \"latin1\")) %&gt;% \n  clean_names() %&gt;% \n  filter(merge_indicator!=1)\n\ndata.morocco %&gt;% \n  group_by(treatment) %&gt;%\n  summarize(mean=mean(nchildren_resid_bl, na.rm=T),\n            std=sd(nchildren_resid_bl, na.rm=T),\n            n=n()) %&gt;% \n  ungroup()\n\n# A tibble: 2 × 4\n  treatment  mean   std     n\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1         0  1.68  1.64  2266\n2         1  1.69  1.64  2199\n\n\nObtenga ahora el valor de la diferencia entre el grupo de tratamiento y el de control, así como su valor \\(p\\) (últimas dos columnas). Para ello, estime una regresión en la que la variable dependiente sea número de niños que vive en el hogar nchildren_resid_bl, en función de la variable de asignación treatment y variables dummy de pareja de localidad (la variable paire indica cuáles son las parejas). La regresión permite recuperar la diferencia de 0.01 niños que se reporta en la fila correspondiente en la tabla 1. Para recuperar el valor \\(p\\), estime errores agrupados usando la variable demi_paire, que es la clave de las distintas localidades, como variable de agrupación. Una forma de realizar esto es con la función coef_test del paquete clubSandwich.2\n[2 puntos] Ahora mostremos que efectivamente este es un ejemplo de una intervención con cumplimiento imperfecto. Genere un cuadro que indique: 1) cuántas personas que fueron asignadas a recibir el tratamiento efectivamente fueron clientes; 2) cuántas personas que fueron asignadas a recibir el tratamiento no se convirtieron en clientes; 3) cuántas personas que no fueron asignadas a recibir el tratamiento sí se convirtieron en clientes; y 4) cuántas personas que no fueron asignadas a recibir el tratamiento tampoco se convirtieron en clientes.\n[5 puntos] Ahora mostraremos que la adopción, es decir, convertirse en cliente, no es independiente de las características de los hogares. Considere las variables members_resid_bl y act_number_bl, que indican el número de miembros del hogar y el número de actividades económicas del hogar. Para cada una de estas dos variables, utilice la misma especificación que en la parte a., pero ahora usando la variable cliente como regresor. ¿Qué concluye?\n[5 puntos] Con estos elementos estamos convencidos de que es necesario emplear lo que sabemos sobre cumplimiento imperfecto. Usaremos ahora los datos en crepon_morocco_analysis.csv, que contiene los datos empleados para evaluar el impacto de la adopción. Estos datos están listos para analizarse. Estime la forma reducida del efecto de ser asignado al tratamiento sobre gasto total, expense_total. Comente los resultados, en particular, comente sobre la magnitud y la significancia estadística de la variable treatment. Aquí y en adelante, incluya los siguientes controles en la regresión: members_resid_bl, nadults_resid_bl, head_age_bl, act_livestock_bl, act_business_bl, borrowed_total_bl, members_resid_d_bl, nadults_resid_d_bl, head_age_d_bl, act_livestock_d_bl, act_business_d_bl, borrowed_total_d_bl, ccm_resp_activ, other_resp_activ, ccm_resp_activ_d y other_resp_activ_d. Además, incluya efectos fijos por pareja introduciendo la variable paire como factor. Use los mismos errores estándar que en la parte a. Con esto deberá poder recuperar el coeficiente y el error estándar de la columna (3) de la tabla 3.\n[5 puntos] Estime ahora la primera etapa, es decir, estime por MCO el efecto causal de la asignación sobre la adopción. Comente sobre la magnitud, la significancia estadística y la interpretación de la variable treatment en términos del comportamiento de los cumplidores. Debería poder replicar el coeficiente y el error estándar de la columna 1 en la tabla 2 del artículo.\n[5 puntos] Considere la columna 3 del panel A en la Tabla 9 del artículo. Aquí se reporta la estimación por MCO de la relación entre client y gasto total, con los mismos controles y tipo de errores que antes. Replique este resultado. ¿Se puede interpretar de forma causal el coeficiente sobre client?\n[5 puntos] ¿Cuáles son los dos supuestos econométricos que permiten la estimación del Local Average Treatment Effect (LATE) en el contexto de este problema? Comente sobre la evidencia que respalda el supuesto de que los instrumentos no son débiles en este problema.\n[5 puntos] Estime el efecto del cumplimiento sobre el gasto total, usando la asignación aleatoria como instrumento del cumplimiento. Es decir, estime el LATE. Use los mismos controles y tipo de errores que en c. Este resultado se reporta en la columna 3 del panel B en la Tabla 9. ¿Cuál es la interpretación del coeficiente de la variable client? En R, la función ivreg del paquete AER le permite hacer la estimación de MC2E."
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-2",
    "href": "tareas/tarea-2.html#pregunta-2",
    "title": "Tarea 2",
    "section": "",
    "text": "[5 puntos] Sea una variable de resultados \\(y_i\\), una variable de asignación aleatoria \\(Z_i\\) y una variable de adopción \\(D_i\\). El estimador de Wald se define como:\n\\[\\hat{\\beta}_{Wald}=\\frac{\\bar{Y}_{Z_i=1}-\\bar{Y}_{Z_i=0}}{\\bar{D}_{Z_i=1}-\\bar{D}_{Z_i=0}}\\]\nEn esta pregunta mostraremos cómo el estimador de Wald es equivalente al estimador de VI cuando no hay controles. Use nuevamente los datos en crepon_morocco_analysis.csv. Obtenga el estimador de Wald como el cociente de la diferencia en gasto total promedio entre los hogares asignados a tratamiento y control dividido por la diferencia en la probabilidad de adopción entre los hogares asignados a tratamiento y control. Recuerde que la variable del gasto total es expense_total.\n[5 puntos] Ahora estime por MC2E el efecto de la adopción sobre el gasto total, usando la variable de asignación como instrumento para la adopción. ¿Qué ventaja observa con respecto al estimador de Wald?"
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-3",
    "href": "tareas/tarea-2.html#pregunta-3",
    "title": "Tarea 2",
    "section": "",
    "text": "En la Pregunta 2, parte a, obtuvo el estimador de Wald para aproximar el efecto de la adopción en el gasto total. Considere dicho cálculo sin controles para lo que resta de esta pregunta.\n\n[5 puntos] Utilice un procedimiento bootstrap a mano para estimar el error estándar del estimador de Wald usando 30 repeticiones. Es decir, debe realizar un remuestreo de los datos originales y para cada muestra obtener el estimador de Wald. Luego, obtenga la desviación estándar de los 30 estadísticos calculados. Utilice una semilla para poder replicar sus resultados.\n[5 puntos] Reemplace la semilla de la parte a. por una nueva semilla y estime nuevamente el error estándar del estimador de Wald con 30 repeticiones. Comente sobre la diferencia entre este error estándar y el de la parte a.\n[5 puntos] Regrese el valor de la semilla al usado en a. y estime nuevamente el error estándar del estimador de Wald, esta vez usando 2000 repeticiones. Comente sobre la diferencia entre este error estándar y el de la parte a."
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-4",
    "href": "tareas/tarea-2.html#pregunta-4",
    "title": "Tarea 2",
    "section": "",
    "text": "Considere nuevamente la base STAR_public_use.csv usada en la Tarea 1 del artículo Angrist, Lang y Oreopoulos (2009)3. En esta pregunta nos concentraremos en los efectos de la intervención en el año 2, mostrados en la columna (4) de la Tabla 6, sobre dos variables, el promedio de calificaciones gpa_year2 y los créditos completados credits_earned2.\nEl propósito de esta pregunta es mostrar la función de los \\(z\\)-scores en el análisis de efectos de tratamiento. De nuevo, puede quedarse solo con las observaciones que tienen noshow igual a 0. Antes de comenzar su análisis, sustituya por NA los valores en credits_earned2 para aquellas observaciones que tienen \\(NA\\) en la variable prob_year1.\n\n[5 puntos] Para tener un punto de comparación, estime la ecuación del efecto de tratamiento para gpa_year2 usando la misma especificación que en la pregunta 5 de la Tarea 1. Use también errores robustos. Deberá poder replicar los coeficientes y errores estándar del panel A, columna (4). ¿Cómo se interpretan el coeficiente sobre la variable ssp?\n[5 puntos] Genere un \\(z\\)-score para la variable gpa_year2 al que llame gpa_year2_sd. Para ello, calcule la media y desviación estándar de gpa_year2 para el grupo de control y luego genere gpa_year2_sd restándole a gpa_year2 la media obtenida y dividiendo esta diferencia por la desviación estándar obtenida. Compruebe que si calcula la media y la desviación estándar de gpa_year2_sd, en el grupo de control estas deberían ser 0 y 1, respectivamente.\n[5 puntos] Realice la misma estimación que en la parte a., pero ahora use como variable dependiente gpa_year2_sd. ¿Cómo se interpreta el coeficiente sobre ssp? ¿Qué es diferente y qué es igual entre los resultados obtenidos en esta parte y los obtenidos en la parte a.?\n[5 puntos] Ahora realizaremos un índice de mejora en educación, al agregar los resultados de estos dos indicadores en una sola variable, como se describe en Banerjee et al. (2015)4. Para ello, primero genere credits_earned2_sd, que será la versión estandarizada de credits_earned2, siguiendo el mismo procedimiento que en la parte b. En seguida, genere una nueva variable llamada indice_escolar, que será el promedio de credits_earned2_sd y gpa_year2_sd. Luego, calcule la media y la desviación estándar de indice_escolar en el grupo de control. Finalmente, genere una nueva variable indice_escolar_sd restándole a indice_escolar la media antes calculada y dividiendo esta diferencia por la desviación estándar antes calculada. Muestre que la variable indice_escolar_sd tiene media 0 y desviación estándar 1 en el grupo de control.\n[5 puntos] Estime ahora el efecto de tratamiento sobre indice_escolar_sd, siguiendo la misma especificación econométrica que en la parte a. y usando errores robustos. ¿Qué concluye?"
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-5",
    "href": "tareas/tarea-2.html#pregunta-5",
    "title": "Tarea 2",
    "section": "",
    "text": "Considere los valores \\(p\\) del archivo pvalues.csv. Cada valor \\(p_i\\) está asociado a una prueba de hipótesis \\(i\\). La variable familia denota tres grupos de hipótesis sobre las cuales estamos interesados en hacer correcciones de múltiples hipótesis. La investigación en cuestión emplea \\(\\alpha=0.05\\).\n\n[5 puntos] Para cada una de las pruebas de hipótesis, genere un cuadro como el que se presenta a continuación y diga si se rechaza o no la hipótesis nula, bajo los siguientes criterios:\n\n\n\n\n\n\n\n\n\n\nHipótesis sin corrección\nControlando la tasa de errores en la familia (FWER) usando el método de Bonferroni\nControlando la tasa de falso descubrimiento (FDR) dentro de la familia usando el método de Benjamini y Hochberg\n\n\n\n\n1\n\n\n\n\n\n\\(\\vdots\\)\n\n\n\n\n\n15\n\n\n\n\n\n\n[5 puntos] Suponga que encuentra buenas razones conceptuales para afirmar que las familias 2 y 3 deben ser consideraras una sola familia. Tendríamos ahora solo dos familias, la familia 1 original y una nueva familia numerada como 4, como se indica en la variable familia_corregida. ¿Cómo cambian sus conclusiones respecto a la parte a. de esta pregunta? Genere un nuevo cuadro con esta redefinición.\n[5 puntos] Suponga que su asistente de investigación olvidó el concepto de familia y realiza las correcciones por pruebas de múltiples hipótesis ignorando las familias. ¿Qué concluiría en este caso? Genere un nuevo cuadro bajo esta circunstancia. Comente sobre la diferencia en las conclusiones entre las partes b. y c."
  },
  {
    "objectID": "tareas/tarea-2.html#footnotes",
    "href": "tareas/tarea-2.html#footnotes",
    "title": "Tarea 2",
    "section": "Notas",
    "text": "Notas\n\n\nPor ejemplo, suponga que estima un modelo al que llame modelo1. Entonces, si ejecuta\n\ncoef_test(modelo1,\n          vcov=\"CR1S\",\n          cluster=mis_datos$demi_paire)[1:2,]\n\nobtendrá los coeficientes con los errores agrupados requeridos. La opción CR1S toma en cuenta el número de grupos o clusters para realizar inferencia. Puede leer más al respecto en la ayuda al ejecutar ?vcovCR. Este es el tipo de ajuste de muestras finitas que usan los autores. Esta corrección consiste en multiplicar la matriz de sándwich agrupada CR0 por \\(\\frac{G(N-1)}{(G-1)(N-p)}\\), donde \\(G\\) es el número de grupos, \\(N\\) es el número total de observaciones y \\(p\\) es el número de regresores.↩︎\nCrépon, B., Devoto, F., Duflo, E., & Parienté, W. (2015). Estimating the impact of microcredit on those who take it up: Evidence from a randomized experiment in Morocco. American Economic Journal: Applied Economics, 7(1), 123-50.↩︎\nAngrist, J., Lang, D., y Oreopoulos, P. (2009). Incentives and services for college achievement: Evidence from a randomized trial. American Economic Journal: Applied Economics, 1(1), 136-63.↩︎\nBanerjee, A. et al. (2015). A multifaceted program causes lasting progress for the very poor: Evidence from six countries. Science, 348(6236).↩︎"
  },
  {
    "objectID": "tareas/tarea-3-respuestas.html",
    "href": "tareas/tarea-3-respuestas.html",
    "title": "Respuestas a la tarea 3",
    "section": "",
    "text": "Stevenson, B. & Wolfers, J. (2006)1 estudian los efectos de la introducción de leyes que permiten el divorcio unilateral en los Estados Unidos. La librería bacondecomp incluye los datos usados en dicho artículo (debe instalar y cargar la librería). Usaremos los datos de 1964 a 1996 para mostrar cómo impactan las leyes de divorcio express (unilateral) a la tasa de suicidios en mujeres.\nAl correr el pedazo de código anterior, obtendrá un objeto de datos wd en donde la variable de impacto es la tasa de suicidios en mujeres, suicide_rate, st identifica a los estados, year identifica a los años y divyear es el año en que se introdujo la legislación del divorcio unilateral. La última fila del código crea el indicador de tratamiento unilaterial, que toma el valor de 1 para los estados tratados en los periodos post tratamiento.\n\nwd &lt;- divorce %&gt;% \nfilter(year&gt;=1964 & year&lt;=1996 & sex==2) %&gt;% \nmutate(suicide_rate=suicide*1000000/(stpop*fshare),\n   year=as.numeric(year),\n   divyear = ifelse(divyear&gt;1996, Inf, divyear),\n   unilateral=ifelse(year&gt;divyear, 1, 0))\n\n\n[5 puntos] ¿Por qué decimos que esta es una aplicación de la estimación de efectos de tratamiento con adopción escalonada?\nEn esta aplicación, cada estado comienza a ser tratado en indistintos momentos del tiempo. Si hacemos un tabulado de divyear para un año fijo, notamos cuántos estados se vuelven tratados en cada año:\n\ntable(filter(wd, year==1996)$divyear)\n\n\n1950 1969 1970 1971 1972 1973 1974 1975 1976 1977 1980 1984 1985  Inf \n   9    2    2    7    3   11    3    2    1    3    1    1    1    5 \n\n\nEl panel comienza en 1964, para cuando ya nueve estados habían sido tratados. Los estados van siendo tratados hasta que, para el fin del periodo analizado, 1996, solo cinco todavía no habían sido tratados. En esta aplicación, esos cinco estados son los nunca tratados.\n[5 puntos] Como punto de partida, estime el efecto del tratamiento sobre suicide_rate usando efectos fijos por estado y año (TWFE) y empleando una librería específica para efectos fijos, como felm. Tome en cuenta la agrupación de los errores. Interprete sus resultados.\nUsando felm:\n\nsummary(felm(suicide_rate ~ unilateral | st + year | 0 | st,\n              data = wd))\n\n\nCall:\n   felm(formula = suicide_rate ~ unilateral | st + year | 0 | st,      data = wd) \n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-37.517  -6.157  -0.141   5.577  57.004 \n\nCoefficients:\n           Estimate Cluster s.e. t value Pr(&gt;|t|)  \nunilateral   -3.777        2.201  -1.716   0.0923 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.85 on 1599 degrees of freedom\nMultiple R-squared(full model): 0.6844   Adjusted R-squared: 0.668 \nMultiple R-squared(proj model): 0.007963   Adjusted R-squared: -0.04353 \nF-statistic(full model, *iid*):41.77 on 83 and 1599 DF, p-value: &lt; 2.2e-16 \nF-statistic(proj model): 2.945 on 1 and 50 DF, p-value: 0.09231 \n\n\n[5 puntos] Compruebe que puede obtener el mismo resultado con una regresión lineal usando el paquete lm e incluyendo, además de la variable de tratamiento, dummies de estado y de año.\nEstimamos con dummies:\n\nsummary(m1 &lt;- lm(suicide_rate ~ unilateral + factor(st) + factor(year),\n              data = wd))$coef[1:2,1:3]\n\n             Estimate Std. Error   t value\n(Intercept) 56.732642   2.468251 22.984953\nunilateral  -3.776552   1.054148 -3.582562\n\n\nLuego estimamos errores agrupados:\n\nstargazer(m1,\n          type = 'text',\n          se = list(sqrt(diag(vcovCR(m1, cluster = wd$st, type = 'CR1')))),\n          keep = c(\"unilateral\"))\n\n\n===============================================\n                        Dependent variable:    \n                    ---------------------------\n                           suicide_rate        \n-----------------------------------------------\nunilateral                    -3.777*          \n                              (2.200)          \n\n-----------------------------------------------\nObservations                   1,683           \nR2                             0.684           \nAdjusted R2                    0.668           \nResidual Std. Error     10.851 (df = 1599)     \nF Statistic          41.770*** (df = 83; 1599) \n===============================================\nNote:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nObtenemos los mismos coeficientes. Aquí también podrán volver a comprobar la importancia de usar errores agrupados. Sin agrupar, el error estimado asumiendo independencia es casi menos de la mitad que el estimado con la matriz de varianzas agrupada.\n[10 puntos] Realice la descomposición de Goodman-Bacon (2021). Construya un gráfico donde muestre en el eje \\(x\\) el peso otorgado a cada comparación 2x2 que el estimador de TWFE realiza mecánicamente y en el eje \\(y\\) el efecto estimado correspondiente a cada comparación. Interprete el gráfico obtenido.\nComo vimos en clase, la descomposición de Bacon se puede obtener con la función bacon:\n\n#Goodman-Bacon decomposition\ndf_bacon &lt;- bacon(suicide_rate ~ unilateral,\n                  data = wd,\n                  id_var = \"st\",\n                  time_var = \"year\")\n\n                      type  weight  avg_est\n1 Earlier vs Later Treated 0.11558  0.13489\n2  Later vs Always Treated 0.41990 -6.95245\n3 Later vs Earlier Treated 0.23125  2.33743\n4     Treated vs Untreated 0.23328 -6.05881\n\ncoef_bacon &lt;- sum(df_bacon$estimate * df_bacon$weight)\nprint(paste(\"Weighted sum of decomposition =\", round(coef_bacon, 4)))\n\n[1] \"Weighted sum of decomposition = -3.7766\"\n\ntwfe &lt;- felm(suicide_rate ~ unilateral | st + year | 0 | st,\n              data = wd)\n\n#Gráfico----\ndf_bacon %&gt;% \n  ggplot(aes(x=weight,\n             y=estimate,\n             shape=type)) +\n  geom_point() +\n  geom_hline(yintercept = round(twfe$coefficients, 4))\n\n\n\n\nLas comparaciones que más pesan en el estimador de efectos fijos son las de estados tratados con los que siempre estuvieron tratados en el panel, recibiendo dos de esas comparaciones alrededor de 13 y el 7% del peso (los dos triángulos más hacia la derecha). otra comparación que recibe alrededor de 7% del peso es la de los tratados con los nunca tratados (cruz más hacia la derecha). En total, las comparaciones con los estados que iniciaron siendo tratados se llevan el 42% del peso. Las comparaciones entre los tratados tarde y los tratados temprano también reciben un peso alto de 23%.\n[10 puntos] Implemente el estimador de Callaway & Sant’Anna (2021) para estimar los efectos del tratamiento específicos para cada cohorte, usando el paquete did. Utilice como grupo de comparación los estados nunca tratados. La columna stid es un identificador numérico de los estados (lo requerirá cuando use att_gt del paquete did).\n\natts_nyt &lt;- att_gt(yname = \"suicide_rate\",\n                      tname = \"year\",\n                      idname = \"stid\",\n                      gname = \"divyear\",\n                      data = wd,\n                      control_group = \"nevertreated\",\n                      est_method = 'reg',\n                      bstrap = TRUE,\n                      biters = 1000,\n                      print_details = FALSE,\n                      panel = TRUE)\nsummary(atts_nyt)\n\n\nCall:\natt_gt(yname = \"suicide_rate\", tname = \"year\", idname = \"stid\", \n    gname = \"divyear\", data = wd, panel = TRUE, control_group = \"nevertreated\", \n    bstrap = TRUE, biters = 1000, est_method = \"reg\", print_details = FALSE)\n\nReference: Callaway, Brantly and Pedro H.C. Sant'Anna.  \"Difference-in-Differences with Multiple Time Periods.\" Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. &lt;https://doi.org/10.1016/j.jeconom.2020.12.001&gt;, &lt;https://arxiv.org/abs/1803.09015&gt; \n\nGroup-Time Average Treatment Effects:\n Group Time ATT(g,t) Std. Error [95% Simult.  Conf. Band]  \n  1969 1965  -0.2781     6.8497      -27.2193     26.6632  \n  1969 1966  -3.1857    12.1574      -51.0031     44.6317  \n  1969 1967  12.5043     9.0500      -23.0910     48.0996  \n  1969 1968   3.1310     7.6537      -26.9725     33.2346  \n  1969 1969   1.1566     6.5207      -24.4905     26.8037  \n  1969 1970  -3.5412    13.3245      -55.9490     48.8667  \n  1969 1971  -6.7647    11.0935      -50.3975     36.8682  \n  1969 1972   1.7696    11.9793      -45.3473     48.8864  \n  1969 1973   2.7611     7.4326      -26.4726     31.9948  \n  1969 1974  -0.3084     8.9068      -35.3405     34.7237  \n  1969 1975  -0.7421     5.7094      -23.1983     21.7142  \n  1969 1976 -10.6073     7.6156      -40.5608     19.3462  \n  1969 1977  -3.9320    11.4296      -48.8867     41.0227  \n  1969 1978 -14.0099    12.0164      -61.2727     33.2528  \n  1969 1979  -8.1059    14.7684      -66.1926     49.9807  \n  1969 1980 -10.6943     7.7519      -41.1838     19.7953  \n  1969 1981  -3.4755    12.0847      -51.0070     44.0559  \n  1969 1982  -7.0072     9.0613      -42.6469     28.6326  \n  1969 1983   5.1998    13.3936      -47.4799     57.8794  \n  1969 1984 -10.0771    12.9116      -60.8607     40.7064  \n  1969 1985   5.9598    17.2201      -61.7700     73.6896  \n  1969 1986  -8.5962    12.7169      -58.6141     41.4217  \n  1969 1987  -8.6897     7.9645      -40.0156     22.6362  \n  1969 1988 -11.9815     8.3038      -44.6420     20.6790  \n  1969 1989  -5.9781    14.7386      -63.9477     51.9916  \n  1969 1990  -7.7327    11.1956      -51.7669     36.3016  \n  1969 1991 -14.7659    11.4140      -59.6591     30.1273  \n  1969 1992  -6.6956     6.6277      -32.7637     19.3725  \n  1969 1993   0.5290    12.2110      -47.4993     48.5573  \n  1969 1994  -6.1575    16.3182      -70.3401     58.0250  \n  1969 1995  -6.7870    16.7481      -72.6601     59.0862  \n  1969 1996   3.0338    14.7651      -55.0401     61.1077  \n  1970 1965   3.9098     3.0320       -8.0158     15.8353  \n  1970 1966  -5.7213    10.2335      -45.9715     34.5289  \n  1970 1967  10.0224     8.2269      -22.3354     42.3801  \n  1970 1968  -5.3764     9.1245      -41.2649     30.5121  \n  1970 1969  10.5202     5.3456      -10.5050     31.5454  \n  1970 1970   5.6377     6.8130      -21.1592     32.4347  \n  1970 1971   1.3987     5.0554      -18.4850     21.2825  \n  1970 1972   1.3331     9.7708      -37.0973     39.7634  \n  1970 1973 -13.0254     3.7149      -27.6370      1.5862  \n  1970 1974 -12.7744     4.8887      -32.0024      6.4535  \n  1970 1975 -15.3434     4.8444      -34.3973      3.7105  \n  1970 1976 -19.8605     4.1302      -36.1052     -3.6158 *\n  1970 1977 -19.5551     5.8132      -42.4193      3.3091  \n  1970 1978 -33.3382     6.0197      -57.0147     -9.6617 *\n  1970 1979 -30.5087    13.0564      -81.8620     20.8446  \n  1970 1980 -44.6366     7.8097      -75.3538    -13.9195 *\n  1970 1981 -34.0557    11.2610      -78.3472     10.2359  \n  1970 1982 -38.7875     9.5775      -76.4578     -1.1173 *\n  1970 1983 -32.9234    14.7062      -90.7658     24.9189  \n  1970 1984 -34.0625    10.3838      -74.9040      6.7790  \n  1970 1985 -30.6346    19.3379     -106.6940     45.4247  \n  1970 1986 -37.0754    18.5711     -110.1191     35.9682  \n  1970 1987 -37.6630    11.4929      -82.8668      7.5407  \n  1970 1988 -43.0563    12.8519      -93.6054      7.4927  \n  1970 1989 -45.1314    14.6881     -102.9024     12.6396  \n  1970 1990 -43.1765     8.2585      -75.6588    -10.6942 *\n  1970 1991 -49.9116     9.3412      -86.6523    -13.1710 *\n  1970 1992 -50.9515    14.7946     -109.1415      7.2385  \n  1970 1993 -44.5526    12.3309      -93.0521      3.9469  \n  1970 1994 -51.5405    17.7129     -121.2086     18.1275  \n  1970 1995 -48.4108    17.3598     -116.6900     19.8684  \n  1970 1996 -48.0618    17.3677     -116.3721     20.2486  \n  1971 1965  -0.3060     3.7195      -14.9355     14.3235  \n  1971 1966 -12.4375    10.1068      -52.1894     27.3145  \n  1971 1967  17.0967     8.9518      -18.1124     52.3059  \n  1971 1968   2.6186     7.8337      -28.1928     33.4301  \n  1971 1969  -2.1268     5.6879      -24.4986     20.2449  \n  1971 1970   5.7625     7.7940      -24.8930     36.4179  \n  1971 1971  -9.3866     7.3095      -38.1364     19.3631  \n  1971 1972 -13.8393     7.8472      -44.7039     17.0252  \n  1971 1973 -12.4602     8.8642      -47.3246     22.4042  \n  1971 1974   0.1729     5.4372      -21.2124     21.5582  \n  1971 1975  -8.8785     8.3259      -41.6259     23.8688  \n  1971 1976  -7.7923     6.2332      -32.3085     16.7239  \n  1971 1977  -6.3192     8.3983      -39.3512     26.7128  \n  1971 1978 -17.4985    10.6874      -59.5339     24.5368  \n  1971 1979 -16.1999     6.1053      -40.2130      7.8132  \n  1971 1980 -22.5395     5.5357      -44.3124     -0.7666 *\n  1971 1981 -12.5894     8.2590      -45.0736     19.8949  \n  1971 1982 -20.6385    11.4796      -65.7899     24.5128  \n  1971 1983 -11.0888     5.9947      -34.6671     12.4894  \n  1971 1984 -12.7478     6.5444      -38.4881     12.9925  \n  1971 1985  -9.3683     8.4171      -42.4742     23.7377  \n  1971 1986 -16.9260     7.4075      -46.0609     12.2089  \n  1971 1987 -12.9962    11.6584      -58.8510     32.8586  \n  1971 1988 -14.6487     8.8020      -49.2688     19.9713  \n  1971 1989 -18.7126     9.8454      -57.4363     20.0112  \n  1971 1990 -17.6198     7.2596      -46.1732     10.9336  \n  1971 1991 -17.2789     9.5731      -54.9316     20.3739  \n  1971 1992 -22.1825    10.3351      -62.8324     18.4675  \n  1971 1993  -9.1278     9.7369      -47.4249     29.1693  \n  1971 1994 -13.7091     8.9343      -48.8493     21.4311  \n  1971 1995 -15.3270     7.4825      -44.7570     14.1029  \n  1971 1996 -11.2124    10.0316      -50.6685     28.2437  \n  1972 1965   3.3603     2.3466       -5.8694     12.5899  \n  1972 1966  -5.2709    11.1945      -49.3008     38.7591  \n  1972 1967   8.3599     8.8504      -26.4504     43.1702  \n  1972 1968   5.3444     7.5268      -24.2597     34.9485  \n  1972 1969  -6.1540     5.3509      -27.2001     14.8921  \n  1972 1970   5.3754     6.1409      -18.7780     29.5289  \n  1972 1971  -0.7708     5.9095      -24.0138     22.4722  \n  1972 1972  -5.3078     4.9781      -24.8874     14.2718  \n  1972 1973  -7.1261     9.0891      -42.8754     28.6231  \n  1972 1974  -4.3635     5.3193      -25.2853     16.5583  \n  1972 1975 -10.7104     6.8621      -37.7005     16.2796  \n  1972 1976  -8.5659     8.8089      -43.2130     26.0811  \n  1972 1977  -1.7264     4.3195      -18.7158     15.2630  \n  1972 1978 -19.5471     8.2612      -52.0401     12.9459  \n  1972 1979  -9.7870    10.3134      -50.3514     30.7774  \n  1972 1980 -16.4149     5.8059      -39.2506      6.4207  \n  1972 1981  -4.6831     5.0252      -24.4483     15.0821  \n  1972 1982  -9.8129     8.3907      -42.8151     23.1894  \n  1972 1983  -5.7570     6.9716      -33.1777     21.6637  \n  1972 1984 -11.1817     6.3013      -35.9659     13.6025  \n  1972 1985  -8.5492     8.0820      -40.3374     23.2389  \n  1972 1986  -3.2909     6.0279      -26.9998     20.4181  \n  1972 1987 -14.5853     7.6227      -44.5666     15.3960  \n  1972 1988 -12.6795     6.4902      -38.2066     12.8477  \n  1972 1989 -10.9845     6.4610      -36.3966     14.4277  \n  1972 1990  -7.7794     7.5706      -37.5558     21.9970  \n  1972 1991 -13.7033     5.3714      -34.8298      7.4233  \n  1972 1992 -11.0100     8.7457      -45.4084     23.3884  \n  1972 1993 -17.3770     7.3155      -46.1500     11.3960  \n  1972 1994 -16.6543     7.6975      -46.9302     13.6215  \n  1972 1995 -16.0626     6.6958      -42.3983     10.2730  \n  1972 1996 -13.6292     5.2614      -34.3234      7.0651  \n  1973 1965   0.3154     3.5419      -13.6154     14.2462  \n  1973 1966 -10.0893    10.2799      -50.5220     30.3433  \n  1973 1967  16.0570     8.8764      -18.8556     50.9697  \n  1973 1968  -4.8486     8.3368      -37.6388     27.9416  \n  1973 1969   3.3129     5.6644      -18.9664     25.5921  \n  1973 1970   5.5555     7.7076      -24.7598     35.8708  \n  1973 1971  -2.0683     7.8127      -32.7972     28.6606  \n  1973 1972  -0.9275     6.9534      -28.2764     26.4213  \n  1973 1973   4.4106     8.5855      -29.3580     38.1791  \n  1973 1974   3.2944     6.1061      -20.7222     27.3109  \n  1973 1975   0.0725    11.2892      -44.3298     44.4749  \n  1973 1976  -1.1180     6.6493      -27.2707     25.0348  \n  1973 1977   2.7203     5.8841      -20.4228     25.8634  \n  1973 1978 -10.3862     9.4844      -47.6902     26.9178  \n  1973 1979  -3.4722     7.3696      -32.4581     25.5137  \n  1973 1980 -11.7465     7.7891      -42.3827     18.8896  \n  1973 1981  -3.1322     7.5434      -32.8018     26.5373  \n  1973 1982  -7.8264    11.1179      -51.5550     35.9021  \n  1973 1983  -4.3281     6.3003      -29.1082     20.4521  \n  1973 1984 -10.3847     6.9307      -37.6444     16.8751  \n  1973 1985  -3.3503     7.3002      -32.0632     25.3625  \n  1973 1986  -9.9416     4.7131      -28.4790      8.5958  \n  1973 1987 -10.5611     9.2516      -46.9495     25.8273  \n  1973 1988 -13.3770    10.1765      -53.4029     26.6490  \n  1973 1989  -9.7072     7.5140      -39.2613     19.8469  \n  1973 1990 -12.5464     6.6770      -38.8085     13.7156  \n  1973 1991 -15.9396     7.9245      -47.1082     15.2290  \n  1973 1992 -17.9985     7.9156      -49.1318     13.1348  \n  1973 1993 -13.8426     8.6409      -47.8289     20.1437  \n  1973 1994  -9.0985     6.3839      -34.2074     16.0105  \n  1973 1995 -12.4104     3.9296      -27.8663      3.0455  \n  1973 1996 -14.4985     5.8760      -37.6100      8.6130  \n  1974 1965  -1.7117     5.6180      -23.8081     20.3848  \n  1974 1966  -3.7313    11.1044      -47.4072     39.9445  \n  1974 1967   9.6967     8.9202      -25.3881     44.7816  \n  1974 1968  -5.6736     7.7912      -36.3177     24.9705  \n  1974 1969   4.7497     5.3413      -16.2584     25.7579  \n  1974 1970   8.9528     5.9228      -14.3428     32.2483  \n  1974 1971  -8.1562     5.9562      -31.5832     15.2708  \n  1974 1972   5.1631     4.2098      -11.3947     21.7209  \n  1974 1973  -4.1358     7.8963      -35.1936     26.9219  \n  1974 1974  -1.5277     4.7412      -20.1759     17.1205  \n  1974 1975  -0.2490     5.1089      -20.3434     19.8454  \n  1974 1976  -4.6623     3.9210      -20.0842     10.7596  \n  1974 1977  -3.6545     7.4242      -32.8553     25.5464  \n  1974 1978  -9.4996     5.6012      -31.5302     12.5309  \n  1974 1979  -1.7953     9.8263      -40.4438     36.8532  \n  1974 1980 -10.9157     5.3148      -31.8196      9.9883  \n  1974 1981  -2.9438     7.6271      -32.9426     27.0551  \n  1974 1982  -6.1358     5.2653      -26.8454     14.5738  \n  1974 1983  -2.2347     7.8832      -33.2405     28.7712  \n  1974 1984  -7.2784     6.7759      -33.9293     19.3725  \n  1974 1985   0.9048    10.9520      -42.1713     43.9810  \n  1974 1986  -3.4953     8.7938      -38.0830     31.0924  \n  1974 1987  -9.3045     8.5199      -42.8149     24.2059  \n  1974 1988  -9.0434     8.7834      -43.5902     25.5033  \n  1974 1989  -6.4758    10.2036      -46.6086     33.6570  \n  1974 1990  -7.6369     8.7936      -42.2238     26.9500  \n  1974 1991 -14.7133     8.0070      -46.2065     16.7799  \n  1974 1992 -14.7711     8.1683      -46.8986     17.3565  \n  1974 1993 -11.2274     9.1163      -47.0837     24.6288  \n  1974 1994 -14.4350    11.1051      -58.1135     29.2435  \n  1974 1995 -13.4194     9.9518      -52.5618     25.7231  \n  1974 1996 -14.8017    10.5500      -56.2967     26.6933  \n  1975 1965  19.2544    14.4193      -37.4592     75.9681  \n  1975 1966 -10.7092     9.6959      -48.8451     27.4267  \n  1975 1967   9.6526     8.8040      -24.9752     44.2803  \n  1975 1968   5.2146     8.1132      -26.6961     37.1254  \n  1975 1969  -2.1343     7.5082      -31.6656     27.3970  \n  1975 1970  -5.6035     9.5772      -43.2723     32.0654  \n  1975 1971   3.4917     9.4385      -33.6317     40.6150  \n  1975 1972 -15.0108     7.4261      -44.2192     14.1976  \n  1975 1973   9.7321     7.4305      -19.4935     38.9577  \n  1975 1974   0.5633     6.2650      -24.0779     25.2045  \n  1975 1975  -4.9361     7.2901      -33.6093     23.7371  \n  1975 1976  -1.1020     4.3675      -18.2802     16.0762  \n  1975 1977  -4.3766     8.9458      -39.5622     30.8089  \n  1975 1978  -8.3191     8.1539      -40.3897     23.7515  \n  1975 1979 -12.7262    14.7290      -70.6579     45.2056  \n  1975 1980 -12.3662     5.6861      -34.7308      9.9985  \n  1975 1981  -7.7023     6.2392      -32.2424     16.8377  \n  1975 1982  -9.7198     8.1205      -41.6591     22.2195  \n  1975 1983  -7.3926     5.9149      -30.6572     15.8720  \n  1975 1984   8.8507     5.6226      -13.2642     30.9655  \n  1975 1985  -5.6163     8.3174      -38.3301     27.0975  \n  1975 1986  -5.2183     5.1726      -25.5630     15.1263  \n  1975 1987  -0.8638     5.2844      -21.6483     19.9208  \n  1975 1988 -15.3668    11.9412      -62.3337     31.6001  \n  1975 1989  -5.4933     6.3673      -30.5370     19.5504  \n  1975 1990   8.5067     5.8913      -14.6648     31.6781  \n  1975 1991   0.7631     6.0860      -23.1742     24.7004  \n  1975 1992  -4.2255     6.3457      -29.1845     20.7335  \n  1975 1993   1.1200     2.5499       -8.9093     11.1493  \n  1975 1994  -8.3655     7.7875      -38.9953     22.2644  \n  1975 1995   1.8041     3.8506      -13.3412     16.9494  \n  1975 1996  -6.9207     5.8457      -29.9130     16.0716  \n  1976 1965  -9.2525     2.2650      -18.1613     -0.3438 *\n  1976 1966  -7.3839    10.1469      -47.2935     32.5257  \n  1976 1967   6.1953     8.7761      -28.3226     40.7133  \n  1976 1968  -3.4100     7.6537      -33.5135     26.6936  \n  1976 1969  -4.5734     5.3509      -25.6195     16.4726  \n  1976 1970  13.6356     5.7737       -9.0733     36.3445  \n  1976 1971   2.1590     5.5379      -19.6227     23.9407  \n  1976 1972  -1.4512     4.0247      -17.2810     14.3785  \n  1976 1973 -23.5440     6.8621      -50.5339      3.4459  \n  1976 1974  37.6970     4.2785       20.8687     54.5253 *\n  1976 1975  -5.8620     9.0069      -41.2878     29.5638  \n  1976 1976   7.3375     6.7834      -19.3427     34.0178  \n  1976 1977  35.4928     7.3478        6.5927     64.3928 *\n  1976 1978  -2.2158     3.3756      -15.4927     11.0611  \n  1976 1979   2.7599    11.1105      -40.9399     46.4597  \n  1976 1980 -10.1277     6.1553      -34.3376     14.0821  \n  1976 1981  -9.1249     7.6546      -39.2320     20.9822  \n  1976 1982  -9.7529     5.2585      -30.4357     10.9298  \n  1976 1983 -12.2793     9.8103      -50.8650     26.3063  \n  1976 1984 -20.1148     7.4221      -49.3072      9.0776  \n  1976 1985  -0.2053    16.2410      -64.0843     63.6737  \n  1976 1986 -27.7992     8.4682      -61.1061      5.5078  \n  1976 1987  -9.9985     4.4562      -27.5254      7.5285  \n  1976 1988 -22.8540     6.0525      -46.6598      0.9517  \n  1976 1989 -14.3020     6.6385      -40.4124     11.8084  \n  1976 1990 -16.7275     5.9040      -39.9490      6.4940  \n  1976 1991 -29.9838     5.5425      -51.7835     -8.1842 *\n  1976 1992 -35.9431     6.3141      -60.7776    -11.1085 *\n  1976 1993 -33.5630     6.7582      -60.1441     -6.9819 *\n  1976 1994 -19.1785    13.9477      -74.0376     35.6805  \n  1976 1995 -18.8943     9.7949      -57.4196     19.6310  \n  1976 1996 -20.0712     8.0000      -51.5365     11.3941  \n  1977 1965   7.9420    16.0486      -55.1800     71.0640  \n  1977 1966 -17.8103    12.2291      -65.9096     30.2890  \n  1977 1967  22.0500     9.0966      -13.7287     57.8287  \n  1977 1968 -12.0551    11.9722      -59.1438     35.0337  \n  1977 1969  11.3299    12.9816      -39.7289     62.3888  \n  1977 1970   7.9543     8.3567      -24.9143     40.8229  \n  1977 1971   0.9514     9.4714      -36.3015     38.2044  \n  1977 1972  -1.0798     9.8947      -39.9975     37.8379  \n  1977 1973  -2.0153     9.6612      -40.0145     35.9839  \n  1977 1974 -10.4409     6.1944      -34.8044     13.9226  \n  1977 1975  -2.6782     7.3530      -31.5988     26.2424  \n  1977 1976   7.5869    19.3117      -68.3697     83.5434  \n  1977 1977  -0.3083    20.7163      -81.7892     81.1727  \n  1977 1978 -18.5991    21.4894     -103.1207     65.9226  \n  1977 1979  -8.3001    28.5726     -120.6815    104.0813  \n  1977 1980 -13.4381    34.6908     -149.8834    123.0072  \n  1977 1981 -12.1467    24.5037     -108.5245     84.2310  \n  1977 1982 -17.4639    18.0748      -88.5555     53.6277  \n  1977 1983   6.1362    33.2051     -124.4656    136.7381  \n  1977 1984  -2.9191    27.5084     -111.1147    105.2765  \n  1977 1985 -14.8995    22.0204     -101.5096     71.7106  \n  1977 1986 -12.3230    15.3699      -72.7755     48.1296  \n  1977 1987 -23.6769    34.1401     -157.9562    110.6024  \n  1977 1988 -25.5547    22.8094     -115.2684     64.1590  \n  1977 1989  -9.2602    41.7259     -173.3757    154.8552  \n  1977 1990 -13.7369    45.9741     -194.5615    167.0877  \n  1977 1991 -25.9731    36.3233     -168.8395    116.8933  \n  1977 1992 -29.9220    24.6738     -126.9684     67.1244  \n  1977 1993 -14.9531    37.7255     -163.3344    133.4283  \n  1977 1994 -11.6033    49.7976     -207.4666    184.2599  \n  1977 1995 -29.0098    23.4604     -121.2837     63.2641  \n  1977 1996 -16.0590    29.2264     -131.0118     98.8938  \n  1980 1965  -3.1314     2.2650      -12.0401      5.7773  \n  1980 1966  -9.4644    10.1469      -49.3741     30.4452  \n  1980 1967  12.2092     8.7761      -22.3087     46.7271  \n  1980 1968   3.0528     7.6537      -27.0508     33.1563  \n  1980 1969  -3.6543     5.3509      -24.7004     17.3917  \n  1980 1970  12.7725     5.7737       -9.9364     35.4814  \n  1980 1971 -11.0126     5.5379      -32.7943     10.7691  \n  1980 1972   5.2094     4.0247      -10.6204     21.0391  \n  1980 1973  -8.0378     6.8621      -35.0277     18.9521  \n  1980 1974   2.0132     4.2785      -14.8151     18.8415  \n  1980 1975  -3.8913     9.0069      -39.3171     31.5344  \n  1980 1976   4.9514     6.7834      -21.7289     31.6316  \n  1980 1977  -1.8244     3.7163      -16.4411     12.7924  \n  1980 1978  -6.3410     7.7499      -36.8229     24.1410  \n  1980 1979   5.7875    11.5127      -39.4942     51.0692  \n  1980 1980 -12.0465     7.0875      -39.9230     15.8301  \n  1980 1981  -7.2766     3.4559      -20.8693      6.3161  \n  1980 1982  -7.7888    13.7039      -61.6887     46.1112  \n  1980 1983   3.8986     3.7649      -10.9094     18.7066  \n  1980 1984  -2.3172     6.3267      -27.2013     22.5668  \n  1980 1985   4.4467     5.1164      -15.6769     24.5703  \n  1980 1986  -9.5981     6.5701      -35.4396     16.2433  \n  1980 1987 -10.0537    11.3335      -54.6305     34.5231  \n  1980 1988 -10.9789     9.1300      -46.8887     24.9310  \n  1980 1989  -6.9527     6.3603      -31.9688     18.0635  \n  1980 1990  -5.3312     6.2450      -29.8938     19.2315  \n  1980 1991  -8.8820     8.2207      -41.2154     23.4513  \n  1980 1992 -12.0023     9.9672      -51.2050     27.2005  \n  1980 1993  -8.3192     7.5524      -38.0241     21.3858  \n  1980 1994 -12.5474     7.1011      -40.4775     15.3826  \n  1980 1995  -6.7308     8.7926      -41.3137     27.8521  \n  1980 1996  -9.1678     7.0565      -36.9225     18.5868  \n  1984 1965   3.7550     2.2650       -5.1537     12.6638  \n  1984 1966  -9.0520    10.1469      -48.9616     30.8576  \n  1984 1967  10.1591     8.7761      -24.3588     44.6771  \n  1984 1968  -3.1247     7.6537      -33.2283     26.9788  \n  1984 1969   4.0091     5.3509      -17.0369     25.0552  \n  1984 1970   4.9470     5.7737      -17.7618     27.6559  \n  1984 1971 -12.3840     5.5379      -34.1658      9.3977  \n  1984 1972   5.1482     4.0247      -10.6815     20.9780  \n  1984 1973  -6.4124     6.8621      -33.4022     20.5775  \n  1984 1974  -5.7358     4.2785      -22.5641     11.0925  \n  1984 1975  -4.0919     9.0069      -39.5176     31.3339  \n  1984 1976   8.7209     6.7834      -17.9593     35.4011  \n  1984 1977   2.6679     3.7163      -11.9489     17.2846  \n  1984 1978  -7.3955     7.7499      -37.8775     23.0864  \n  1984 1979   2.2253    11.5127      -43.0565     47.5070  \n  1984 1980  -8.3661     7.0875      -36.2426     19.5105  \n  1984 1981  10.0008     5.6947      -12.3976     32.3991  \n  1984 1982  -3.2324    10.2480      -43.5396     37.0748  \n  1984 1983  11.0979    10.4009      -29.8106     52.0063  \n  1984 1984  -1.6979     3.0237      -13.5905     10.1947  \n  1984 1985   4.0744     6.4308      -21.2189     29.3677  \n  1984 1986  -8.0341     2.9094      -19.4773      3.4092  \n  1984 1987 -10.4189     8.0305      -42.0042     21.1664  \n  1984 1988  -7.8277     5.8269      -30.7461     15.0907  \n  1984 1989  -9.2894     3.8762      -24.5352      5.9565  \n  1984 1990  -6.2529     2.9419      -17.8241      5.3182  \n  1984 1991 -10.1584     5.2819      -30.9332     10.6164  \n  1984 1992 -11.4694     6.6641      -37.6807     14.7418  \n  1984 1993  -9.2844     4.4284      -26.7022      8.1333  \n  1984 1994 -14.6630     5.2893      -35.4667      6.1408  \n  1984 1995 -12.5044     3.7261      -27.1598      2.1510  \n  1984 1996 -10.2449     3.2720      -23.1143      2.6246  \n  1985 1965  -2.7099     2.2650      -11.6186      6.1988  \n  1985 1966  29.3180    10.1469      -10.5916     69.2277  \n  1985 1967  -6.8558     8.7761      -41.3737     27.6621  \n  1985 1968  -5.9545     7.6537      -36.0581     24.1490  \n  1985 1969  12.1675     5.3509       -8.8785     33.2136  \n  1985 1970  12.3074     5.7737      -10.4015     35.0163  \n  1985 1971   4.9424     5.5379      -16.8393     26.7241  \n  1985 1972   5.1718     4.0247      -10.6579     21.0016  \n  1985 1973 -41.2443     6.8621      -68.2342    -14.2545 *\n  1985 1974   9.0064     4.2785       -7.8219     25.8348  \n  1985 1975  -9.1424     9.0069      -44.5681     26.2834  \n  1985 1976   2.8125     6.7834      -23.8677     29.4927  \n  1985 1977  -2.1400     3.7163      -16.7567     12.4768  \n  1985 1978   5.7781     7.7499      -24.7038     36.2601  \n  1985 1979  -3.8368    11.5127      -49.1185     41.4450  \n  1985 1980   1.5265     7.0875      -26.3500     29.4031  \n  1985 1981  -2.8105     5.6947      -25.2088     19.5878  \n  1985 1982  13.2242    10.2480      -27.0831     53.5314  \n  1985 1983  -5.5714    10.4009      -46.4799     35.3371  \n  1985 1984  -5.5493     3.0237      -17.4419      6.3433  \n  1985 1985  11.4728     8.5549      -22.1750     45.1206  \n  1985 1986  10.1715     3.4372       -3.3478     23.6908  \n  1985 1987  17.5291     5.0068       -2.1636     37.2218  \n  1985 1988  -9.6423     3.9206      -25.0627      5.7782  \n  1985 1989  19.8229     5.3527       -1.2303     40.8760  \n  1985 1990  26.2350     2.5434       16.2314     36.2385 *\n  1985 1991   6.2209     3.5620       -7.7891     20.2310  \n  1985 1992  18.3602     6.2606       -6.2638     42.9841  \n  1985 1993  23.0343     2.8585       11.7915     34.2771 *\n  1985 1994  15.2612     6.2622       -9.3691     39.8916  \n  1985 1995  15.4633     4.9242       -3.9044     34.8310  \n  1985 1996  26.5282     3.9405       11.0296     42.0269 *\n---\nSignif. codes: `*' confidence band does not cover 0\n\nControl Group:  Never Treated,  Anticipation Periods:  0\nEstimation Method:  Outcome Regression\n\nggdid(atts_nyt)\n\n\n\n\n[10 puntos] Reporte los resultados agregados obtenidos a partir del estimador Callaway & Sant’Anna (2021), usando una agregación dinámica que muestre los efectos promedio para cada periodo antes y después del tratamiento. Grafique los resultados.\nGraficamos:\n\nagg.es &lt;- aggte(atts_nyt,\n                type = \"dynamic\")\nsummary(agg.es)\n\n\nCall:\naggte(MP = atts_nyt, type = \"dynamic\")\n\nReference: Callaway, Brantly and Pedro H.C. Sant'Anna.  \"Difference-in-Differences with Multiple Time Periods.\" Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. &lt;https://doi.org/10.1016/j.jeconom.2020.12.001&gt;, &lt;https://arxiv.org/abs/1803.09015&gt; \n\n\nOverall summary of ATT's based on event-study/dynamic aggregation:  \n      ATT    Std. Error     [ 95%  Conf. Int.]  \n -11.1957        3.7505   -18.5465     -3.8448 *\n\n\nDynamic Effects:\n Event time Estimate Std. Error [95% Simult.  Conf. Band]  \n        -20  -2.7099     2.5607       -9.7316      4.3118  \n        -19  16.5365     9.8342      -10.4299     43.5030  \n        -18  -7.9539     1.7929      -12.8702     -3.0376 *\n        -17   2.1023     5.9979      -14.3445     18.5492  \n        -16   4.5214     5.7379      -11.2124     20.2552  \n        -15   4.3951     5.0594       -9.4783     18.2684  \n        -14   0.1417     4.7473      -12.8760     13.1594  \n        -13   1.6657     6.8160      -17.0244     20.3557  \n        -12  -1.5362     9.8503      -28.5466     25.4742  \n        -11  -9.1062     5.8890      -25.2545      7.0420  \n        -10  10.5744     5.9761       -5.8126     26.9613  \n         -9  -5.7346     3.9427      -16.5458      5.0766  \n         -8   2.3457     2.4518       -4.3773      9.0686  \n         -7  -1.6033     3.8162      -12.0678      8.8613  \n         -6   4.3835     3.2669       -4.5747     13.3416  \n         -5  -3.0193     3.3486      -12.2016      6.1630  \n         -4   4.8722     2.5824       -2.2089     11.9534  \n         -3  -0.3596     2.3817       -6.8905      6.1713  \n         -2   1.1409     2.4245       -5.5072      7.7891  \n         -1   1.9481     2.9949       -6.2641     10.1602  \n          0  -0.8065     2.5825       -7.8880      6.2751  \n          1  -2.7726     3.0722      -11.1969      5.6517  \n          2  -4.2845     4.1906      -15.7755      7.2065  \n          3  -3.9743     2.7938      -11.6352      3.6866  \n          4  -4.5620     3.4012      -13.8884      4.7645  \n          5  -7.4465     3.0625      -15.8442      0.9513  \n          6  -6.2541     3.6575      -16.2834      3.7752  \n          7 -10.6094     3.6823      -20.7065     -0.5123 *\n          8  -9.9746     3.7565      -20.2754      0.3262  \n          9 -10.1110     3.5969      -19.9740     -0.2479 *\n         10 -11.0023     4.0832      -22.1989      0.1942  \n         11 -12.2896     3.9761      -23.1924     -1.3868 *\n         12  -8.8234     4.4417      -21.0029      3.3562  \n         13 -12.1880     4.5561      -24.6811      0.3051  \n         14 -11.2760     4.6171      -23.9365      1.3845  \n         15 -14.8487     5.2839      -29.3377     -0.3596 *\n         16 -11.6965     4.7960      -24.8476      1.4547  \n         17 -14.3232     4.7327      -27.3007     -1.3456 *\n         18 -17.1010     5.0292      -30.8915     -3.3105 *\n         19 -17.4748     4.3357      -29.3638     -5.5858 *\n         20 -14.9783     4.5176      -27.3661     -2.5905 *\n         21 -15.8960     4.7739      -28.9866     -2.8054 *\n         22 -15.2219     4.2998      -27.0125     -3.4313 *\n         23 -16.2453     5.0785      -30.1710     -2.3195 *\n         24 -17.8714     7.5826      -38.6636      2.9208  \n         25 -17.0567     9.9576      -44.3613     10.2479  \n         26 -27.4244    19.3710      -80.5416     25.6929  \n         27   3.0338    13.1112      -32.9183     38.9859  \n---\nSignif. codes: `*' confidence band does not cover 0\n\nControl Group:  Never Treated,  Anticipation Periods:  0\nEstimation Method:  Outcome Regression\n\nggdid(agg.es)\n\n\n\n\n[5 puntos] ¿Cuáles son las ventajas del estimador de Callaway & Sant’Anna (2021) respecto al estimador de TWFE?\nLas ventajas del estimador de Callaway & Sant’Anna respecto a TWFE son las siguientes: - Evita las comapraciones prohibidas (usar unidades tratadas como controles para unidades que son tratadas en periodos posteriores) - Hace explícito el grupo de comparación que se usa para comparar a las unidades tratadas - Hace explícita la manera en que se agregan los resultados de cada comparación \\(ATT(g,t)\\) - No impone efectos monótonos en el tiempo ni homogéneos entre unidades"
  },
  {
    "objectID": "tareas/tarea-3-respuestas.html#pregunta-1",
    "href": "tareas/tarea-3-respuestas.html#pregunta-1",
    "title": "Respuestas a la tarea 3",
    "section": "",
    "text": "Stevenson, B. & Wolfers, J. (2006)1 estudian los efectos de la introducción de leyes que permiten el divorcio unilateral en los Estados Unidos. La librería bacondecomp incluye los datos usados en dicho artículo (debe instalar y cargar la librería). Usaremos los datos de 1964 a 1996 para mostrar cómo impactan las leyes de divorcio express (unilateral) a la tasa de suicidios en mujeres.\nAl correr el pedazo de código anterior, obtendrá un objeto de datos wd en donde la variable de impacto es la tasa de suicidios en mujeres, suicide_rate, st identifica a los estados, year identifica a los años y divyear es el año en que se introdujo la legislación del divorcio unilateral. La última fila del código crea el indicador de tratamiento unilaterial, que toma el valor de 1 para los estados tratados en los periodos post tratamiento.\n\nwd &lt;- divorce %&gt;% \nfilter(year&gt;=1964 & year&lt;=1996 & sex==2) %&gt;% \nmutate(suicide_rate=suicide*1000000/(stpop*fshare),\n   year=as.numeric(year),\n   divyear = ifelse(divyear&gt;1996, Inf, divyear),\n   unilateral=ifelse(year&gt;divyear, 1, 0))\n\n\n[5 puntos] ¿Por qué decimos que esta es una aplicación de la estimación de efectos de tratamiento con adopción escalonada?\nEn esta aplicación, cada estado comienza a ser tratado en indistintos momentos del tiempo. Si hacemos un tabulado de divyear para un año fijo, notamos cuántos estados se vuelven tratados en cada año:\n\ntable(filter(wd, year==1996)$divyear)\n\n\n1950 1969 1970 1971 1972 1973 1974 1975 1976 1977 1980 1984 1985  Inf \n   9    2    2    7    3   11    3    2    1    3    1    1    1    5 \n\n\nEl panel comienza en 1964, para cuando ya nueve estados habían sido tratados. Los estados van siendo tratados hasta que, para el fin del periodo analizado, 1996, solo cinco todavía no habían sido tratados. En esta aplicación, esos cinco estados son los nunca tratados.\n[5 puntos] Como punto de partida, estime el efecto del tratamiento sobre suicide_rate usando efectos fijos por estado y año (TWFE) y empleando una librería específica para efectos fijos, como felm. Tome en cuenta la agrupación de los errores. Interprete sus resultados.\nUsando felm:\n\nsummary(felm(suicide_rate ~ unilateral | st + year | 0 | st,\n              data = wd))\n\n\nCall:\n   felm(formula = suicide_rate ~ unilateral | st + year | 0 | st,      data = wd) \n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-37.517  -6.157  -0.141   5.577  57.004 \n\nCoefficients:\n           Estimate Cluster s.e. t value Pr(&gt;|t|)  \nunilateral   -3.777        2.201  -1.716   0.0923 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.85 on 1599 degrees of freedom\nMultiple R-squared(full model): 0.6844   Adjusted R-squared: 0.668 \nMultiple R-squared(proj model): 0.007963   Adjusted R-squared: -0.04353 \nF-statistic(full model, *iid*):41.77 on 83 and 1599 DF, p-value: &lt; 2.2e-16 \nF-statistic(proj model): 2.945 on 1 and 50 DF, p-value: 0.09231 \n\n\n[5 puntos] Compruebe que puede obtener el mismo resultado con una regresión lineal usando el paquete lm e incluyendo, además de la variable de tratamiento, dummies de estado y de año.\nEstimamos con dummies:\n\nsummary(m1 &lt;- lm(suicide_rate ~ unilateral + factor(st) + factor(year),\n              data = wd))$coef[1:2,1:3]\n\n             Estimate Std. Error   t value\n(Intercept) 56.732642   2.468251 22.984953\nunilateral  -3.776552   1.054148 -3.582562\n\n\nLuego estimamos errores agrupados:\n\nstargazer(m1,\n          type = 'text',\n          se = list(sqrt(diag(vcovCR(m1, cluster = wd$st, type = 'CR1')))),\n          keep = c(\"unilateral\"))\n\n\n===============================================\n                        Dependent variable:    \n                    ---------------------------\n                           suicide_rate        \n-----------------------------------------------\nunilateral                    -3.777*          \n                              (2.200)          \n\n-----------------------------------------------\nObservations                   1,683           \nR2                             0.684           \nAdjusted R2                    0.668           \nResidual Std. Error     10.851 (df = 1599)     \nF Statistic          41.770*** (df = 83; 1599) \n===============================================\nNote:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nObtenemos los mismos coeficientes. Aquí también podrán volver a comprobar la importancia de usar errores agrupados. Sin agrupar, el error estimado asumiendo independencia es casi menos de la mitad que el estimado con la matriz de varianzas agrupada.\n[10 puntos] Realice la descomposición de Goodman-Bacon (2021). Construya un gráfico donde muestre en el eje \\(x\\) el peso otorgado a cada comparación 2x2 que el estimador de TWFE realiza mecánicamente y en el eje \\(y\\) el efecto estimado correspondiente a cada comparación. Interprete el gráfico obtenido.\nComo vimos en clase, la descomposición de Bacon se puede obtener con la función bacon:\n\n#Goodman-Bacon decomposition\ndf_bacon &lt;- bacon(suicide_rate ~ unilateral,\n                  data = wd,\n                  id_var = \"st\",\n                  time_var = \"year\")\n\n                      type  weight  avg_est\n1 Earlier vs Later Treated 0.11558  0.13489\n2  Later vs Always Treated 0.41990 -6.95245\n3 Later vs Earlier Treated 0.23125  2.33743\n4     Treated vs Untreated 0.23328 -6.05881\n\ncoef_bacon &lt;- sum(df_bacon$estimate * df_bacon$weight)\nprint(paste(\"Weighted sum of decomposition =\", round(coef_bacon, 4)))\n\n[1] \"Weighted sum of decomposition = -3.7766\"\n\ntwfe &lt;- felm(suicide_rate ~ unilateral | st + year | 0 | st,\n              data = wd)\n\n#Gráfico----\ndf_bacon %&gt;% \n  ggplot(aes(x=weight,\n             y=estimate,\n             shape=type)) +\n  geom_point() +\n  geom_hline(yintercept = round(twfe$coefficients, 4))\n\n\n\n\nLas comparaciones que más pesan en el estimador de efectos fijos son las de estados tratados con los que siempre estuvieron tratados en el panel, recibiendo dos de esas comparaciones alrededor de 13 y el 7% del peso (los dos triángulos más hacia la derecha). otra comparación que recibe alrededor de 7% del peso es la de los tratados con los nunca tratados (cruz más hacia la derecha). En total, las comparaciones con los estados que iniciaron siendo tratados se llevan el 42% del peso. Las comparaciones entre los tratados tarde y los tratados temprano también reciben un peso alto de 23%.\n[10 puntos] Implemente el estimador de Callaway & Sant’Anna (2021) para estimar los efectos del tratamiento específicos para cada cohorte, usando el paquete did. Utilice como grupo de comparación los estados nunca tratados. La columna stid es un identificador numérico de los estados (lo requerirá cuando use att_gt del paquete did).\n\natts_nyt &lt;- att_gt(yname = \"suicide_rate\",\n                      tname = \"year\",\n                      idname = \"stid\",\n                      gname = \"divyear\",\n                      data = wd,\n                      control_group = \"nevertreated\",\n                      est_method = 'reg',\n                      bstrap = TRUE,\n                      biters = 1000,\n                      print_details = FALSE,\n                      panel = TRUE)\nsummary(atts_nyt)\n\n\nCall:\natt_gt(yname = \"suicide_rate\", tname = \"year\", idname = \"stid\", \n    gname = \"divyear\", data = wd, panel = TRUE, control_group = \"nevertreated\", \n    bstrap = TRUE, biters = 1000, est_method = \"reg\", print_details = FALSE)\n\nReference: Callaway, Brantly and Pedro H.C. Sant'Anna.  \"Difference-in-Differences with Multiple Time Periods.\" Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. &lt;https://doi.org/10.1016/j.jeconom.2020.12.001&gt;, &lt;https://arxiv.org/abs/1803.09015&gt; \n\nGroup-Time Average Treatment Effects:\n Group Time ATT(g,t) Std. Error [95% Simult.  Conf. Band]  \n  1969 1965  -0.2781     6.8497      -27.2193     26.6632  \n  1969 1966  -3.1857    12.1574      -51.0031     44.6317  \n  1969 1967  12.5043     9.0500      -23.0910     48.0996  \n  1969 1968   3.1310     7.6537      -26.9725     33.2346  \n  1969 1969   1.1566     6.5207      -24.4905     26.8037  \n  1969 1970  -3.5412    13.3245      -55.9490     48.8667  \n  1969 1971  -6.7647    11.0935      -50.3975     36.8682  \n  1969 1972   1.7696    11.9793      -45.3473     48.8864  \n  1969 1973   2.7611     7.4326      -26.4726     31.9948  \n  1969 1974  -0.3084     8.9068      -35.3405     34.7237  \n  1969 1975  -0.7421     5.7094      -23.1983     21.7142  \n  1969 1976 -10.6073     7.6156      -40.5608     19.3462  \n  1969 1977  -3.9320    11.4296      -48.8867     41.0227  \n  1969 1978 -14.0099    12.0164      -61.2727     33.2528  \n  1969 1979  -8.1059    14.7684      -66.1926     49.9807  \n  1969 1980 -10.6943     7.7519      -41.1838     19.7953  \n  1969 1981  -3.4755    12.0847      -51.0070     44.0559  \n  1969 1982  -7.0072     9.0613      -42.6469     28.6326  \n  1969 1983   5.1998    13.3936      -47.4799     57.8794  \n  1969 1984 -10.0771    12.9116      -60.8607     40.7064  \n  1969 1985   5.9598    17.2201      -61.7700     73.6896  \n  1969 1986  -8.5962    12.7169      -58.6141     41.4217  \n  1969 1987  -8.6897     7.9645      -40.0156     22.6362  \n  1969 1988 -11.9815     8.3038      -44.6420     20.6790  \n  1969 1989  -5.9781    14.7386      -63.9477     51.9916  \n  1969 1990  -7.7327    11.1956      -51.7669     36.3016  \n  1969 1991 -14.7659    11.4140      -59.6591     30.1273  \n  1969 1992  -6.6956     6.6277      -32.7637     19.3725  \n  1969 1993   0.5290    12.2110      -47.4993     48.5573  \n  1969 1994  -6.1575    16.3182      -70.3401     58.0250  \n  1969 1995  -6.7870    16.7481      -72.6601     59.0862  \n  1969 1996   3.0338    14.7651      -55.0401     61.1077  \n  1970 1965   3.9098     3.0320       -8.0158     15.8353  \n  1970 1966  -5.7213    10.2335      -45.9715     34.5289  \n  1970 1967  10.0224     8.2269      -22.3354     42.3801  \n  1970 1968  -5.3764     9.1245      -41.2649     30.5121  \n  1970 1969  10.5202     5.3456      -10.5050     31.5454  \n  1970 1970   5.6377     6.8130      -21.1592     32.4347  \n  1970 1971   1.3987     5.0554      -18.4850     21.2825  \n  1970 1972   1.3331     9.7708      -37.0973     39.7634  \n  1970 1973 -13.0254     3.7149      -27.6370      1.5862  \n  1970 1974 -12.7744     4.8887      -32.0024      6.4535  \n  1970 1975 -15.3434     4.8444      -34.3973      3.7105  \n  1970 1976 -19.8605     4.1302      -36.1052     -3.6158 *\n  1970 1977 -19.5551     5.8132      -42.4193      3.3091  \n  1970 1978 -33.3382     6.0197      -57.0147     -9.6617 *\n  1970 1979 -30.5087    13.0564      -81.8620     20.8446  \n  1970 1980 -44.6366     7.8097      -75.3538    -13.9195 *\n  1970 1981 -34.0557    11.2610      -78.3472     10.2359  \n  1970 1982 -38.7875     9.5775      -76.4578     -1.1173 *\n  1970 1983 -32.9234    14.7062      -90.7658     24.9189  \n  1970 1984 -34.0625    10.3838      -74.9040      6.7790  \n  1970 1985 -30.6346    19.3379     -106.6940     45.4247  \n  1970 1986 -37.0754    18.5711     -110.1191     35.9682  \n  1970 1987 -37.6630    11.4929      -82.8668      7.5407  \n  1970 1988 -43.0563    12.8519      -93.6054      7.4927  \n  1970 1989 -45.1314    14.6881     -102.9024     12.6396  \n  1970 1990 -43.1765     8.2585      -75.6588    -10.6942 *\n  1970 1991 -49.9116     9.3412      -86.6523    -13.1710 *\n  1970 1992 -50.9515    14.7946     -109.1415      7.2385  \n  1970 1993 -44.5526    12.3309      -93.0521      3.9469  \n  1970 1994 -51.5405    17.7129     -121.2086     18.1275  \n  1970 1995 -48.4108    17.3598     -116.6900     19.8684  \n  1970 1996 -48.0618    17.3677     -116.3721     20.2486  \n  1971 1965  -0.3060     3.7195      -14.9355     14.3235  \n  1971 1966 -12.4375    10.1068      -52.1894     27.3145  \n  1971 1967  17.0967     8.9518      -18.1124     52.3059  \n  1971 1968   2.6186     7.8337      -28.1928     33.4301  \n  1971 1969  -2.1268     5.6879      -24.4986     20.2449  \n  1971 1970   5.7625     7.7940      -24.8930     36.4179  \n  1971 1971  -9.3866     7.3095      -38.1364     19.3631  \n  1971 1972 -13.8393     7.8472      -44.7039     17.0252  \n  1971 1973 -12.4602     8.8642      -47.3246     22.4042  \n  1971 1974   0.1729     5.4372      -21.2124     21.5582  \n  1971 1975  -8.8785     8.3259      -41.6259     23.8688  \n  1971 1976  -7.7923     6.2332      -32.3085     16.7239  \n  1971 1977  -6.3192     8.3983      -39.3512     26.7128  \n  1971 1978 -17.4985    10.6874      -59.5339     24.5368  \n  1971 1979 -16.1999     6.1053      -40.2130      7.8132  \n  1971 1980 -22.5395     5.5357      -44.3124     -0.7666 *\n  1971 1981 -12.5894     8.2590      -45.0736     19.8949  \n  1971 1982 -20.6385    11.4796      -65.7899     24.5128  \n  1971 1983 -11.0888     5.9947      -34.6671     12.4894  \n  1971 1984 -12.7478     6.5444      -38.4881     12.9925  \n  1971 1985  -9.3683     8.4171      -42.4742     23.7377  \n  1971 1986 -16.9260     7.4075      -46.0609     12.2089  \n  1971 1987 -12.9962    11.6584      -58.8510     32.8586  \n  1971 1988 -14.6487     8.8020      -49.2688     19.9713  \n  1971 1989 -18.7126     9.8454      -57.4363     20.0112  \n  1971 1990 -17.6198     7.2596      -46.1732     10.9336  \n  1971 1991 -17.2789     9.5731      -54.9316     20.3739  \n  1971 1992 -22.1825    10.3351      -62.8324     18.4675  \n  1971 1993  -9.1278     9.7369      -47.4249     29.1693  \n  1971 1994 -13.7091     8.9343      -48.8493     21.4311  \n  1971 1995 -15.3270     7.4825      -44.7570     14.1029  \n  1971 1996 -11.2124    10.0316      -50.6685     28.2437  \n  1972 1965   3.3603     2.3466       -5.8694     12.5899  \n  1972 1966  -5.2709    11.1945      -49.3008     38.7591  \n  1972 1967   8.3599     8.8504      -26.4504     43.1702  \n  1972 1968   5.3444     7.5268      -24.2597     34.9485  \n  1972 1969  -6.1540     5.3509      -27.2001     14.8921  \n  1972 1970   5.3754     6.1409      -18.7780     29.5289  \n  1972 1971  -0.7708     5.9095      -24.0138     22.4722  \n  1972 1972  -5.3078     4.9781      -24.8874     14.2718  \n  1972 1973  -7.1261     9.0891      -42.8754     28.6231  \n  1972 1974  -4.3635     5.3193      -25.2853     16.5583  \n  1972 1975 -10.7104     6.8621      -37.7005     16.2796  \n  1972 1976  -8.5659     8.8089      -43.2130     26.0811  \n  1972 1977  -1.7264     4.3195      -18.7158     15.2630  \n  1972 1978 -19.5471     8.2612      -52.0401     12.9459  \n  1972 1979  -9.7870    10.3134      -50.3514     30.7774  \n  1972 1980 -16.4149     5.8059      -39.2506      6.4207  \n  1972 1981  -4.6831     5.0252      -24.4483     15.0821  \n  1972 1982  -9.8129     8.3907      -42.8151     23.1894  \n  1972 1983  -5.7570     6.9716      -33.1777     21.6637  \n  1972 1984 -11.1817     6.3013      -35.9659     13.6025  \n  1972 1985  -8.5492     8.0820      -40.3374     23.2389  \n  1972 1986  -3.2909     6.0279      -26.9998     20.4181  \n  1972 1987 -14.5853     7.6227      -44.5666     15.3960  \n  1972 1988 -12.6795     6.4902      -38.2066     12.8477  \n  1972 1989 -10.9845     6.4610      -36.3966     14.4277  \n  1972 1990  -7.7794     7.5706      -37.5558     21.9970  \n  1972 1991 -13.7033     5.3714      -34.8298      7.4233  \n  1972 1992 -11.0100     8.7457      -45.4084     23.3884  \n  1972 1993 -17.3770     7.3155      -46.1500     11.3960  \n  1972 1994 -16.6543     7.6975      -46.9302     13.6215  \n  1972 1995 -16.0626     6.6958      -42.3983     10.2730  \n  1972 1996 -13.6292     5.2614      -34.3234      7.0651  \n  1973 1965   0.3154     3.5419      -13.6154     14.2462  \n  1973 1966 -10.0893    10.2799      -50.5220     30.3433  \n  1973 1967  16.0570     8.8764      -18.8556     50.9697  \n  1973 1968  -4.8486     8.3368      -37.6388     27.9416  \n  1973 1969   3.3129     5.6644      -18.9664     25.5921  \n  1973 1970   5.5555     7.7076      -24.7598     35.8708  \n  1973 1971  -2.0683     7.8127      -32.7972     28.6606  \n  1973 1972  -0.9275     6.9534      -28.2764     26.4213  \n  1973 1973   4.4106     8.5855      -29.3580     38.1791  \n  1973 1974   3.2944     6.1061      -20.7222     27.3109  \n  1973 1975   0.0725    11.2892      -44.3298     44.4749  \n  1973 1976  -1.1180     6.6493      -27.2707     25.0348  \n  1973 1977   2.7203     5.8841      -20.4228     25.8634  \n  1973 1978 -10.3862     9.4844      -47.6902     26.9178  \n  1973 1979  -3.4722     7.3696      -32.4581     25.5137  \n  1973 1980 -11.7465     7.7891      -42.3827     18.8896  \n  1973 1981  -3.1322     7.5434      -32.8018     26.5373  \n  1973 1982  -7.8264    11.1179      -51.5550     35.9021  \n  1973 1983  -4.3281     6.3003      -29.1082     20.4521  \n  1973 1984 -10.3847     6.9307      -37.6444     16.8751  \n  1973 1985  -3.3503     7.3002      -32.0632     25.3625  \n  1973 1986  -9.9416     4.7131      -28.4790      8.5958  \n  1973 1987 -10.5611     9.2516      -46.9495     25.8273  \n  1973 1988 -13.3770    10.1765      -53.4029     26.6490  \n  1973 1989  -9.7072     7.5140      -39.2613     19.8469  \n  1973 1990 -12.5464     6.6770      -38.8085     13.7156  \n  1973 1991 -15.9396     7.9245      -47.1082     15.2290  \n  1973 1992 -17.9985     7.9156      -49.1318     13.1348  \n  1973 1993 -13.8426     8.6409      -47.8289     20.1437  \n  1973 1994  -9.0985     6.3839      -34.2074     16.0105  \n  1973 1995 -12.4104     3.9296      -27.8663      3.0455  \n  1973 1996 -14.4985     5.8760      -37.6100      8.6130  \n  1974 1965  -1.7117     5.6180      -23.8081     20.3848  \n  1974 1966  -3.7313    11.1044      -47.4072     39.9445  \n  1974 1967   9.6967     8.9202      -25.3881     44.7816  \n  1974 1968  -5.6736     7.7912      -36.3177     24.9705  \n  1974 1969   4.7497     5.3413      -16.2584     25.7579  \n  1974 1970   8.9528     5.9228      -14.3428     32.2483  \n  1974 1971  -8.1562     5.9562      -31.5832     15.2708  \n  1974 1972   5.1631     4.2098      -11.3947     21.7209  \n  1974 1973  -4.1358     7.8963      -35.1936     26.9219  \n  1974 1974  -1.5277     4.7412      -20.1759     17.1205  \n  1974 1975  -0.2490     5.1089      -20.3434     19.8454  \n  1974 1976  -4.6623     3.9210      -20.0842     10.7596  \n  1974 1977  -3.6545     7.4242      -32.8553     25.5464  \n  1974 1978  -9.4996     5.6012      -31.5302     12.5309  \n  1974 1979  -1.7953     9.8263      -40.4438     36.8532  \n  1974 1980 -10.9157     5.3148      -31.8196      9.9883  \n  1974 1981  -2.9438     7.6271      -32.9426     27.0551  \n  1974 1982  -6.1358     5.2653      -26.8454     14.5738  \n  1974 1983  -2.2347     7.8832      -33.2405     28.7712  \n  1974 1984  -7.2784     6.7759      -33.9293     19.3725  \n  1974 1985   0.9048    10.9520      -42.1713     43.9810  \n  1974 1986  -3.4953     8.7938      -38.0830     31.0924  \n  1974 1987  -9.3045     8.5199      -42.8149     24.2059  \n  1974 1988  -9.0434     8.7834      -43.5902     25.5033  \n  1974 1989  -6.4758    10.2036      -46.6086     33.6570  \n  1974 1990  -7.6369     8.7936      -42.2238     26.9500  \n  1974 1991 -14.7133     8.0070      -46.2065     16.7799  \n  1974 1992 -14.7711     8.1683      -46.8986     17.3565  \n  1974 1993 -11.2274     9.1163      -47.0837     24.6288  \n  1974 1994 -14.4350    11.1051      -58.1135     29.2435  \n  1974 1995 -13.4194     9.9518      -52.5618     25.7231  \n  1974 1996 -14.8017    10.5500      -56.2967     26.6933  \n  1975 1965  19.2544    14.4193      -37.4592     75.9681  \n  1975 1966 -10.7092     9.6959      -48.8451     27.4267  \n  1975 1967   9.6526     8.8040      -24.9752     44.2803  \n  1975 1968   5.2146     8.1132      -26.6961     37.1254  \n  1975 1969  -2.1343     7.5082      -31.6656     27.3970  \n  1975 1970  -5.6035     9.5772      -43.2723     32.0654  \n  1975 1971   3.4917     9.4385      -33.6317     40.6150  \n  1975 1972 -15.0108     7.4261      -44.2192     14.1976  \n  1975 1973   9.7321     7.4305      -19.4935     38.9577  \n  1975 1974   0.5633     6.2650      -24.0779     25.2045  \n  1975 1975  -4.9361     7.2901      -33.6093     23.7371  \n  1975 1976  -1.1020     4.3675      -18.2802     16.0762  \n  1975 1977  -4.3766     8.9458      -39.5622     30.8089  \n  1975 1978  -8.3191     8.1539      -40.3897     23.7515  \n  1975 1979 -12.7262    14.7290      -70.6579     45.2056  \n  1975 1980 -12.3662     5.6861      -34.7308      9.9985  \n  1975 1981  -7.7023     6.2392      -32.2424     16.8377  \n  1975 1982  -9.7198     8.1205      -41.6591     22.2195  \n  1975 1983  -7.3926     5.9149      -30.6572     15.8720  \n  1975 1984   8.8507     5.6226      -13.2642     30.9655  \n  1975 1985  -5.6163     8.3174      -38.3301     27.0975  \n  1975 1986  -5.2183     5.1726      -25.5630     15.1263  \n  1975 1987  -0.8638     5.2844      -21.6483     19.9208  \n  1975 1988 -15.3668    11.9412      -62.3337     31.6001  \n  1975 1989  -5.4933     6.3673      -30.5370     19.5504  \n  1975 1990   8.5067     5.8913      -14.6648     31.6781  \n  1975 1991   0.7631     6.0860      -23.1742     24.7004  \n  1975 1992  -4.2255     6.3457      -29.1845     20.7335  \n  1975 1993   1.1200     2.5499       -8.9093     11.1493  \n  1975 1994  -8.3655     7.7875      -38.9953     22.2644  \n  1975 1995   1.8041     3.8506      -13.3412     16.9494  \n  1975 1996  -6.9207     5.8457      -29.9130     16.0716  \n  1976 1965  -9.2525     2.2650      -18.1613     -0.3438 *\n  1976 1966  -7.3839    10.1469      -47.2935     32.5257  \n  1976 1967   6.1953     8.7761      -28.3226     40.7133  \n  1976 1968  -3.4100     7.6537      -33.5135     26.6936  \n  1976 1969  -4.5734     5.3509      -25.6195     16.4726  \n  1976 1970  13.6356     5.7737       -9.0733     36.3445  \n  1976 1971   2.1590     5.5379      -19.6227     23.9407  \n  1976 1972  -1.4512     4.0247      -17.2810     14.3785  \n  1976 1973 -23.5440     6.8621      -50.5339      3.4459  \n  1976 1974  37.6970     4.2785       20.8687     54.5253 *\n  1976 1975  -5.8620     9.0069      -41.2878     29.5638  \n  1976 1976   7.3375     6.7834      -19.3427     34.0178  \n  1976 1977  35.4928     7.3478        6.5927     64.3928 *\n  1976 1978  -2.2158     3.3756      -15.4927     11.0611  \n  1976 1979   2.7599    11.1105      -40.9399     46.4597  \n  1976 1980 -10.1277     6.1553      -34.3376     14.0821  \n  1976 1981  -9.1249     7.6546      -39.2320     20.9822  \n  1976 1982  -9.7529     5.2585      -30.4357     10.9298  \n  1976 1983 -12.2793     9.8103      -50.8650     26.3063  \n  1976 1984 -20.1148     7.4221      -49.3072      9.0776  \n  1976 1985  -0.2053    16.2410      -64.0843     63.6737  \n  1976 1986 -27.7992     8.4682      -61.1061      5.5078  \n  1976 1987  -9.9985     4.4562      -27.5254      7.5285  \n  1976 1988 -22.8540     6.0525      -46.6598      0.9517  \n  1976 1989 -14.3020     6.6385      -40.4124     11.8084  \n  1976 1990 -16.7275     5.9040      -39.9490      6.4940  \n  1976 1991 -29.9838     5.5425      -51.7835     -8.1842 *\n  1976 1992 -35.9431     6.3141      -60.7776    -11.1085 *\n  1976 1993 -33.5630     6.7582      -60.1441     -6.9819 *\n  1976 1994 -19.1785    13.9477      -74.0376     35.6805  \n  1976 1995 -18.8943     9.7949      -57.4196     19.6310  \n  1976 1996 -20.0712     8.0000      -51.5365     11.3941  \n  1977 1965   7.9420    16.0486      -55.1800     71.0640  \n  1977 1966 -17.8103    12.2291      -65.9096     30.2890  \n  1977 1967  22.0500     9.0966      -13.7287     57.8287  \n  1977 1968 -12.0551    11.9722      -59.1438     35.0337  \n  1977 1969  11.3299    12.9816      -39.7289     62.3888  \n  1977 1970   7.9543     8.3567      -24.9143     40.8229  \n  1977 1971   0.9514     9.4714      -36.3015     38.2044  \n  1977 1972  -1.0798     9.8947      -39.9975     37.8379  \n  1977 1973  -2.0153     9.6612      -40.0145     35.9839  \n  1977 1974 -10.4409     6.1944      -34.8044     13.9226  \n  1977 1975  -2.6782     7.3530      -31.5988     26.2424  \n  1977 1976   7.5869    19.3117      -68.3697     83.5434  \n  1977 1977  -0.3083    20.7163      -81.7892     81.1727  \n  1977 1978 -18.5991    21.4894     -103.1207     65.9226  \n  1977 1979  -8.3001    28.5726     -120.6815    104.0813  \n  1977 1980 -13.4381    34.6908     -149.8834    123.0072  \n  1977 1981 -12.1467    24.5037     -108.5245     84.2310  \n  1977 1982 -17.4639    18.0748      -88.5555     53.6277  \n  1977 1983   6.1362    33.2051     -124.4656    136.7381  \n  1977 1984  -2.9191    27.5084     -111.1147    105.2765  \n  1977 1985 -14.8995    22.0204     -101.5096     71.7106  \n  1977 1986 -12.3230    15.3699      -72.7755     48.1296  \n  1977 1987 -23.6769    34.1401     -157.9562    110.6024  \n  1977 1988 -25.5547    22.8094     -115.2684     64.1590  \n  1977 1989  -9.2602    41.7259     -173.3757    154.8552  \n  1977 1990 -13.7369    45.9741     -194.5615    167.0877  \n  1977 1991 -25.9731    36.3233     -168.8395    116.8933  \n  1977 1992 -29.9220    24.6738     -126.9684     67.1244  \n  1977 1993 -14.9531    37.7255     -163.3344    133.4283  \n  1977 1994 -11.6033    49.7976     -207.4666    184.2599  \n  1977 1995 -29.0098    23.4604     -121.2837     63.2641  \n  1977 1996 -16.0590    29.2264     -131.0118     98.8938  \n  1980 1965  -3.1314     2.2650      -12.0401      5.7773  \n  1980 1966  -9.4644    10.1469      -49.3741     30.4452  \n  1980 1967  12.2092     8.7761      -22.3087     46.7271  \n  1980 1968   3.0528     7.6537      -27.0508     33.1563  \n  1980 1969  -3.6543     5.3509      -24.7004     17.3917  \n  1980 1970  12.7725     5.7737       -9.9364     35.4814  \n  1980 1971 -11.0126     5.5379      -32.7943     10.7691  \n  1980 1972   5.2094     4.0247      -10.6204     21.0391  \n  1980 1973  -8.0378     6.8621      -35.0277     18.9521  \n  1980 1974   2.0132     4.2785      -14.8151     18.8415  \n  1980 1975  -3.8913     9.0069      -39.3171     31.5344  \n  1980 1976   4.9514     6.7834      -21.7289     31.6316  \n  1980 1977  -1.8244     3.7163      -16.4411     12.7924  \n  1980 1978  -6.3410     7.7499      -36.8229     24.1410  \n  1980 1979   5.7875    11.5127      -39.4942     51.0692  \n  1980 1980 -12.0465     7.0875      -39.9230     15.8301  \n  1980 1981  -7.2766     3.4559      -20.8693      6.3161  \n  1980 1982  -7.7888    13.7039      -61.6887     46.1112  \n  1980 1983   3.8986     3.7649      -10.9094     18.7066  \n  1980 1984  -2.3172     6.3267      -27.2013     22.5668  \n  1980 1985   4.4467     5.1164      -15.6769     24.5703  \n  1980 1986  -9.5981     6.5701      -35.4396     16.2433  \n  1980 1987 -10.0537    11.3335      -54.6305     34.5231  \n  1980 1988 -10.9789     9.1300      -46.8887     24.9310  \n  1980 1989  -6.9527     6.3603      -31.9688     18.0635  \n  1980 1990  -5.3312     6.2450      -29.8938     19.2315  \n  1980 1991  -8.8820     8.2207      -41.2154     23.4513  \n  1980 1992 -12.0023     9.9672      -51.2050     27.2005  \n  1980 1993  -8.3192     7.5524      -38.0241     21.3858  \n  1980 1994 -12.5474     7.1011      -40.4775     15.3826  \n  1980 1995  -6.7308     8.7926      -41.3137     27.8521  \n  1980 1996  -9.1678     7.0565      -36.9225     18.5868  \n  1984 1965   3.7550     2.2650       -5.1537     12.6638  \n  1984 1966  -9.0520    10.1469      -48.9616     30.8576  \n  1984 1967  10.1591     8.7761      -24.3588     44.6771  \n  1984 1968  -3.1247     7.6537      -33.2283     26.9788  \n  1984 1969   4.0091     5.3509      -17.0369     25.0552  \n  1984 1970   4.9470     5.7737      -17.7618     27.6559  \n  1984 1971 -12.3840     5.5379      -34.1658      9.3977  \n  1984 1972   5.1482     4.0247      -10.6815     20.9780  \n  1984 1973  -6.4124     6.8621      -33.4022     20.5775  \n  1984 1974  -5.7358     4.2785      -22.5641     11.0925  \n  1984 1975  -4.0919     9.0069      -39.5176     31.3339  \n  1984 1976   8.7209     6.7834      -17.9593     35.4011  \n  1984 1977   2.6679     3.7163      -11.9489     17.2846  \n  1984 1978  -7.3955     7.7499      -37.8775     23.0864  \n  1984 1979   2.2253    11.5127      -43.0565     47.5070  \n  1984 1980  -8.3661     7.0875      -36.2426     19.5105  \n  1984 1981  10.0008     5.6947      -12.3976     32.3991  \n  1984 1982  -3.2324    10.2480      -43.5396     37.0748  \n  1984 1983  11.0979    10.4009      -29.8106     52.0063  \n  1984 1984  -1.6979     3.0237      -13.5905     10.1947  \n  1984 1985   4.0744     6.4308      -21.2189     29.3677  \n  1984 1986  -8.0341     2.9094      -19.4773      3.4092  \n  1984 1987 -10.4189     8.0305      -42.0042     21.1664  \n  1984 1988  -7.8277     5.8269      -30.7461     15.0907  \n  1984 1989  -9.2894     3.8762      -24.5352      5.9565  \n  1984 1990  -6.2529     2.9419      -17.8241      5.3182  \n  1984 1991 -10.1584     5.2819      -30.9332     10.6164  \n  1984 1992 -11.4694     6.6641      -37.6807     14.7418  \n  1984 1993  -9.2844     4.4284      -26.7022      8.1333  \n  1984 1994 -14.6630     5.2893      -35.4667      6.1408  \n  1984 1995 -12.5044     3.7261      -27.1598      2.1510  \n  1984 1996 -10.2449     3.2720      -23.1143      2.6246  \n  1985 1965  -2.7099     2.2650      -11.6186      6.1988  \n  1985 1966  29.3180    10.1469      -10.5916     69.2277  \n  1985 1967  -6.8558     8.7761      -41.3737     27.6621  \n  1985 1968  -5.9545     7.6537      -36.0581     24.1490  \n  1985 1969  12.1675     5.3509       -8.8785     33.2136  \n  1985 1970  12.3074     5.7737      -10.4015     35.0163  \n  1985 1971   4.9424     5.5379      -16.8393     26.7241  \n  1985 1972   5.1718     4.0247      -10.6579     21.0016  \n  1985 1973 -41.2443     6.8621      -68.2342    -14.2545 *\n  1985 1974   9.0064     4.2785       -7.8219     25.8348  \n  1985 1975  -9.1424     9.0069      -44.5681     26.2834  \n  1985 1976   2.8125     6.7834      -23.8677     29.4927  \n  1985 1977  -2.1400     3.7163      -16.7567     12.4768  \n  1985 1978   5.7781     7.7499      -24.7038     36.2601  \n  1985 1979  -3.8368    11.5127      -49.1185     41.4450  \n  1985 1980   1.5265     7.0875      -26.3500     29.4031  \n  1985 1981  -2.8105     5.6947      -25.2088     19.5878  \n  1985 1982  13.2242    10.2480      -27.0831     53.5314  \n  1985 1983  -5.5714    10.4009      -46.4799     35.3371  \n  1985 1984  -5.5493     3.0237      -17.4419      6.3433  \n  1985 1985  11.4728     8.5549      -22.1750     45.1206  \n  1985 1986  10.1715     3.4372       -3.3478     23.6908  \n  1985 1987  17.5291     5.0068       -2.1636     37.2218  \n  1985 1988  -9.6423     3.9206      -25.0627      5.7782  \n  1985 1989  19.8229     5.3527       -1.2303     40.8760  \n  1985 1990  26.2350     2.5434       16.2314     36.2385 *\n  1985 1991   6.2209     3.5620       -7.7891     20.2310  \n  1985 1992  18.3602     6.2606       -6.2638     42.9841  \n  1985 1993  23.0343     2.8585       11.7915     34.2771 *\n  1985 1994  15.2612     6.2622       -9.3691     39.8916  \n  1985 1995  15.4633     4.9242       -3.9044     34.8310  \n  1985 1996  26.5282     3.9405       11.0296     42.0269 *\n---\nSignif. codes: `*' confidence band does not cover 0\n\nControl Group:  Never Treated,  Anticipation Periods:  0\nEstimation Method:  Outcome Regression\n\nggdid(atts_nyt)\n\n\n\n\n[10 puntos] Reporte los resultados agregados obtenidos a partir del estimador Callaway & Sant’Anna (2021), usando una agregación dinámica que muestre los efectos promedio para cada periodo antes y después del tratamiento. Grafique los resultados.\nGraficamos:\n\nagg.es &lt;- aggte(atts_nyt,\n                type = \"dynamic\")\nsummary(agg.es)\n\n\nCall:\naggte(MP = atts_nyt, type = \"dynamic\")\n\nReference: Callaway, Brantly and Pedro H.C. Sant'Anna.  \"Difference-in-Differences with Multiple Time Periods.\" Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. &lt;https://doi.org/10.1016/j.jeconom.2020.12.001&gt;, &lt;https://arxiv.org/abs/1803.09015&gt; \n\n\nOverall summary of ATT's based on event-study/dynamic aggregation:  \n      ATT    Std. Error     [ 95%  Conf. Int.]  \n -11.1957        3.7505   -18.5465     -3.8448 *\n\n\nDynamic Effects:\n Event time Estimate Std. Error [95% Simult.  Conf. Band]  \n        -20  -2.7099     2.5607       -9.7316      4.3118  \n        -19  16.5365     9.8342      -10.4299     43.5030  \n        -18  -7.9539     1.7929      -12.8702     -3.0376 *\n        -17   2.1023     5.9979      -14.3445     18.5492  \n        -16   4.5214     5.7379      -11.2124     20.2552  \n        -15   4.3951     5.0594       -9.4783     18.2684  \n        -14   0.1417     4.7473      -12.8760     13.1594  \n        -13   1.6657     6.8160      -17.0244     20.3557  \n        -12  -1.5362     9.8503      -28.5466     25.4742  \n        -11  -9.1062     5.8890      -25.2545      7.0420  \n        -10  10.5744     5.9761       -5.8126     26.9613  \n         -9  -5.7346     3.9427      -16.5458      5.0766  \n         -8   2.3457     2.4518       -4.3773      9.0686  \n         -7  -1.6033     3.8162      -12.0678      8.8613  \n         -6   4.3835     3.2669       -4.5747     13.3416  \n         -5  -3.0193     3.3486      -12.2016      6.1630  \n         -4   4.8722     2.5824       -2.2089     11.9534  \n         -3  -0.3596     2.3817       -6.8905      6.1713  \n         -2   1.1409     2.4245       -5.5072      7.7891  \n         -1   1.9481     2.9949       -6.2641     10.1602  \n          0  -0.8065     2.5825       -7.8880      6.2751  \n          1  -2.7726     3.0722      -11.1969      5.6517  \n          2  -4.2845     4.1906      -15.7755      7.2065  \n          3  -3.9743     2.7938      -11.6352      3.6866  \n          4  -4.5620     3.4012      -13.8884      4.7645  \n          5  -7.4465     3.0625      -15.8442      0.9513  \n          6  -6.2541     3.6575      -16.2834      3.7752  \n          7 -10.6094     3.6823      -20.7065     -0.5123 *\n          8  -9.9746     3.7565      -20.2754      0.3262  \n          9 -10.1110     3.5969      -19.9740     -0.2479 *\n         10 -11.0023     4.0832      -22.1989      0.1942  \n         11 -12.2896     3.9761      -23.1924     -1.3868 *\n         12  -8.8234     4.4417      -21.0029      3.3562  \n         13 -12.1880     4.5561      -24.6811      0.3051  \n         14 -11.2760     4.6171      -23.9365      1.3845  \n         15 -14.8487     5.2839      -29.3377     -0.3596 *\n         16 -11.6965     4.7960      -24.8476      1.4547  \n         17 -14.3232     4.7327      -27.3007     -1.3456 *\n         18 -17.1010     5.0292      -30.8915     -3.3105 *\n         19 -17.4748     4.3357      -29.3638     -5.5858 *\n         20 -14.9783     4.5176      -27.3661     -2.5905 *\n         21 -15.8960     4.7739      -28.9866     -2.8054 *\n         22 -15.2219     4.2998      -27.0125     -3.4313 *\n         23 -16.2453     5.0785      -30.1710     -2.3195 *\n         24 -17.8714     7.5826      -38.6636      2.9208  \n         25 -17.0567     9.9576      -44.3613     10.2479  \n         26 -27.4244    19.3710      -80.5416     25.6929  \n         27   3.0338    13.1112      -32.9183     38.9859  \n---\nSignif. codes: `*' confidence band does not cover 0\n\nControl Group:  Never Treated,  Anticipation Periods:  0\nEstimation Method:  Outcome Regression\n\nggdid(agg.es)\n\n\n\n\n[5 puntos] ¿Cuáles son las ventajas del estimador de Callaway & Sant’Anna (2021) respecto al estimador de TWFE?\nLas ventajas del estimador de Callaway & Sant’Anna respecto a TWFE son las siguientes: - Evita las comapraciones prohibidas (usar unidades tratadas como controles para unidades que son tratadas en periodos posteriores) - Hace explícito el grupo de comparación que se usa para comparar a las unidades tratadas - Hace explícita la manera en que se agregan los resultados de cada comparación \\(ATT(g,t)\\) - No impone efectos monótonos en el tiempo ni homogéneos entre unidades"
  },
  {
    "objectID": "tareas/tarea-3-respuestas.html#pregunta-2",
    "href": "tareas/tarea-3-respuestas.html#pregunta-2",
    "title": "Respuestas a la tarea 3",
    "section": "Pregunta 2",
    "text": "Pregunta 2\nLa ENIGH 2020 incluyó un módulo para la evaluación del Programa Jóvenes Construyendo el futuro. Se buscó que la cobertura de la encuesta pudiera incluir suficientes participantes del programa para poder compararlos con los no participantes. Los datos en datos_jcf_analisis.csv fueron construidos a partir de dicha encuesta. En este ejercicio estimaremos el efecto de participar en el programa sobre el ingreso trimestral, ingtot_tri, usando métodos de matching.\nLas siguientes variables están incluidas en el archivo de datos: mujer (dummy de sexo), indigena (dummy de pertenencia a una etnia), rural (dummy del ámbito rural), escoacum (años de escolaridad), casadounion (dummy para casados o en unión libre), jefehog (dummy para jefes del hogar), haymenores (dummy para la presencia de menores de edad en el hogar), proggob (dummy para beneficiarios de programas de gobierno), y tot_integ (número de miembros del hogar). También se incluye la clave de las entidades, cve_ent.\n\n[5 puntos] Considere la comparación para el ingreso trimestral, ingtot_tri, entre beneficiarios y su grupo de comparación, que serán los jóvenes que no asisten a la escuela y no están empleados. Los beneficiarios tienen jcf2==1 y los jóvenes que no asisten a la escuela y no están empleados tienen jcf2==0. Muestre qué tan similares o qué tan diferentes son los individuos en ambos grupos en términos de las características indicadas anteriormente y del ingreso trimestral.\nEstadística descriptiva:\n\ndata.jcf &lt;- read_csv(\"C:/Users/rojas/Dropbox/Evaluación de Programas Sociales/2023/tareas/datos_jcf_analisis.csv\")\n\nset.seed(1023)\n\nAquí usé datasummary para calcular la estadística descriptiva por grupos:\n\ndatasummary(ingtot_tri + mujer + indigena + rural + escoacum + casadounion + jefehog + haymenores + proggob + tot_integ ~ factor(jcf2) * (mean + sd) * Arguments(na.rm=TRUE),\n                fmt = \"%.2f\",\n                data = data.jcf)\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n\n\n1\n\n\n\n\nmean\nsd\nmean\nsd\n\n\n\n\ningtot_tri\n1510.36\n8478.60\n9643.06\n6632.56\n\n\nmujer\n0.76\n0.43\n0.59\n0.49\n\n\nindigena\n0.22\n0.41\n0.59\n0.49\n\n\nrural\n0.40\n0.49\n0.35\n0.48\n\n\nescoacum\n10.39\n3.23\n12.03\n2.70\n\n\ncasadounion\n0.53\n0.50\n0.41\n0.49\n\n\njefehog\n0.06\n0.23\n0.14\n0.35\n\n\nhaymenores\n0.66\n0.47\n0.54\n0.50\n\n\nproggob\n0.19\n0.39\n0.21\n0.41\n\n\ntot_integ\n4.82\n1.97\n4.25\n2.00\n\n\n\n\n\n\n\nClaramente los individuos que participan en el programa son diferentes a los que no. En el programa hay una proporción menor de mujeres que en el grupo no tratado; en el grupo tratado hay un nivel mayor de escolaridad acumulada; y los individuos del grupo tratado viven en hogares más pequeños que los del grupo no tratado. Entre muchas otras diferencias.\nEl problema entonces es que existen factores que influyen en la probabilidad de recibir el tratamiento y en el ingreso, por lo que una comparación simple de individuos tratados y no tratados confundirá el efecto del tratamiento.\n[5 puntos] Estime el TOT (TT o ATT) del programa en el ingreso trimestral, ingtot_tri usando el algoritmo de vecino más cercano. Para estimar el impacto en el ingreso trimestral se comparan a los beneficiarios de JCF con los jóvenes que no asisten a la escuela y no están empleados. Los beneficiarios tienen jcf2==1 y los jóvenes que no asisten a la escuela y no están empleados tienen jcf2==0. Escoja la especificación del propensity score que más le parezca adecuada. Realice la inferencia estadística con errores agrupados a nivel grupo de emparejamiento. ¿De qué tamaño es el TOT estimado y es este efecto estadísticamente significativo?\nEste es el modelo para el propensity score que yo escogí:\n\nsub.data &lt;- data.jcf %&gt;%\ndplyr::select(ingtot_tri, jcf2, mujer, indigena, cve_ent, rural, escoacum, casadounion,\n    jefehog, haymenores, proggob, tot_integ, factor.x)\n\nsub.data &lt;- sub.data[complete.cases(sub.data), ]\n\n\nm.out.a &lt;- matchit(formula=jcf2 ~ mujer + indigena + factor(cve_ent) + rural  + escoacum + casadounion + jefehog + haymenores + proggob + tot_integ,\n                 method = \"nearest\",\n                 distance= \"glm\",\n                 replace = FALSE,\n                 data = sub.data)\n\nEstimamos el efecto del tratamiento:\n\ntt1 &lt;- lm(ingtot_tri ~ jcf2,\n      data = match.data(m.out.a))\n\n#Errores agrupados a nivel subclass\ncoeftest(tt1,\n         vcov. = vcovCL,\n         cluster = ~subclass)\n\n\nt test of coefficients:\n\n            Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  1669.95     407.99  4.0931 5.735e-05 ***\njcf2         7973.11     708.27 11.2572 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSe estima un efecto de 7973 pesos adicionales de ingreso trimestral para los participantes en el programa.\n[5 puntos] En el matching de la parte b., evalúe qué tan bueno es el procedimiento en balancear las características observadas una vez realizado el matching. Cree un love plot para evaluar qué tan bueno es el procedimiento de matching para obtener una muestra balanceada.\nbal.tab del paquete cobalt nos permite ver un resumen del balance:\n\n#Con esto elimino las dummies de estado de la salida\nbal.tab(m.out.a, m.threshold=0.1, un=T)\n\nBalance Measures\n                       Type Diff.Un Diff.Adj        M.Threshold\ndistance           Distance  1.1091   0.0881     Balanced, &lt;0.1\nmujer                Binary -0.1660   0.0551     Balanced, &lt;0.1\nindigena             Binary  0.3714   0.0551     Balanced, &lt;0.1\nfactor(cve_ent)_01   Binary -0.1720  -0.0157     Balanced, &lt;0.1\nfactor(cve_ent)_02   Binary -0.3428  -0.0079     Balanced, &lt;0.1\nfactor(cve_ent)_03   Binary  0.0168   0.0079     Balanced, &lt;0.1\nfactor(cve_ent)_04   Binary  0.5524   0.0157     Balanced, &lt;0.1\nfactor(cve_ent)_05   Binary -0.0544   0.0000     Balanced, &lt;0.1\nrural                Binary -0.0553   0.0709     Balanced, &lt;0.1\nescoacum            Contin.  0.6086  -0.2096 Not Balanced, &gt;0.1\ncasadounion          Binary -0.1170   0.0709     Balanced, &lt;0.1\njefehog              Binary  0.0831   0.0551     Balanced, &lt;0.1\nhaymenores           Binary -0.1193   0.0787     Balanced, &lt;0.1\nproggob              Binary  0.0220   0.0079     Balanced, &lt;0.1\ntot_integ           Contin. -0.2856   0.0158     Balanced, &lt;0.1\n\nBalance tally for mean differences\n                   count\nBalanced, &lt;0.1        14\nNot Balanced, &gt;0.1     1\n\nVariable with the greatest mean difference\n Variable Diff.Adj        M.Threshold\n escoacum  -0.2096 Not Balanced, &gt;0.1\n\nSample sizes\n          Control Treated\nAll          1894     127\nMatched       127     127\nUnmatched    1767       0\n\n\nY finalmente el loveplot:\n\nm.out.a[[\"X\"]][[\"factor(cve_ent)\"]] &lt;- NULL\n\nlove.plot(bal.tab(m.out.a),\n      threshold = .1)\n\n\n\n\nParece haber un buen balance, aunque la educación es la única variable que no queda bien balanceada. Después del emparejamiento, las medias (estandarizadas) entre tratados y no tratados difieren en más de 0.1.\n[5 puntos] Estime ahora el TOT en el ingreso trimestral, como en la parte b., pero usando un caliper de 0.1 y 3 vecinos a ser emparejados. ¿Cómo cambian sus resultados respecto a los de la parte b.?\n\nsub.data &lt;- data.jcf %&gt;% \n  dplyr::select(ingtot_tri, jcf2, mujer, indigena, cve_ent, rural, escoacum, \n           casadounion, jefehog, haymenores, proggob, tot_integ, factor.x)\n\nsub.data &lt;- sub.data[complete.cases(sub.data), ] \n\nm.out.c &lt;- matchit(formula=jcf2 ~ mujer + indigena + factor(cve_ent) + rural  + escoacum + casadounion + jefehog + haymenores + proggob + tot_integ,\n                 method = \"nearest\",\n                 distance= \"glm\",\n                 ratio = 3,\n                 caliper = 0.1,\n                 replace = FALSE,\n                 data = sub.data)\n\nEstimamos el efecto del tratamiento:\n\ntt3 &lt;- lm(ingtot_tri ~ jcf2,\n      data = match.data(m.out.c))\n\n#Errores agrupados a nivel subclass\ncoeftest(tt3,\n         vcov. = vcovCL,\n         cluster = ~subclass)\n\n\nt test of coefficients:\n\n            Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  2261.79     438.85   5.154 4.016e-07 ***\njcf2         7302.34     717.02  10.184 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSe estima ahora un efecto de 7258 pesos, menor al efecto de 7973 pesos estimado en la parte b."
  },
  {
    "objectID": "tareas/tarea-3-respuestas.html#footnotes",
    "href": "tareas/tarea-3-respuestas.html#footnotes",
    "title": "Respuestas a la tarea 3",
    "section": "Notas",
    "text": "Notas\n\n\nStevenson, B. & Wolfers, J. (2006). Bargaining in the Shadow of the Law: Divorce Laws and Family Distress. The Quarterly Journal of Economics, 121(1), 267-288.↩︎"
  },
  {
    "objectID": "tareas/tarea-4.html",
    "href": "tareas/tarea-4.html",
    "title": "Tarea 4",
    "section": "",
    "text": "Fecha de entrega: 4 de diciembre a las 20:00\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los leguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-4.html#pregunta-1",
    "href": "tareas/tarea-4.html#pregunta-1",
    "title": "Tarea 4",
    "section": "Pregunta 1",
    "text": "Pregunta 1\nLos datos del archivo salud_peru.csv contienen información de una encuesta en hogares realizada en Perú. Un programa del gobierno otorgó un seguro de salud para cubrir a hogares de trabajadores informales y pobres, típicamente excluidos de los servicios de salud. Para ello, se uso un índice de ingreso (IFH), expresado en soles, para determinar la elegibilidad. Aquellos hogares con un IFH menor o igual a 55 soles son considerados pobres. Se desea estimar el efecto del programa en la probabilidad de recibir algún tipo de anteción médica, curative, y sobre la probabilidad de recibir algún tipo de asistencia médica en un hospital o con un doctor, hospinter. La columna ifh contiene el indicador del ingreso.\n\n[10 puntos] Genere una gráfica donde muestre evidencia de una discontinuidad en la variable curative para aquellos hogares que recibieron los beneficios del programa. Debe usar solo a los trabajadores informales, formal==0. Primero, realice la gráfica con una ventana de 100 soles a la izquierda y 100 soles a la derecha del corte de elegibilidad y en la que cada punto represente la media de la variable curative en bins de 5 soles. Agregue una línea de regresión lineal para cada lado del corte de elegibilidad.\n[5 puntos] Genere el mismo gráfico que en la parte a., pero ahora con una ventana de 25 soles a cada lado de la discontinuidad.\n[5 puntos] Genere el mismo gráfico que en la parte a., pero calcule la media de la variable curative en bins de 10 soles.\n[5 puntos] Ahora use rdplot del paquete rdrobust para construir el mismo gráfico.\n[10 puntos] Estime la versión más básica de un modelo de regresión discontinua para el efecto del programa sobre hospinter. Reporte el coeficiente estimado del efecto del tratamiento y su significancia estadística. Use una ventana de 20 soles en el IFH antes y después del corte de elegibilidad. Interprete sus resultados.\n[5 puntos] Estime la misma especificación que en la parte d., pero ahora con una ventana de 10 soles en el IFH. Interprete sus resultados.\n[5 puntos] Regrese a una ventana de 20 soles como en la parte d., pero ahora permita un coeficiente distinto para el IFH antes y después del corte, y un polinomio de orden 2 para la variable de asignación. Interprete sus resultados.\n[5 puntos] Use rdrobust para estimar el efecto usando un polinomio de orden 2 y una regresión local no paramétrica. Use algún selector de ancho de banda óptimo."
  },
  {
    "objectID": "tareas/tarea-4.html#pregunta-2",
    "href": "tareas/tarea-4.html#pregunta-2",
    "title": "Tarea 4",
    "section": "Pregunta 2",
    "text": "Pregunta 2\nEl archivo basque.csv contiene los datos empleados por Abadie y Gardeazabal (2003) para estimar el efecto del terrorismo en el PIB per cápita (gdpcap) en el País Vasco usando el método de control sintético. Los autores consideran como periodo pre intervención a 1955 - 1969.\n\n[10 puntos] Estime el control sintético del PIB per cápita del País Vasco usando como grupo donador al resto de las regiones de España. Esto es, encuentre la matriz \\(W\\) que otorga pesos a las distintas regiones usando una serie de predictores observables. Para este propósito, use como predictores el promedio de las siguientes variables para el periodo 1964-1969:\n\nLa inversión como porcentaje del PIB, invest\nEl porcentaje de la población analfabeta, school.illit\nEl porcentaje de la población con educación primaria, school.prim\nEl porcentaje de la población con educación media, school.med\nEl porcentaje de la población con educación superior, school.high\nEl porcentaje de la población con educación más que superior, school.post.high\n\nAdemás, use como predictores especiales los siguientes valores:\n\nEl promedio del PIB per capita, gdpcap, de 1960 a 1969\nLa densidad de población, popdens, de 1969\nEl promedio de la participación de la agricultura, sec.agriculture, de 1961 a 1969\nEl promedio de la participación de la energía, sec.energy, de 1961 a 1969\nEl promedio de la participación de la industria, sec.industry, de 1961 a 1969\nEl promedio de la participación de la construcción, sec.construction, de 1961 a 1969\nEl promedio de la participación de los servicios, sec.services.venta, de 1961 a 1969\nEl promedio de la participación de los servicios no comerciables, sec.services.nonventa, de 1961 a 1969\n\nNote que el País Vasco está identificado con el número 17 de la variable regionno. Realice el procedimiento de optimización para minimizar las discrepancias entre la unidad tratada y su sintético usando el periodo 1960-1969.\n¿Qué regiones y con qué pesos contribuyen a construir el País Vasco sintético?\n[5 puntos] Obtenga un gráfico en donde represente las series de tiempo del PIB per cápita del País Vasco que efectivamente se realizó, la de su correspondiente control sintético y la del promedio simple del resto de las regiones españolas.\n[5 puntos] Genere una gráfica de brecha que muestre el efecto del terrorismo sobre el PIB per cápita. La brecha es la diferencia entre la serie de tiempo realizada y su contraparte sintética.\n[10 puntos] Ahora verificará la robustez de los resultados de este trabajo a la elección de los predictores que entran en las matrices \\(X_1\\) y \\(X_0\\) estudiadas en clase. Primero, obtenga de nuevo el control sintético, esta vez eliminando todos los predictores especiales. Construya la correspondiente gráfica de brecha y sobrepóngala con la gráfica de brecha que se obtiene con la especificación de la parte a.\n[10 puntos] Regrese a la especificación original de la parte a. y ahora estime el control sintético empleando solamente predictores especiales. Construya la correspondiente gráfica de brecha y sobrepóngala con las gráficas de brechas que se obtiene con la especificación de la parte a. y de la parte d.\n[10 puntos] Finalmente, regrese a la especificación original de la parte a., pero ahora conserve en los predictores especiales solo al PIB per cápita (gdpcap), además de la lista de predictores convencionales usadas en la especificación original. Construya la correspondiente gráfica de brecha y sobrepóngala con las gráficas de brechas que se obtiene con la especificación de las partes a., d. y e."
  }
]