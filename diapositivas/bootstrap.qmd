---
format:
  revealjs:
    title-slide-attributes:
      data-background-color: "#00573F"
      data-background-transition: "fade"
      class: portada
    slide-number: c/t
    width: 1600
    height: 900
    scrollable: false
    theme: [default, "./cide.scss"]
    logo: https://d1yjjnpx0p53s8.cloudfront.net/styles/logo-thumbnail/s3/122010/logo_cide_verde.png?itok=NUstTkpt
    title-slide: false
    includes:
      in-header:
        - fontawesome.html
---



# Bootstrap {.portada}

<div style="text-align: center; font-size: 1.2em; font-weight: bold;">
  Inferencia Causal
</div>

<div style="text-align: center; margin-top: 1em;">
  <strong>Irvin Rojas</strong>  
  <br>
  <a href="https://rojasirvin.com" style="color: #ffffff;">rojasirvin.com</a>
</div>


<div style="text-align: center; margin-top: 1em;">
  <a href="https://github.com/rojasirvin" target="_blank" style="margin-right: 0 10px;">
    {{< bi github >}}
  </a>
  <a href="https://twitter.com/RojasIrvin" target="_blank" style="margin-right: 0 10px;">
    {{< bi twitter >}}
  </a>
  <a href="https://scholar.google.com/citations?user=FUwdSTMAAAAJ&hl=en" style="margin: 0 10px;">
    {{< bi google >}}
  </a>
</div>

**Centro de Investigación y Docencia Económicas**
División de Economía

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.path = "figures/")

library(tidyverse)
library(janitor)
library(sandwich)
library(clubSandwich)
library(modelsummary)

xfun::pkg_load2(c('base64enc', 'htmltools', 'mime'))
```

```{css, echo = FALSE}
.huge .remark-code { /*Change made here*/
  font-size: 200% !important;
}
.tiny .remark-code { /*Change made here*/
  font-size: 60% !important;
}
```



# Bootstrap {.inverse .center .middle}


## Introducción a bootstrap

- A veces es difícil encontrar una expresión analítica de los errores estándar

- La idea de las técnicas bootstrap es consutrir una distribución empírica del estimador de interés

- Una muestra bootstrap es una muestra tomada de los mismos datos


- En las rutinas para errores bootstrap, pensamos en $\{(y_1,x_1),\ldots,(y_N,X_n)\}$ como la población

- Una muestra bootstrap es una muestra de tamaño $N$ tomada de la muestra original


- El procedimiento bootstrap más usado es el bootstrap no paramétrico o boostrap en parejas (nos enfocaremos en este tipo de bootstrap en el curso)

- La idea es remuestrear la pareja completa $(y_i,x_i)$

## Algoritmo para errores estándar bootstrap

1. Dada una muestra $W_1,\ldots,W_N$, obtener una muestra de tamaño $N$, remuestreando de la muestra original **con reemplazo**

1. Calcular el estadístico $\hat{\theta}_b$ usado con la muestra bootstrap (coeficiente de regresión, diferencia de medias, función de coeficientes)

1. Repetir los pasos 1 y 2 $B$ veces, donde $B$ es lo suficientemente grande (usualmente 1000 es suficiente)

1. Usar las $B$ repeticiones para obtener el error estándar del estadístico como la raíz cuadrada de $s^2_{\hat{\theta},B}$:

$$s^2_{\hat{\theta},B}=\frac{1}{B-1}\sum_{b=1}^B(\hat{\theta}_{b}-\bar{\hat{\theta}})^2$$
donde $\bar{\hat{\theta}}=\frac{1}{B}\sum_{b=1}^B\hat{\theta}_b$


## ¿Cómo hacer remuestreo en R?

```{r}
#| echo: true

set.seed(927)

data.morocco<- read.csv("./crepon_morocco_analysis.csv")%>%
  select(treatment,client,expense_total )

obs <- nrow(data.morocco)
obs

#En la muestra original
mean(data.morocco$expense_total)
```


## ¿Cómo hacer remuestreo en R?

```{r}
#| echo: true

#Una muestra bootstrap
data.b <-data.morocco[sample(nrow(data.morocco),obs, replace = TRUE),]

mean(data.b$expense_total)

#Otra muestra bootstrap
data.b <-data.morocco[sample(nrow(data.morocco),obs, replace = TRUE),]

mean(data.b$expense_total)
```





## Aplicaciones comunes de bootstrap

- Métodos de varias etapas (por ejemplo, el estimador de dos etapas de Heckman)

- Funciones de estimadores (aunque aquí el método Delta también podría ser usado)

- Datos agrupados con pocos grupos (remuestrear grupos en vez de individuos)

- El consejo práctico es usar resultados teóricos cuando se puede (por ejemplo, las matrices robustas descritas antes)

- Pensemos siempre en la estructura de los datos antes de hacer boostrap

- Usar una semilla siempre para poder reproducir sus resultados



## Bootstrap salvaje

- En presencia de heterocedasticidad se prefiere usar bootstrap salvaje (*wild bootstrap*) ([MacKinnon, 2012](https://link.springer.com/chapter/10.1007%2F978-1-4614-1653-1_17#enumeration))

- Propuesto originalmente por Liu (1988), cada muestra bootstrap tiene la siguiente forma:

$$y_i^*=X_i\hat{\beta}+f(\hat{u}_i)v_i^*$$
- Noten que mantiene fijos los $X_i$ en cada muestra bootstrap


- Una especificación comúnmente usada es hacer es $f(\hat{u}_i)=\hat{u}_i$ y 
$$v_i^*=\begin{cases} 1 \quad\text{con probabilidad 0.5} \\ -1 \quad\text{con probabilidad 0.5} \end{cases}$$

- $\hat{\beta}$ y $\hat{u}_i$ son estimados con la muestra original

## Bootstrap salvaje

- En cada una de las $B$ muestras bootstrap, mantenemos a los mismos individuos (no hay remuestreo)

- Tendremos $B$ muestras bootstrap, pero ahora la aleatoriedad viene por $f(\hat{u}_i)v_i^*$

- Pueden usarse otras funciones más complicadas para $f(\hat{u}_i)$

- La ventaja de este método es que conserva la relación entre las varianzas residuales y las $X_i$ observadas en los datos originales

- [Davidson & Flachaire (2008)](https://www.sciencedirect.com/science/article/pii/S0304407608000833) utilizan simulaciones para mostrar que con esta forma para $f(\hat{u}_i)v_i^*$ la inferencia es más confiable que con otras especificaciones



## Refinamiento asintótico

- Una aplicación de las técnicas bootstrap es el *refinamiento asintótico* de la prueba $t$ de coeficientes de regresión

- Supongamos que $H_0:\quad \beta=0$ y trabajamos con un nivel $\alpha$ 

- En cada repetición bootstrap el estadístico calculado es $t_b$

- Ordenamos los $B$ estadísticos obtenidos

- Rechazamos $H_0$ si $|t|$ está por encima del $(1-\alpha)$ésimo percentil de los $|t_b|$ en la distribución bootstrap

- A pesar de sus propiedades teóricas, el refinamiento asintótico es poco usado


## Jacknife

- Formalmente no es un método bootstrap

- Una muestra jacknife es una muestra de tamaño $N-1$ construida a partir de la muestra original donde una observación es eliminada a la vez

- En cada muestra jacknife estimamos el estadístico de interés $\hat{\theta}_{(j)}$ (tendremos $N$ estadísticos)

- El error estándar jacknife será

$$\hat{se}(\hat{\theta})=\left(\frac{N-1}{N}\sum_{j=1}^N\left(\hat{\theta}_{(j)}-\hat{\theta}\right)^2\right)^{1/2}$$

- Funciona bien para *estadísticas suaves* y funciones lineales

- Se puede hacer jacknife por bloques [(Cameron y Miller, 2015)](http://jhr.uwpress.org/content/50/2/317.short?casa_token=LU3qZABduyQAAAAA:ULxVXC96LBZLgeri-TafnH4u4KH-N_FxSQ0Cx2gAED5k1yXSvCs1IgLo4sR-4zyM-Pq8yko57aL8)


#  {.inverse .center .middle}

Material de clase en versión preliminar.

**No reproducir, no distribuir, no citar.**


